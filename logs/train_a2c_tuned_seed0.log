wandb: Currently logged in as: lee_changmin (lee_changmin-sangmyung-uni) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run 8w4npn8j
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in /home/cia/disk1/bci_intern/AAAI2026/RLDoom/logs/wandb/wandb/run-20251206_211410-8w4npn8j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run a2c_tuned_seed0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lee_changmin-sangmyung-uni/RLDoom
wandb: üöÄ View run at https://wandb.ai/lee_changmin-sangmyung-uni/RLDoom/runs/8w4npn8j
pci id for fd 8: 1a03:2000, driver (null)
MESA-LOADER: failed to open ast: /usr/lib/dri/ast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)
pci id for fd 9: 1a03:2000, driver (null)
kmsro: driver missing
a2c_tuned train:   0%|          | 0/3000 [00:00<?, ?it/s]a2c_tuned train:   0%|          | 1/3000 [00:01<1:29:33,  1.79s/it]a2c_tuned train:   0%|          | 2/3000 [00:03<1:17:50,  1.56s/it]a2c_tuned train:   0%|          | 3/3000 [00:04<1:15:24,  1.51s/it]a2c_tuned train:   0%|          | 4/3000 [00:05<1:10:41,  1.42s/it]a2c_tuned train:   0%|          | 5/3000 [00:07<1:19:25,  1.59s/it]a2c_tuned train:   0%|          | 6/3000 [00:09<1:15:37,  1.52s/it]a2c_tuned train:   0%|          | 7/3000 [00:11<1:22:21,  1.65s/it]a2c_tuned train:   0%|          | 8/3000 [00:13<1:32:12,  1.85s/it]a2c_tuned train:   0%|          | 9/3000 [00:14<1:24:19,  1.69s/it]a2c_tuned train:   0%|          | 10/3000 [00:15<1:17:07,  1.55s/it]a2c_tuned train:   0%|          | 11/3000 [00:17<1:14:16,  1.49s/it]a2c_tuned train:   0%|          | 12/3000 [00:18<1:13:21,  1.47s/it]a2c_tuned train:   0%|          | 13/3000 [00:20<1:23:48,  1.68s/it]a2c_tuned train:   0%|          | 14/3000 [00:22<1:25:53,  1.73s/it]a2c_tuned train:   0%|          | 15/3000 [00:23<1:13:25,  1.48s/it]a2c_tuned train:   1%|          | 16/3000 [00:25<1:12:14,  1.45s/it]a2c_tuned train:   1%|          | 17/3000 [00:26<1:10:35,  1.42s/it]a2c_tuned train:   1%|          | 18/3000 [00:27<1:01:57,  1.25s/it]a2c_tuned train:   1%|          | 19/3000 [00:29<1:10:07,  1.41s/it]a2c_tuned train:   1%|          | 20/3000 [00:32<1:38:07,  1.98s/it]a2c_tuned train:   1%|          | 21/3000 [00:33<1:29:41,  1.81s/it]a2c_tuned train:   1%|          | 22/3000 [00:34<1:21:33,  1.64s/it]a2c_tuned train:   1%|          | 23/3000 [00:36<1:18:29,  1.58s/it]a2c_tuned train:   1%|          | 24/3000 [00:37<1:15:56,  1.53s/it]a2c_tuned train:   1%|          | 25/3000 [00:39<1:22:36,  1.67s/it]a2c_tuned train:   1%|          | 26/3000 [00:41<1:24:42,  1.71s/it]a2c_tuned train:   1%|          | 27/3000 [00:43<1:26:55,  1.75s/it]a2c_tuned train:   1%|          | 28/3000 [00:44<1:13:07,  1.48s/it]a2c_tuned train:   1%|          | 29/3000 [00:45<1:04:02,  1.29s/it]a2c_tuned train:   1%|          | 30/3000 [00:48<1:28:58,  1.80s/it]a2c_tuned train:   1%|          | 31/3000 [00:48<1:14:36,  1.51s/it]a2c_tuned train:   1%|          | 32/3000 [00:50<1:12:12,  1.46s/it]a2c_tuned train:   1%|          | 33/3000 [00:52<1:18:37,  1.59s/it]a2c_tuned train:   1%|          | 34/3000 [00:53<1:15:09,  1.52s/it]a2c_tuned train:   1%|          | 35/3000 [00:54<1:05:16,  1.32s/it]a2c_tuned train:   1%|          | 36/3000 [00:56<1:15:22,  1.53s/it]a2c_tuned train:   1%|          | 37/3000 [00:58<1:22:41,  1.67s/it]a2c_tuned train:   1%|‚ñè         | 38/3000 [01:00<1:26:01,  1.74s/it]a2c_tuned train:   1%|‚ñè         | 39/3000 [01:02<1:36:37,  1.96s/it]a2c_tuned train:   1%|‚ñè         | 40/3000 [01:04<1:27:57,  1.78s/it]a2c_tuned train:   1%|‚ñè         | 41/3000 [01:06<1:29:15,  1.81s/it]a2c_tuned train:   1%|‚ñè         | 42/3000 [01:10<2:02:38,  2.49s/it]a2c_tuned train:   1%|‚ñè         | 43/3000 [01:11<1:46:30,  2.16s/it]a2c_tuned train:   1%|‚ñè         | 44/3000 [01:12<1:26:48,  1.76s/it]a2c_tuned train:   2%|‚ñè         | 45/3000 [01:13<1:19:19,  1.61s/it]a2c_tuned train:   2%|‚ñè         | 46/3000 [01:14<1:07:00,  1.36s/it]a2c_tuned train:   2%|‚ñè         | 47/3000 [01:15<1:07:08,  1.36s/it]a2c_tuned train:   2%|‚ñè         | 48/3000 [01:17<1:05:15,  1.33s/it]a2c_tuned train:   2%|‚ñè         | 49/3000 [01:18<1:05:31,  1.33s/it]a2c_tuned train:   2%|‚ñè         | 50/3000 [01:20<1:20:31,  1.64s/it]a2c_tuned train:   2%|‚ñè         | 51/3000 [01:21<1:08:42,  1.40s/it]a2c_tuned train:   2%|‚ñè         | 52/3000 [01:22<1:08:09,  1.39s/it]a2c_tuned train:   2%|‚ñè         | 53/3000 [01:25<1:28:59,  1.81s/it]a2c_tuned train:   2%|‚ñè         | 54/3000 [01:28<1:39:32,  2.03s/it]a2c_tuned train:   2%|‚ñè         | 55/3000 [01:29<1:29:07,  1.82s/it][step=1] episode=1.0000 return=-67.0583 length=19.0000 global_step=19.0000 loss=1697.3475 policy_loss=-113.2800 value_loss=3621.2939 entropy=1.9459
[step=2] episode=2.0000 return=-66.8696 length=20.0000 global_step=39.0000 loss=1671.4536 policy_loss=-113.8446 value_loss=3570.6353 entropy=1.9458
[step=3] episode=3.0000 return=10.7408 length=21.0000 global_step=60.0000 loss=956.1718 policy_loss=-25.2508 value_loss=1962.8842 entropy=1.9455
[step=4] episode=4.0000 return=-20.1686 length=20.0000 global_step=80.0000 loss=757.1969 policy_loss=-47.1656 value_loss=1608.7640 entropy=1.9451
[step=5] episode=5.0000 return=-64.0322 length=29.0000 global_step=109.0000 loss=3011.3098 policy_loss=-140.0254 value_loss=6302.7095 entropy=1.9422
[step=6] episode=6.0000 return=-115.9776 length=20.0000 global_step=129.0000 loss=4509.5527 policy_loss=-186.4279 value_loss=9391.9990 entropy=1.9278
[step=7] episode=7.0000 return=-112.2827 length=28.0000 global_step=157.0000 loss=3280.7498 policy_loss=-150.1057 value_loss=6861.7485 entropy=1.8722
[step=8] episode=8.0000 return=-99.0369 length=34.0000 global_step=191.0000 loss=2321.8782 policy_loss=-104.6764 value_loss=4853.1431 entropy=1.6756
[step=9] episode=9.0000 return=-98.2321 length=19.0000 global_step=210.0000 loss=2351.0601 policy_loss=-108.0658 value_loss=4918.2793 entropy=1.3752
[step=10] episode=10.0000 return=-115.9535 length=18.0000 global_step=228.0000 loss=2721.8486 policy_loss=-25.2213 value_loss=5494.1553 entropy=0.7844
[step=11] episode=11.0000 return=-115.9321 length=20.0000 global_step=248.0000 loss=2147.9233 policy_loss=-30.5439 value_loss=4356.9448 entropy=0.5199
[step=12] episode=12.0000 return=-115.9762 length=19.0000 global_step=267.0000 loss=917.9554 policy_loss=-23.9489 value_loss=1883.8162 entropy=0.3793
[step=13] episode=13.0000 return=-115.9974 length=34.0000 global_step=301.0000 loss=79.7507 policy_loss=-1.2853 value_loss=162.0762 entropy=0.2116
[step=14] episode=14.0000 return=-115.9968 length=27.0000 global_step=328.0000 loss=272.5098 policy_loss=0.6807 value_loss=543.6608 entropy=0.1358
[step=15] episode=15.0000 return=-115.9565 length=13.0000 global_step=341.0000 loss=962.1816 policy_loss=0.3273 value_loss=1923.7095 entropy=0.0448
[step=16] episode=16.0000 return=-115.8870 length=21.0000 global_step=362.0000 loss=2512.0789 policy_loss=0.0646 value_loss=5024.0288 entropy=0.0075
[step=17] episode=17.0000 return=-115.9921 length=19.0000 global_step=381.0000 loss=3208.2056 policy_loss=0.0087 value_loss=6416.3940 entropy=0.0012
[step=18] episode=18.0000 return=-115.9932 length=12.0000 global_step=393.0000 loss=2997.3528 policy_loss=0.0022 value_loss=5994.7012 entropy=0.0003
[step=19] episode=19.0000 return=-115.9995 length=26.0000 global_step=419.0000 loss=3295.3438 policy_loss=0.0016 value_loss=6590.6841 entropy=0.0002
[step=20] episode=20.0000 return=-115.9358 length=48.0000 global_step=467.0000 loss=3029.0952 policy_loss=0.0021 value_loss=6058.1865 entropy=0.0003
[step=21] episode=21.0000 return=-115.9360 length=20.0000 global_step=487.0000 loss=1327.4214 policy_loss=0.0024 value_loss=2654.8379 entropy=0.0005
[step=22] episode=22.0000 return=-115.9926 length=20.0000 global_step=507.0000 loss=596.0591 policy_loss=0.0036 value_loss=1192.1110 entropy=0.0011
[step=23] episode=23.0000 return=-115.9998 length=20.0000 global_step=527.0000 loss=126.3099 policy_loss=0.0047 value_loss=252.6106 entropy=0.0028
[step=24] episode=24.0000 return=-115.9900 length=20.0000 global_step=547.0000 loss=10.2933 policy_loss=-0.0025 value_loss=20.5918 entropy=0.0070
[step=25] episode=25.0000 return=-115.9936 length=29.0000 global_step=576.0000 loss=67.2923 policy_loss=-0.0175 value_loss=134.6198 entropy=0.0119
[step=26] episode=26.0000 return=-115.9013 length=26.0000 global_step=602.0000 loss=119.0559 policy_loss=-0.0306 value_loss=238.1733 entropy=0.0153
[step=27] episode=27.0000 return=-115.9096 length=29.0000 global_step=631.0000 loss=182.0968 policy_loss=-0.0461 value_loss=364.2862 entropy=0.0174
[step=28] episode=28.0000 return=-115.9384 length=12.0000 global_step=643.0000 loss=312.1432 policy_loss=-0.0561 value_loss=624.3988 entropy=0.0163
[step=29] episode=29.0000 return=-115.8259 length=13.0000 global_step=656.0000 loss=232.2911 policy_loss=-0.0410 value_loss=464.6646 entropy=0.0141
[step=30] episode=30.0000 return=-115.9812 length=44.0000 global_step=700.0000 loss=24.2538 policy_loss=1.1073 value_loss=46.2934 entropy=0.0110
[step=31] episode=31.0000 return=-115.9529 length=13.0000 global_step=713.0000 loss=34.1686 policy_loss=-0.0102 value_loss=68.3579 entropy=0.0107
[step=32] episode=32.0000 return=-115.7152 length=20.0000 global_step=733.0000 loss=13.6946 policy_loss=0.0044 value_loss=27.3804 entropy=0.0094
[step=33] episode=33.0000 return=-115.9989 length=28.0000 global_step=761.0000 loss=217.3127 policy_loss=0.0282 value_loss=434.5693 entropy=0.0105
[step=34] episode=34.0000 return=-115.9912 length=19.0000 global_step=780.0000 loss=199.3348 policy_loss=0.0347 value_loss=398.6006 entropy=0.0131
[step=35] episode=35.0000 return=-115.9978 length=12.0000 global_step=792.0000 loss=85.4943 policy_loss=0.0305 value_loss=170.9280 entropy=0.0173
[step=36] episode=36.0000 return=-115.9858 length=30.0000 global_step=822.0000 loss=141.9417 policy_loss=0.0583 value_loss=283.7672 entropy=0.0235
[step=37] episode=37.0000 return=-115.8819 length=30.0000 global_step=852.0000 loss=102.4678 policy_loss=0.0613 value_loss=204.8137 entropy=0.0298
[step=38] episode=38.0000 return=-115.9840 length=30.0000 global_step=882.0000 loss=21.5108 policy_loss=0.0228 value_loss=42.9767 entropy=0.0365
[step=39] episode=39.0000 return=-115.9385 length=37.0000 global_step=919.0000 loss=27.4881 policy_loss=-0.0240 value_loss=55.0253 entropy=0.0471
[step=40] episode=40.0000 return=-115.9998 length=21.0000 global_step=940.0000 loss=136.5310 policy_loss=-0.1569 value_loss=273.3769 entropy=0.0547
[step=41] episode=41.0000 return=-115.9939 length=28.0000 global_step=968.0000 loss=160.1689 policy_loss=-2.2848 value_loss=324.9088 entropy=0.0706
[step=42] episode=42.0000 return=-116.0000 length=61.0000 global_step=1029.0000 loss=58.2466 policy_loss=-0.0236 value_loss=116.5414 entropy=0.0584
[step=43] episode=43.0000 return=-115.9126 length=20.0000 global_step=1049.0000 loss=141.1345 policy_loss=-3.4642 value_loss=289.1984 entropy=0.0467
[step=44] episode=44.0000 return=-115.9679 length=11.0000 global_step=1060.0000 loss=169.2696 policy_loss=-0.0394 value_loss=338.6184 entropy=0.0157
[step=45] episode=45.0000 return=-115.9651 length=18.0000 global_step=1078.0000 loss=26.0506 policy_loss=-0.0032 value_loss=52.1077 entropy=0.0046
[step=46] episode=46.0000 return=-115.7544 length=11.0000 global_step=1089.0000 loss=12.5629 policy_loss=0.0000 value_loss=25.1257 entropy=0.0010
[step=47] episode=47.0000 return=-115.9945 length=20.0000 global_step=1109.0000 loss=82.0173 policy_loss=0.0003 value_loss=164.0341 entropy=0.0003
[step=48] episode=48.0000 return=-115.9491 length=19.0000 global_step=1128.0000 loss=84.9045 policy_loss=0.0001 value_loss=169.8088 entropy=0.0001
[step=49] episode=49.0000 return=-115.8739 length=20.0000 global_step=1148.0000 loss=51.2150 policy_loss=0.0000 value_loss=102.4300 entropy=0.0000
[step=50] episode=50.0000 return=-115.9968 length=36.0000 global_step=1184.0000 loss=211.6456 policy_loss=0.0000 value_loss=423.2912 entropy=0.0000
[step=51] episode=51.0000 return=-115.9928 length=12.0000 global_step=1196.0000 loss=13.3135 policy_loss=-0.0000 value_loss=26.6271 entropy=0.0000
[step=52] episode=52.0000 return=-115.9957 length=21.0000 global_step=1217.0000 loss=12.3324 policy_loss=0.0000 value_loss=24.6648 entropy=0.0000
[step=53] episode=53.0000 return=-115.9502 length=42.0000 global_step=1259.0000 loss=32.5843 policy_loss=0.0000 value_loss=65.1686 entropy=0.0000
[step=54] episode=54.0000 return=-115.9837 length=37.0000 global_step=1296.0000 loss=25.3200 policy_loss=-0.0000 value_loss=50.6401 entropy=0.0001
[step=55] episode=55.0000 return=-115.9948 length=19.0000 global_step=1315.0000 loss=112.9252 policy_loss=-0.0001 value_loss=225.8505 entropy=0.0001
a2c_tuned train:   2%|‚ñè         | 56/3000 [01:32<1:45:46,  2.16s/it]a2c_tuned train:   2%|‚ñè         | 57/3000 [01:37<2:23:02,  2.92s/it]a2c_tuned train:   2%|‚ñè         | 58/3000 [01:38<2:00:02,  2.45s/it]a2c_tuned train:   2%|‚ñè         | 59/3000 [01:39<1:35:18,  1.94s/it]a2c_tuned train:   2%|‚ñè         | 60/3000 [01:42<1:52:19,  2.29s/it]a2c_tuned train:   2%|‚ñè         | 61/3000 [01:44<1:48:12,  2.21s/it]a2c_tuned train:   2%|‚ñè         | 62/3000 [01:46<1:42:14,  2.09s/it]a2c_tuned train:   2%|‚ñè         | 63/3000 [01:48<1:38:50,  2.02s/it]a2c_tuned train:   2%|‚ñè         | 64/3000 [01:49<1:29:10,  1.82s/it]a2c_tuned train:   2%|‚ñè         | 65/3000 [01:51<1:35:07,  1.94s/it]a2c_tuned train:   2%|‚ñè         | 66/3000 [01:53<1:25:43,  1.75s/it]a2c_tuned train:   2%|‚ñè         | 67/3000 [01:54<1:19:13,  1.62s/it]a2c_tuned train:   2%|‚ñè         | 68/3000 [01:56<1:25:18,  1.75s/it]a2c_tuned train:   2%|‚ñè         | 69/3000 [01:57<1:12:06,  1.48s/it]a2c_tuned train:   2%|‚ñè         | 70/3000 [01:58<1:11:58,  1.47s/it]a2c_tuned train:   2%|‚ñè         | 71/3000 [02:00<1:20:03,  1.64s/it]a2c_tuned train:   2%|‚ñè         | 72/3000 [02:02<1:20:55,  1.66s/it]a2c_tuned train:   2%|‚ñè         | 73/3000 [02:03<1:17:51,  1.60s/it]a2c_tuned train:   2%|‚ñè         | 74/3000 [02:05<1:22:06,  1.68s/it]a2c_tuned train:   2%|‚ñé         | 75/3000 [02:07<1:17:40,  1.59s/it]a2c_tuned train:   3%|‚ñé         | 76/3000 [02:09<1:22:34,  1.69s/it]a2c_tuned train:   3%|‚ñé         | 77/3000 [02:10<1:25:31,  1.76s/it]a2c_tuned train:   3%|‚ñé         | 78/3000 [02:11<1:12:09,  1.48s/it]a2c_tuned train:   3%|‚ñé         | 79/3000 [02:13<1:17:41,  1.60s/it]a2c_tuned train:   3%|‚ñé         | 80/3000 [02:14<1:06:55,  1.38s/it]a2c_tuned train:   3%|‚ñé         | 81/3000 [02:15<1:06:12,  1.36s/it]a2c_tuned train:   3%|‚ñé         | 82/3000 [02:17<1:04:37,  1.33s/it]a2c_tuned train:   3%|‚ñé         | 83/3000 [02:18<1:06:08,  1.36s/it]a2c_tuned train:   3%|‚ñé         | 84/3000 [02:19<1:05:01,  1.34s/it]a2c_tuned train:   3%|‚ñé         | 85/3000 [02:21<1:14:05,  1.52s/it]a2c_tuned train:   3%|‚ñé         | 86/3000 [02:23<1:11:39,  1.48s/it]a2c_tuned train:   3%|‚ñé         | 87/3000 [02:25<1:18:24,  1.61s/it]a2c_tuned train:   3%|‚ñé         | 88/3000 [02:26<1:20:08,  1.65s/it]a2c_tuned train:   3%|‚ñé         | 89/3000 [02:28<1:16:07,  1.57s/it]a2c_tuned train:   3%|‚ñé         | 90/3000 [02:29<1:17:28,  1.60s/it]a2c_tuned train:   3%|‚ñé         | 91/3000 [02:31<1:13:45,  1.52s/it]a2c_tuned train:   3%|‚ñé         | 92/3000 [02:33<1:17:55,  1.61s/it]a2c_tuned train:   3%|‚ñé         | 93/3000 [02:34<1:15:51,  1.57s/it]a2c_tuned train:   3%|‚ñé         | 94/3000 [02:36<1:19:23,  1.64s/it]a2c_tuned train:   3%|‚ñé         | 95/3000 [02:39<1:45:40,  2.18s/it]a2c_tuned train:   3%|‚ñé         | 96/3000 [02:40<1:27:13,  1.80s/it]a2c_tuned train:   3%|‚ñé         | 97/3000 [02:41<1:12:40,  1.50s/it]a2c_tuned train:   3%|‚ñé         | 98/3000 [02:42<1:11:26,  1.48s/it]a2c_tuned train:   3%|‚ñé         | 99/3000 [02:46<1:40:30,  2.08s/it]a2c_tuned train:   3%|‚ñé         | 100/3000 [02:47<1:32:34,  1.92s/it]a2c_tuned train:   3%|‚ñé         | 101/3000 [02:50<1:39:05,  2.05s/it]a2c_tuned train:   3%|‚ñé         | 102/3000 [02:51<1:29:19,  1.85s/it]a2c_tuned train:   3%|‚ñé         | 103/3000 [02:53<1:23:33,  1.73s/it]a2c_tuned train:   3%|‚ñé         | 104/3000 [02:53<1:09:57,  1.45s/it]a2c_tuned train:   4%|‚ñé         | 105/3000 [02:55<1:08:50,  1.43s/it]a2c_tuned train:   4%|‚ñé         | 106/3000 [02:56<1:07:16,  1.39s/it]a2c_tuned train:   4%|‚ñé         | 107/3000 [02:58<1:07:55,  1.41s/it]a2c_tuned train:   4%|‚ñé         | 108/3000 [02:58<58:47,  1.22s/it]  a2c_tuned train:   4%|‚ñé         | 109/3000 [03:00<58:34,  1.22s/it]a2c_tuned train:   4%|‚ñé         | 110/3000 [03:01<1:00:35,  1.26s/it][step=56] episode=56.0000 return=-115.9950 length=45.0000 global_step=1360.0000 loss=35.6723 policy_loss=-0.0000 value_loss=71.3445 entropy=0.0001
[step=57] episode=57.0000 return=-115.9998 length=71.0000 global_step=1431.0000 loss=93.6818 policy_loss=0.0000 value_loss=187.3635 entropy=0.0000
[step=58] episode=58.0000 return=-115.9951 length=21.0000 global_step=1452.0000 loss=84.1035 policy_loss=-0.0000 value_loss=168.2070 entropy=0.0000
[step=59] episode=59.0000 return=-115.9923 length=12.0000 global_step=1464.0000 loss=145.0557 policy_loss=-0.0000 value_loss=290.1114 entropy=0.0000
[step=60] episode=60.0000 return=-115.9865 length=46.0000 global_step=1510.0000 loss=28.7698 policy_loss=-0.0000 value_loss=57.5395 entropy=0.0000
[step=61] episode=61.0000 return=-115.9959 length=30.0000 global_step=1540.0000 loss=20.5363 policy_loss=-0.0000 value_loss=41.0727 entropy=0.0000
[step=62] episode=62.0000 return=-115.9925 length=28.0000 global_step=1568.0000 loss=20.5979 policy_loss=-0.0000 value_loss=41.1957 entropy=0.0000
[step=63] episode=63.0000 return=-115.9989 length=28.0000 global_step=1596.0000 loss=24.2321 policy_loss=-0.0000 value_loss=48.4642 entropy=0.0000
[step=64] episode=64.0000 return=-115.8484 length=19.0000 global_step=1615.0000 loss=18.1046 policy_loss=-0.0000 value_loss=36.2092 entropy=0.0000
[step=65] episode=65.0000 return=-115.9995 length=34.0000 global_step=1649.0000 loss=23.6809 policy_loss=-0.0000 value_loss=47.3618 entropy=0.0000
[step=66] episode=66.0000 return=-115.8870 length=19.0000 global_step=1668.0000 loss=19.9052 policy_loss=-0.0000 value_loss=39.8104 entropy=0.0000
[step=67] episode=67.0000 return=-115.9096 length=20.0000 global_step=1688.0000 loss=11.8484 policy_loss=-0.0000 value_loss=23.6968 entropy=0.0000
[step=68] episode=68.0000 return=-115.9955 length=30.0000 global_step=1718.0000 loss=35.5016 policy_loss=-0.0000 value_loss=71.0032 entropy=0.0000
[step=69] episode=69.0000 return=-115.9500 length=12.0000 global_step=1730.0000 loss=17.6597 policy_loss=-0.0000 value_loss=35.3194 entropy=0.0000
[step=70] episode=70.0000 return=-115.9988 length=21.0000 global_step=1751.0000 loss=25.6329 policy_loss=-0.0000 value_loss=51.2659 entropy=0.0000
[step=71] episode=71.0000 return=-115.9840 length=30.0000 global_step=1781.0000 loss=68.5617 policy_loss=-0.0000 value_loss=137.1235 entropy=0.0000
[step=72] episode=72.0000 return=-115.9954 length=27.0000 global_step=1808.0000 loss=35.3693 policy_loss=-0.0000 value_loss=70.7385 entropy=0.0000
[step=73] episode=73.0000 return=-115.8798 length=21.0000 global_step=1829.0000 loss=13.5895 policy_loss=-0.0000 value_loss=27.1791 entropy=0.0000
[step=74] episode=74.0000 return=-115.9886 length=28.0000 global_step=1857.0000 loss=9.4276 policy_loss=-0.0000 value_loss=18.8552 entropy=0.0000
[step=75] episode=75.0000 return=-115.9968 length=21.0000 global_step=1878.0000 loss=14.7742 policy_loss=-0.0000 value_loss=29.5484 entropy=0.0000
[step=76] episode=76.0000 return=-115.9770 length=29.0000 global_step=1907.0000 loss=29.3054 policy_loss=-0.0000 value_loss=58.6108 entropy=0.0000
[step=77] episode=77.0000 return=-115.9901 length=29.0000 global_step=1936.0000 loss=8.3090 policy_loss=-0.0000 value_loss=16.6180 entropy=0.0000
[step=78] episode=78.0000 return=-115.9874 length=12.0000 global_step=1948.0000 loss=42.7607 policy_loss=-0.0000 value_loss=85.5215 entropy=0.0000
[step=79] episode=79.0000 return=-115.9978 length=27.0000 global_step=1975.0000 loss=18.4208 policy_loss=-0.0000 value_loss=36.8416 entropy=0.0000
[step=80] episode=80.0000 return=-115.8358 length=13.0000 global_step=1988.0000 loss=45.6909 policy_loss=-0.0000 value_loss=91.3819 entropy=0.0000
[step=81] episode=81.0000 return=-115.9696 length=20.0000 global_step=2008.0000 loss=23.4618 policy_loss=-0.0000 value_loss=46.9236 entropy=0.0000
[step=82] episode=82.0000 return=-115.9842 length=19.0000 global_step=2027.0000 loss=9.7016 policy_loss=-0.0000 value_loss=19.4033 entropy=0.0000
[step=83] episode=83.0000 return=-115.9713 length=21.0000 global_step=2048.0000 loss=12.7340 policy_loss=-0.0000 value_loss=25.4679 entropy=0.0000
[step=84] episode=84.0000 return=-115.9948 length=20.0000 global_step=2068.0000 loss=9.4514 policy_loss=-0.0000 value_loss=18.9029 entropy=0.0000
[step=85] episode=85.0000 return=-115.9280 length=28.0000 global_step=2096.0000 loss=10.3487 policy_loss=-0.0000 value_loss=20.6975 entropy=0.0000
[step=86] episode=86.0000 return=-115.8201 length=21.0000 global_step=2117.0000 loss=33.9837 policy_loss=-0.0000 value_loss=67.9674 entropy=0.0000
[step=87] episode=87.0000 return=-115.9948 length=28.0000 global_step=2145.0000 loss=11.8709 policy_loss=-0.0000 value_loss=23.7419 entropy=0.0000
[step=88] episode=88.0000 return=-115.9626 length=26.0000 global_step=2171.0000 loss=10.9345 policy_loss=-0.0000 value_loss=21.8691 entropy=0.0000
[step=89] episode=89.0000 return=-115.9989 length=21.0000 global_step=2192.0000 loss=10.1124 policy_loss=-0.0000 value_loss=20.2247 entropy=0.0000
[step=90] episode=90.0000 return=-115.9429 length=25.0000 global_step=2217.0000 loss=4.0874 policy_loss=-0.0000 value_loss=8.1749 entropy=0.0000
[step=91] episode=91.0000 return=-115.9968 length=19.0000 global_step=2236.0000 loss=8.1177 policy_loss=-0.0000 value_loss=16.2354 entropy=0.0000
[step=92] episode=92.0000 return=-115.9820 length=28.0000 global_step=2264.0000 loss=12.9459 policy_loss=-0.0000 value_loss=25.8919 entropy=0.0000
[step=93] episode=93.0000 return=-115.9928 length=21.0000 global_step=2285.0000 loss=11.6041 policy_loss=-0.0000 value_loss=23.2082 entropy=0.0000
[step=94] episode=94.0000 return=-115.9820 length=26.0000 global_step=2311.0000 loss=4.7781 policy_loss=-0.0000 value_loss=9.5561 entropy=0.0000
[step=95] episode=95.0000 return=-116.0000 length=53.0000 global_step=2364.0000 loss=62.2735 policy_loss=-0.0000 value_loss=124.5469 entropy=0.0000
[step=96] episode=96.0000 return=-115.7625 length=13.0000 global_step=2377.0000 loss=143.4522 policy_loss=-0.0000 value_loss=286.9044 entropy=0.0000
[step=97] episode=97.0000 return=-115.8369 length=11.0000 global_step=2388.0000 loss=193.4573 policy_loss=-0.0000 value_loss=386.9145 entropy=0.0000
[step=98] episode=98.0000 return=-115.9968 length=21.0000 global_step=2409.0000 loss=107.0083 policy_loss=-0.0000 value_loss=214.0166 entropy=0.0000
[step=99] episode=99.0000 return=-115.9997 length=51.0000 global_step=2460.0000 loss=26.0427 policy_loss=-0.0000 value_loss=52.0855 entropy=0.0000
[step=100] episode=100.0000 return=-115.9892 length=22.0000 global_step=2482.0000 loss=57.6246 policy_loss=-0.0000 value_loss=115.2493 entropy=0.0000
[step=101] episode=101.0000 return=-115.9998 length=36.0000 global_step=2518.0000 loss=60.3759 policy_loss=-0.0000 value_loss=120.7518 entropy=0.0000
[step=102] episode=102.0000 return=-115.9442 length=21.0000 global_step=2539.0000 loss=3.3610 policy_loss=-0.0000 value_loss=6.7220 entropy=0.0000
[step=103] episode=103.0000 return=-115.9995 length=21.0000 global_step=2560.0000 loss=22.1274 policy_loss=-0.0000 value_loss=44.2548 entropy=0.0000
[step=104] episode=104.0000 return=-115.7995 length=12.0000 global_step=2572.0000 loss=16.2259 policy_loss=-0.0000 value_loss=32.4518 entropy=0.0000
[step=105] episode=105.0000 return=-115.9910 length=21.0000 global_step=2593.0000 loss=18.1670 policy_loss=-0.0000 value_loss=36.3341 entropy=0.0000
[step=106] episode=106.0000 return=-115.9832 length=20.0000 global_step=2613.0000 loss=10.9865 policy_loss=-0.0000 value_loss=21.9731 entropy=0.0000
[step=107] episode=107.0000 return=-115.9391 length=21.0000 global_step=2634.0000 loss=12.9721 policy_loss=-0.0000 value_loss=25.9442 entropy=0.0000
[step=108] episode=108.0000 return=-115.8260 length=11.0000 global_step=2645.0000 loss=60.2972 policy_loss=-0.0000 value_loss=120.5944 entropy=0.0000
[step=109] episode=109.0000 return=-115.9022 length=18.0000 global_step=2663.0000 loss=31.6808 policy_loss=-0.0000 value_loss=63.3616 entropy=0.0000
[step=110] episode=110.0000 return=-115.9976 length=20.0000 global_step=2683.0000 loss=11.9378 policy_loss=-0.0000 value_loss=23.8756 entropy=0.0000
a2c_tuned train:   4%|‚ñé         | 111/3000 [03:03<1:08:54,  1.43s/it]a2c_tuned train:   4%|‚ñé         | 112/3000 [03:04<1:08:11,  1.42s/it]a2c_tuned train:   4%|‚ñç         | 113/3000 [03:06<1:16:08,  1.58s/it]a2c_tuned train:   4%|‚ñç         | 114/3000 [03:07<1:05:15,  1.36s/it]a2c_tuned train:   4%|‚ñç         | 115/3000 [03:08<1:04:20,  1.34s/it]a2c_tuned train:   4%|‚ñç         | 116/3000 [03:10<1:14:43,  1.55s/it]a2c_tuned train:   4%|‚ñç         | 117/3000 [03:12<1:21:18,  1.69s/it]a2c_tuned train:   4%|‚ñç         | 118/3000 [03:13<1:08:07,  1.42s/it]a2c_tuned train:   4%|‚ñç         | 119/3000 [03:14<1:07:44,  1.41s/it]a2c_tuned train:   4%|‚ñç         | 120/3000 [03:16<1:14:59,  1.56s/it]a2c_tuned train:   4%|‚ñç         | 121/3000 [03:18<1:12:32,  1.51s/it]a2c_tuned train:   4%|‚ñç         | 122/3000 [03:22<1:49:36,  2.29s/it]a2c_tuned train:   4%|‚ñç         | 123/3000 [03:23<1:29:55,  1.88s/it]a2c_tuned train:   4%|‚ñç         | 124/3000 [03:24<1:21:42,  1.70s/it]a2c_tuned train:   4%|‚ñç         | 125/3000 [03:25<1:10:21,  1.47s/it]a2c_tuned train:   4%|‚ñç         | 126/3000 [03:26<1:08:06,  1.42s/it]a2c_tuned train:   4%|‚ñç         | 127/3000 [03:27<1:00:47,  1.27s/it]a2c_tuned train:   4%|‚ñç         | 128/3000 [03:29<1:02:24,  1.30s/it]a2c_tuned train:   4%|‚ñç         | 129/3000 [03:30<1:04:36,  1.35s/it]a2c_tuned train:   4%|‚ñç         | 130/3000 [03:31<1:06:09,  1.38s/it]a2c_tuned train:   4%|‚ñç         | 131/3000 [03:34<1:28:57,  1.86s/it]a2c_tuned train:   4%|‚ñç         | 132/3000 [03:36<1:20:43,  1.69s/it]a2c_tuned train:   4%|‚ñç         | 133/3000 [03:38<1:30:38,  1.90s/it]a2c_tuned train:   4%|‚ñç         | 134/3000 [03:39<1:15:52,  1.59s/it]a2c_tuned train:   4%|‚ñç         | 135/3000 [03:40<1:14:08,  1.55s/it]a2c_tuned train:   5%|‚ñç         | 136/3000 [03:42<1:19:52,  1.67s/it]a2c_tuned train:   5%|‚ñç         | 137/3000 [03:44<1:24:03,  1.76s/it]a2c_tuned train:   5%|‚ñç         | 138/3000 [03:46<1:26:07,  1.81s/it]a2c_tuned train:   5%|‚ñç         | 139/3000 [03:48<1:28:18,  1.85s/it]a2c_tuned train:   5%|‚ñç         | 140/3000 [03:50<1:29:17,  1.87s/it]a2c_tuned train:   5%|‚ñç         | 141/3000 [03:52<1:32:51,  1.95s/it]a2c_tuned train:   5%|‚ñç         | 142/3000 [03:55<1:47:00,  2.25s/it]a2c_tuned train:   5%|‚ñç         | 143/3000 [03:57<1:40:25,  2.11s/it]a2c_tuned train:   5%|‚ñç         | 144/3000 [03:58<1:28:27,  1.86s/it]a2c_tuned train:   5%|‚ñç         | 145/3000 [03:59<1:12:45,  1.53s/it]a2c_tuned train:   5%|‚ñç         | 146/3000 [04:01<1:17:56,  1.64s/it]a2c_tuned train:   5%|‚ñç         | 147/3000 [04:03<1:25:12,  1.79s/it]a2c_tuned train:   5%|‚ñç         | 148/3000 [04:05<1:25:22,  1.80s/it]a2c_tuned train:   5%|‚ñç         | 149/3000 [04:07<1:25:00,  1.79s/it]a2c_tuned train:   5%|‚ñå         | 150/3000 [04:08<1:18:53,  1.66s/it]a2c_tuned train:   5%|‚ñå         | 151/3000 [04:10<1:29:15,  1.88s/it]a2c_tuned train:   5%|‚ñå         | 152/3000 [04:12<1:30:45,  1.91s/it]a2c_tuned train:   5%|‚ñå         | 153/3000 [04:14<1:24:26,  1.78s/it]a2c_tuned train:   5%|‚ñå         | 154/3000 [04:16<1:34:50,  2.00s/it]a2c_tuned train:   5%|‚ñå         | 155/3000 [04:18<1:25:51,  1.81s/it]a2c_tuned train:   5%|‚ñå         | 156/3000 [04:19<1:18:27,  1.66s/it]a2c_tuned train:   5%|‚ñå         | 157/3000 [04:21<1:27:51,  1.85s/it]a2c_tuned train:   5%|‚ñå         | 158/3000 [04:23<1:20:11,  1.69s/it]a2c_tuned train:   5%|‚ñå         | 159/3000 [04:24<1:15:53,  1.60s/it]a2c_tuned train:   5%|‚ñå         | 160/3000 [04:27<1:29:58,  1.90s/it]a2c_tuned train:   5%|‚ñå         | 161/3000 [04:29<1:36:31,  2.04s/it]a2c_tuned train:   5%|‚ñå         | 162/3000 [04:31<1:36:43,  2.04s/it]a2c_tuned train:   5%|‚ñå         | 163/3000 [04:32<1:26:38,  1.83s/it]a2c_tuned train:   5%|‚ñå         | 164/3000 [04:34<1:20:56,  1.71s/it][step=111] episode=111.0000 return=-115.9266 length=28.0000 global_step=2711.0000 loss=28.9676 policy_loss=-0.0000 value_loss=57.9352 entropy=0.0000
[step=112] episode=112.0000 return=-115.8569 length=20.0000 global_step=2731.0000 loss=4.2472 policy_loss=-0.0000 value_loss=8.4943 entropy=0.0000
[step=113] episode=113.0000 return=-115.9371 length=28.0000 global_step=2759.0000 loss=9.9391 policy_loss=-0.0000 value_loss=19.8783 entropy=0.0000
[step=114] episode=114.0000 return=-115.9999 length=12.0000 global_step=2771.0000 loss=23.3144 policy_loss=-0.0000 value_loss=46.6287 entropy=0.0000
[step=115] episode=115.0000 return=-115.9308 length=19.0000 global_step=2790.0000 loss=7.4575 policy_loss=-0.0000 value_loss=14.9150 entropy=0.0000
[step=116] episode=116.0000 return=-115.9384 length=30.0000 global_step=2820.0000 loss=17.7059 policy_loss=-0.0000 value_loss=35.4119 entropy=0.0000
[step=117] episode=117.0000 return=-115.9808 length=30.0000 global_step=2850.0000 loss=16.4914 policy_loss=-0.0000 value_loss=32.9827 entropy=0.0000
[step=118] episode=118.0000 return=-115.8017 length=11.0000 global_step=2861.0000 loss=142.2689 policy_loss=-0.0000 value_loss=284.5378 entropy=0.0000
[step=119] episode=119.0000 return=-115.9994 length=21.0000 global_step=2882.0000 loss=106.1527 policy_loss=-0.0000 value_loss=212.3054 entropy=0.0000
[step=120] episode=120.0000 return=-115.9883 length=28.0000 global_step=2910.0000 loss=58.7070 policy_loss=-0.0000 value_loss=117.4140 entropy=0.0000
[step=121] episode=121.0000 return=-115.9989 length=20.0000 global_step=2930.0000 loss=69.0878 policy_loss=-0.0000 value_loss=138.1756 entropy=0.0000
[step=122] episode=122.0000 return=-115.9997 length=61.0000 global_step=2991.0000 loss=132.0321 policy_loss=-0.0000 value_loss=264.0642 entropy=0.0000
[step=123] episode=123.0000 return=-115.8586 length=13.0000 global_step=3004.0000 loss=55.2026 policy_loss=-0.0000 value_loss=110.4053 entropy=0.0000
[step=124] episode=124.0000 return=-115.8215 length=19.0000 global_step=3023.0000 loss=4.6841 policy_loss=-0.0000 value_loss=9.3683 entropy=0.0000
[step=125] episode=125.0000 return=-115.8174 length=13.0000 global_step=3036.0000 loss=15.4746 policy_loss=-0.0000 value_loss=30.9491 entropy=0.0000
[step=126] episode=126.0000 return=-115.8925 length=19.0000 global_step=3055.0000 loss=84.3036 policy_loss=-0.0000 value_loss=168.6071 entropy=0.0000
[step=127] episode=127.0000 return=-115.9759 length=13.0000 global_step=3068.0000 loss=29.2259 policy_loss=-0.0000 value_loss=58.4518 entropy=0.0000
[step=128] episode=128.0000 return=-115.8760 length=20.0000 global_step=3088.0000 loss=39.9081 policy_loss=-0.0000 value_loss=79.8162 entropy=0.0000
[step=129] episode=129.0000 return=-115.9917 length=21.0000 global_step=3109.0000 loss=10.4749 policy_loss=-0.0000 value_loss=20.9498 entropy=0.0000
[step=130] episode=130.0000 return=-115.9849 length=21.0000 global_step=3130.0000 loss=36.0227 policy_loss=-0.0000 value_loss=72.0454 entropy=0.0000
[step=131] episode=131.0000 return=-115.9988 length=44.0000 global_step=3174.0000 loss=52.6885 policy_loss=-0.0000 value_loss=105.3770 entropy=0.0000
[step=132] episode=132.0000 return=-115.9972 length=18.0000 global_step=3192.0000 loss=102.6981 policy_loss=-0.0000 value_loss=205.3962 entropy=0.0000
[step=133] episode=133.0000 return=-115.9972 length=35.0000 global_step=3227.0000 loss=55.1668 policy_loss=-0.0000 value_loss=110.3337 entropy=0.0000
[step=134] episode=134.0000 return=-115.9997 length=13.0000 global_step=3240.0000 loss=228.3714 policy_loss=-0.0000 value_loss=456.7427 entropy=0.0000
[step=135] episode=135.0000 return=-115.9917 length=21.0000 global_step=3261.0000 loss=86.5617 policy_loss=-0.0000 value_loss=173.1234 entropy=0.0000
[step=136] episode=136.0000 return=-115.9969 length=29.0000 global_step=3290.0000 loss=19.9188 policy_loss=-0.0000 value_loss=39.8377 entropy=0.0000
[step=137] episode=137.0000 return=-115.9989 length=29.0000 global_step=3319.0000 loss=28.5366 policy_loss=-0.0000 value_loss=57.0733 entropy=0.0000
[step=138] episode=138.0000 return=-115.9989 length=28.0000 global_step=3347.0000 loss=61.8679 policy_loss=-0.0000 value_loss=123.7357 entropy=0.0000
[step=139] episode=139.0000 return=-115.9313 length=30.0000 global_step=3377.0000 loss=82.7140 policy_loss=-0.0000 value_loss=165.4280 entropy=0.0000
[step=140] episode=140.0000 return=-115.9994 length=28.0000 global_step=3405.0000 loss=59.4318 policy_loss=-0.0000 value_loss=118.8637 entropy=0.0000
[step=141] episode=141.0000 return=-115.9968 length=30.0000 global_step=3435.0000 loss=7.8432 policy_loss=-0.0000 value_loss=15.6865 entropy=0.0000
[step=142] episode=142.0000 return=-115.9970 length=44.0000 global_step=3479.0000 loss=26.7835 policy_loss=-0.0000 value_loss=53.5670 entropy=0.0000
[step=143] episode=143.0000 return=-115.9096 length=27.0000 global_step=3506.0000 loss=88.3628 policy_loss=-0.0000 value_loss=176.7256 entropy=0.0000
[step=144] episode=144.0000 return=-116.0000 length=20.0000 global_step=3526.0000 loss=205.1049 policy_loss=-0.0001 value_loss=410.2099 entropy=0.0000
[step=145] episode=145.0000 return=-115.8377 length=12.0000 global_step=3538.0000 loss=371.2285 policy_loss=-0.0001 value_loss=742.4572 entropy=0.0001
[step=146] episode=146.0000 return=-115.9999 length=29.0000 global_step=3567.0000 loss=138.4662 policy_loss=-0.0001 value_loss=276.9324 entropy=0.0000
[step=147] episode=147.0000 return=-115.9941 length=33.0000 global_step=3600.0000 loss=74.7045 policy_loss=-0.0000 value_loss=149.4091 entropy=0.0000
[step=148] episode=148.0000 return=-115.9998 length=26.0000 global_step=3626.0000 loss=42.8667 policy_loss=-0.0000 value_loss=85.7334 entropy=0.0000
[step=149] episode=149.0000 return=-115.9998 length=26.0000 global_step=3652.0000 loss=14.9028 policy_loss=-0.0000 value_loss=29.8057 entropy=0.0000
[step=150] episode=150.0000 return=-115.9839 length=20.0000 global_step=3672.0000 loss=13.4938 policy_loss=-0.0000 value_loss=26.9875 entropy=0.0000
[step=151] episode=151.0000 return=-115.9994 length=35.0000 global_step=3707.0000 loss=47.9795 policy_loss=-0.0000 value_loss=95.9591 entropy=0.0000
[step=152] episode=152.0000 return=-115.9971 length=29.0000 global_step=3736.0000 loss=41.4695 policy_loss=-0.0000 value_loss=82.9389 entropy=0.0000
[step=153] episode=153.0000 return=-115.8581 length=20.0000 global_step=3756.0000 loss=9.1208 policy_loss=-0.0000 value_loss=18.2416 entropy=0.0000
[step=154] episode=154.0000 return=-115.9928 length=37.0000 global_step=3793.0000 loss=45.1856 policy_loss=-0.0000 value_loss=90.3711 entropy=0.0000
[step=155] episode=155.0000 return=-115.8189 length=21.0000 global_step=3814.0000 loss=31.1008 policy_loss=-0.0000 value_loss=62.2016 entropy=0.0000
[step=156] episode=156.0000 return=-115.9764 length=20.0000 global_step=3834.0000 loss=26.3634 policy_loss=-0.0000 value_loss=52.7268 entropy=0.0000
[step=157] episode=157.0000 return=-115.9853 length=34.0000 global_step=3868.0000 loss=26.0683 policy_loss=-0.0000 value_loss=52.1366 entropy=0.0000
[step=158] episode=158.0000 return=-115.9984 length=20.0000 global_step=3888.0000 loss=16.2884 policy_loss=-0.0000 value_loss=32.5767 entropy=0.0000
[step=159] episode=159.0000 return=-115.9723 length=21.0000 global_step=3909.0000 loss=9.6128 policy_loss=-0.0000 value_loss=19.2257 entropy=0.0000
[step=160] episode=160.0000 return=-115.9876 length=38.0000 global_step=3947.0000 loss=66.8890 policy_loss=-0.0000 value_loss=133.7781 entropy=0.0000
[step=161] episode=161.0000 return=-115.9943 length=35.0000 global_step=3982.0000 loss=73.8038 policy_loss=-0.0000 value_loss=147.6076 entropy=0.0000
[step=162] episode=162.0000 return=-115.9959 length=30.0000 global_step=4012.0000 loss=32.0425 policy_loss=-0.0000 value_loss=64.0850 entropy=0.0000
[step=163] episode=163.0000 return=-115.9966 length=20.0000 global_step=4032.0000 loss=9.1250 policy_loss=-0.0000 value_loss=18.2499 entropy=0.0000
[step=164] episode=164.0000 return=-115.9655 length=21.0000 global_step=4053.0000 loss=33.0689 policy_loss=-0.0000 value_loss=66.1379 entropy=0.0000
a2c_tuned train:   6%|‚ñå         | 165/3000 [04:35<1:09:28,  1.47s/it]a2c_tuned train:   6%|‚ñå         | 166/3000 [04:37<1:23:59,  1.78s/it]a2c_tuned train:   6%|‚ñå         | 167/3000 [04:39<1:17:17,  1.64s/it]a2c_tuned train:   6%|‚ñå         | 168/3000 [04:41<1:20:58,  1.72s/it]a2c_tuned train:   6%|‚ñå         | 169/3000 [04:43<1:25:51,  1.82s/it]a2c_tuned train:   6%|‚ñå         | 170/3000 [04:45<1:28:04,  1.87s/it]a2c_tuned train:   6%|‚ñå         | 171/3000 [04:47<1:30:03,  1.91s/it]a2c_tuned train:   6%|‚ñå         | 172/3000 [04:47<1:13:40,  1.56s/it]a2c_tuned train:   6%|‚ñå         | 173/3000 [04:49<1:11:50,  1.52s/it]a2c_tuned train:   6%|‚ñå         | 174/3000 [04:50<1:10:07,  1.49s/it]a2c_tuned train:   6%|‚ñå         | 175/3000 [04:51<1:00:15,  1.28s/it]a2c_tuned train:   6%|‚ñå         | 176/3000 [04:53<1:06:46,  1.42s/it]a2c_tuned train:   6%|‚ñå         | 177/3000 [04:54<1:06:50,  1.42s/it]a2c_tuned train:   6%|‚ñå         | 178/3000 [04:55<1:05:54,  1.40s/it]a2c_tuned train:   6%|‚ñå         | 179/3000 [04:57<1:05:08,  1.39s/it]a2c_tuned train:   6%|‚ñå         | 180/3000 [04:59<1:21:07,  1.73s/it]a2c_tuned train:   6%|‚ñå         | 181/3000 [05:01<1:23:29,  1.78s/it]a2c_tuned train:   6%|‚ñå         | 182/3000 [05:02<1:10:46,  1.51s/it]a2c_tuned train:   6%|‚ñå         | 183/3000 [05:03<1:01:50,  1.32s/it]a2c_tuned train:   6%|‚ñå         | 184/3000 [05:04<1:00:34,  1.29s/it]a2c_tuned train:   6%|‚ñå         | 185/3000 [05:06<1:02:37,  1.33s/it]a2c_tuned train:   6%|‚ñå         | 186/3000 [05:07<1:02:52,  1.34s/it]a2c_tuned train:   6%|‚ñå         | 187/3000 [05:10<1:19:58,  1.71s/it]a2c_tuned train:   6%|‚ñã         | 188/3000 [05:12<1:30:10,  1.92s/it]a2c_tuned train:   6%|‚ñã         | 189/3000 [05:14<1:37:19,  2.08s/it]a2c_tuned train:   6%|‚ñã         | 190/3000 [05:16<1:27:36,  1.87s/it]a2c_tuned train:   6%|‚ñã         | 191/3000 [05:18<1:26:28,  1.85s/it]a2c_tuned train:   6%|‚ñã         | 192/3000 [05:20<1:28:00,  1.88s/it]a2c_tuned train:   6%|‚ñã         | 193/3000 [05:20<1:12:30,  1.55s/it]a2c_tuned train:   6%|‚ñã         | 194/3000 [05:22<1:09:01,  1.48s/it]a2c_tuned train:   6%|‚ñã         | 195/3000 [05:23<1:08:46,  1.47s/it]a2c_tuned train:   7%|‚ñã         | 196/3000 [05:26<1:22:59,  1.78s/it]a2c_tuned train:   7%|‚ñã         | 197/3000 [05:28<1:33:35,  2.00s/it]a2c_tuned train:   7%|‚ñã         | 198/3000 [05:30<1:25:58,  1.84s/it]a2c_tuned train:   7%|‚ñã         | 199/3000 [05:32<1:27:23,  1.87s/it]a2c_tuned train:   7%|‚ñã         | 200/3000 [05:33<1:20:33,  1.73s/it]a2c_tuned train:   7%|‚ñã         | 201/3000 [05:34<1:13:39,  1.58s/it]a2c_tuned train:   7%|‚ñã         | 202/3000 [05:35<1:03:21,  1.36s/it]a2c_tuned train:   7%|‚ñã         | 203/3000 [05:36<1:02:54,  1.35s/it]a2c_tuned train:   7%|‚ñã         | 204/3000 [05:38<1:09:33,  1.49s/it]a2c_tuned train:   7%|‚ñã         | 205/3000 [05:39<1:01:05,  1.31s/it]a2c_tuned train:   7%|‚ñã         | 206/3000 [05:42<1:26:12,  1.85s/it]a2c_tuned train:   7%|‚ñã         | 207/3000 [05:44<1:19:35,  1.71s/it]a2c_tuned train:   7%|‚ñã         | 208/3000 [05:45<1:20:36,  1.73s/it]a2c_tuned train:   7%|‚ñã         | 209/3000 [05:48<1:32:22,  1.99s/it]a2c_tuned train:   7%|‚ñã         | 210/3000 [05:49<1:24:41,  1.82s/it]a2c_tuned train:   7%|‚ñã         | 211/3000 [05:51<1:18:40,  1.69s/it]a2c_tuned train:   7%|‚ñã         | 212/3000 [05:52<1:16:15,  1.64s/it]a2c_tuned train:   7%|‚ñã         | 213/3000 [05:55<1:29:05,  1.92s/it]a2c_tuned train:   7%|‚ñã         | 214/3000 [05:57<1:29:44,  1.93s/it]a2c_tuned train:   7%|‚ñã         | 215/3000 [05:58<1:23:33,  1.80s/it]a2c_tuned train:   7%|‚ñã         | 216/3000 [06:01<1:41:32,  2.19s/it]a2c_tuned train:   7%|‚ñã         | 217/3000 [06:03<1:36:52,  2.09s/it]a2c_tuned train:   7%|‚ñã         | 218/3000 [06:05<1:27:41,  1.89s/it][step=165] episode=165.0000 return=-115.8364 length=13.0000 global_step=4066.0000 loss=30.8021 policy_loss=-0.0000 value_loss=61.6041 entropy=0.0000
[step=166] episode=166.0000 return=-115.8656 length=37.0000 global_step=4103.0000 loss=53.9527 policy_loss=-0.0000 value_loss=107.9054 entropy=0.0000
[step=167] episode=167.0000 return=-115.9764 length=20.0000 global_step=4123.0000 loss=28.3367 policy_loss=-0.0000 value_loss=56.6735 entropy=0.0000
[step=168] episode=168.0000 return=-115.9979 length=28.0000 global_step=4151.0000 loss=33.7556 policy_loss=-0.0000 value_loss=67.5113 entropy=0.0000
[step=169] episode=169.0000 return=-115.9571 length=30.0000 global_step=4181.0000 loss=25.7146 policy_loss=-0.0000 value_loss=51.4292 entropy=0.0000
[step=170] episode=170.0000 return=-115.9962 length=28.0000 global_step=4209.0000 loss=21.7399 policy_loss=-0.0000 value_loss=43.4797 entropy=0.0000
[step=171] episode=171.0000 return=-115.9942 length=30.0000 global_step=4239.0000 loss=31.0154 policy_loss=-0.0000 value_loss=62.0309 entropy=0.0000
[step=172] episode=172.0000 return=-115.9886 length=11.0000 global_step=4250.0000 loss=135.3114 policy_loss=-0.0000 value_loss=270.6228 entropy=0.0000
[step=173] episode=173.0000 return=-115.9146 length=21.0000 global_step=4271.0000 loss=34.2388 policy_loss=-0.0000 value_loss=68.4777 entropy=0.0000
[step=174] episode=174.0000 return=-115.9096 length=21.0000 global_step=4292.0000 loss=12.0797 policy_loss=-0.0000 value_loss=24.1593 entropy=0.0000
[step=175] episode=175.0000 return=-115.9784 length=11.0000 global_step=4303.0000 loss=15.2178 policy_loss=-0.0000 value_loss=30.4357 entropy=0.0000
[step=176] episode=176.0000 return=-115.9983 length=26.0000 global_step=4329.0000 loss=184.8264 policy_loss=-0.0000 value_loss=369.6528 entropy=0.0000
[step=177] episode=177.0000 return=-115.9998 length=20.0000 global_step=4349.0000 loss=240.8455 policy_loss=-0.0000 value_loss=481.6910 entropy=0.0000
[step=178] episode=178.0000 return=-115.9917 length=20.0000 global_step=4369.0000 loss=184.6523 policy_loss=-0.0000 value_loss=369.3047 entropy=0.0000
[step=179] episode=179.0000 return=-115.9352 length=19.0000 global_step=4388.0000 loss=282.3987 policy_loss=-0.0000 value_loss=564.7974 entropy=0.0000
[step=180] episode=180.0000 return=-115.9946 length=38.0000 global_step=4426.0000 loss=296.7138 policy_loss=-0.0000 value_loss=593.4276 entropy=0.0000
[step=181] episode=181.0000 return=-115.9975 length=29.0000 global_step=4455.0000 loss=115.3722 policy_loss=-0.0000 value_loss=230.7443 entropy=0.0000
[step=182] episode=182.0000 return=-115.8126 length=13.0000 global_step=4468.0000 loss=20.0281 policy_loss=-0.0000 value_loss=40.0562 entropy=0.0000
[step=183] episode=183.0000 return=-115.9968 length=13.0000 global_step=4481.0000 loss=67.9915 policy_loss=-0.0000 value_loss=135.9830 entropy=0.0000
[step=184] episode=184.0000 return=-115.9975 length=19.0000 global_step=4500.0000 loss=39.6929 policy_loss=-0.0000 value_loss=79.3858 entropy=0.0000
[step=185] episode=185.0000 return=-115.9206 length=21.0000 global_step=4521.0000 loss=21.1946 policy_loss=-0.0000 value_loss=42.3891 entropy=0.0000
[step=186] episode=186.0000 return=-115.9963 length=19.0000 global_step=4540.0000 loss=14.1427 policy_loss=-0.0000 value_loss=28.2853 entropy=0.0000
[step=187] episode=187.0000 return=-115.9893 length=38.0000 global_step=4578.0000 loss=94.5560 policy_loss=-0.0000 value_loss=189.1120 entropy=0.0000
[step=188] episode=188.0000 return=-115.9996 length=36.0000 global_step=4614.0000 loss=134.5210 policy_loss=-0.0000 value_loss=269.0419 entropy=0.0000
[step=189] episode=189.0000 return=-115.9968 length=36.0000 global_step=4650.0000 loss=126.8053 policy_loss=-0.0000 value_loss=253.6106 entropy=0.0000
[step=190] episode=190.0000 return=-115.9996 length=20.0000 global_step=4670.0000 loss=7.4033 policy_loss=-0.0000 value_loss=14.8065 entropy=0.0000
[step=191] episode=191.0000 return=-115.9968 length=28.0000 global_step=4698.0000 loss=15.4617 policy_loss=-0.0000 value_loss=30.9234 entropy=0.0000
[step=192] episode=192.0000 return=-115.9991 length=29.0000 global_step=4727.0000 loss=35.2131 policy_loss=-0.0000 value_loss=70.4262 entropy=0.0000
[step=193] episode=193.0000 return=-115.7233 length=11.0000 global_step=4738.0000 loss=214.8188 policy_loss=-0.0000 value_loss=429.6376 entropy=0.0000
[step=194] episode=194.0000 return=-115.9997 length=20.0000 global_step=4758.0000 loss=127.8260 policy_loss=-0.0000 value_loss=255.6519 entropy=0.0000
[step=195] episode=195.0000 return=-115.9840 length=21.0000 global_step=4779.0000 loss=113.0438 policy_loss=-0.0000 value_loss=226.0875 entropy=0.0000
[step=196] episode=196.0000 return=-116.0000 length=36.0000 global_step=4815.0000 loss=25.4788 policy_loss=-0.0000 value_loss=50.9576 entropy=0.0000
[step=197] episode=197.0000 return=-115.9939 length=38.0000 global_step=4853.0000 loss=39.5304 policy_loss=-0.0000 value_loss=79.0608 entropy=0.0000
[step=198] episode=198.0000 return=-115.9770 length=21.0000 global_step=4874.0000 loss=7.1042 policy_loss=-0.0000 value_loss=14.2083 entropy=0.0000
[step=199] episode=199.0000 return=-115.9092 length=29.0000 global_step=4903.0000 loss=62.0615 policy_loss=-0.0000 value_loss=124.1231 entropy=0.0000
[step=200] episode=200.0000 return=-115.9998 length=21.0000 global_step=4924.0000 loss=50.2353 policy_loss=-0.0000 value_loss=100.4706 entropy=0.0000
[step=201] episode=201.0000 return=-115.9895 length=19.0000 global_step=4943.0000 loss=29.2818 policy_loss=-0.0000 value_loss=58.5637 entropy=0.0000
[step=202] episode=202.0000 return=-115.8870 length=13.0000 global_step=4956.0000 loss=10.2636 policy_loss=-0.0000 value_loss=20.5272 entropy=0.0000
[step=203] episode=203.0000 return=-115.8624 length=20.0000 global_step=4976.0000 loss=14.6703 policy_loss=-0.0000 value_loss=29.3406 entropy=0.0000
[step=204] episode=204.0000 return=-115.9727 length=27.0000 global_step=5003.0000 loss=12.1497 policy_loss=-0.0000 value_loss=24.2995 entropy=0.0000
[step=205] episode=205.0000 return=-115.9996 length=12.0000 global_step=5015.0000 loss=73.7740 policy_loss=-0.0000 value_loss=147.5481 entropy=0.0000
[step=206] episode=206.0000 return=-115.9960 length=46.0000 global_step=5061.0000 loss=20.1368 policy_loss=-0.0000 value_loss=40.2735 entropy=0.0000
[step=207] episode=207.0000 return=-115.9882 length=21.0000 global_step=5082.0000 loss=80.7430 policy_loss=-0.0000 value_loss=161.4859 entropy=0.0000
[step=208] episode=208.0000 return=-115.9874 length=28.0000 global_step=5110.0000 loss=51.9939 policy_loss=-0.0000 value_loss=103.9878 entropy=0.0000
[step=209] episode=209.0000 return=-115.9979 length=38.0000 global_step=5148.0000 loss=27.5064 policy_loss=-0.0000 value_loss=55.0127 entropy=0.0000
[step=210] episode=210.0000 return=-115.8668 length=22.0000 global_step=5170.0000 loss=45.4457 policy_loss=-0.0000 value_loss=90.8914 entropy=0.0000
[step=211] episode=211.0000 return=-115.9878 length=20.0000 global_step=5190.0000 loss=10.4716 policy_loss=-0.0000 value_loss=20.9432 entropy=0.0000
[step=212] episode=212.0000 return=-115.9988 length=22.0000 global_step=5212.0000 loss=43.5094 policy_loss=-0.0000 value_loss=87.0187 entropy=0.0000
[step=213] episode=213.0000 return=-115.9989 length=38.0000 global_step=5250.0000 loss=203.3510 policy_loss=-0.0000 value_loss=406.7020 entropy=0.0000
[step=214] episode=214.0000 return=-115.9912 length=29.0000 global_step=5279.0000 loss=133.9693 policy_loss=-0.0000 value_loss=267.9385 entropy=0.0000
[step=215] episode=215.0000 return=-115.9977 length=21.0000 global_step=5300.0000 loss=55.1883 policy_loss=-0.0000 value_loss=110.3766 entropy=0.0000
[step=216] episode=216.0000 return=-115.9979 length=45.0000 global_step=5345.0000 loss=226.5941 policy_loss=-0.0000 value_loss=453.1882 entropy=0.0000
[step=217] episode=217.0000 return=-115.9876 length=27.0000 global_step=5372.0000 loss=21.5190 policy_loss=-0.0000 value_loss=43.0380 entropy=0.0000
[step=218] episode=218.0000 return=-115.9827 length=20.0000 global_step=5392.0000 loss=48.2569 policy_loss=-0.0000 value_loss=96.5138 entropy=0.0000
a2c_tuned train:   7%|‚ñã         | 219/3000 [06:08<1:41:34,  2.19s/it]a2c_tuned train:   7%|‚ñã         | 220/3000 [06:09<1:36:02,  2.07s/it]a2c_tuned train:   7%|‚ñã         | 221/3000 [06:12<1:42:16,  2.21s/it]a2c_tuned train:   7%|‚ñã         | 222/3000 [06:13<1:29:21,  1.93s/it]a2c_tuned train:   7%|‚ñã         | 223/3000 [06:15<1:27:19,  1.89s/it]a2c_tuned train:   7%|‚ñã         | 224/3000 [06:17<1:34:36,  2.04s/it]a2c_tuned train:   8%|‚ñä         | 225/3000 [06:19<1:27:14,  1.89s/it]a2c_tuned train:   8%|‚ñä         | 226/3000 [06:20<1:19:43,  1.72s/it]a2c_tuned train:   8%|‚ñä         | 227/3000 [06:22<1:21:39,  1.77s/it]a2c_tuned train:   8%|‚ñä         | 228/3000 [06:23<1:15:50,  1.64s/it]a2c_tuned train:   8%|‚ñä         | 229/3000 [06:25<1:14:01,  1.60s/it]a2c_tuned train:   8%|‚ñä         | 230/3000 [06:26<1:10:50,  1.53s/it]a2c_tuned train:   8%|‚ñä         | 231/3000 [06:28<1:08:30,  1.48s/it]a2c_tuned train:   8%|‚ñä         | 232/3000 [06:29<1:11:17,  1.55s/it]a2c_tuned train:   8%|‚ñä         | 233/3000 [06:31<1:16:45,  1.66s/it]a2c_tuned train:   8%|‚ñä         | 234/3000 [06:33<1:21:16,  1.76s/it]a2c_tuned train:   8%|‚ñä         | 235/3000 [06:36<1:34:52,  2.06s/it]a2c_tuned train:   8%|‚ñä         | 236/3000 [06:38<1:32:15,  2.00s/it]a2c_tuned train:   8%|‚ñä         | 237/3000 [06:39<1:24:01,  1.82s/it]a2c_tuned train:   8%|‚ñä         | 238/3000 [06:41<1:17:55,  1.69s/it]a2c_tuned train:   8%|‚ñä         | 239/3000 [06:42<1:07:30,  1.47s/it]a2c_tuned train:   8%|‚ñä         | 240/3000 [06:43<1:05:29,  1.42s/it]a2c_tuned train:   8%|‚ñä         | 241/3000 [06:44<1:05:22,  1.42s/it]a2c_tuned train:   8%|‚ñä         | 242/3000 [06:47<1:17:39,  1.69s/it]a2c_tuned train:   8%|‚ñä         | 243/3000 [06:48<1:18:14,  1.70s/it]a2c_tuned train:   8%|‚ñä         | 244/3000 [06:50<1:18:30,  1.71s/it]a2c_tuned train:   8%|‚ñä         | 245/3000 [06:52<1:25:46,  1.87s/it]a2c_tuned train:   8%|‚ñä         | 246/3000 [06:53<1:10:43,  1.54s/it]a2c_tuned train:   8%|‚ñä         | 247/3000 [06:54<1:02:25,  1.36s/it]a2c_tuned train:   8%|‚ñä         | 248/3000 [06:55<1:02:07,  1.35s/it]a2c_tuned train:   8%|‚ñä         | 249/3000 [06:57<1:08:41,  1.50s/it]a2c_tuned train:   8%|‚ñä         | 250/3000 [06:59<1:14:04,  1.62s/it]a2c_tuned train:   8%|‚ñä         | 251/3000 [07:01<1:12:38,  1.59s/it]a2c_tuned train:   8%|‚ñä         | 252/3000 [07:04<1:34:10,  2.06s/it]a2c_tuned train:   8%|‚ñä         | 253/3000 [07:05<1:23:46,  1.83s/it]a2c_tuned train:   8%|‚ñä         | 254/3000 [07:07<1:23:57,  1.83s/it]a2c_tuned train:   8%|‚ñä         | 255/3000 [07:08<1:09:44,  1.52s/it]a2c_tuned train:   9%|‚ñä         | 256/3000 [07:09<1:09:07,  1.51s/it]a2c_tuned train:   9%|‚ñä         | 257/3000 [07:11<1:07:31,  1.48s/it]a2c_tuned train:   9%|‚ñä         | 258/3000 [07:13<1:13:22,  1.61s/it]a2c_tuned train:   9%|‚ñä         | 259/3000 [07:15<1:17:58,  1.71s/it]a2c_tuned train:   9%|‚ñä         | 260/3000 [07:16<1:14:24,  1.63s/it]a2c_tuned train:   9%|‚ñä         | 261/3000 [07:17<1:08:39,  1.50s/it]a2c_tuned train:   9%|‚ñä         | 262/3000 [07:19<1:14:22,  1.63s/it]a2c_tuned train:   9%|‚ñâ         | 263/3000 [07:21<1:17:39,  1.70s/it]a2c_tuned train:   9%|‚ñâ         | 264/3000 [07:22<1:06:01,  1.45s/it]a2c_tuned train:   9%|‚ñâ         | 265/3000 [07:23<1:05:04,  1.43s/it]a2c_tuned train:   9%|‚ñâ         | 266/3000 [07:26<1:21:11,  1.78s/it]a2c_tuned train:   9%|‚ñâ         | 267/3000 [07:28<1:20:45,  1.77s/it]a2c_tuned train:   9%|‚ñâ         | 268/3000 [07:29<1:14:41,  1.64s/it]a2c_tuned train:   9%|‚ñâ         | 269/3000 [07:31<1:17:18,  1.70s/it]a2c_tuned train:   9%|‚ñâ         | 270/3000 [07:33<1:27:23,  1.92s/it]a2c_tuned train:   9%|‚ñâ         | 271/3000 [07:34<1:14:14,  1.63s/it]a2c_tuned train:   9%|‚ñâ         | 272/3000 [07:35<1:03:45,  1.40s/it][step=219] episode=219.0000 return=-115.9998 length=44.0000 global_step=5436.0000 loss=41.7261 policy_loss=-0.0000 value_loss=83.4522 entropy=0.0000
[step=220] episode=220.0000 return=-115.9979 length=26.0000 global_step=5462.0000 loss=97.9014 policy_loss=-0.0000 value_loss=195.8028 entropy=0.0000
[step=221] episode=221.0000 return=-115.9831 length=38.0000 global_step=5500.0000 loss=53.4677 policy_loss=-0.0000 value_loss=106.9353 entropy=0.0000
[step=222] episode=222.0000 return=-115.8936 length=18.0000 global_step=5518.0000 loss=152.5897 policy_loss=-0.0000 value_loss=305.1794 entropy=0.0000
[step=223] episode=223.0000 return=-115.9978 length=27.0000 global_step=5545.0000 loss=14.9101 policy_loss=-0.0000 value_loss=29.8203 entropy=0.0000
[step=224] episode=224.0000 return=-115.9974 length=37.0000 global_step=5582.0000 loss=77.8751 policy_loss=-0.0000 value_loss=155.7502 entropy=0.0000
[step=225] episode=225.0000 return=-115.9647 length=22.0000 global_step=5604.0000 loss=32.4949 policy_loss=-0.0000 value_loss=64.9898 entropy=0.0000
[step=226] episode=226.0000 return=-115.9941 length=19.0000 global_step=5623.0000 loss=29.0029 policy_loss=-0.0000 value_loss=58.0057 entropy=0.0000
[step=227] episode=227.0000 return=-115.9958 length=28.0000 global_step=5651.0000 loss=72.9707 policy_loss=-0.0000 value_loss=145.9415 entropy=0.0000
[step=228] episode=228.0000 return=-115.9785 length=20.0000 global_step=5671.0000 loss=9.4876 policy_loss=-0.0000 value_loss=18.9752 entropy=0.0000
[step=229] episode=229.0000 return=-115.9767 length=22.0000 global_step=5693.0000 loss=14.4082 policy_loss=-0.0000 value_loss=28.8163 entropy=0.0000
[step=230] episode=230.0000 return=-115.9958 length=20.0000 global_step=5713.0000 loss=34.2179 policy_loss=-0.0000 value_loss=68.4359 entropy=0.0000
[step=231] episode=231.0000 return=-115.9837 length=19.0000 global_step=5732.0000 loss=33.5916 policy_loss=-0.0000 value_loss=67.1831 entropy=0.0000
[step=232] episode=232.0000 return=-115.9326 length=25.0000 global_step=5757.0000 loss=11.6073 policy_loss=-0.0000 value_loss=23.2147 entropy=0.0000
[step=233] episode=233.0000 return=-115.9963 length=30.0000 global_step=5787.0000 loss=16.6309 policy_loss=-0.0000 value_loss=33.2618 entropy=0.0000
[step=234] episode=234.0000 return=-115.9947 length=28.0000 global_step=5815.0000 loss=9.6760 policy_loss=-0.0000 value_loss=19.3519 entropy=0.0000
[step=235] episode=235.0000 return=-115.9914 length=41.0000 global_step=5856.0000 loss=47.6726 policy_loss=-0.0000 value_loss=95.3453 entropy=0.0000
[step=236] episode=236.0000 return=-115.9948 length=27.0000 global_step=5883.0000 loss=14.1201 policy_loss=-0.0000 value_loss=28.2402 entropy=0.0000
[step=237] episode=237.0000 return=-115.9993 length=21.0000 global_step=5904.0000 loss=41.3180 policy_loss=-0.0000 value_loss=82.6359 entropy=0.0000
[step=238] episode=238.0000 return=-115.9707 length=20.0000 global_step=5924.0000 loss=62.1124 policy_loss=-0.0000 value_loss=124.2248 entropy=0.0000
[step=239] episode=239.0000 return=-115.8168 length=13.0000 global_step=5937.0000 loss=134.6545 policy_loss=-0.0000 value_loss=269.3091 entropy=0.0000
[step=240] episode=240.0000 return=-115.9968 length=19.0000 global_step=5956.0000 loss=34.1851 policy_loss=-0.0000 value_loss=68.3702 entropy=0.0000
[step=241] episode=241.0000 return=-115.9891 length=21.0000 global_step=5977.0000 loss=9.8994 policy_loss=-0.0000 value_loss=19.7989 entropy=0.0000
[step=242] episode=242.0000 return=-115.9988 length=35.0000 global_step=6012.0000 loss=130.7022 policy_loss=-0.0000 value_loss=261.4043 entropy=0.0000
[step=243] episode=243.0000 return=-115.9968 length=26.0000 global_step=6038.0000 loss=107.6744 policy_loss=-0.0000 value_loss=215.3489 entropy=0.0000
[step=244] episode=244.0000 return=-115.9968 length=26.0000 global_step=6064.0000 loss=126.3802 policy_loss=-0.0000 value_loss=252.7604 entropy=0.0000
[step=245] episode=245.0000 return=-116.0000 length=34.0000 global_step=6098.0000 loss=146.7518 policy_loss=-0.0000 value_loss=293.5036 entropy=0.0000
[step=246] episode=246.0000 return=-115.7611 length=11.0000 global_step=6109.0000 loss=11.8252 policy_loss=-0.0000 value_loss=23.6505 entropy=0.0000
[step=247] episode=247.0000 return=-115.9961 length=13.0000 global_step=6122.0000 loss=18.3304 policy_loss=-0.0000 value_loss=36.6608 entropy=0.0000
[step=248] episode=248.0000 return=-115.9781 length=20.0000 global_step=6142.0000 loss=14.6808 policy_loss=-0.0000 value_loss=29.3615 entropy=0.0000
[step=249] episode=249.0000 return=-115.9997 length=28.0000 global_step=6170.0000 loss=7.7100 policy_loss=-0.0000 value_loss=15.4199 entropy=0.0000
[step=250] episode=250.0000 return=-115.9949 length=28.0000 global_step=6198.0000 loss=19.9151 policy_loss=-0.0000 value_loss=39.8302 entropy=0.0000
[step=251] episode=251.0000 return=-115.9652 length=22.0000 global_step=6220.0000 loss=40.8382 policy_loss=-0.0000 value_loss=81.6764 entropy=0.0000
[step=252] episode=252.0000 return=-115.9690 length=48.0000 global_step=6268.0000 loss=26.3664 policy_loss=-0.0000 value_loss=52.7329 entropy=0.0000
[step=253] episode=253.0000 return=-115.9975 length=19.0000 global_step=6287.0000 loss=93.4739 policy_loss=-0.0000 value_loss=186.9478 entropy=0.0000
[step=254] episode=254.0000 return=-115.9942 length=28.0000 global_step=6315.0000 loss=27.6722 policy_loss=-0.0000 value_loss=55.3444 entropy=0.0000
[step=255] episode=255.0000 return=-115.9791 length=12.0000 global_step=6327.0000 loss=78.7326 policy_loss=-0.0000 value_loss=157.4652 entropy=0.0000
[step=256] episode=256.0000 return=-115.9145 length=21.0000 global_step=6348.0000 loss=17.1276 policy_loss=-0.0000 value_loss=34.2551 entropy=0.0000
[step=257] episode=257.0000 return=-115.9948 length=20.0000 global_step=6368.0000 loss=34.2614 policy_loss=-0.0000 value_loss=68.5227 entropy=0.0000
[step=258] episode=258.0000 return=-115.9968 length=28.0000 global_step=6396.0000 loss=44.7370 policy_loss=-0.0000 value_loss=89.4740 entropy=0.0000
[step=259] episode=259.0000 return=-115.9952 length=28.0000 global_step=6424.0000 loss=60.3146 policy_loss=-0.0000 value_loss=120.6292 entropy=0.0000
[step=260] episode=260.0000 return=-115.9771 length=21.0000 global_step=6445.0000 loss=8.0792 policy_loss=-0.0000 value_loss=16.1584 entropy=0.0000
[step=261] episode=261.0000 return=-115.8668 length=18.0000 global_step=6463.0000 loss=26.6084 policy_loss=-0.0000 value_loss=53.2168 entropy=0.0000
[step=262] episode=262.0000 return=-115.9840 length=29.0000 global_step=6492.0000 loss=22.0624 policy_loss=-0.0000 value_loss=44.1249 entropy=0.0000
[step=263] episode=263.0000 return=-115.9926 length=28.0000 global_step=6520.0000 loss=23.9891 policy_loss=-0.0000 value_loss=47.9782 entropy=0.0000
[step=264] episode=264.0000 return=-115.9824 length=12.0000 global_step=6532.0000 loss=93.9559 policy_loss=-0.0000 value_loss=187.9119 entropy=0.0000
[step=265] episode=265.0000 return=-115.9996 length=20.0000 global_step=6552.0000 loss=12.2201 policy_loss=-0.0000 value_loss=24.4403 entropy=0.0000
[step=266] episode=266.0000 return=-115.9999 length=38.0000 global_step=6590.0000 loss=117.4597 policy_loss=-0.0000 value_loss=234.9193 entropy=0.0000
[step=267] episode=267.0000 return=-115.9096 length=26.0000 global_step=6616.0000 loss=44.3740 policy_loss=-0.0000 value_loss=88.7480 entropy=0.0000
[step=268] episode=268.0000 return=-115.9737 length=19.0000 global_step=6635.0000 loss=49.1733 policy_loss=-0.0000 value_loss=98.3466 entropy=0.0000
[step=269] episode=269.0000 return=-115.9968 length=26.0000 global_step=6661.0000 loss=53.5261 policy_loss=-0.0000 value_loss=107.0522 entropy=0.0000
[step=270] episode=270.0000 return=-115.9977 length=36.0000 global_step=6697.0000 loss=41.9697 policy_loss=-0.0000 value_loss=83.9393 entropy=0.0000
[step=271] episode=271.0000 return=-115.9770 length=13.0000 global_step=6710.0000 loss=80.5256 policy_loss=-0.0000 value_loss=161.0512 entropy=0.0000
[step=272] episode=272.0000 return=-115.7558 length=13.0000 global_step=6723.0000 loss=123.5272 policy_loss=-0.0000 value_loss=247.0544 entropy=0.0000
a2c_tuned train:   9%|‚ñâ         | 273/3000 [07:37<1:10:31,  1.55s/it]a2c_tuned train:   9%|‚ñâ         | 274/3000 [07:38<1:08:00,  1.50s/it]a2c_tuned train:   9%|‚ñâ         | 275/3000 [07:39<59:08,  1.30s/it]  a2c_tuned train:   9%|‚ñâ         | 276/3000 [07:40<59:38,  1.31s/it]a2c_tuned train:   9%|‚ñâ         | 277/3000 [07:42<1:08:02,  1.50s/it]a2c_tuned train:   9%|‚ñâ         | 278/3000 [07:44<1:13:54,  1.63s/it]a2c_tuned train:   9%|‚ñâ         | 279/3000 [07:45<1:03:05,  1.39s/it]a2c_tuned train:   9%|‚ñâ         | 280/3000 [07:47<1:09:34,  1.53s/it]a2c_tuned train:   9%|‚ñâ         | 281/3000 [07:48<1:06:45,  1.47s/it]a2c_tuned train:   9%|‚ñâ         | 282/3000 [07:50<1:04:16,  1.42s/it]a2c_tuned train:   9%|‚ñâ         | 283/3000 [07:50<55:16,  1.22s/it]  a2c_tuned train:   9%|‚ñâ         | 284/3000 [07:52<58:48,  1.30s/it]a2c_tuned train:  10%|‚ñâ         | 285/3000 [07:54<1:08:50,  1.52s/it]a2c_tuned train:  10%|‚ñâ         | 286/3000 [07:56<1:14:32,  1.65s/it]a2c_tuned train:  10%|‚ñâ         | 287/3000 [07:58<1:20:19,  1.78s/it]a2c_tuned train:  10%|‚ñâ         | 288/3000 [08:00<1:29:44,  1.99s/it]a2c_tuned train:  10%|‚ñâ         | 289/3000 [08:02<1:20:00,  1.77s/it]a2c_tuned train:  10%|‚ñâ         | 290/3000 [08:04<1:20:38,  1.79s/it]a2c_tuned train:  10%|‚ñâ         | 291/3000 [08:06<1:31:53,  2.04s/it]a2c_tuned train:  10%|‚ñâ         | 292/3000 [08:07<1:14:58,  1.66s/it]a2c_tuned train:  10%|‚ñâ         | 293/3000 [08:09<1:26:58,  1.93s/it]a2c_tuned train:  10%|‚ñâ         | 294/3000 [08:10<1:12:41,  1.61s/it]a2c_tuned train:  10%|‚ñâ         | 295/3000 [08:12<1:18:39,  1.74s/it]a2c_tuned train:  10%|‚ñâ         | 296/3000 [08:14<1:11:46,  1.59s/it]a2c_tuned train:  10%|‚ñâ         | 297/3000 [08:15<1:09:52,  1.55s/it]a2c_tuned train:  10%|‚ñâ         | 298/3000 [08:16<1:01:13,  1.36s/it]a2c_tuned train:  10%|‚ñâ         | 299/3000 [08:17<1:00:09,  1.34s/it]a2c_tuned train:  10%|‚ñà         | 300/3000 [08:19<1:00:54,  1.35s/it]a2c_tuned train:  10%|‚ñà         | 301/3000 [08:19<52:27,  1.17s/it]  a2c_tuned train:  10%|‚ñà         | 302/3000 [08:21<54:03,  1.20s/it]a2c_tuned train:  10%|‚ñà         | 303/3000 [08:22<56:28,  1.26s/it]a2c_tuned train:  10%|‚ñà         | 304/3000 [08:23<50:15,  1.12s/it]a2c_tuned train:  10%|‚ñà         | 305/3000 [08:25<1:07:41,  1.51s/it]a2c_tuned train:  10%|‚ñà         | 306/3000 [08:26<59:03,  1.32s/it]  a2c_tuned train:  10%|‚ñà         | 307/3000 [08:28<1:05:59,  1.47s/it]a2c_tuned train:  10%|‚ñà         | 308/3000 [08:29<1:05:57,  1.47s/it]a2c_tuned train:  10%|‚ñà         | 309/3000 [08:31<1:04:05,  1.43s/it]a2c_tuned train:  10%|‚ñà         | 310/3000 [08:32<55:57,  1.25s/it]  a2c_tuned train:  10%|‚ñà         | 311/3000 [08:33<57:54,  1.29s/it]a2c_tuned train:  10%|‚ñà         | 312/3000 [08:34<53:09,  1.19s/it]a2c_tuned train:  10%|‚ñà         | 313/3000 [08:36<1:02:10,  1.39s/it]a2c_tuned train:  10%|‚ñà         | 314/3000 [08:37<1:03:31,  1.42s/it]a2c_tuned train:  10%|‚ñà         | 315/3000 [08:40<1:17:15,  1.73s/it]a2c_tuned train:  11%|‚ñà         | 316/3000 [08:41<1:12:22,  1.62s/it]a2c_tuned train:  11%|‚ñà         | 317/3000 [08:44<1:27:03,  1.95s/it]a2c_tuned train:  11%|‚ñà         | 318/3000 [08:47<1:36:57,  2.17s/it]a2c_tuned train:  11%|‚ñà         | 319/3000 [08:49<1:40:59,  2.26s/it]a2c_tuned train:  11%|‚ñà         | 320/3000 [08:50<1:22:34,  1.85s/it]a2c_tuned train:  11%|‚ñà         | 321/3000 [08:52<1:23:08,  1.86s/it]a2c_tuned train:  11%|‚ñà         | 322/3000 [08:54<1:24:12,  1.89s/it]a2c_tuned train:  11%|‚ñà         | 323/3000 [08:55<1:15:10,  1.68s/it]a2c_tuned train:  11%|‚ñà         | 324/3000 [08:58<1:34:22,  2.12s/it]a2c_tuned train:  11%|‚ñà         | 325/3000 [08:59<1:24:09,  1.89s/it]a2c_tuned train:  11%|‚ñà         | 326/3000 [09:00<1:09:43,  1.56s/it][step=273] episode=273.0000 return=-115.9930 length=29.0000 global_step=6752.0000 loss=27.0876 policy_loss=-0.0000 value_loss=54.1752 entropy=0.0000
[step=274] episode=274.0000 return=-115.9998 length=20.0000 global_step=6772.0000 loss=38.8631 policy_loss=-0.0000 value_loss=77.7262 entropy=0.0000
[step=275] episode=275.0000 return=-115.9622 length=12.0000 global_step=6784.0000 loss=49.1410 policy_loss=-0.0000 value_loss=98.2821 entropy=0.0000
[step=276] episode=276.0000 return=-115.7610 length=20.0000 global_step=6804.0000 loss=3.0076 policy_loss=-0.0000 value_loss=6.0152 entropy=0.0000
[step=277] episode=277.0000 return=-115.9968 length=27.0000 global_step=6831.0000 loss=152.0771 policy_loss=-0.0000 value_loss=304.1543 entropy=0.0000
[step=278] episode=278.0000 return=-115.9958 length=29.0000 global_step=6860.0000 loss=291.7893 policy_loss=-0.0000 value_loss=583.5787 entropy=0.0000
[step=279] episode=279.0000 return=-115.8783 length=13.0000 global_step=6873.0000 loss=117.1220 policy_loss=-0.0000 value_loss=234.2440 entropy=0.0000
[step=280] episode=280.0000 return=-115.9955 length=28.0000 global_step=6901.0000 loss=257.1075 policy_loss=-0.0000 value_loss=514.2149 entropy=0.0000
[step=281] episode=281.0000 return=-115.9986 length=19.0000 global_step=6920.0000 loss=85.8408 policy_loss=-0.0000 value_loss=171.6816 entropy=0.0000
[step=282] episode=282.0000 return=-115.9709 length=19.0000 global_step=6939.0000 loss=13.4042 policy_loss=-0.0000 value_loss=26.8084 entropy=0.0000
[step=283] episode=283.0000 return=-115.7613 length=11.0000 global_step=6950.0000 loss=52.4793 policy_loss=-0.0000 value_loss=104.9585 entropy=0.0000
[step=284] episode=284.0000 return=-115.9988 length=22.0000 global_step=6972.0000 loss=37.9846 policy_loss=-0.0000 value_loss=75.9692 entropy=0.0000
[step=285] episode=285.0000 return=-115.9998 length=29.0000 global_step=7001.0000 loss=34.3051 policy_loss=-0.0000 value_loss=68.6102 entropy=0.0000
[step=286] episode=286.0000 return=-115.9971 length=28.0000 global_step=7029.0000 loss=51.3857 policy_loss=-0.0000 value_loss=102.7713 entropy=0.0000
[step=287] episode=287.0000 return=-115.9979 length=30.0000 global_step=7059.0000 loss=15.3677 policy_loss=-0.0000 value_loss=30.7354 entropy=0.0000
[step=288] episode=288.0000 return=-115.9999 length=37.0000 global_step=7096.0000 loss=44.5796 policy_loss=-0.0000 value_loss=89.1593 entropy=0.0000
[step=289] episode=289.0000 return=-115.8870 length=19.0000 global_step=7115.0000 loss=9.1421 policy_loss=-0.0000 value_loss=18.2842 entropy=0.0000
[step=290] episode=290.0000 return=-115.9960 length=27.0000 global_step=7142.0000 loss=51.3342 policy_loss=-0.0000 value_loss=102.6683 entropy=0.0000
[step=291] episode=291.0000 return=-115.9892 length=38.0000 global_step=7180.0000 loss=109.1720 policy_loss=-0.0000 value_loss=218.3440 entropy=0.0000
[step=292] episode=292.0000 return=-115.8850 length=11.0000 global_step=7191.0000 loss=11.9065 policy_loss=-0.0000 value_loss=23.8131 entropy=0.0000
[step=293] episode=293.0000 return=-115.9986 length=38.0000 global_step=7229.0000 loss=116.6468 policy_loss=-0.0000 value_loss=233.2935 entropy=0.0000
[step=294] episode=294.0000 return=-115.8141 length=13.0000 global_step=7242.0000 loss=14.3211 policy_loss=-0.0000 value_loss=28.6422 entropy=0.0000
[step=295] episode=295.0000 return=-115.9991 length=30.0000 global_step=7272.0000 loss=56.7467 policy_loss=-0.0000 value_loss=113.4935 entropy=0.0000
[step=296] episode=296.0000 return=-115.8870 length=18.0000 global_step=7290.0000 loss=9.6254 policy_loss=-0.0000 value_loss=19.2507 entropy=0.0000
[step=297] episode=297.0000 return=-115.9986 length=21.0000 global_step=7311.0000 loss=9.8787 policy_loss=-0.0000 value_loss=19.7573 entropy=0.0000
[step=298] episode=298.0000 return=-115.9624 length=14.0000 global_step=7325.0000 loss=44.1994 policy_loss=-0.0000 value_loss=88.3987 entropy=0.0000
[step=299] episode=299.0000 return=-115.8418 length=19.0000 global_step=7344.0000 loss=11.8414 policy_loss=-0.0000 value_loss=23.6828 entropy=0.0000
[step=300] episode=300.0000 return=-115.9925 length=20.0000 global_step=7364.0000 loss=10.2495 policy_loss=-0.0000 value_loss=20.4991 entropy=0.0000
[step=301] episode=301.0000 return=-115.7429 length=11.0000 global_step=7375.0000 loss=13.9834 policy_loss=-0.0000 value_loss=27.9668 entropy=0.0000
[step=302] episode=302.0000 return=-115.9609 length=19.0000 global_step=7394.0000 loss=26.5428 policy_loss=-0.0000 value_loss=53.0857 entropy=0.0000
[step=303] episode=303.0000 return=-115.9936 length=21.0000 global_step=7415.0000 loss=9.7597 policy_loss=-0.0000 value_loss=19.5193 entropy=0.0000
[step=304] episode=304.0000 return=-115.7229 length=11.0000 global_step=7426.0000 loss=10.6267 policy_loss=-0.0000 value_loss=21.2535 entropy=0.0000
[step=305] episode=305.0000 return=-115.9930 length=37.0000 global_step=7463.0000 loss=106.4428 policy_loss=-0.0000 value_loss=212.8856 entropy=0.0000
[step=306] episode=306.0000 return=-115.7583 length=12.0000 global_step=7475.0000 loss=17.5825 policy_loss=-0.0000 value_loss=35.1650 entropy=0.0000
[step=307] episode=307.0000 return=-115.9985 length=27.0000 global_step=7502.0000 loss=10.3688 policy_loss=-0.0000 value_loss=20.7375 entropy=0.0000
[step=308] episode=308.0000 return=-115.9096 length=22.0000 global_step=7524.0000 loss=10.9877 policy_loss=-0.0000 value_loss=21.9754 entropy=0.0000
[step=309] episode=309.0000 return=-115.9984 length=20.0000 global_step=7544.0000 loss=16.9316 policy_loss=-0.0000 value_loss=33.8633 entropy=0.0000
[step=310] episode=310.0000 return=-100.0000 length=11.0000 global_step=7555.0000 loss=21.7315 policy_loss=-0.0000 value_loss=43.4629 entropy=0.0000
[step=311] episode=311.0000 return=-115.9707 length=20.0000 global_step=7575.0000 loss=19.0630 policy_loss=-0.0000 value_loss=38.1261 entropy=0.0000
[step=312] episode=312.0000 return=-115.8305 length=13.0000 global_step=7588.0000 loss=28.6543 policy_loss=-0.0000 value_loss=57.3085 entropy=0.0000
[step=313] episode=313.0000 return=-115.9988 length=28.0000 global_step=7616.0000 loss=23.2788 policy_loss=-0.0000 value_loss=46.5576 entropy=0.0000
[step=314] episode=314.0000 return=-115.9385 length=21.0000 global_step=7637.0000 loss=29.0306 policy_loss=-0.0000 value_loss=58.0611 entropy=0.0000
[step=315] episode=315.0000 return=-115.9941 length=37.0000 global_step=7674.0000 loss=159.6870 policy_loss=-0.0000 value_loss=319.3740 entropy=0.0000
[step=316] episode=316.0000 return=-115.9840 length=20.0000 global_step=7694.0000 loss=11.3180 policy_loss=-0.0000 value_loss=22.6360 entropy=0.0000
[step=317] episode=317.0000 return=-115.9567 length=41.0000 global_step=7735.0000 loss=64.9759 policy_loss=-0.0000 value_loss=129.9518 entropy=0.0000
[step=318] episode=318.0000 return=-115.9981 length=41.0000 global_step=7776.0000 loss=22.7556 policy_loss=-0.0000 value_loss=45.5112 entropy=0.0000
[step=319] episode=319.0000 return=-115.9999 length=37.0000 global_step=7813.0000 loss=61.3142 policy_loss=-0.0000 value_loss=122.6284 entropy=0.0000
[step=320] episode=320.0000 return=-115.8162 length=13.0000 global_step=7826.0000 loss=381.0250 policy_loss=-0.0000 value_loss=762.0499 entropy=0.0000
[step=321] episode=321.0000 return=-115.9781 length=28.0000 global_step=7854.0000 loss=187.5354 policy_loss=-0.0000 value_loss=375.0707 entropy=0.0000
[step=322] episode=322.0000 return=-115.9975 length=29.0000 global_step=7883.0000 loss=172.7965 policy_loss=-0.0000 value_loss=345.5930 entropy=0.0000
[step=323] episode=323.0000 return=-115.8643 length=18.0000 global_step=7901.0000 loss=210.5337 policy_loss=-0.0000 value_loss=421.0674 entropy=0.0000
[step=324] episode=324.0000 return=-115.9947 length=46.0000 global_step=7947.0000 loss=40.3703 policy_loss=-0.0000 value_loss=80.7407 entropy=0.0000
[step=325] episode=325.0000 return=-115.9764 length=20.0000 global_step=7967.0000 loss=21.3263 policy_loss=-0.0000 value_loss=42.6526 entropy=0.0000
[step=326] episode=326.0000 return=-115.7313 length=12.0000 global_step=7979.0000 loss=12.5287 policy_loss=-0.0000 value_loss=25.0573 entropy=0.0000
a2c_tuned train:  11%|‚ñà         | 327/3000 [09:02<1:05:55,  1.48s/it]a2c_tuned train:  11%|‚ñà         | 328/3000 [09:02<56:30,  1.27s/it]  a2c_tuned train:  11%|‚ñà         | 329/3000 [09:04<57:09,  1.28s/it]a2c_tuned train:  11%|‚ñà         | 330/3000 [09:05<52:06,  1.17s/it]a2c_tuned train:  11%|‚ñà         | 331/3000 [09:05<48:35,  1.09s/it]a2c_tuned train:  11%|‚ñà         | 332/3000 [09:06<45:35,  1.03s/it]a2c_tuned train:  11%|‚ñà         | 333/3000 [09:07<42:21,  1.05it/s]a2c_tuned train:  11%|‚ñà         | 334/3000 [09:10<1:01:58,  1.39s/it]a2c_tuned train:  11%|‚ñà         | 335/3000 [09:11<1:02:10,  1.40s/it]a2c_tuned train:  11%|‚ñà         | 336/3000 [09:13<1:15:27,  1.70s/it]a2c_tuned train:  11%|‚ñà         | 337/3000 [09:16<1:24:31,  1.90s/it]a2c_tuned train:  11%|‚ñà‚ñè        | 338/3000 [09:19<1:39:18,  2.24s/it]a2c_tuned train:  11%|‚ñà‚ñè        | 339/3000 [09:20<1:28:36,  2.00s/it]a2c_tuned train:  11%|‚ñà‚ñè        | 340/3000 [09:22<1:21:04,  1.83s/it]a2c_tuned train:  11%|‚ñà‚ñè        | 341/3000 [09:23<1:15:27,  1.70s/it]a2c_tuned train:  11%|‚ñà‚ñè        | 342/3000 [09:24<1:09:31,  1.57s/it]a2c_tuned train:  11%|‚ñà‚ñè        | 343/3000 [09:26<1:14:49,  1.69s/it]a2c_tuned train:  11%|‚ñà‚ñè        | 344/3000 [09:29<1:24:24,  1.91s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 345/3000 [09:30<1:10:32,  1.59s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 346/3000 [09:31<1:11:50,  1.62s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 347/3000 [09:34<1:23:44,  1.89s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 348/3000 [09:35<1:16:09,  1.72s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 349/3000 [09:36<1:04:23,  1.46s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 350/3000 [09:37<55:01,  1.25s/it]  a2c_tuned train:  12%|‚ñà‚ñè        | 351/3000 [09:38<1:00:57,  1.38s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 352/3000 [09:40<1:09:44,  1.58s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 353/3000 [09:41<59:24,  1.35s/it]  a2c_tuned train:  12%|‚ñà‚ñè        | 354/3000 [09:43<1:05:01,  1.47s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 355/3000 [09:44<1:04:30,  1.46s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 356/3000 [09:46<1:11:33,  1.62s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 357/3000 [09:48<1:06:45,  1.52s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 358/3000 [09:49<1:05:03,  1.48s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 359/3000 [09:50<1:04:24,  1.46s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 360/3000 [09:51<49:48,  1.13s/it]  a2c_tuned train:  12%|‚ñà‚ñè        | 361/3000 [09:54<1:18:40,  1.79s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 362/3000 [09:55<1:11:28,  1.63s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 363/3000 [09:56<1:02:06,  1.41s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 364/3000 [09:58<1:00:54,  1.39s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 365/3000 [10:00<1:08:21,  1.56s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 366/3000 [10:01<1:12:18,  1.65s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 367/3000 [10:03<1:09:04,  1.57s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 368/3000 [10:05<1:21:09,  1.85s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 369/3000 [10:09<1:39:26,  2.27s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 370/3000 [10:11<1:42:11,  2.33s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 371/3000 [10:12<1:21:28,  1.86s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 372/3000 [10:13<1:06:45,  1.52s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 373/3000 [10:14<1:04:43,  1.48s/it]a2c_tuned train:  12%|‚ñà‚ñè        | 374/3000 [10:15<56:40,  1.30s/it]  a2c_tuned train:  12%|‚ñà‚ñé        | 375/3000 [10:16<58:11,  1.33s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 376/3000 [10:19<1:11:27,  1.63s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 377/3000 [10:20<1:14:24,  1.70s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 378/3000 [10:21<1:03:49,  1.46s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 379/3000 [10:22<55:15,  1.26s/it]  a2c_tuned train:  13%|‚ñà‚ñé        | 380/3000 [10:24<1:04:20,  1.47s/it][step=327] episode=327.0000 return=-115.9967 length=19.0000 global_step=7998.0000 loss=160.4505 policy_loss=-0.0000 value_loss=320.9010 entropy=0.0000
[step=328] episode=328.0000 return=-115.9987 length=11.0000 global_step=8009.0000 loss=236.3896 policy_loss=-0.0000 value_loss=472.7792 entropy=0.0000
[step=329] episode=329.0000 return=-115.9849 length=20.0000 global_step=8029.0000 loss=448.5037 policy_loss=-0.0000 value_loss=897.0074 entropy=0.0000
[step=330] episode=330.0000 return=-115.8795 length=13.0000 global_step=8042.0000 loss=285.3775 policy_loss=-0.0000 value_loss=570.7550 entropy=0.0000
[step=331] episode=331.0000 return=-115.7525 length=13.0000 global_step=8055.0000 loss=177.8442 policy_loss=-0.0000 value_loss=355.6885 entropy=0.0000
[step=332] episode=332.0000 return=-115.8463 length=12.0000 global_step=8067.0000 loss=62.6118 policy_loss=-0.0000 value_loss=125.2237 entropy=0.0000
[step=333] episode=333.0000 return=-115.9617 length=12.0000 global_step=8079.0000 loss=11.8136 policy_loss=-0.0000 value_loss=23.6272 entropy=0.0000
[step=334] episode=334.0000 return=-115.9941 length=36.0000 global_step=8115.0000 loss=12.8718 policy_loss=-0.0000 value_loss=25.7437 entropy=0.0000
[step=335] episode=335.0000 return=-115.9879 length=21.0000 global_step=8136.0000 loss=131.3277 policy_loss=-0.0000 value_loss=262.6553 entropy=0.0000
[step=336] episode=336.0000 return=-115.9941 length=37.0000 global_step=8173.0000 loss=125.7234 policy_loss=-0.0000 value_loss=251.4467 entropy=0.0000
[step=337] episode=337.0000 return=-115.9837 length=34.0000 global_step=8207.0000 loss=203.4507 policy_loss=-0.0000 value_loss=406.9014 entropy=0.0000
[step=338] episode=338.0000 return=-115.9874 length=45.0000 global_step=8252.0000 loss=160.5784 policy_loss=-0.0000 value_loss=321.1568 entropy=0.0000
[step=339] episode=339.0000 return=-115.9792 length=20.0000 global_step=8272.0000 loss=327.8377 policy_loss=-0.0000 value_loss=655.6754 entropy=0.0000
[step=340] episode=340.0000 return=-115.9673 length=20.0000 global_step=8292.0000 loss=235.3210 policy_loss=-0.0000 value_loss=470.6421 entropy=0.0000
[step=341] episode=341.0000 return=-115.9676 length=20.0000 global_step=8312.0000 loss=107.5306 policy_loss=-0.0000 value_loss=215.0612 entropy=0.0000
[step=342] episode=342.0000 return=-115.8030 length=19.0000 global_step=8331.0000 loss=40.3189 policy_loss=-0.0000 value_loss=80.6377 entropy=0.0000
[step=343] episode=343.0000 return=-115.9829 length=29.0000 global_step=8360.0000 loss=52.2380 policy_loss=-0.0000 value_loss=104.4760 entropy=0.0000
[step=344] episode=344.0000 return=-115.9999 length=36.0000 global_step=8396.0000 loss=235.9200 policy_loss=-0.0000 value_loss=471.8400 entropy=0.0000
[step=345] episode=345.0000 return=-115.9926 length=12.0000 global_step=8408.0000 loss=100.0714 policy_loss=-0.0000 value_loss=200.1429 entropy=0.0000
[step=346] episode=346.0000 return=-115.9887 length=26.0000 global_step=8434.0000 loss=266.2514 policy_loss=-0.0000 value_loss=532.5027 entropy=0.0000
[step=347] episode=347.0000 return=-115.9972 length=37.0000 global_step=8471.0000 loss=237.8211 policy_loss=-0.0000 value_loss=475.6422 entropy=0.0000
[step=348] episode=348.0000 return=-115.9914 length=19.0000 global_step=8490.0000 loss=30.5524 policy_loss=-0.0000 value_loss=61.1048 entropy=0.0000
[step=349] episode=349.0000 return=-115.9825 length=12.0000 global_step=8502.0000 loss=26.3184 policy_loss=-0.0000 value_loss=52.6369 entropy=0.0000
[step=350] episode=350.0000 return=-115.7005 length=11.0000 global_step=8513.0000 loss=60.8452 policy_loss=-0.0000 value_loss=121.6903 entropy=0.0000
[step=351] episode=351.0000 return=-115.9570 length=26.0000 global_step=8539.0000 loss=19.2922 policy_loss=-0.0000 value_loss=38.5843 entropy=0.0000
[step=352] episode=352.0000 return=-115.9801 length=30.0000 global_step=8569.0000 loss=14.9036 policy_loss=-0.0000 value_loss=29.8073 entropy=0.0000
[step=353] episode=353.0000 return=-115.9997 length=12.0000 global_step=8581.0000 loss=42.0778 policy_loss=-0.0000 value_loss=84.1556 entropy=0.0000
[step=354] episode=354.0000 return=-115.9925 length=27.0000 global_step=8608.0000 loss=40.1479 policy_loss=-0.0000 value_loss=80.2958 entropy=0.0000
[step=355] episode=355.0000 return=-115.9384 length=22.0000 global_step=8630.0000 loss=16.3385 policy_loss=-0.0000 value_loss=32.6770 entropy=0.0000
[step=356] episode=356.0000 return=-115.9996 length=30.0000 global_step=8660.0000 loss=66.5108 policy_loss=-0.0000 value_loss=133.0216 entropy=0.0000
[step=357] episode=357.0000 return=-115.9974 length=20.0000 global_step=8680.0000 loss=12.8239 policy_loss=-0.0000 value_loss=25.6477 entropy=0.0000
[step=358] episode=358.0000 return=-115.9501 length=20.0000 global_step=8700.0000 loss=15.7105 policy_loss=-0.0000 value_loss=31.4211 entropy=0.0000
[step=359] episode=359.0000 return=-115.9999 length=21.0000 global_step=8721.0000 loss=23.0426 policy_loss=-0.0000 value_loss=46.0853 entropy=0.0000
[step=360] episode=360.0000 return=-112.8160 length=5.0000 global_step=8726.0000 loss=191.8238 policy_loss=-0.0000 value_loss=383.6475 entropy=0.0000
[step=361] episode=361.0000 return=-115.9876 length=47.0000 global_step=8773.0000 loss=91.8285 policy_loss=-0.0000 value_loss=183.6569 entropy=0.0000
[step=362] episode=362.0000 return=-115.8644 length=18.0000 global_step=8791.0000 loss=12.9725 policy_loss=-0.0000 value_loss=25.9450 entropy=0.0000
[step=363] episode=363.0000 return=-115.9972 length=12.0000 global_step=8803.0000 loss=20.9431 policy_loss=-0.0000 value_loss=41.8862 entropy=0.0000
[step=364] episode=364.0000 return=-115.7409 length=20.0000 global_step=8823.0000 loss=23.7334 policy_loss=-0.0000 value_loss=47.4668 entropy=0.0000
[step=365] episode=365.0000 return=-115.9096 length=29.0000 global_step=8852.0000 loss=110.9394 policy_loss=-0.0000 value_loss=221.8788 entropy=0.0000
[step=366] episode=366.0000 return=-115.9573 length=29.0000 global_step=8881.0000 loss=79.1294 policy_loss=-0.0000 value_loss=158.2589 entropy=0.0000
[step=367] episode=367.0000 return=-115.8866 length=21.0000 global_step=8902.0000 loss=4.2210 policy_loss=-0.0000 value_loss=8.4420 entropy=0.0000
[step=368] episode=368.0000 return=-115.9992 length=36.0000 global_step=8938.0000 loss=44.8454 policy_loss=-0.0000 value_loss=89.6909 entropy=0.0000
[step=369] episode=369.0000 return=-115.9988 length=48.0000 global_step=8986.0000 loss=44.3635 policy_loss=-0.0000 value_loss=88.7270 entropy=0.0000
[step=370] episode=370.0000 return=-115.9975 length=36.0000 global_step=9022.0000 loss=85.6028 policy_loss=-0.0000 value_loss=171.2056 entropy=0.0000
[step=371] episode=371.0000 return=-115.9969 length=11.0000 global_step=9033.0000 loss=429.7120 policy_loss=-0.0000 value_loss=859.4240 entropy=0.0000
[step=372] episode=372.0000 return=-115.9949 length=11.0000 global_step=9044.0000 loss=480.8102 policy_loss=-0.0000 value_loss=961.6204 entropy=0.0000
[step=373] episode=373.0000 return=-115.9990 length=20.0000 global_step=9064.0000 loss=272.5259 policy_loss=-0.0000 value_loss=545.0518 entropy=0.0000
[step=374] episode=374.0000 return=-115.8046 length=13.0000 global_step=9077.0000 loss=310.7867 policy_loss=-0.0000 value_loss=621.5734 entropy=0.0000
[step=375] episode=375.0000 return=-115.9880 length=21.0000 global_step=9098.0000 loss=132.6844 policy_loss=-0.0000 value_loss=265.3688 entropy=0.0000
[step=376] episode=376.0000 return=-115.9986 length=35.0000 global_step=9133.0000 loss=8.5569 policy_loss=-0.0000 value_loss=17.1137 entropy=0.0000
[step=377] episode=377.0000 return=-115.9610 length=28.0000 global_step=9161.0000 loss=22.2291 policy_loss=-0.0000 value_loss=44.4583 entropy=0.0000
[step=378] episode=378.0000 return=-115.7966 length=13.0000 global_step=9174.0000 loss=9.4587 policy_loss=-0.0000 value_loss=18.9174 entropy=0.0000
[step=379] episode=379.0000 return=-115.8378 length=11.0000 global_step=9185.0000 loss=15.7559 policy_loss=-0.0000 value_loss=31.5119 entropy=0.0000
[step=380] episode=380.0000 return=-115.9929 length=29.0000 global_step=9214.0000 loss=36.7119 policy_loss=-0.0000 value_loss=73.4239 entropy=0.0000
a2c_tuned train:  13%|‚ñà‚ñé        | 381/3000 [10:25<55:30,  1.27s/it]  a2c_tuned train:  13%|‚ñà‚ñé        | 382/3000 [10:26<57:16,  1.31s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 383/3000 [10:28<57:38,  1.32s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 384/3000 [10:29<1:04:01,  1.47s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 385/3000 [10:30<57:23,  1.32s/it]  a2c_tuned train:  13%|‚ñà‚ñé        | 386/3000 [10:31<50:57,  1.17s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 387/3000 [10:34<1:12:26,  1.66s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 388/3000 [10:35<1:00:50,  1.40s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 389/3000 [10:37<1:15:26,  1.73s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 390/3000 [10:39<1:13:06,  1.68s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 391/3000 [10:41<1:16:17,  1.75s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 392/3000 [10:42<1:11:44,  1.65s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 393/3000 [10:45<1:20:46,  1.86s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 394/3000 [10:47<1:22:57,  1.91s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 395/3000 [10:48<1:22:26,  1.90s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 396/3000 [10:51<1:30:05,  2.08s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 397/3000 [10:54<1:36:00,  2.21s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 398/3000 [10:55<1:25:02,  1.96s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 399/3000 [10:56<1:16:16,  1.76s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 400/3000 [10:58<1:11:41,  1.65s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 401/3000 [10:59<1:07:25,  1.56s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 402/3000 [10:59<51:42,  1.19s/it]  a2c_tuned train:  13%|‚ñà‚ñé        | 403/3000 [11:00<48:04,  1.11s/it]a2c_tuned train:  13%|‚ñà‚ñé        | 404/3000 [11:03<1:15:05,  1.74s/it]a2c_tuned train:  14%|‚ñà‚ñé        | 405/3000 [11:05<1:09:44,  1.61s/it]a2c_tuned train:  14%|‚ñà‚ñé        | 406/3000 [11:07<1:22:38,  1.91s/it]a2c_tuned train:  14%|‚ñà‚ñé        | 407/3000 [11:09<1:21:06,  1.88s/it]a2c_tuned train:  14%|‚ñà‚ñé        | 408/3000 [11:12<1:28:22,  2.05s/it]a2c_tuned train:  14%|‚ñà‚ñé        | 409/3000 [11:13<1:18:28,  1.82s/it]a2c_tuned train:  14%|‚ñà‚ñé        | 410/3000 [11:15<1:17:30,  1.80s/it]a2c_tuned train:  14%|‚ñà‚ñé        | 411/3000 [11:16<1:13:00,  1.69s/it]a2c_tuned train:  14%|‚ñà‚ñé        | 412/3000 [11:18<1:15:44,  1.76s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 413/3000 [11:19<1:09:38,  1.62s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 414/3000 [11:20<1:01:08,  1.42s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 415/3000 [11:23<1:13:31,  1.71s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 416/3000 [11:23<1:01:45,  1.43s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 417/3000 [11:25<1:08:43,  1.60s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 418/3000 [11:27<1:05:53,  1.53s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 419/3000 [11:28<56:51,  1.32s/it]  a2c_tuned train:  14%|‚ñà‚ñç        | 420/3000 [11:29<1:04:50,  1.51s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 421/3000 [11:32<1:15:53,  1.77s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 422/3000 [11:33<1:09:12,  1.61s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 423/3000 [11:34<58:40,  1.37s/it]  a2c_tuned train:  14%|‚ñà‚ñç        | 424/3000 [11:37<1:18:12,  1.82s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 425/3000 [11:38<1:11:42,  1.67s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 426/3000 [11:40<1:09:56,  1.63s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 427/3000 [11:41<1:07:16,  1.57s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 428/3000 [11:41<51:08,  1.19s/it]  a2c_tuned train:  14%|‚ñà‚ñç        | 429/3000 [11:43<53:30,  1.25s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 430/3000 [11:44<48:30,  1.13s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 431/3000 [11:46<1:07:46,  1.58s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 432/3000 [11:48<1:06:06,  1.54s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 433/3000 [11:50<1:18:09,  1.83s/it]a2c_tuned train:  14%|‚ñà‚ñç        | 434/3000 [11:52<1:18:54,  1.84s/it][step=381] episode=381.0000 return=-115.9948 length=12.0000 global_step=9226.0000 loss=17.3084 policy_loss=-0.0000 value_loss=34.6167 entropy=0.0000
[step=382] episode=382.0000 return=-115.9968 length=21.0000 global_step=9247.0000 loss=9.3971 policy_loss=-0.0000 value_loss=18.7942 entropy=0.0000
[step=383] episode=383.0000 return=-115.9854 length=20.0000 global_step=9267.0000 loss=14.1690 policy_loss=-0.0000 value_loss=28.3381 entropy=0.0000
[step=384] episode=384.0000 return=-115.9989 length=27.0000 global_step=9294.0000 loss=13.2456 policy_loss=-0.0000 value_loss=26.4913 entropy=0.0000
[step=385] episode=385.0000 return=-115.8188 length=13.0000 global_step=9307.0000 loss=59.9641 policy_loss=-0.0000 value_loss=119.9282 entropy=0.0000
[step=386] episode=386.0000 return=-115.9951 length=13.0000 global_step=9320.0000 loss=38.7740 policy_loss=-0.0000 value_loss=77.5481 entropy=0.0000
[step=387] episode=387.0000 return=-115.9986 length=41.0000 global_step=9361.0000 loss=98.1903 policy_loss=-0.0000 value_loss=196.3807 entropy=0.0000
[step=388] episode=388.0000 return=-115.9995 length=11.0000 global_step=9372.0000 loss=15.0131 policy_loss=-0.0000 value_loss=30.0263 entropy=0.0000
[step=389] episode=389.0000 return=-115.9840 length=37.0000 global_step=9409.0000 loss=99.5139 policy_loss=-0.0000 value_loss=199.0277 entropy=0.0000
[step=390] episode=390.0000 return=-115.8289 length=21.0000 global_step=9430.0000 loss=13.7503 policy_loss=-0.0000 value_loss=27.5006 entropy=0.0000
[step=391] episode=391.0000 return=-115.9964 length=28.0000 global_step=9458.0000 loss=61.9240 policy_loss=-0.0000 value_loss=123.8480 entropy=0.0000
[step=392] episode=392.0000 return=-115.9502 length=21.0000 global_step=9479.0000 loss=5.4431 policy_loss=-0.0000 value_loss=10.8861 entropy=0.0000
[step=393] episode=393.0000 return=-115.9986 length=34.0000 global_step=9513.0000 loss=18.9713 policy_loss=-0.0000 value_loss=37.9425 entropy=0.0000
[step=394] episode=394.0000 return=-115.9978 length=29.0000 global_step=9542.0000 loss=41.6761 policy_loss=-0.0000 value_loss=83.3521 entropy=0.0000
[step=395] episode=395.0000 return=-115.9993 length=27.0000 global_step=9569.0000 loss=83.4170 policy_loss=-0.0000 value_loss=166.8341 entropy=0.0000
[step=396] episode=396.0000 return=-115.9482 length=37.0000 global_step=9606.0000 loss=102.3699 policy_loss=-0.0000 value_loss=204.7398 entropy=0.0000
[step=397] episode=397.0000 return=-115.9819 length=36.0000 global_step=9642.0000 loss=60.3141 policy_loss=-0.0000 value_loss=120.6282 entropy=0.0000
[step=398] episode=398.0000 return=-115.9071 length=21.0000 global_step=9663.0000 loss=156.6638 policy_loss=-0.0000 value_loss=313.3276 entropy=0.0000
[step=399] episode=399.0000 return=-115.8309 length=20.0000 global_step=9683.0000 loss=87.4639 policy_loss=-0.0000 value_loss=174.9279 entropy=0.0000
[step=400] episode=400.0000 return=-115.9947 length=20.0000 global_step=9703.0000 loss=9.3791 policy_loss=-0.0000 value_loss=18.7582 entropy=0.0000
[step=401] episode=401.0000 return=-115.9925 length=20.0000 global_step=9723.0000 loss=21.1191 policy_loss=-0.0000 value_loss=42.2381 entropy=0.0000
[step=402] episode=402.0000 return=-115.7355 length=5.0000 global_step=9728.0000 loss=67.0429 policy_loss=-0.0000 value_loss=134.0858 entropy=0.0000
[step=403] episode=403.0000 return=-115.9890 length=13.0000 global_step=9741.0000 loss=29.7123 policy_loss=-0.0000 value_loss=59.4246 entropy=0.0000
[step=404] episode=404.0000 return=-116.0000 length=47.0000 global_step=9788.0000 loss=359.9087 policy_loss=-0.0000 value_loss=719.8174 entropy=0.0000
[step=405] episode=405.0000 return=-115.9920 length=19.0000 global_step=9807.0000 loss=69.8715 policy_loss=-0.0000 value_loss=139.7430 entropy=0.0000
[step=406] episode=406.0000 return=-115.9934 length=38.0000 global_step=9845.0000 loss=86.6037 policy_loss=-0.0000 value_loss=173.2075 entropy=0.0000
[step=407] episode=407.0000 return=-115.9986 length=27.0000 global_step=9872.0000 loss=10.7217 policy_loss=-0.0000 value_loss=21.4434 entropy=0.0000
[step=408] episode=408.0000 return=-116.0000 length=37.0000 global_step=9909.0000 loss=15.4836 policy_loss=-0.0000 value_loss=30.9671 entropy=0.0000
[step=409] episode=409.0000 return=-115.8939 length=19.0000 global_step=9928.0000 loss=95.2418 policy_loss=-0.0000 value_loss=190.4836 entropy=0.0000
[step=410] episode=410.0000 return=-115.9921 length=25.0000 global_step=9953.0000 loss=73.4322 policy_loss=-0.0000 value_loss=146.8643 entropy=0.0000
[step=411] episode=411.0000 return=-115.8260 length=22.0000 global_step=9975.0000 loss=150.8181 policy_loss=-0.0000 value_loss=301.6362 entropy=0.0000
[step=412] episode=412.0000 return=-115.9972 length=29.0000 global_step=10004.0000 loss=33.6422 policy_loss=-0.0000 value_loss=67.2843 entropy=0.0000
[step=413] episode=413.0000 return=-115.9953 length=20.0000 global_step=10024.0000 loss=21.5627 policy_loss=-0.0000 value_loss=43.1253 entropy=0.0000
[step=414] episode=414.0000 return=-115.9867 length=13.0000 global_step=10037.0000 loss=14.4003 policy_loss=-0.0000 value_loss=28.8006 entropy=0.0000
[step=415] episode=415.0000 return=-115.9999 length=36.0000 global_step=10073.0000 loss=213.4973 policy_loss=-0.0000 value_loss=426.9946 entropy=0.0000
[step=416] episode=416.0000 return=-115.8229 length=11.0000 global_step=10084.0000 loss=89.9356 policy_loss=-0.0000 value_loss=179.8712 entropy=0.0000
[step=417] episode=417.0000 return=-115.9913 length=28.0000 global_step=10112.0000 loss=215.8770 policy_loss=-0.0000 value_loss=431.7539 entropy=0.0000
[step=418] episode=418.0000 return=-115.9999 length=20.0000 global_step=10132.0000 loss=168.3450 policy_loss=-0.0000 value_loss=336.6900 entropy=0.0000
[step=419] episode=419.0000 return=-115.7907 length=11.0000 global_step=10143.0000 loss=49.1207 policy_loss=-0.0000 value_loss=98.2415 entropy=0.0000
[step=420] episode=420.0000 return=-115.9907 length=29.0000 global_step=10172.0000 loss=42.9098 policy_loss=-0.0000 value_loss=85.8197 entropy=0.0000
[step=421] episode=421.0000 return=-115.9757 length=36.0000 global_step=10208.0000 loss=23.6521 policy_loss=-0.0000 value_loss=47.3041 entropy=0.0000
[step=422] episode=422.0000 return=-115.9203 length=18.0000 global_step=10226.0000 loss=72.9947 policy_loss=-0.0000 value_loss=145.9893 entropy=0.0000
[step=423] episode=423.0000 return=-115.9353 length=11.0000 global_step=10237.0000 loss=231.8427 policy_loss=-0.0000 value_loss=463.6853 entropy=0.0000
[step=424] episode=424.0000 return=-115.9956 length=43.0000 global_step=10280.0000 loss=61.6500 policy_loss=-0.0000 value_loss=123.2999 entropy=0.0000
[step=425] episode=425.0000 return=-115.9998 length=19.0000 global_step=10299.0000 loss=178.6754 policy_loss=-0.0000 value_loss=357.3507 entropy=0.0000
[step=426] episode=426.0000 return=-115.9991 length=22.0000 global_step=10321.0000 loss=117.3904 policy_loss=-0.0000 value_loss=234.7809 entropy=0.0000
[step=427] episode=427.0000 return=-115.9718 length=21.0000 global_step=10342.0000 loss=67.4845 policy_loss=-0.0000 value_loss=134.9690 entropy=0.0000
[step=428] episode=428.0000 return=-115.7600 length=4.0000 global_step=10346.0000 loss=232.2798 policy_loss=-0.0000 value_loss=464.5596 entropy=0.0000
[step=429] episode=429.0000 return=-115.9952 length=19.0000 global_step=10365.0000 loss=22.3165 policy_loss=-0.0000 value_loss=44.6330 entropy=0.0000
[step=430] episode=430.0000 return=-115.9029 length=12.0000 global_step=10377.0000 loss=25.8706 policy_loss=-0.0000 value_loss=51.7411 entropy=0.0000
[step=431] episode=431.0000 return=-115.9971 length=38.0000 global_step=10415.0000 loss=257.2573 policy_loss=-0.0000 value_loss=514.5145 entropy=0.0000
[step=432] episode=432.0000 return=-115.9968 length=21.0000 global_step=10436.0000 loss=108.3764 policy_loss=-0.0000 value_loss=216.7528 entropy=0.0000
[step=433] episode=433.0000 return=-115.9474 length=37.0000 global_step=10473.0000 loss=194.0331 policy_loss=-0.0000 value_loss=388.0661 entropy=0.0000
[step=434] episode=434.0000 return=-115.9913 length=28.0000 global_step=10501.0000 loss=58.2326 policy_loss=-0.0000 value_loss=116.4653 entropy=0.0000
a2c_tuned train:  14%|‚ñà‚ñç        | 435/3000 [11:53<1:06:02,  1.54s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 436/3000 [11:56<1:26:11,  2.02s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 437/3000 [11:57<1:17:38,  1.82s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 438/3000 [12:00<1:22:07,  1.92s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 439/3000 [12:01<1:20:36,  1.89s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 440/3000 [12:03<1:15:42,  1.77s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 441/3000 [12:04<1:12:36,  1.70s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 442/3000 [12:06<1:15:47,  1.78s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 443/3000 [12:08<1:10:37,  1.66s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 444/3000 [12:09<1:11:56,  1.69s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 445/3000 [12:10<1:02:14,  1.46s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 446/3000 [12:12<1:06:00,  1.55s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 447/3000 [12:13<1:02:32,  1.47s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 448/3000 [12:16<1:15:54,  1.78s/it]a2c_tuned train:  15%|‚ñà‚ñç        | 449/3000 [12:17<1:03:23,  1.49s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 450/3000 [12:18<1:03:00,  1.48s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 451/3000 [12:19<54:20,  1.28s/it]  a2c_tuned train:  15%|‚ñà‚ñå        | 452/3000 [12:21<1:08:06,  1.60s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 453/3000 [12:23<1:06:04,  1.56s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 454/3000 [12:24<1:03:16,  1.49s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 455/3000 [12:26<1:09:46,  1.64s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 456/3000 [12:28<1:13:15,  1.73s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 457/3000 [12:30<1:09:29,  1.64s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 458/3000 [12:32<1:18:14,  1.85s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 459/3000 [12:33<1:12:23,  1.71s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 460/3000 [12:35<1:08:39,  1.62s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 461/3000 [12:37<1:12:27,  1.71s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 462/3000 [12:38<1:09:34,  1.64s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 463/3000 [12:40<1:18:52,  1.87s/it]a2c_tuned train:  15%|‚ñà‚ñå        | 464/3000 [12:42<1:18:33,  1.86s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 465/3000 [12:43<1:06:11,  1.57s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 466/3000 [12:46<1:17:28,  1.83s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 467/3000 [12:47<1:10:26,  1.67s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 468/3000 [12:48<59:40,  1.41s/it]  a2c_tuned train:  16%|‚ñà‚ñå        | 469/3000 [12:49<59:20,  1.41s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 470/3000 [12:50<56:57,  1.35s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 471/3000 [12:51<52:23,  1.24s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 472/3000 [12:53<54:00,  1.28s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 473/3000 [12:54<48:19,  1.15s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 474/3000 [12:55<51:13,  1.22s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 475/3000 [12:56<45:24,  1.08s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 476/3000 [12:57<49:38,  1.18s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 477/3000 [12:59<59:32,  1.42s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 478/3000 [13:01<1:06:53,  1.59s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 479/3000 [13:02<1:03:47,  1.52s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 480/3000 [13:04<1:00:11,  1.43s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 481/3000 [13:06<1:06:10,  1.58s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 482/3000 [13:07<1:04:11,  1.53s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 483/3000 [13:09<1:09:20,  1.65s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 484/3000 [13:10<58:48,  1.40s/it]  a2c_tuned train:  16%|‚ñà‚ñå        | 485/3000 [13:11<52:00,  1.24s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 486/3000 [13:12<53:26,  1.28s/it]a2c_tuned train:  16%|‚ñà‚ñå        | 487/3000 [13:14<1:00:40,  1.45s/it]a2c_tuned train:  16%|‚ñà‚ñã        | 488/3000 [13:15<58:37,  1.40s/it]  [step=435] episode=435.0000 return=-115.9996 length=12.0000 global_step=10513.0000 loss=47.3010 policy_loss=-0.0000 value_loss=94.6020 entropy=0.0000
[step=436] episode=436.0000 return=-115.9973 length=46.0000 global_step=10559.0000 loss=49.4796 policy_loss=-0.0000 value_loss=98.9591 entropy=0.0000
[step=437] episode=437.0000 return=-115.9870 length=20.0000 global_step=10579.0000 loss=102.6769 policy_loss=-0.0000 value_loss=205.3539 entropy=0.0000
[step=438] episode=438.0000 return=-115.9959 length=33.0000 global_step=10612.0000 loss=79.4722 policy_loss=-0.0000 value_loss=158.9443 entropy=0.0000
[step=439] episode=439.0000 return=-115.9839 length=28.0000 global_step=10640.0000 loss=114.5827 policy_loss=-0.0000 value_loss=229.1654 entropy=0.0000
[step=440] episode=440.0000 return=-115.9943 length=20.0000 global_step=10660.0000 loss=168.8799 policy_loss=-0.0000 value_loss=337.7599 entropy=0.0000
[step=441] episode=441.0000 return=-115.9379 length=22.0000 global_step=10682.0000 loss=47.4338 policy_loss=-0.0000 value_loss=94.8677 entropy=0.0000
[step=442] episode=442.0000 return=-115.9756 length=30.0000 global_step=10712.0000 loss=7.0944 policy_loss=-0.0000 value_loss=14.1888 entropy=0.0000
[step=443] episode=443.0000 return=-115.9492 length=20.0000 global_step=10732.0000 loss=4.3096 policy_loss=-0.0000 value_loss=8.6192 entropy=0.0000
[step=444] episode=444.0000 return=-115.9574 length=25.0000 global_step=10757.0000 loss=39.9104 policy_loss=-0.0000 value_loss=79.8209 entropy=0.0000
[step=445] episode=445.0000 return=-115.9794 length=13.0000 global_step=10770.0000 loss=21.7084 policy_loss=-0.0000 value_loss=43.4167 entropy=0.0000
[step=446] episode=446.0000 return=-115.9042 length=26.0000 global_step=10796.0000 loss=49.1275 policy_loss=-0.0000 value_loss=98.2550 entropy=0.0000
[step=447] episode=447.0000 return=-115.9886 length=20.0000 global_step=10816.0000 loss=30.3260 policy_loss=-0.0000 value_loss=60.6520 entropy=0.0000
[step=448] episode=448.0000 return=-115.9781 length=37.0000 global_step=10853.0000 loss=68.0895 policy_loss=-0.0000 value_loss=136.1791 entropy=0.0000
[step=449] episode=449.0000 return=-115.9643 length=12.0000 global_step=10865.0000 loss=56.9570 policy_loss=-0.0000 value_loss=113.9140 entropy=0.0000
[step=450] episode=450.0000 return=-115.9454 length=20.0000 global_step=10885.0000 loss=72.7388 policy_loss=-0.0000 value_loss=145.4775 entropy=0.0000
[step=451] episode=451.0000 return=-115.9989 length=12.0000 global_step=10897.0000 loss=132.2091 policy_loss=-0.0000 value_loss=264.4183 entropy=0.0000
[step=452] episode=452.0000 return=-115.9895 length=34.0000 global_step=10931.0000 loss=12.3442 policy_loss=-0.0000 value_loss=24.6884 entropy=0.0000
[step=453] episode=453.0000 return=-115.9975 length=21.0000 global_step=10952.0000 loss=8.7535 policy_loss=-0.0000 value_loss=17.5070 entropy=0.0000
[step=454] episode=454.0000 return=-115.9975 length=20.0000 global_step=10972.0000 loss=15.6149 policy_loss=-0.0000 value_loss=31.2297 entropy=0.0000
[step=455] episode=455.0000 return=-115.9995 length=30.0000 global_step=11002.0000 loss=81.0312 policy_loss=-0.0000 value_loss=162.0623 entropy=0.0000
[step=456] episode=456.0000 return=-115.9840 length=29.0000 global_step=11031.0000 loss=84.9765 policy_loss=-0.0000 value_loss=169.9531 entropy=0.0000
[step=457] episode=457.0000 return=-115.9660 length=21.0000 global_step=11052.0000 loss=22.4413 policy_loss=-0.0000 value_loss=44.8827 entropy=0.0000
[step=458] episode=458.0000 return=-115.9978 length=34.0000 global_step=11086.0000 loss=49.6807 policy_loss=-0.0000 value_loss=99.3614 entropy=0.0000
[step=459] episode=459.0000 return=-115.9934 length=20.0000 global_step=11106.0000 loss=31.5700 policy_loss=-0.0000 value_loss=63.1399 entropy=0.0000
[step=460] episode=460.0000 return=-115.9804 length=20.0000 global_step=11126.0000 loss=56.2406 policy_loss=-0.0000 value_loss=112.4812 entropy=0.0000
[step=461] episode=461.0000 return=-115.9910 length=27.0000 global_step=11153.0000 loss=32.2229 policy_loss=-0.0000 value_loss=64.4458 entropy=0.0000
[step=462] episode=462.0000 return=-115.9978 length=21.0000 global_step=11174.0000 loss=44.9813 policy_loss=-0.0000 value_loss=89.9626 entropy=0.0000
[step=463] episode=463.0000 return=-115.8985 length=37.0000 global_step=11211.0000 loss=11.9940 policy_loss=-0.0000 value_loss=23.9880 entropy=0.0000
[step=464] episode=464.0000 return=-115.9894 length=27.0000 global_step=11238.0000 loss=15.3168 policy_loss=-0.0000 value_loss=30.6337 entropy=0.0000
[step=465] episode=465.0000 return=-115.7996 length=13.0000 global_step=11251.0000 loss=60.9528 policy_loss=-0.0000 value_loss=121.9056 entropy=0.0000
[step=466] episode=466.0000 return=-115.9978 length=36.0000 global_step=11287.0000 loss=16.8334 policy_loss=-0.0000 value_loss=33.6669 entropy=0.0000
[step=467] episode=467.0000 return=-115.9974 length=19.0000 global_step=11306.0000 loss=17.5708 policy_loss=-0.0000 value_loss=35.1416 entropy=0.0000
[step=468] episode=468.0000 return=-115.9434 length=11.0000 global_step=11317.0000 loss=43.3949 policy_loss=-0.0000 value_loss=86.7899 entropy=0.0000
[step=469] episode=469.0000 return=-115.9965 length=20.0000 global_step=11337.0000 loss=9.5128 policy_loss=-0.0000 value_loss=19.0255 entropy=0.0000
[step=470] episode=470.0000 return=-115.8870 length=18.0000 global_step=11355.0000 loss=11.8884 policy_loss=-0.0000 value_loss=23.7768 entropy=0.0000
[step=471] episode=471.0000 return=-115.6708 length=14.0000 global_step=11369.0000 loss=14.3062 policy_loss=-0.0000 value_loss=28.6125 entropy=0.0000
[step=472] episode=472.0000 return=-115.7462 length=19.0000 global_step=11388.0000 loss=9.8371 policy_loss=-0.0000 value_loss=19.6741 entropy=0.0000
[step=473] episode=473.0000 return=-115.8694 length=12.0000 global_step=11400.0000 loss=16.4520 policy_loss=-0.0000 value_loss=32.9040 entropy=0.0000
[step=474] episode=474.0000 return=-115.9947 length=20.0000 global_step=11420.0000 loss=16.4616 policy_loss=-0.0000 value_loss=32.9232 entropy=0.0000
[step=475] episode=475.0000 return=-115.7484 length=10.0000 global_step=11430.0000 loss=18.7863 policy_loss=-0.0000 value_loss=37.5726 entropy=0.0000
[step=476] episode=476.0000 return=-115.9660 length=21.0000 global_step=11451.0000 loss=14.7844 policy_loss=-0.0000 value_loss=29.5689 entropy=0.0000
[step=477] episode=477.0000 return=-115.9969 length=28.0000 global_step=11479.0000 loss=10.6303 policy_loss=-0.0000 value_loss=21.2606 entropy=0.0000
[step=478] episode=478.0000 return=-115.9357 length=29.0000 global_step=11508.0000 loss=15.0727 policy_loss=-0.0000 value_loss=30.1453 entropy=0.0000
[step=479] episode=479.0000 return=-115.7320 length=19.0000 global_step=11527.0000 loss=35.8333 policy_loss=-0.0000 value_loss=71.6666 entropy=0.0000
[step=480] episode=480.0000 return=-115.9036 length=18.0000 global_step=11545.0000 loss=55.8166 policy_loss=-0.0000 value_loss=111.6333 entropy=0.0000
[step=481] episode=481.0000 return=-115.9989 length=28.0000 global_step=11573.0000 loss=36.2301 policy_loss=-0.0000 value_loss=72.4602 entropy=0.0000
[step=482] episode=482.0000 return=-115.9659 length=21.0000 global_step=11594.0000 loss=24.6809 policy_loss=-0.0000 value_loss=49.3618 entropy=0.0000
[step=483] episode=483.0000 return=-115.9917 length=28.0000 global_step=11622.0000 loss=22.5863 policy_loss=-0.0000 value_loss=45.1726 entropy=0.0000
[step=484] episode=484.0000 return=-115.8156 length=12.0000 global_step=11634.0000 loss=21.6305 policy_loss=-0.0000 value_loss=43.2610 entropy=0.0000
[step=485] episode=485.0000 return=-115.8340 length=13.0000 global_step=11647.0000 loss=11.0411 policy_loss=-0.0000 value_loss=22.0822 entropy=0.0000
[step=486] episode=486.0000 return=-115.9403 length=20.0000 global_step=11667.0000 loss=88.7804 policy_loss=-0.0000 value_loss=177.5608 entropy=0.0000
[step=487] episode=487.0000 return=-115.9786 length=28.0000 global_step=11695.0000 loss=191.4293 policy_loss=-0.0000 value_loss=382.8585 entropy=0.0000
[step=488] episode=488.0000 return=-115.9939 length=18.0000 global_step=11713.0000 loss=89.5764 policy_loss=-0.0000 value_loss=179.1528 entropy=0.0000
a2c_tuned train:  16%|‚ñà‚ñã        | 489/3000 [13:17<59:15,  1.42s/it]a2c_tuned train:  16%|‚ñà‚ñã        | 490/3000 [13:17<52:46,  1.26s/it]a2c_tuned train:  16%|‚ñà‚ñã        | 491/3000 [13:20<1:02:08,  1.49s/it]a2c_tuned train:  16%|‚ñà‚ñã        | 492/3000 [13:22<1:08:46,  1.65s/it]a2c_tuned train:  16%|‚ñà‚ñã        | 493/3000 [13:23<1:11:38,  1.71s/it]a2c_tuned train:  16%|‚ñà‚ñã        | 494/3000 [13:25<1:15:02,  1.80s/it]a2c_tuned train:  16%|‚ñà‚ñã        | 495/3000 [13:28<1:24:55,  2.03s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 496/3000 [13:29<1:17:57,  1.87s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 497/3000 [13:32<1:25:17,  2.04s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 498/3000 [13:34<1:24:34,  2.03s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 499/3000 [13:36<1:22:40,  1.98s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 500/3000 [13:37<1:14:40,  1.79s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 501/3000 [13:38<1:02:23,  1.50s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 502/3000 [13:39<1:00:03,  1.44s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 503/3000 [13:41<1:06:59,  1.61s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 504/3000 [13:43<1:08:58,  1.66s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 505/3000 [13:44<1:04:36,  1.55s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 506/3000 [13:46<1:09:24,  1.67s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 507/3000 [13:48<1:12:15,  1.74s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 508/3000 [13:49<59:56,  1.44s/it]  a2c_tuned train:  17%|‚ñà‚ñã        | 509/3000 [13:51<1:13:52,  1.78s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 510/3000 [13:53<1:09:26,  1.67s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 511/3000 [13:54<59:52,  1.44s/it]  a2c_tuned train:  17%|‚ñà‚ñã        | 512/3000 [13:55<53:08,  1.28s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 513/3000 [13:56<48:14,  1.16s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 514/3000 [13:57<50:20,  1.22s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 515/3000 [13:58<52:41,  1.27s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 516/3000 [14:00<1:01:39,  1.49s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 517/3000 [14:02<1:01:29,  1.49s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 518/3000 [14:04<1:07:57,  1.64s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 519/3000 [14:06<1:17:54,  1.88s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 520/3000 [14:09<1:32:06,  2.23s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 521/3000 [14:11<1:21:31,  1.97s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 522/3000 [14:13<1:21:44,  1.98s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 523/3000 [14:14<1:15:56,  1.84s/it]a2c_tuned train:  17%|‚ñà‚ñã        | 524/3000 [14:17<1:24:06,  2.04s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 525/3000 [14:18<1:09:41,  1.69s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 526/3000 [14:20<1:14:00,  1.79s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 527/3000 [14:21<1:02:54,  1.53s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 528/3000 [14:22<1:01:05,  1.48s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 529/3000 [14:24<1:07:46,  1.65s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 530/3000 [14:27<1:27:56,  2.14s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 531/3000 [14:30<1:33:10,  2.26s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 532/3000 [14:31<1:21:04,  1.97s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 533/3000 [14:32<1:06:45,  1.62s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 534/3000 [14:34<1:16:59,  1.87s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 535/3000 [14:35<1:03:53,  1.55s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 536/3000 [14:37<1:07:32,  1.64s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 537/3000 [14:39<1:11:24,  1.74s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 538/3000 [14:40<58:53,  1.44s/it]  a2c_tuned train:  18%|‚ñà‚ñä        | 539/3000 [14:42<1:04:29,  1.57s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 540/3000 [14:42<55:07,  1.34s/it]  a2c_tuned train:  18%|‚ñà‚ñä        | 541/3000 [14:43<49:59,  1.22s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 542/3000 [14:46<1:07:01,  1.64s/it][step=489] episode=489.0000 return=-115.9917 length=21.0000 global_step=11734.0000 loss=77.5402 policy_loss=-0.0000 value_loss=155.0805 entropy=0.0000
[step=490] episode=490.0000 return=-115.8310 length=13.0000 global_step=11747.0000 loss=7.1256 policy_loss=-0.0000 value_loss=14.2512 entropy=0.0000
[step=491] episode=491.0000 return=-115.9907 length=30.0000 global_step=11777.0000 loss=24.0643 policy_loss=-0.0000 value_loss=48.1286 entropy=0.0000
[step=492] episode=492.0000 return=-115.9989 length=29.0000 global_step=11806.0000 loss=31.3588 policy_loss=-0.0000 value_loss=62.7176 entropy=0.0000
[step=493] episode=493.0000 return=-115.9928 length=27.0000 global_step=11833.0000 loss=76.5543 policy_loss=-0.0000 value_loss=153.1087 entropy=0.0000
[step=494] episode=494.0000 return=-115.9984 length=29.0000 global_step=11862.0000 loss=95.1265 policy_loss=-0.0000 value_loss=190.2531 entropy=0.0000
[step=495] episode=495.0000 return=-115.9096 length=37.0000 global_step=11899.0000 loss=60.5351 policy_loss=-0.0000 value_loss=121.0701 entropy=0.0000
[step=496] episode=496.0000 return=-115.9863 length=21.0000 global_step=11920.0000 loss=105.4240 policy_loss=-0.0000 value_loss=210.8480 entropy=0.0000
[step=497] episode=497.0000 return=-115.9853 length=37.0000 global_step=11957.0000 loss=27.7997 policy_loss=-0.0000 value_loss=55.5994 entropy=0.0000
[step=498] episode=498.0000 return=-115.9970 length=29.0000 global_step=11986.0000 loss=5.9209 policy_loss=-0.0000 value_loss=11.8419 entropy=0.0000
[step=499] episode=499.0000 return=-115.9013 length=28.0000 global_step=12014.0000 loss=79.2860 policy_loss=-0.0000 value_loss=158.5719 entropy=0.0000
[step=500] episode=500.0000 return=-115.9925 length=20.0000 global_step=12034.0000 loss=76.3461 policy_loss=-0.0000 value_loss=152.6921 entropy=0.0000
[step=501] episode=501.0000 return=-115.9999 length=12.0000 global_step=12046.0000 loss=30.1351 policy_loss=-0.0000 value_loss=60.2702 entropy=0.0000
[step=502] episode=502.0000 return=-115.9096 length=18.0000 global_step=12064.0000 loss=90.0025 policy_loss=-0.0000 value_loss=180.0051 entropy=0.0000
[step=503] episode=503.0000 return=-115.9814 length=29.0000 global_step=12093.0000 loss=110.6443 policy_loss=-0.0000 value_loss=221.2887 entropy=0.0000
[step=504] episode=504.0000 return=-115.9953 length=26.0000 global_step=12119.0000 loss=9.8427 policy_loss=-0.0000 value_loss=19.6855 entropy=0.0000
[step=505] episode=505.0000 return=-115.9957 length=20.0000 global_step=12139.0000 loss=18.2294 policy_loss=-0.0000 value_loss=36.4587 entropy=0.0000
[step=506] episode=506.0000 return=-115.8634 length=29.0000 global_step=12168.0000 loss=22.0560 policy_loss=-0.0000 value_loss=44.1121 entropy=0.0000
[step=507] episode=507.0000 return=-115.9968 length=27.0000 global_step=12195.0000 loss=30.0107 policy_loss=-0.0000 value_loss=60.0214 entropy=0.0000
[step=508] episode=508.0000 return=-115.8070 length=10.0000 global_step=12205.0000 loss=137.8785 policy_loss=-0.0000 value_loss=275.7570 entropy=0.0000
[step=509] episode=509.0000 return=-115.9951 length=38.0000 global_step=12243.0000 loss=22.8480 policy_loss=-0.0000 value_loss=45.6960 entropy=0.0000
[step=510] episode=510.0000 return=-115.9785 length=21.0000 global_step=12264.0000 loss=18.5357 policy_loss=-0.0000 value_loss=37.0714 entropy=0.0000
[step=511] episode=511.0000 return=-114.9524 length=13.0000 global_step=12277.0000 loss=81.8343 policy_loss=-0.0000 value_loss=163.6687 entropy=0.0000
[step=512] episode=512.0000 return=-115.8141 length=14.0000 global_step=12291.0000 loss=8.6827 policy_loss=-0.0000 value_loss=17.3653 entropy=0.0000
[step=513] episode=513.0000 return=-115.7992 length=13.0000 global_step=12304.0000 loss=25.6943 policy_loss=-0.0000 value_loss=51.3886 entropy=0.0000
[step=514] episode=514.0000 return=-115.8870 length=20.0000 global_step=12324.0000 loss=149.8152 policy_loss=-0.0000 value_loss=299.6304 entropy=0.0000
[step=515] episode=515.0000 return=-115.9997 length=20.0000 global_step=12344.0000 loss=136.4779 policy_loss=-0.0000 value_loss=272.9557 entropy=0.0000
[step=516] episode=516.0000 return=-115.9482 length=29.0000 global_step=12373.0000 loss=124.8419 policy_loss=-0.0000 value_loss=249.6837 entropy=0.0000
[step=517] episode=517.0000 return=-115.9045 length=21.0000 global_step=12394.0000 loss=58.1016 policy_loss=-0.0000 value_loss=116.2033 entropy=0.0000
[step=518] episode=518.0000 return=-115.9434 length=30.0000 global_step=12424.0000 loss=42.3058 policy_loss=-0.0000 value_loss=84.6116 entropy=0.0000
[step=519] episode=519.0000 return=-115.9989 length=36.0000 global_step=12460.0000 loss=12.8329 policy_loss=-0.0000 value_loss=25.6659 entropy=0.0000
[step=520] episode=520.0000 return=-115.9973 length=44.0000 global_step=12504.0000 loss=26.0697 policy_loss=-0.0000 value_loss=52.1395 entropy=0.0000
[step=521] episode=521.0000 return=-115.9756 length=20.0000 global_step=12524.0000 loss=102.9707 policy_loss=-0.0000 value_loss=205.9414 entropy=0.0000
[step=522] episode=522.0000 return=-115.9681 length=28.0000 global_step=12552.0000 loss=65.9258 policy_loss=-0.0000 value_loss=131.8516 entropy=0.0000
[step=523] episode=523.0000 return=-115.9379 length=21.0000 global_step=12573.0000 loss=72.8113 policy_loss=-0.0000 value_loss=145.6226 entropy=0.0000
[step=524] episode=524.0000 return=-115.9096 length=37.0000 global_step=12610.0000 loss=16.6015 policy_loss=-0.0000 value_loss=33.2030 entropy=0.0000
[step=525] episode=525.0000 return=-115.8192 length=12.0000 global_step=12622.0000 loss=58.6002 policy_loss=-0.0000 value_loss=117.2004 entropy=0.0000
[step=526] episode=526.0000 return=-115.9840 length=29.0000 global_step=12651.0000 loss=32.6406 policy_loss=-0.0000 value_loss=65.2812 entropy=0.0000
[step=527] episode=527.0000 return=-115.9732 length=12.0000 global_step=12663.0000 loss=9.7459 policy_loss=-0.0000 value_loss=19.4917 entropy=0.0000
[step=528] episode=528.0000 return=-115.9973 length=20.0000 global_step=12683.0000 loss=52.1296 policy_loss=-0.0000 value_loss=104.2592 entropy=0.0000
[step=529] episode=529.0000 return=-115.8762 length=29.0000 global_step=12712.0000 loss=102.9537 policy_loss=-0.0000 value_loss=205.9075 entropy=0.0000
[step=530] episode=530.0000 return=-115.9855 length=47.0000 global_step=12759.0000 loss=221.8782 policy_loss=-0.0000 value_loss=443.7565 entropy=0.0000
[step=531] episode=531.0000 return=-115.9829 length=38.0000 global_step=12797.0000 loss=124.1253 policy_loss=-0.0000 value_loss=248.2505 entropy=0.0000
[step=532] episode=532.0000 return=-115.9668 length=20.0000 global_step=12817.0000 loss=10.6862 policy_loss=-0.0000 value_loss=21.3724 entropy=0.0000
[step=533] episode=533.0000 return=-115.7995 length=12.0000 global_step=12829.0000 loss=71.5838 policy_loss=-0.0000 value_loss=143.1676 entropy=0.0000
[step=534] episode=534.0000 return=-115.9840 length=37.0000 global_step=12866.0000 loss=13.1634 policy_loss=-0.0000 value_loss=26.3267 entropy=0.0000
[step=535] episode=535.0000 return=-115.7559 length=12.0000 global_step=12878.0000 loss=67.4303 policy_loss=-0.0000 value_loss=134.8606 entropy=0.0000
[step=536] episode=536.0000 return=-115.9858 length=28.0000 global_step=12906.0000 loss=14.5228 policy_loss=-0.0000 value_loss=29.0456 entropy=0.0000
[step=537] episode=537.0000 return=-115.9568 length=29.0000 global_step=12935.0000 loss=27.6643 policy_loss=-0.0000 value_loss=55.3286 entropy=0.0000
[step=538] episode=538.0000 return=-115.9918 length=11.0000 global_step=12946.0000 loss=32.3616 policy_loss=-0.0000 value_loss=64.7233 entropy=0.0000
[step=539] episode=539.0000 return=-116.0000 length=28.0000 global_step=12974.0000 loss=27.7672 policy_loss=-0.0000 value_loss=55.5343 entropy=0.0000
[step=540] episode=540.0000 return=-115.9171 length=11.0000 global_step=12985.0000 loss=32.4952 policy_loss=-0.0000 value_loss=64.9904 entropy=0.0000
[step=541] episode=541.0000 return=-115.7558 length=13.0000 global_step=12998.0000 loss=22.1069 policy_loss=-0.0000 value_loss=44.2138 entropy=0.0000
[step=542] episode=542.0000 return=-115.9983 length=38.0000 global_step=13036.0000 loss=83.9809 policy_loss=-0.0000 value_loss=167.9618 entropy=0.0000
a2c_tuned train:  18%|‚ñà‚ñä        | 543/3000 [14:48<1:08:24,  1.67s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 544/3000 [14:49<1:05:18,  1.60s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 545/3000 [14:52<1:16:13,  1.86s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 546/3000 [14:53<1:15:06,  1.84s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 547/3000 [14:56<1:24:55,  2.08s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 548/3000 [14:57<1:09:17,  1.70s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 549/3000 [14:59<1:11:41,  1.76s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 550/3000 [15:00<1:07:37,  1.66s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 551/3000 [15:02<1:11:48,  1.76s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 552/3000 [15:04<1:07:34,  1.66s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 553/3000 [15:05<1:11:24,  1.75s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 554/3000 [15:08<1:18:18,  1.92s/it]a2c_tuned train:  18%|‚ñà‚ñä        | 555/3000 [15:09<1:11:01,  1.74s/it]a2c_tuned train:  19%|‚ñà‚ñä        | 556/3000 [15:12<1:22:49,  2.03s/it]a2c_tuned train:  19%|‚ñà‚ñä        | 557/3000 [15:13<1:14:23,  1.83s/it]a2c_tuned train:  19%|‚ñà‚ñä        | 558/3000 [15:15<1:10:20,  1.73s/it]a2c_tuned train:  19%|‚ñà‚ñä        | 559/3000 [15:16<1:06:47,  1.64s/it]a2c_tuned train:  19%|‚ñà‚ñä        | 560/3000 [15:17<56:46,  1.40s/it]  a2c_tuned train:  19%|‚ñà‚ñä        | 561/3000 [15:18<56:45,  1.40s/it]a2c_tuned train:  19%|‚ñà‚ñä        | 562/3000 [15:19<49:56,  1.23s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 563/3000 [15:21<51:44,  1.27s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 564/3000 [15:22<53:02,  1.31s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 565/3000 [15:24<59:44,  1.47s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 566/3000 [15:26<1:06:17,  1.63s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 567/3000 [15:28<1:10:19,  1.73s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 568/3000 [15:31<1:25:44,  2.12s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 569/3000 [15:32<1:10:58,  1.75s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 570/3000 [15:33<1:06:02,  1.63s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 571/3000 [15:35<1:09:41,  1.72s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 572/3000 [15:36<1:06:31,  1.64s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 573/3000 [15:37<56:10,  1.39s/it]  a2c_tuned train:  19%|‚ñà‚ñâ        | 574/3000 [15:39<55:46,  1.38s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 575/3000 [15:40<56:32,  1.40s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 576/3000 [15:41<49:12,  1.22s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 577/3000 [15:43<58:10,  1.44s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 578/3000 [15:45<1:02:30,  1.55s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 579/3000 [15:45<52:45,  1.31s/it]  a2c_tuned train:  19%|‚ñà‚ñâ        | 580/3000 [15:47<59:36,  1.48s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 581/3000 [15:49<1:02:19,  1.55s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 582/3000 [15:50<1:01:26,  1.52s/it]a2c_tuned train:  19%|‚ñà‚ñâ        | 583/3000 [15:52<57:55,  1.44s/it]  a2c_tuned train:  19%|‚ñà‚ñâ        | 584/3000 [15:53<57:51,  1.44s/it]a2c_tuned train:  20%|‚ñà‚ñâ        | 585/3000 [15:55<1:05:01,  1.62s/it]a2c_tuned train:  20%|‚ñà‚ñâ        | 586/3000 [15:56<55:25,  1.38s/it]  a2c_tuned train:  20%|‚ñà‚ñâ        | 587/3000 [15:58<1:01:37,  1.53s/it]a2c_tuned train:  20%|‚ñà‚ñâ        | 588/3000 [15:59<59:39,  1.48s/it]  a2c_tuned train:  20%|‚ñà‚ñâ        | 589/3000 [16:00<52:18,  1.30s/it]a2c_tuned train:  20%|‚ñà‚ñâ        | 590/3000 [16:03<1:07:04,  1.67s/it]a2c_tuned train:  20%|‚ñà‚ñâ        | 591/3000 [16:05<1:17:49,  1.94s/it]a2c_tuned train:  20%|‚ñà‚ñâ        | 592/3000 [16:07<1:10:42,  1.76s/it]a2c_tuned train:  20%|‚ñà‚ñâ        | 593/3000 [16:08<1:06:14,  1.65s/it]a2c_tuned train:  20%|‚ñà‚ñâ        | 594/3000 [16:09<1:02:39,  1.56s/it]a2c_tuned train:  20%|‚ñà‚ñâ        | 595/3000 [16:11<1:05:14,  1.63s/it]a2c_tuned train:  20%|‚ñà‚ñâ        | 596/3000 [16:14<1:16:37,  1.91s/it][step=543] episode=543.0000 return=-115.9997 length=26.0000 global_step=13062.0000 loss=37.0820 policy_loss=-0.0000 value_loss=74.1640 entropy=0.0000
[step=544] episode=544.0000 return=-115.9772 length=20.0000 global_step=13082.0000 loss=9.1899 policy_loss=-0.0000 value_loss=18.3798 entropy=0.0000
[step=545] episode=545.0000 return=-115.9927 length=37.0000 global_step=13119.0000 loss=53.9541 policy_loss=-0.0000 value_loss=107.9083 entropy=0.0000
[step=546] episode=546.0000 return=-115.9096 length=26.0000 global_step=13145.0000 loss=30.0205 policy_loss=-0.0000 value_loss=60.0410 entropy=0.0000
[step=547] episode=547.0000 return=-115.9933 length=40.0000 global_step=13185.0000 loss=27.5918 policy_loss=-0.0000 value_loss=55.1836 entropy=0.0000
[step=548] episode=548.0000 return=-115.9977 length=12.0000 global_step=13197.0000 loss=147.3123 policy_loss=-0.0000 value_loss=294.6246 entropy=0.0000
[step=549] episode=549.0000 return=-115.9979 length=28.0000 global_step=13225.0000 loss=33.6950 policy_loss=-0.0000 value_loss=67.3900 entropy=0.0000
[step=550] episode=550.0000 return=-115.8765 length=21.0000 global_step=13246.0000 loss=19.4319 policy_loss=-0.0000 value_loss=38.8637 entropy=0.0000
[step=551] episode=551.0000 return=-115.9997 length=29.0000 global_step=13275.0000 loss=35.2071 policy_loss=-0.0000 value_loss=70.4141 entropy=0.0000
[step=552] episode=552.0000 return=-115.8736 length=20.0000 global_step=13295.0000 loss=23.8326 policy_loss=-0.0000 value_loss=47.6652 entropy=0.0000
[step=553] episode=553.0000 return=-115.9926 length=28.0000 global_step=13323.0000 loss=71.7282 policy_loss=-0.0000 value_loss=143.4564 entropy=0.0000
[step=554] episode=554.0000 return=-115.9971 length=34.0000 global_step=13357.0000 loss=46.9773 policy_loss=-0.0000 value_loss=93.9546 entropy=0.0000
[step=555] episode=555.0000 return=-115.9999 length=19.0000 global_step=13376.0000 loss=9.2873 policy_loss=-0.0000 value_loss=18.5746 entropy=0.0000
[step=556] episode=556.0000 return=-115.9886 length=38.0000 global_step=13414.0000 loss=44.2248 policy_loss=-0.0000 value_loss=88.4496 entropy=0.0000
[step=557] episode=557.0000 return=-115.9959 length=20.0000 global_step=13434.0000 loss=32.5647 policy_loss=-0.0000 value_loss=65.1294 entropy=0.0000
[step=558] episode=558.0000 return=-115.9838 length=21.0000 global_step=13455.0000 loss=37.1484 policy_loss=-0.0000 value_loss=74.2967 entropy=0.0000
[step=559] episode=559.0000 return=-115.9999 length=21.0000 global_step=13476.0000 loss=28.5072 policy_loss=-0.0000 value_loss=57.0145 entropy=0.0000
[step=560] episode=560.0000 return=-115.7290 length=12.0000 global_step=13488.0000 loss=97.2400 policy_loss=-0.0000 value_loss=194.4801 entropy=0.0000
[step=561] episode=561.0000 return=-115.9991 length=20.0000 global_step=13508.0000 loss=8.5499 policy_loss=-0.0000 value_loss=17.0997 entropy=0.0000
[step=562] episode=562.0000 return=-115.9572 length=12.0000 global_step=13520.0000 loss=9.4877 policy_loss=-0.0000 value_loss=18.9755 entropy=0.0000
[step=563] episode=563.0000 return=-115.9939 length=19.0000 global_step=13539.0000 loss=20.3306 policy_loss=-0.0000 value_loss=40.6612 entropy=0.0000
[step=564] episode=564.0000 return=-115.9687 length=20.0000 global_step=13559.0000 loss=21.9520 policy_loss=-0.0000 value_loss=43.9039 entropy=0.0000
[step=565] episode=565.0000 return=-115.9914 length=28.0000 global_step=13587.0000 loss=26.3589 policy_loss=-0.0000 value_loss=52.7179 entropy=0.0000
[step=566] episode=566.0000 return=-115.8329 length=29.0000 global_step=13616.0000 loss=9.0849 policy_loss=-0.0000 value_loss=18.1698 entropy=0.0000
[step=567] episode=567.0000 return=-115.9326 length=30.0000 global_step=13646.0000 loss=14.3890 policy_loss=-0.0000 value_loss=28.7781 entropy=0.0000
[step=568] episode=568.0000 return=-115.9932 length=46.0000 global_step=13692.0000 loss=32.6660 policy_loss=-0.0000 value_loss=65.3320 entropy=0.0000
[step=569] episode=569.0000 return=-115.9955 length=12.0000 global_step=13704.0000 loss=168.5426 policy_loss=-0.0000 value_loss=337.0851 entropy=0.0000
[step=570] episode=570.0000 return=-115.9953 length=20.0000 global_step=13724.0000 loss=58.1459 policy_loss=-0.0000 value_loss=116.2919 entropy=0.0000
[step=571] episode=571.0000 return=-115.9995 length=29.0000 global_step=13753.0000 loss=15.5001 policy_loss=-0.0000 value_loss=31.0003 entropy=0.0000
[step=572] episode=572.0000 return=-115.9978 length=21.0000 global_step=13774.0000 loss=10.4316 policy_loss=-0.0000 value_loss=20.8632 entropy=0.0000
[step=573] episode=573.0000 return=-115.9962 length=11.0000 global_step=13785.0000 loss=11.0146 policy_loss=-0.0000 value_loss=22.0292 entropy=0.0000
[step=574] episode=574.0000 return=-115.9990 length=20.0000 global_step=13805.0000 loss=106.6423 policy_loss=-0.0000 value_loss=213.2847 entropy=0.0000
[step=575] episode=575.0000 return=-115.9384 length=21.0000 global_step=13826.0000 loss=161.6377 policy_loss=-0.0000 value_loss=323.2754 entropy=0.0000
[step=576] episode=576.0000 return=-115.9727 length=12.0000 global_step=13838.0000 loss=95.0905 policy_loss=-0.0000 value_loss=190.1811 entropy=0.0000
[step=577] episode=577.0000 return=-115.9944 length=29.0000 global_step=13867.0000 loss=245.6172 policy_loss=-0.0000 value_loss=491.2343 entropy=0.0000
[step=578] episode=578.0000 return=-115.9958 length=28.0000 global_step=13895.0000 loss=72.2562 policy_loss=-0.0000 value_loss=144.5124 entropy=0.0000
[step=579] episode=579.0000 return=-115.7491 length=10.0000 global_step=13905.0000 loss=19.6041 policy_loss=-0.0000 value_loss=39.2082 entropy=0.0000
[step=580] episode=580.0000 return=-116.0000 length=29.0000 global_step=13934.0000 loss=11.9419 policy_loss=-0.0000 value_loss=23.8838 entropy=0.0000
[step=581] episode=581.0000 return=-115.8880 length=26.0000 global_step=13960.0000 loss=25.8477 policy_loss=-0.0000 value_loss=51.6954 entropy=0.0000
[step=582] episode=582.0000 return=-115.9796 length=21.0000 global_step=13981.0000 loss=73.9697 policy_loss=-0.0000 value_loss=147.9393 entropy=0.0000
[step=583] episode=583.0000 return=-115.9978 length=18.0000 global_step=13999.0000 loss=110.1669 policy_loss=-0.0000 value_loss=220.3339 entropy=0.0000
[step=584] episode=584.0000 return=-115.9901 length=20.0000 global_step=14019.0000 loss=65.1834 policy_loss=-0.0000 value_loss=130.3668 entropy=0.0000
[step=585] episode=585.0000 return=-115.9959 length=30.0000 global_step=14049.0000 loss=9.5732 policy_loss=-0.0000 value_loss=19.1463 entropy=0.0000
[step=586] episode=586.0000 return=-115.9973 length=11.0000 global_step=14060.0000 loss=19.6936 policy_loss=-0.0000 value_loss=39.3872 entropy=0.0000
[step=587] episode=587.0000 return=-115.9932 length=29.0000 global_step=14089.0000 loss=98.9212 policy_loss=-0.0000 value_loss=197.8424 entropy=0.0000
[step=588] episode=588.0000 return=-115.9997 length=20.0000 global_step=14109.0000 loss=119.9759 policy_loss=-0.0000 value_loss=239.9517 entropy=0.0000
[step=589] episode=589.0000 return=-115.9242 length=13.0000 global_step=14122.0000 loss=58.3888 policy_loss=-0.0000 value_loss=116.7776 entropy=0.0000
[step=590] episode=590.0000 return=-115.9995 length=36.0000 global_step=14158.0000 loss=223.5858 policy_loss=-0.0000 value_loss=447.1716 entropy=0.0000
[step=591] episode=591.0000 return=-115.9886 length=38.0000 global_step=14196.0000 loss=141.3601 policy_loss=-0.0000 value_loss=282.7202 entropy=0.0000
[step=592] episode=592.0000 return=-115.9975 length=20.0000 global_step=14216.0000 loss=12.1163 policy_loss=-0.0000 value_loss=24.2327 entropy=0.0000
[step=593] episode=593.0000 return=-115.9955 length=20.0000 global_step=14236.0000 loss=42.2736 policy_loss=-0.0000 value_loss=84.5471 entropy=0.0000
[step=594] episode=594.0000 return=-116.0000 length=20.0000 global_step=14256.0000 loss=52.7234 policy_loss=-0.0000 value_loss=105.4469 entropy=0.0000
[step=595] episode=595.0000 return=-115.9984 length=27.0000 global_step=14283.0000 loss=28.8149 policy_loss=-0.0000 value_loss=57.6297 entropy=0.0000
[step=596] episode=596.0000 return=-115.9978 length=38.0000 global_step=14321.0000 loss=28.5908 policy_loss=-0.0000 value_loss=57.1816 entropy=0.0000
a2c_tuned train:  20%|‚ñà‚ñâ        | 597/3000 [16:15<1:10:02,  1.75s/it]a2c_tuned train:  20%|‚ñà‚ñâ        | 598/3000 [16:16<1:00:04,  1.50s/it]a2c_tuned train:  20%|‚ñà‚ñâ        | 599/3000 [16:17<52:39,  1.32s/it]  a2c_tuned train:  20%|‚ñà‚ñà        | 600/3000 [16:18<49:09,  1.23s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 601/3000 [16:20<1:04:30,  1.61s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 602/3000 [16:22<1:02:22,  1.56s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 603/3000 [16:23<1:01:06,  1.53s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 604/3000 [16:26<1:11:28,  1.79s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 605/3000 [16:27<1:05:52,  1.65s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 606/3000 [16:29<1:09:35,  1.74s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 607/3000 [16:31<1:12:45,  1.82s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 608/3000 [16:32<1:08:21,  1.71s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 609/3000 [16:34<1:03:35,  1.60s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 610/3000 [16:35<1:01:15,  1.54s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 611/3000 [16:38<1:13:56,  1.86s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 612/3000 [16:40<1:13:21,  1.84s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 613/3000 [16:42<1:20:38,  2.03s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 614/3000 [16:47<1:51:36,  2.81s/it]a2c_tuned train:  20%|‚ñà‚ñà        | 615/3000 [16:49<1:42:27,  2.58s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 616/3000 [16:49<1:21:40,  2.06s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 617/3000 [16:50<1:07:04,  1.69s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 618/3000 [16:52<1:04:19,  1.62s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 619/3000 [16:54<1:14:01,  1.87s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 620/3000 [16:56<1:08:52,  1.74s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 621/3000 [16:57<1:04:07,  1.62s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 622/3000 [16:58<1:00:49,  1.53s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 623/3000 [17:00<1:04:12,  1.62s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 624/3000 [17:02<1:08:09,  1.72s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 625/3000 [17:04<1:10:15,  1.77s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 626/3000 [17:05<1:05:28,  1.65s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 627/3000 [17:07<1:09:45,  1.76s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 628/3000 [17:09<1:10:57,  1.79s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 629/3000 [17:12<1:17:53,  1.97s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 630/3000 [17:14<1:16:46,  1.94s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 631/3000 [17:15<1:11:04,  1.80s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 632/3000 [17:17<1:11:58,  1.82s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 633/3000 [17:19<1:19:59,  2.03s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 634/3000 [17:21<1:18:48,  2.00s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 635/3000 [17:23<1:18:44,  2.00s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 636/3000 [17:25<1:12:01,  1.83s/it]a2c_tuned train:  21%|‚ñà‚ñà        | 637/3000 [17:27<1:13:54,  1.88s/it]a2c_tuned train:  21%|‚ñà‚ñà‚ñè       | 638/3000 [17:29<1:13:48,  1.87s/it]a2c_tuned train:  21%|‚ñà‚ñà‚ñè       | 639/3000 [17:30<1:05:38,  1.67s/it]a2c_tuned train:  21%|‚ñà‚ñà‚ñè       | 640/3000 [17:32<1:12:38,  1.85s/it]a2c_tuned train:  21%|‚ñà‚ñà‚ñè       | 641/3000 [17:33<1:07:44,  1.72s/it]a2c_tuned train:  21%|‚ñà‚ñà‚ñè       | 642/3000 [17:35<1:11:10,  1.81s/it]a2c_tuned train:  21%|‚ñà‚ñà‚ñè       | 643/3000 [17:37<1:13:26,  1.87s/it]a2c_tuned train:  21%|‚ñà‚ñà‚ñè       | 644/3000 [17:39<1:14:49,  1.91s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 645/3000 [17:41<1:13:15,  1.87s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 646/3000 [17:42<1:00:41,  1.55s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 647/3000 [17:44<1:10:22,  1.79s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 648/3000 [17:45<59:00,  1.51s/it]  a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 649/3000 [17:47<1:03:43,  1.63s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 650/3000 [17:48<54:32,  1.39s/it]  [step=597] episode=597.0000 return=-115.9899 length=20.0000 global_step=14341.0000 loss=31.6304 policy_loss=-0.0000 value_loss=63.2608 entropy=0.0000
[step=598] episode=598.0000 return=-115.7981 length=13.0000 global_step=14354.0000 loss=49.7897 policy_loss=-0.0000 value_loss=99.5795 entropy=0.0000
[step=599] episode=599.0000 return=-115.9733 length=13.0000 global_step=14367.0000 loss=11.2298 policy_loss=-0.0000 value_loss=22.4595 entropy=0.0000
[step=600] episode=600.0000 return=-115.8180 length=13.0000 global_step=14380.0000 loss=17.7959 policy_loss=-0.0000 value_loss=35.5918 entropy=0.0000
[step=601] episode=601.0000 return=-115.9961 length=37.0000 global_step=14417.0000 loss=249.9473 policy_loss=-0.0000 value_loss=499.8945 entropy=0.0000
[step=602] episode=602.0000 return=-115.9997 length=21.0000 global_step=14438.0000 loss=61.3934 policy_loss=-0.0000 value_loss=122.7868 entropy=0.0000
[step=603] episode=603.0000 return=-115.9396 length=21.0000 global_step=14459.0000 loss=49.9451 policy_loss=-0.0000 value_loss=99.8902 entropy=0.0000
[step=604] episode=604.0000 return=-115.9975 length=36.0000 global_step=14495.0000 loss=32.8212 policy_loss=-0.0000 value_loss=65.6423 entropy=0.0000
[step=605] episode=605.0000 return=-115.9960 length=19.0000 global_step=14514.0000 loss=50.4914 policy_loss=-0.0000 value_loss=100.9828 entropy=0.0000
[step=606] episode=606.0000 return=-115.9832 length=28.0000 global_step=14542.0000 loss=50.7853 policy_loss=-0.0000 value_loss=101.5706 entropy=0.0000
[step=607] episode=607.0000 return=-115.9576 length=30.0000 global_step=14572.0000 loss=55.6144 policy_loss=-0.0000 value_loss=111.2289 entropy=0.0000
[step=608] episode=608.0000 return=-115.8340 length=21.0000 global_step=14593.0000 loss=171.8129 policy_loss=-0.0000 value_loss=343.6259 entropy=0.0000
[step=609] episode=609.0000 return=-115.7953 length=20.0000 global_step=14613.0000 loss=88.8906 policy_loss=-0.0000 value_loss=177.7812 entropy=0.0000
[step=610] episode=610.0000 return=-115.9096 length=21.0000 global_step=14634.0000 loss=10.3057 policy_loss=-0.0000 value_loss=20.6113 entropy=0.0000
[step=611] episode=611.0000 return=-116.0000 length=38.0000 global_step=14672.0000 loss=153.6434 policy_loss=-0.0000 value_loss=307.2868 entropy=0.0000
[step=612] episode=612.0000 return=-115.9805 length=28.0000 global_step=14700.0000 loss=99.0692 policy_loss=-0.0000 value_loss=198.1383 entropy=0.0000
[step=613] episode=613.0000 return=-115.9982 length=38.0000 global_step=14738.0000 loss=125.2860 policy_loss=-0.0000 value_loss=250.5721 entropy=0.0000
[step=614] episode=614.0000 return=-115.9988 length=72.0000 global_step=14810.0000 loss=237.0356 policy_loss=-0.0000 value_loss=474.0711 entropy=0.0000
[step=615] episode=615.0000 return=-115.9982 length=30.0000 global_step=14840.0000 loss=39.7000 policy_loss=-0.0000 value_loss=79.4000 entropy=0.0000
[step=616] episode=616.0000 return=-115.9284 length=13.0000 global_step=14853.0000 loss=283.1008 policy_loss=-0.0000 value_loss=566.2016 entropy=0.0000
[step=617] episode=617.0000 return=-115.9982 length=12.0000 global_step=14865.0000 loss=304.6674 policy_loss=-0.0000 value_loss=609.3349 entropy=0.0000
[step=618] episode=618.0000 return=-115.8711 length=22.0000 global_step=14887.0000 loss=130.6346 policy_loss=-0.0000 value_loss=261.2692 entropy=0.0000
[step=619] episode=619.0000 return=-115.9978 length=36.0000 global_step=14923.0000 loss=14.5998 policy_loss=-0.0000 value_loss=29.1997 entropy=0.0000
[step=620] episode=620.0000 return=-115.9513 length=22.0000 global_step=14945.0000 loss=12.4965 policy_loss=-0.0000 value_loss=24.9930 entropy=0.0000
[step=621] episode=621.0000 return=-115.9810 length=19.0000 global_step=14964.0000 loss=31.7650 policy_loss=-0.0000 value_loss=63.5299 entropy=0.0000
[step=622] episode=622.0000 return=-115.9955 length=20.0000 global_step=14984.0000 loss=21.1281 policy_loss=-0.0000 value_loss=42.2562 entropy=0.0000
[step=623] episode=623.0000 return=-115.9953 length=26.0000 global_step=15010.0000 loss=120.0688 policy_loss=-0.0000 value_loss=240.1376 entropy=0.0000
[step=624] episode=624.0000 return=-115.9962 length=28.0000 global_step=15038.0000 loss=59.2532 policy_loss=-0.0000 value_loss=118.5064 entropy=0.0000
[step=625] episode=625.0000 return=-115.9987 length=29.0000 global_step=15067.0000 loss=18.3525 policy_loss=-0.0000 value_loss=36.7049 entropy=0.0000
[step=626] episode=626.0000 return=-115.9957 length=20.0000 global_step=15087.0000 loss=105.0343 policy_loss=-0.0000 value_loss=210.0687 entropy=0.0000
[step=627] episode=627.0000 return=-115.9975 length=29.0000 global_step=15116.0000 loss=56.9392 policy_loss=-0.0000 value_loss=113.8784 entropy=0.0000
[step=628] episode=628.0000 return=-115.9948 length=28.0000 global_step=15144.0000 loss=61.2029 policy_loss=-0.0000 value_loss=122.4059 entropy=0.0000
[step=629] episode=629.0000 return=-115.9964 length=35.0000 global_step=15179.0000 loss=30.8457 policy_loss=-0.0000 value_loss=61.6913 entropy=0.0000
[step=630] episode=630.0000 return=-115.9959 length=27.0000 global_step=15206.0000 loss=33.6188 policy_loss=-0.0000 value_loss=67.2377 entropy=0.0000
[step=631] episode=631.0000 return=-115.9965 length=22.0000 global_step=15228.0000 loss=8.4276 policy_loss=-0.0000 value_loss=16.8552 entropy=0.0000
[step=632] episode=632.0000 return=-115.9812 length=27.0000 global_step=15255.0000 loss=64.1647 policy_loss=-0.0000 value_loss=128.3295 entropy=0.0000
[step=633] episode=633.0000 return=-115.9959 length=38.0000 global_step=15293.0000 loss=207.7601 policy_loss=-0.0000 value_loss=415.5202 entropy=0.0000
[step=634] episode=634.0000 return=-115.9909 length=29.0000 global_step=15322.0000 loss=116.6666 policy_loss=-0.0000 value_loss=233.3331 entropy=0.0000
[step=635] episode=635.0000 return=-115.9768 length=29.0000 global_step=15351.0000 loss=45.1942 policy_loss=-0.0000 value_loss=90.3884 entropy=0.0000
[step=636] episode=636.0000 return=-115.9972 length=21.0000 global_step=15372.0000 loss=10.1447 policy_loss=-0.0000 value_loss=20.2894 entropy=0.0000
[step=637] episode=637.0000 return=-115.9062 length=29.0000 global_step=15401.0000 loss=25.1627 policy_loss=-0.0000 value_loss=50.3255 entropy=0.0000
[step=638] episode=638.0000 return=-115.9968 length=28.0000 global_step=15429.0000 loss=47.4013 policy_loss=-0.0000 value_loss=94.8027 entropy=0.0000
[step=639] episode=639.0000 return=-115.9385 length=18.0000 global_step=15447.0000 loss=149.3262 policy_loss=-0.0000 value_loss=298.6525 entropy=0.0000
[step=640] episode=640.0000 return=-115.9988 length=33.0000 global_step=15480.0000 loss=33.2370 policy_loss=-0.0000 value_loss=66.4741 entropy=0.0000
[step=641] episode=641.0000 return=-115.9978 length=21.0000 global_step=15501.0000 loss=36.3933 policy_loss=-0.0000 value_loss=72.7867 entropy=0.0000
[step=642] episode=642.0000 return=-115.9995 length=30.0000 global_step=15531.0000 loss=24.9305 policy_loss=-0.0000 value_loss=49.8609 entropy=0.0000
[step=643] episode=643.0000 return=-115.9961 length=29.0000 global_step=15560.0000 loss=47.8640 policy_loss=-0.0000 value_loss=95.7280 entropy=0.0000
[step=644] episode=644.0000 return=-115.9845 length=28.0000 global_step=15588.0000 loss=50.3553 policy_loss=-0.0000 value_loss=100.7106 entropy=0.0000
[step=645] episode=645.0000 return=-115.9848 length=26.0000 global_step=15614.0000 loss=6.9623 policy_loss=-0.0000 value_loss=13.9246 entropy=0.0000
[step=646] episode=646.0000 return=-115.7384 length=12.0000 global_step=15626.0000 loss=46.3337 policy_loss=-0.0000 value_loss=92.6674 entropy=0.0000
[step=647] episode=647.0000 return=-115.9983 length=34.0000 global_step=15660.0000 loss=18.5089 policy_loss=-0.0000 value_loss=37.0177 entropy=0.0000
[step=648] episode=648.0000 return=-115.9475 length=12.0000 global_step=15672.0000 loss=84.6594 policy_loss=-0.0000 value_loss=169.3188 entropy=0.0000
[step=649] episode=649.0000 return=-115.9931 length=27.0000 global_step=15699.0000 loss=15.9233 policy_loss=-0.0000 value_loss=31.8466 entropy=0.0000
[step=650] episode=650.0000 return=-115.8978 length=12.0000 global_step=15711.0000 loss=52.7308 policy_loss=-0.0000 value_loss=105.4617 entropy=0.0000
a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 651/3000 [17:50<1:00:45,  1.55s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 652/3000 [17:53<1:13:29,  1.88s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 653/3000 [17:54<1:13:22,  1.88s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 654/3000 [17:56<1:14:24,  1.90s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 655/3000 [17:58<1:15:16,  1.93s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 656/3000 [18:00<1:13:02,  1.87s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 657/3000 [18:02<1:15:42,  1.94s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 658/3000 [18:04<1:09:20,  1.78s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 659/3000 [18:05<1:05:20,  1.67s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 660/3000 [18:06<1:01:44,  1.58s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 661/3000 [18:08<1:03:47,  1.64s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 662/3000 [18:10<1:06:48,  1.71s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 663/3000 [18:12<1:03:27,  1.63s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 664/3000 [18:12<54:41,  1.40s/it]  a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 665/3000 [18:14<54:07,  1.39s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 666/3000 [18:16<1:02:15,  1.60s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 667/3000 [18:18<1:06:21,  1.71s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 668/3000 [18:19<1:03:47,  1.64s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 669/3000 [18:21<1:00:46,  1.56s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 670/3000 [18:22<1:00:27,  1.56s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 671/3000 [18:24<58:10,  1.50s/it]  a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 672/3000 [18:26<1:09:09,  1.78s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 673/3000 [18:27<58:14,  1.50s/it]  a2c_tuned train:  22%|‚ñà‚ñà‚ñè       | 674/3000 [18:29<1:09:58,  1.81s/it]a2c_tuned train:  22%|‚ñà‚ñà‚ñé       | 675/3000 [18:31<1:04:01,  1.65s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 676/3000 [18:33<1:07:50,  1.75s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 677/3000 [18:34<1:03:03,  1.63s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 678/3000 [18:36<1:05:17,  1.69s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 679/3000 [18:37<1:02:18,  1.61s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 680/3000 [18:38<57:31,  1.49s/it]  a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 681/3000 [18:39<49:33,  1.28s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 682/3000 [18:41<50:10,  1.30s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 683/3000 [18:42<50:29,  1.31s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 684/3000 [18:43<44:51,  1.16s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 685/3000 [18:44<48:10,  1.25s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 686/3000 [18:47<1:01:04,  1.58s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 687/3000 [18:47<52:05,  1.35s/it]  a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 688/3000 [18:50<1:06:42,  1.73s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 689/3000 [18:52<1:10:02,  1.82s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 690/3000 [18:53<1:05:54,  1.71s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 691/3000 [18:55<1:04:12,  1.67s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 692/3000 [18:56<1:00:02,  1.56s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 693/3000 [19:00<1:24:07,  2.19s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 694/3000 [19:01<1:15:05,  1.95s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 695/3000 [19:02<1:01:02,  1.59s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 696/3000 [19:04<58:58,  1.54s/it]  a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 697/3000 [19:06<1:04:55,  1.69s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 698/3000 [19:09<1:19:38,  2.08s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 699/3000 [19:10<1:10:45,  1.84s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 700/3000 [19:11<1:06:05,  1.72s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 701/3000 [19:13<1:05:55,  1.72s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 702/3000 [19:14<56:46,  1.48s/it]  a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 703/3000 [19:16<59:40,  1.56s/it]a2c_tuned train:  23%|‚ñà‚ñà‚ñé       | 704/3000 [19:18<1:11:11,  1.86s/it][step=651] episode=651.0000 return=-115.9655 length=29.0000 global_step=15740.0000 loss=32.1195 policy_loss=-0.0000 value_loss=64.2390 entropy=0.0000
[step=652] episode=652.0000 return=-115.9343 length=38.0000 global_step=15778.0000 loss=65.6603 policy_loss=-0.0000 value_loss=131.3207 entropy=0.0000
[step=653] episode=653.0000 return=-115.9979 length=28.0000 global_step=15806.0000 loss=46.7242 policy_loss=-0.0000 value_loss=93.4484 entropy=0.0000
[step=654] episode=654.0000 return=-115.9973 length=30.0000 global_step=15836.0000 loss=26.3185 policy_loss=-0.0000 value_loss=52.6369 entropy=0.0000
[step=655] episode=655.0000 return=-115.9840 length=30.0000 global_step=15866.0000 loss=15.3871 policy_loss=-0.0000 value_loss=30.7742 entropy=0.0000
[step=656] episode=656.0000 return=-115.9385 length=27.0000 global_step=15893.0000 loss=63.7889 policy_loss=-0.0000 value_loss=127.5779 entropy=0.0000
[step=657] episode=657.0000 return=-115.9984 length=30.0000 global_step=15923.0000 loss=23.7755 policy_loss=-0.0000 value_loss=47.5511 entropy=0.0000
[step=658] episode=658.0000 return=-115.9882 length=21.0000 global_step=15944.0000 loss=25.6484 policy_loss=-0.0000 value_loss=51.2969 entropy=0.0000
[step=659] episode=659.0000 return=-115.9385 length=21.0000 global_step=15965.0000 loss=8.7044 policy_loss=-0.0000 value_loss=17.4089 entropy=0.0000
[step=660] episode=660.0000 return=-115.9948 length=20.0000 global_step=15985.0000 loss=18.8668 policy_loss=-0.0000 value_loss=37.7336 entropy=0.0000
[step=661] episode=661.0000 return=-115.9837 length=26.0000 global_step=16011.0000 loss=68.6143 policy_loss=-0.0000 value_loss=137.2287 entropy=0.0000
[step=662] episode=662.0000 return=-115.9997 length=28.0000 global_step=16039.0000 loss=82.2296 policy_loss=-0.0000 value_loss=164.4592 entropy=0.0000
[step=663] episode=663.0000 return=-115.9958 length=20.0000 global_step=16059.0000 loss=15.9674 policy_loss=-0.0000 value_loss=31.9348 entropy=0.0000
[step=664] episode=664.0000 return=-115.9097 length=12.0000 global_step=16071.0000 loss=28.8580 policy_loss=-0.0000 value_loss=57.7160 entropy=0.0000
[step=665] episode=665.0000 return=-115.9949 length=19.0000 global_step=16090.0000 loss=14.4821 policy_loss=-0.0000 value_loss=28.9643 entropy=0.0000
[step=666] episode=666.0000 return=-115.9989 length=31.0000 global_step=16121.0000 loss=7.7816 policy_loss=-0.0000 value_loss=15.5631 entropy=0.0000
[step=667] episode=667.0000 return=-115.9841 length=29.0000 global_step=16150.0000 loss=16.1789 policy_loss=-0.0000 value_loss=32.3579 entropy=0.0000
[step=668] episode=668.0000 return=-115.9845 length=21.0000 global_step=16171.0000 loss=20.8935 policy_loss=-0.0000 value_loss=41.7869 entropy=0.0000
[step=669] episode=669.0000 return=-115.9548 length=20.0000 global_step=16191.0000 loss=27.9419 policy_loss=-0.0000 value_loss=55.8838 entropy=0.0000
[step=670] episode=670.0000 return=-116.0000 length=22.0000 global_step=16213.0000 loss=10.0730 policy_loss=-0.0000 value_loss=20.1460 entropy=0.0000
[step=671] episode=671.0000 return=-115.9821 length=20.0000 global_step=16233.0000 loss=12.9653 policy_loss=-0.0000 value_loss=25.9305 entropy=0.0000
[step=672] episode=672.0000 return=-116.0000 length=36.0000 global_step=16269.0000 loss=96.6214 policy_loss=-0.0000 value_loss=193.2428 entropy=0.0000
[step=673] episode=673.0000 return=-115.9953 length=12.0000 global_step=16281.0000 loss=27.2823 policy_loss=-0.0000 value_loss=54.5645 entropy=0.0000
[step=674] episode=674.0000 return=-115.9999 length=38.0000 global_step=16319.0000 loss=56.6616 policy_loss=-0.0000 value_loss=113.3231 entropy=0.0000
[step=675] episode=675.0000 return=-115.9271 length=18.0000 global_step=16337.0000 loss=22.7039 policy_loss=-0.0000 value_loss=45.4079 entropy=0.0000
[step=676] episode=676.0000 return=-115.9918 length=29.0000 global_step=16366.0000 loss=9.5763 policy_loss=-0.0000 value_loss=19.1526 entropy=0.0000
[step=677] episode=677.0000 return=-115.9965 length=20.0000 global_step=16386.0000 loss=15.4348 policy_loss=-0.0000 value_loss=30.8695 entropy=0.0000
[step=678] episode=678.0000 return=-115.9831 length=27.0000 global_step=16413.0000 loss=18.5687 policy_loss=-0.0000 value_loss=37.1375 entropy=0.0000
[step=679] episode=679.0000 return=-115.9968 length=21.0000 global_step=16434.0000 loss=7.9057 policy_loss=-0.0000 value_loss=15.8115 entropy=0.0000
[step=680] episode=680.0000 return=-115.9096 length=18.0000 global_step=16452.0000 loss=7.2109 policy_loss=-0.0000 value_loss=14.4217 entropy=0.0000
[step=681] episode=681.0000 return=-115.9974 length=12.0000 global_step=16464.0000 loss=21.3262 policy_loss=-0.0000 value_loss=42.6524 entropy=0.0000
[step=682] episode=682.0000 return=-115.9994 length=20.0000 global_step=16484.0000 loss=22.9655 policy_loss=-0.0000 value_loss=45.9311 entropy=0.0000
[step=683] episode=683.0000 return=-115.8210 length=20.0000 global_step=16504.0000 loss=8.9153 policy_loss=-0.0000 value_loss=17.8307 entropy=0.0000
[step=684] episode=684.0000 return=-115.9949 length=12.0000 global_step=16516.0000 loss=10.2975 policy_loss=-0.0000 value_loss=20.5950 entropy=0.0000
[step=685] episode=685.0000 return=-115.9984 length=21.0000 global_step=16537.0000 loss=7.0225 policy_loss=-0.0000 value_loss=14.0450 entropy=0.0000
[step=686] episode=686.0000 return=-115.9999 length=36.0000 global_step=16573.0000 loss=80.7253 policy_loss=-0.0000 value_loss=161.4506 entropy=0.0000
[step=687] episode=687.0000 return=-115.8937 length=11.0000 global_step=16584.0000 loss=63.0246 policy_loss=-0.0000 value_loss=126.0491 entropy=0.0000
[step=688] episode=688.0000 return=-115.9941 length=38.0000 global_step=16622.0000 loss=35.9453 policy_loss=-0.0000 value_loss=71.8906 entropy=0.0000
[step=689] episode=689.0000 return=-115.9830 length=30.0000 global_step=16652.0000 loss=18.0225 policy_loss=-0.0000 value_loss=36.0450 entropy=0.0000
[step=690] episode=690.0000 return=-115.9945 length=20.0000 global_step=16672.0000 loss=45.7363 policy_loss=-0.0000 value_loss=91.4726 entropy=0.0000
[step=691] episode=691.0000 return=-115.9993 length=22.0000 global_step=16694.0000 loss=23.0523 policy_loss=-0.0000 value_loss=46.1046 entropy=0.0000
[step=692] episode=692.0000 return=-115.9707 length=20.0000 global_step=16714.0000 loss=10.7647 policy_loss=-0.0000 value_loss=21.5293 entropy=0.0000
[step=693] episode=693.0000 return=-115.9882 length=53.0000 global_step=16767.0000 loss=168.1450 policy_loss=-0.0000 value_loss=336.2899 entropy=0.0000
[step=694] episode=694.0000 return=-115.8864 length=20.0000 global_step=16787.0000 loss=19.1307 policy_loss=-0.0000 value_loss=38.2615 entropy=0.0000
[step=695] episode=695.0000 return=-115.7681 length=11.0000 global_step=16798.0000 loss=13.9720 policy_loss=-0.0000 value_loss=27.9440 entropy=0.0000
[step=696] episode=696.0000 return=-115.9949 length=21.0000 global_step=16819.0000 loss=23.3600 policy_loss=-0.0000 value_loss=46.7199 entropy=0.0000
[step=697] episode=697.0000 return=-115.9850 length=29.0000 global_step=16848.0000 loss=21.1872 policy_loss=-0.0000 value_loss=42.3743 entropy=0.0000
[step=698] episode=698.0000 return=-115.9870 length=43.0000 global_step=16891.0000 loss=55.1635 policy_loss=-0.0000 value_loss=110.3269 entropy=0.0000
[step=699] episode=699.0000 return=-115.8869 length=19.0000 global_step=16910.0000 loss=60.4656 policy_loss=-0.0000 value_loss=120.9312 entropy=0.0000
[step=700] episode=700.0000 return=-115.9837 length=21.0000 global_step=16931.0000 loss=165.3886 policy_loss=-0.0000 value_loss=330.7773 entropy=0.0000
[step=701] episode=701.0000 return=-115.9941 length=25.0000 global_step=16956.0000 loss=74.2298 policy_loss=-0.0000 value_loss=148.4596 entropy=0.0000
[step=702] episode=702.0000 return=-115.8765 length=13.0000 global_step=16969.0000 loss=68.2922 policy_loss=-0.0000 value_loss=136.5843 entropy=0.0000
[step=703] episode=703.0000 return=-115.9950 length=26.0000 global_step=16995.0000 loss=42.5575 policy_loss=-0.0000 value_loss=85.1150 entropy=0.0000
[step=704] episode=704.0000 return=-115.9999 length=38.0000 global_step=17033.0000 loss=116.0738 policy_loss=-0.0000 value_loss=232.1476 entropy=0.0000
a2c_tuned train:  24%|‚ñà‚ñà‚ñé       | 705/3000 [19:20<1:13:58,  1.93s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñé       | 706/3000 [19:23<1:21:29,  2.13s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñé       | 707/3000 [19:24<1:06:27,  1.74s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñé       | 708/3000 [19:25<55:57,  1.46s/it]  a2c_tuned train:  24%|‚ñà‚ñà‚ñé       | 709/3000 [19:26<59:18,  1.55s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñé       | 710/3000 [19:30<1:23:44,  2.19s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñé       | 711/3000 [19:33<1:34:00,  2.46s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñé       | 712/3000 [19:35<1:25:58,  2.25s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 713/3000 [19:37<1:21:54,  2.15s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 714/3000 [19:41<1:39:10,  2.60s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 715/3000 [19:44<1:43:58,  2.73s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 716/3000 [19:45<1:28:37,  2.33s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 717/3000 [19:47<1:26:58,  2.29s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 718/3000 [19:49<1:21:27,  2.14s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 719/3000 [19:50<1:12:02,  1.90s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 720/3000 [19:51<1:01:01,  1.61s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 721/3000 [19:53<1:02:54,  1.66s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 722/3000 [19:54<59:51,  1.58s/it]  a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 723/3000 [19:56<58:26,  1.54s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 724/3000 [19:57<51:01,  1.35s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 725/3000 [19:59<58:20,  1.54s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 726/3000 [20:00<57:20,  1.51s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 727/3000 [20:02<56:16,  1.49s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 728/3000 [20:02<49:23,  1.30s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 729/3000 [20:04<56:55,  1.50s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 730/3000 [20:06<1:01:35,  1.63s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 731/3000 [20:08<1:05:07,  1.72s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 732/3000 [20:10<1:08:49,  1.82s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 733/3000 [20:13<1:20:43,  2.14s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 734/3000 [20:14<1:07:00,  1.77s/it]a2c_tuned train:  24%|‚ñà‚ñà‚ñç       | 735/3000 [20:16<1:06:51,  1.77s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 736/3000 [20:18<1:08:16,  1.81s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 737/3000 [20:20<1:08:44,  1.82s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 738/3000 [20:21<1:04:31,  1.71s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 739/3000 [20:23<1:07:01,  1.78s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 740/3000 [20:24<1:02:26,  1.66s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 741/3000 [20:25<51:45,  1.37s/it]  a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 742/3000 [20:26<45:41,  1.21s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 743/3000 [20:28<57:43,  1.53s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 744/3000 [20:30<1:02:43,  1.67s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 745/3000 [20:32<1:06:39,  1.77s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 746/3000 [20:33<55:44,  1.48s/it]  a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 747/3000 [20:34<53:12,  1.42s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 748/3000 [20:36<58:08,  1.55s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñç       | 749/3000 [20:38<55:58,  1.49s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 750/3000 [20:40<1:02:04,  1.66s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 751/3000 [20:41<58:26,  1.56s/it]  a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 752/3000 [20:43<1:08:53,  1.84s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 753/3000 [20:45<1:04:57,  1.73s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 754/3000 [20:46<1:00:05,  1.61s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 755/3000 [20:48<1:01:49,  1.65s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 756/3000 [20:49<52:10,  1.40s/it]  a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 757/3000 [20:50<51:13,  1.37s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 758/3000 [20:52<58:10,  1.56s/it][step=705] episode=705.0000 return=-115.9984 length=30.0000 global_step=17063.0000 loss=86.7081 policy_loss=-0.0000 value_loss=173.4162 entropy=0.0000
[step=706] episode=706.0000 return=-115.9993 length=38.0000 global_step=17101.0000 loss=116.9078 policy_loss=-0.0000 value_loss=233.8155 entropy=0.0000
[step=707] episode=707.0000 return=-115.9747 length=12.0000 global_step=17113.0000 loss=66.3557 policy_loss=-0.0000 value_loss=132.7114 entropy=0.0000
[step=708] episode=708.0000 return=-115.7757 length=11.0000 global_step=17124.0000 loss=102.6403 policy_loss=-0.0000 value_loss=205.2805 entropy=0.0000
[step=709] episode=709.0000 return=-115.9959 length=25.0000 global_step=17149.0000 loss=16.5126 policy_loss=-0.0000 value_loss=33.0251 entropy=0.0000
[step=710] episode=710.0000 return=-115.9931 length=54.0000 global_step=17203.0000 loss=104.4112 policy_loss=-0.0000 value_loss=208.8224 entropy=0.0000
[step=711] episode=711.0000 return=-115.9748 length=45.0000 global_step=17248.0000 loss=50.6490 policy_loss=-0.0000 value_loss=101.2980 entropy=0.0000
[step=712] episode=712.0000 return=-115.9949 length=27.0000 global_step=17275.0000 loss=15.8213 policy_loss=-0.0000 value_loss=31.6426 entropy=0.0000
[step=713] episode=713.0000 return=-115.9895 length=28.0000 global_step=17303.0000 loss=18.1322 policy_loss=-0.0000 value_loss=36.2644 entropy=0.0000
[step=714] episode=714.0000 return=-115.9977 length=55.0000 global_step=17358.0000 loss=72.8267 policy_loss=-0.0000 value_loss=145.6533 entropy=0.0000
[step=715] episode=715.0000 return=-115.9095 length=46.0000 global_step=17404.0000 loss=50.7833 policy_loss=-0.0000 value_loss=101.5667 entropy=0.0000
[step=716] episode=716.0000 return=-115.9973 length=20.0000 global_step=17424.0000 loss=76.8873 policy_loss=-0.0000 value_loss=153.7745 entropy=0.0000
[step=717] episode=717.0000 return=-115.9840 length=33.0000 global_step=17457.0000 loss=32.8929 policy_loss=-0.0000 value_loss=65.7857 entropy=0.0000
[step=718] episode=718.0000 return=-115.9929 length=26.0000 global_step=17483.0000 loss=31.0841 policy_loss=-0.0000 value_loss=62.1682 entropy=0.0000
[step=719] episode=719.0000 return=-115.9691 length=19.0000 global_step=17502.0000 loss=18.1440 policy_loss=-0.0000 value_loss=36.2879 entropy=0.0000
[step=720] episode=720.0000 return=-115.9994 length=13.0000 global_step=17515.0000 loss=7.7756 policy_loss=-0.0000 value_loss=15.5512 entropy=0.0000
[step=721] episode=721.0000 return=-115.9941 length=26.0000 global_step=17541.0000 loss=133.6750 policy_loss=-0.0000 value_loss=267.3499 entropy=0.0000
[step=722] episode=722.0000 return=-115.9938 length=20.0000 global_step=17561.0000 loss=148.6531 policy_loss=-0.0000 value_loss=297.3061 entropy=0.0000
[step=723] episode=723.0000 return=-115.9995 length=21.0000 global_step=17582.0000 loss=88.5571 policy_loss=-0.0000 value_loss=177.1142 entropy=0.0000
[step=724] episode=724.0000 return=-115.8250 length=13.0000 global_step=17595.0000 loss=10.2881 policy_loss=-0.0000 value_loss=20.5763 entropy=0.0000
[step=725] episode=725.0000 return=-115.9950 length=30.0000 global_step=17625.0000 loss=16.4833 policy_loss=-0.0000 value_loss=32.9665 entropy=0.0000
[step=726] episode=726.0000 return=-115.9955 length=21.0000 global_step=17646.0000 loss=78.9999 policy_loss=-0.0000 value_loss=157.9999 entropy=0.0000
[step=727] episode=727.0000 return=-115.8870 length=21.0000 global_step=17667.0000 loss=127.9715 policy_loss=-0.0000 value_loss=255.9429 entropy=0.0000
[step=728] episode=728.0000 return=-115.8370 length=12.0000 global_step=17679.0000 loss=227.7949 policy_loss=-0.0000 value_loss=455.5898 entropy=0.0000
[step=729] episode=729.0000 return=-115.8503 length=29.0000 global_step=17708.0000 loss=21.8424 policy_loss=-0.0000 value_loss=43.6847 entropy=0.0000
[step=730] episode=730.0000 return=-115.9978 length=28.0000 global_step=17736.0000 loss=7.5553 policy_loss=-0.0000 value_loss=15.1105 entropy=0.0000
[step=731] episode=731.0000 return=-115.9840 length=29.0000 global_step=17765.0000 loss=84.1196 policy_loss=-0.0000 value_loss=168.2391 entropy=0.0000
[step=732] episode=732.0000 return=-115.9984 length=30.0000 global_step=17795.0000 loss=92.6952 policy_loss=-0.0000 value_loss=185.3905 entropy=0.0000
[step=733] episode=733.0000 return=-115.9983 length=42.0000 global_step=17837.0000 loss=125.3655 policy_loss=-0.0000 value_loss=250.7310 entropy=0.0000
[step=734] episode=734.0000 return=-115.8548 length=13.0000 global_step=17850.0000 loss=35.7359 policy_loss=-0.0000 value_loss=71.4719 entropy=0.0000
[step=735] episode=735.0000 return=-115.9993 length=25.0000 global_step=17875.0000 loss=18.0627 policy_loss=-0.0000 value_loss=36.1253 entropy=0.0000
[step=736] episode=736.0000 return=-115.9939 length=29.0000 global_step=17904.0000 loss=28.7216 policy_loss=-0.0000 value_loss=57.4431 entropy=0.0000
[step=737] episode=737.0000 return=-115.9968 length=28.0000 global_step=17932.0000 loss=15.0854 policy_loss=-0.0000 value_loss=30.1708 entropy=0.0000
[step=738] episode=738.0000 return=-115.9831 length=21.0000 global_step=17953.0000 loss=9.4715 policy_loss=-0.0000 value_loss=18.9430 entropy=0.0000
[step=739] episode=739.0000 return=-115.9983 length=28.0000 global_step=17981.0000 loss=42.3343 policy_loss=-0.0000 value_loss=84.6686 entropy=0.0000
[step=740] episode=740.0000 return=-115.9995 length=20.0000 global_step=18001.0000 loss=16.6838 policy_loss=-0.0000 value_loss=33.3676 entropy=0.0000
[step=741] episode=741.0000 return=-115.6609 length=10.0000 global_step=18011.0000 loss=14.4466 policy_loss=-0.0000 value_loss=28.8932 entropy=0.0000
[step=742] episode=742.0000 return=-115.9930 length=12.0000 global_step=18023.0000 loss=10.1397 policy_loss=-0.0000 value_loss=20.2794 entropy=0.0000
[step=743] episode=743.0000 return=-115.9759 length=34.0000 global_step=18057.0000 loss=134.9428 policy_loss=-0.0000 value_loss=269.8856 entropy=0.0000
[step=744] episode=744.0000 return=-115.9970 length=29.0000 global_step=18086.0000 loss=57.9349 policy_loss=-0.0000 value_loss=115.8697 entropy=0.0000
[step=745] episode=745.0000 return=-115.9948 length=29.0000 global_step=18115.0000 loss=17.4228 policy_loss=-0.0000 value_loss=34.8457 entropy=0.0000
[step=746] episode=746.0000 return=-115.9845 length=12.0000 global_step=18127.0000 loss=151.0985 policy_loss=-0.0000 value_loss=302.1970 entropy=0.0000
[step=747] episode=747.0000 return=-115.9915 length=19.0000 global_step=18146.0000 loss=101.7201 policy_loss=-0.0000 value_loss=203.4402 entropy=0.0000
[step=748] episode=748.0000 return=-115.9991 length=28.0000 global_step=18174.0000 loss=27.3238 policy_loss=-0.0000 value_loss=54.6476 entropy=0.0000
[step=749] episode=749.0000 return=-115.9975 length=20.0000 global_step=18194.0000 loss=12.1777 policy_loss=-0.0000 value_loss=24.3553 entropy=0.0000
[step=750] episode=750.0000 return=-116.0000 length=29.0000 global_step=18223.0000 loss=75.8118 policy_loss=-0.0000 value_loss=151.6236 entropy=0.0000
[step=751] episode=751.0000 return=-115.9915 length=19.0000 global_step=18242.0000 loss=50.5728 policy_loss=-0.0000 value_loss=101.1456 entropy=0.0000
[step=752] episode=752.0000 return=-115.9942 length=37.0000 global_step=18279.0000 loss=95.1628 policy_loss=-0.0000 value_loss=190.3255 entropy=0.0000
[step=753] episode=753.0000 return=-115.9997 length=22.0000 global_step=18301.0000 loss=4.7987 policy_loss=-0.0000 value_loss=9.5974 entropy=0.0000
[step=754] episode=754.0000 return=-115.9797 length=19.0000 global_step=18320.0000 loss=27.1533 policy_loss=-0.0000 value_loss=54.3065 entropy=0.0000
[step=755] episode=755.0000 return=-115.9408 length=26.0000 global_step=18346.0000 loss=15.6226 policy_loss=-0.0000 value_loss=31.2451 entropy=0.0000
[step=756] episode=756.0000 return=-115.8811 length=11.0000 global_step=18357.0000 loss=54.3985 policy_loss=-0.0000 value_loss=108.7969 entropy=0.0000
[step=757] episode=757.0000 return=-115.9934 length=19.0000 global_step=18376.0000 loss=8.8748 policy_loss=-0.0000 value_loss=17.7496 entropy=0.0000
[step=758] episode=758.0000 return=-116.0000 length=29.0000 global_step=18405.0000 loss=40.3282 policy_loss=-0.0000 value_loss=80.6564 entropy=0.0000
a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 759/3000 [20:54<1:03:02,  1.69s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 760/3000 [20:56<1:05:29,  1.75s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 761/3000 [20:57<55:03,  1.48s/it]  a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 762/3000 [21:00<1:09:19,  1.86s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 763/3000 [21:01<1:09:23,  1.86s/it]a2c_tuned train:  25%|‚ñà‚ñà‚ñå       | 764/3000 [21:03<1:04:21,  1.73s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 765/3000 [21:04<1:01:04,  1.64s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 766/3000 [21:05<52:02,  1.40s/it]  a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 767/3000 [21:07<52:34,  1.41s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 768/3000 [21:08<57:57,  1.56s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 769/3000 [21:10<1:01:37,  1.66s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 770/3000 [21:12<58:16,  1.57s/it]  a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 771/3000 [21:14<1:04:07,  1.73s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 772/3000 [21:16<1:06:13,  1.78s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 773/3000 [21:17<1:02:12,  1.68s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 774/3000 [21:19<1:09:08,  1.86s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 775/3000 [21:21<1:02:21,  1.68s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 776/3000 [21:22<59:58,  1.62s/it]  a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 777/3000 [21:24<1:04:19,  1.74s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 778/3000 [21:26<1:01:04,  1.65s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 779/3000 [21:26<51:30,  1.39s/it]  a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 780/3000 [21:27<46:16,  1.25s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 781/3000 [21:28<41:29,  1.12s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 782/3000 [21:32<1:09:37,  1.88s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 783/3000 [21:34<1:15:54,  2.05s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 784/3000 [21:35<1:06:56,  1.81s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 785/3000 [21:37<1:02:24,  1.69s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 786/3000 [21:38<58:42,  1.59s/it]  a2c_tuned train:  26%|‚ñà‚ñà‚ñå       | 787/3000 [21:40<56:10,  1.52s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñã       | 788/3000 [21:42<1:00:32,  1.64s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñã       | 789/3000 [21:43<1:02:05,  1.69s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñã       | 790/3000 [21:45<58:24,  1.59s/it]  a2c_tuned train:  26%|‚ñà‚ñà‚ñã       | 791/3000 [21:47<1:02:34,  1.70s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñã       | 792/3000 [21:47<51:52,  1.41s/it]  a2c_tuned train:  26%|‚ñà‚ñà‚ñã       | 793/3000 [21:49<52:42,  1.43s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñã       | 794/3000 [21:50<50:38,  1.38s/it]a2c_tuned train:  26%|‚ñà‚ñà‚ñã       | 795/3000 [21:51<50:36,  1.38s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 796/3000 [21:53<50:07,  1.36s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 797/3000 [21:55<56:13,  1.53s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 798/3000 [21:57<59:58,  1.63s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 799/3000 [21:59<1:03:33,  1.73s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 800/3000 [21:59<53:33,  1.46s/it]  a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 801/3000 [22:01<58:15,  1.59s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 802/3000 [22:03<55:39,  1.52s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 803/3000 [22:04<55:16,  1.51s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 804/3000 [22:05<52:32,  1.44s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 805/3000 [22:07<57:58,  1.58s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 806/3000 [22:09<56:02,  1.53s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 807/3000 [22:10<55:12,  1.51s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 808/3000 [22:12<54:31,  1.49s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 809/3000 [22:13<53:59,  1.48s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 810/3000 [22:15<1:01:36,  1.69s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 811/3000 [22:17<57:56,  1.59s/it]  a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 812/3000 [22:19<1:07:59,  1.86s/it][step=759] episode=759.0000 return=-115.9983 length=30.0000 global_step=18435.0000 loss=73.0786 policy_loss=-0.0000 value_loss=146.1573 entropy=0.0000
[step=760] episode=760.0000 return=-115.9864 length=28.0000 global_step=18463.0000 loss=14.9503 policy_loss=-0.0000 value_loss=29.9007 entropy=0.0000
[step=761] episode=761.0000 return=-115.9996 length=12.0000 global_step=18475.0000 loss=137.3695 policy_loss=-0.0000 value_loss=274.7391 entropy=0.0000
[step=762] episode=762.0000 return=-115.9929 length=42.0000 global_step=18517.0000 loss=27.5587 policy_loss=-0.0000 value_loss=55.1174 entropy=0.0000
[step=763] episode=763.0000 return=-115.9926 length=28.0000 global_step=18545.0000 loss=20.5247 policy_loss=-0.0000 value_loss=41.0494 entropy=0.0000
[step=764] episode=764.0000 return=-115.9629 length=20.0000 global_step=18565.0000 loss=33.5752 policy_loss=-0.0000 value_loss=67.1503 entropy=0.0000
[step=765] episode=765.0000 return=-115.7798 length=21.0000 global_step=18586.0000 loss=12.1936 policy_loss=-0.0000 value_loss=24.3872 entropy=0.0000
[step=766] episode=766.0000 return=-115.8693 length=11.0000 global_step=18597.0000 loss=47.6239 policy_loss=-0.0000 value_loss=95.2479 entropy=0.0000
[step=767] episode=767.0000 return=-115.9569 length=21.0000 global_step=18618.0000 loss=117.6740 policy_loss=-0.0000 value_loss=235.3480 entropy=0.0000
[step=768] episode=768.0000 return=-115.9081 length=28.0000 global_step=18646.0000 loss=42.5512 policy_loss=-0.0000 value_loss=85.1024 entropy=0.0000
[step=769] episode=769.0000 return=-115.9975 length=28.0000 global_step=18674.0000 loss=20.0152 policy_loss=-0.0000 value_loss=40.0303 entropy=0.0000
[step=770] episode=770.0000 return=-115.9998 length=20.0000 global_step=18694.0000 loss=123.5936 policy_loss=-0.0000 value_loss=247.1872 entropy=0.0000
[step=771] episode=771.0000 return=-115.9602 length=29.0000 global_step=18723.0000 loss=87.5993 policy_loss=-0.0000 value_loss=175.1987 entropy=0.0000
[step=772] episode=772.0000 return=-115.9875 length=28.0000 global_step=18751.0000 loss=43.7431 policy_loss=-0.0000 value_loss=87.4862 entropy=0.0000
[step=773] episode=773.0000 return=-115.9989 length=21.0000 global_step=18772.0000 loss=10.3804 policy_loss=-0.0000 value_loss=20.7607 entropy=0.0000
[step=774] episode=774.0000 return=-115.9104 length=35.0000 global_step=18807.0000 loss=95.9362 policy_loss=-0.0000 value_loss=191.8725 entropy=0.0000
[step=775] episode=775.0000 return=-115.9233 length=19.0000 global_step=18826.0000 loss=13.8878 policy_loss=-0.0000 value_loss=27.7757 entropy=0.0000
[step=776] episode=776.0000 return=-115.9999 length=22.0000 global_step=18848.0000 loss=37.6723 policy_loss=-0.0000 value_loss=75.3446 entropy=0.0000
[step=777] episode=777.0000 return=-115.9997 length=30.0000 global_step=18878.0000 loss=19.1334 policy_loss=-0.0000 value_loss=38.2669 entropy=0.0000
[step=778] episode=778.0000 return=-115.9996 length=21.0000 global_step=18899.0000 loss=70.6323 policy_loss=-0.0000 value_loss=141.2645 entropy=0.0000
[step=779] episode=779.0000 return=-115.7613 length=11.0000 global_step=18910.0000 loss=196.7185 policy_loss=-0.0000 value_loss=393.4369 entropy=0.0000
[step=780] episode=780.0000 return=-115.8870 length=12.0000 global_step=18922.0000 loss=99.2940 policy_loss=-0.0000 value_loss=198.5879 entropy=0.0000
[step=781] episode=781.0000 return=-115.9353 length=11.0000 global_step=18933.0000 loss=17.4709 policy_loss=-0.0000 value_loss=34.9417 entropy=0.0000
[step=782] episode=782.0000 return=-115.9937 length=55.0000 global_step=18988.0000 loss=461.2351 policy_loss=-0.0000 value_loss=922.4703 entropy=0.0000
[step=783] episode=783.0000 return=-115.9975 length=36.0000 global_step=19024.0000 loss=264.7650 policy_loss=-0.0000 value_loss=529.5300 entropy=0.0000
[step=784] episode=784.0000 return=-115.9096 length=18.0000 global_step=19042.0000 loss=17.9543 policy_loss=-0.0000 value_loss=35.9085 entropy=0.0000
[step=785] episode=785.0000 return=-115.9939 length=21.0000 global_step=19063.0000 loss=17.2333 policy_loss=-0.0000 value_loss=34.4667 entropy=0.0000
[step=786] episode=786.0000 return=-115.9096 length=19.0000 global_step=19082.0000 loss=71.0954 policy_loss=-0.0000 value_loss=142.1908 entropy=0.0000
[step=787] episode=787.0000 return=-115.9405 length=21.0000 global_step=19103.0000 loss=71.7613 policy_loss=-0.0000 value_loss=143.5225 entropy=0.0000
[step=788] episode=788.0000 return=-115.9837 length=28.0000 global_step=19131.0000 loss=32.2928 policy_loss=-0.0000 value_loss=64.5856 entropy=0.0000
[step=789] episode=789.0000 return=-115.9941 length=26.0000 global_step=19157.0000 loss=15.9737 policy_loss=-0.0000 value_loss=31.9474 entropy=0.0000
[step=790] episode=790.0000 return=-115.9999 length=20.0000 global_step=19177.0000 loss=20.8061 policy_loss=-0.0000 value_loss=41.6121 entropy=0.0000
[step=791] episode=791.0000 return=-115.9985 length=30.0000 global_step=19207.0000 loss=31.9078 policy_loss=-0.0000 value_loss=63.8157 entropy=0.0000
[step=792] episode=792.0000 return=-115.7974 length=11.0000 global_step=19218.0000 loss=22.0921 policy_loss=-0.0000 value_loss=44.1842 entropy=0.0000
[step=793] episode=793.0000 return=-115.9388 length=21.0000 global_step=19239.0000 loss=11.8804 policy_loss=-0.0000 value_loss=23.7608 entropy=0.0000
[step=794] episode=794.0000 return=-115.9096 length=18.0000 global_step=19257.0000 loss=8.8615 policy_loss=-0.0000 value_loss=17.7230 entropy=0.0000
[step=795] episode=795.0000 return=-115.9925 length=20.0000 global_step=19277.0000 loss=7.9202 policy_loss=-0.0000 value_loss=15.8404 entropy=0.0000
[step=796] episode=796.0000 return=-115.8072 length=19.0000 global_step=19296.0000 loss=27.8162 policy_loss=-0.0000 value_loss=55.6324 entropy=0.0000
[step=797] episode=797.0000 return=-115.9794 length=29.0000 global_step=19325.0000 loss=30.7182 policy_loss=-0.0000 value_loss=61.4363 entropy=0.0000
[step=798] episode=798.0000 return=-115.9930 length=27.0000 global_step=19352.0000 loss=14.9090 policy_loss=-0.0000 value_loss=29.8180 entropy=0.0000
[step=799] episode=799.0000 return=-115.9980 length=28.0000 global_step=19380.0000 loss=16.9931 policy_loss=-0.0000 value_loss=33.9862 entropy=0.0000
[step=800] episode=800.0000 return=-115.8341 length=12.0000 global_step=19392.0000 loss=113.3828 policy_loss=-0.0000 value_loss=226.7656 entropy=0.0000
[step=801] episode=801.0000 return=-115.9895 length=28.0000 global_step=19420.0000 loss=19.6162 policy_loss=-0.0000 value_loss=39.2323 entropy=0.0000
[step=802] episode=802.0000 return=-115.9925 length=20.0000 global_step=19440.0000 loss=16.5027 policy_loss=-0.0000 value_loss=33.0054 entropy=0.0000
[step=803] episode=803.0000 return=-115.9840 length=21.0000 global_step=19461.0000 loss=7.6155 policy_loss=-0.0000 value_loss=15.2310 entropy=0.0000
[step=804] episode=804.0000 return=-115.8856 length=19.0000 global_step=19480.0000 loss=20.7194 policy_loss=-0.0000 value_loss=41.4388 entropy=0.0000
[step=805] episode=805.0000 return=-115.9890 length=28.0000 global_step=19508.0000 loss=52.8948 policy_loss=-0.0000 value_loss=105.7896 entropy=0.0000
[step=806] episode=806.0000 return=-115.9931 length=20.0000 global_step=19528.0000 loss=16.2465 policy_loss=-0.0000 value_loss=32.4930 entropy=0.0000
[step=807] episode=807.0000 return=-115.9899 length=20.0000 global_step=19548.0000 loss=6.4743 policy_loss=-0.0000 value_loss=12.9486 entropy=0.0000
[step=808] episode=808.0000 return=-115.9824 length=21.0000 global_step=19569.0000 loss=6.5469 policy_loss=-0.0000 value_loss=13.0938 entropy=0.0000
[step=809] episode=809.0000 return=-115.9896 length=22.0000 global_step=19591.0000 loss=4.1164 policy_loss=-0.0000 value_loss=8.2329 entropy=0.0000
[step=810] episode=810.0000 return=-115.9385 length=31.0000 global_step=19622.0000 loss=16.0891 policy_loss=-0.0000 value_loss=32.1783 entropy=0.0000
[step=811] episode=811.0000 return=-115.8963 length=21.0000 global_step=19643.0000 loss=22.9853 policy_loss=-0.0000 value_loss=45.9705 entropy=0.0000
[step=812] episode=812.0000 return=-115.9114 length=37.0000 global_step=19680.0000 loss=14.8339 policy_loss=0.0000 value_loss=29.6677 entropy=0.0000
a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 813/3000 [22:22<1:21:21,  2.23s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 814/3000 [22:24<1:17:56,  2.14s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 815/3000 [22:27<1:27:18,  2.40s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 816/3000 [22:29<1:21:04,  2.23s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 817/3000 [22:30<1:11:22,  1.96s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 818/3000 [22:32<1:04:33,  1.78s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 819/3000 [22:34<1:15:13,  2.07s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 820/3000 [22:37<1:25:31,  2.35s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 821/3000 [22:38<1:09:35,  1.92s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 822/3000 [22:40<1:03:09,  1.74s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 823/3000 [22:41<1:04:15,  1.77s/it]a2c_tuned train:  27%|‚ñà‚ñà‚ñã       | 824/3000 [22:45<1:18:47,  2.17s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 825/3000 [22:47<1:15:55,  2.09s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 826/3000 [22:47<1:01:31,  1.70s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 827/3000 [22:49<1:01:49,  1.71s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 828/3000 [22:51<1:03:24,  1.75s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 829/3000 [22:53<1:11:07,  1.97s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 830/3000 [22:55<1:04:33,  1.79s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 831/3000 [22:57<1:11:45,  1.99s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 832/3000 [22:58<59:57,  1.66s/it]  a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 833/3000 [23:00<1:02:27,  1.73s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 834/3000 [23:01<58:41,  1.63s/it]  a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 835/3000 [23:03<55:47,  1.55s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 836/3000 [23:06<1:10:00,  1.94s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 837/3000 [23:08<1:12:20,  2.01s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 838/3000 [23:09<1:05:02,  1.81s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 839/3000 [23:11<1:02:00,  1.72s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 840/3000 [23:13<1:10:10,  1.95s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 841/3000 [23:14<58:22,  1.62s/it]  a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 842/3000 [23:16<1:01:08,  1.70s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 843/3000 [23:17<51:48,  1.44s/it]  a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 844/3000 [23:18<51:09,  1.42s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 845/3000 [23:19<44:54,  1.25s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 846/3000 [23:21<50:57,  1.42s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 847/3000 [23:22<54:37,  1.52s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 848/3000 [23:24<51:53,  1.45s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 849/3000 [23:25<46:25,  1.30s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 850/3000 [23:26<52:04,  1.45s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 851/3000 [23:28<51:16,  1.43s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 852/3000 [23:30<56:26,  1.58s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 853/3000 [23:31<54:30,  1.52s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 854/3000 [23:33<1:00:02,  1.68s/it]a2c_tuned train:  28%|‚ñà‚ñà‚ñä       | 855/3000 [23:35<56:54,  1.59s/it]  a2c_tuned train:  29%|‚ñà‚ñà‚ñä       | 856/3000 [23:37<1:00:51,  1.70s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñä       | 857/3000 [23:38<58:37,  1.64s/it]  a2c_tuned train:  29%|‚ñà‚ñà‚ñä       | 858/3000 [23:40<1:07:15,  1.88s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñä       | 859/3000 [23:42<1:01:15,  1.72s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñä       | 860/3000 [23:43<57:28,  1.61s/it]  a2c_tuned train:  29%|‚ñà‚ñà‚ñä       | 861/3000 [23:45<1:00:07,  1.69s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñä       | 862/3000 [23:47<1:07:30,  1.89s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 863/3000 [23:49<1:02:31,  1.76s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 864/3000 [23:51<1:07:35,  1.90s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 865/3000 [23:52<1:01:24,  1.73s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 866/3000 [23:55<1:08:13,  1.92s/it][step=813] episode=813.0000 return=-115.9995 length=46.0000 global_step=19726.0000 loss=32.9473 policy_loss=0.0000 value_loss=65.8946 entropy=0.0000
[step=814] episode=814.0000 return=-115.9901 length=29.0000 global_step=19755.0000 loss=27.3771 policy_loss=-0.0000 value_loss=54.7542 entropy=0.0000
[step=815] episode=815.0000 return=-115.9989 length=46.0000 global_step=19801.0000 loss=55.9832 policy_loss=0.0000 value_loss=111.9664 entropy=0.0000
[step=816] episode=816.0000 return=-115.9822 length=27.0000 global_step=19828.0000 loss=36.0635 policy_loss=-0.0000 value_loss=72.1271 entropy=0.0000
[step=817] episode=817.0000 return=-115.9990 length=20.0000 global_step=19848.0000 loss=27.8849 policy_loss=-0.0000 value_loss=55.7699 entropy=0.0000
[step=818] episode=818.0000 return=-115.8961 length=19.0000 global_step=19867.0000 loss=14.4884 policy_loss=-0.0000 value_loss=28.9767 entropy=0.0000
[step=819] episode=819.0000 return=-115.9576 length=40.0000 global_step=19907.0000 loss=73.3579 policy_loss=-0.0000 value_loss=146.7158 entropy=0.0000
[step=820] episode=820.0000 return=-115.9998 length=44.0000 global_step=19951.0000 loss=182.3479 policy_loss=-0.0000 value_loss=364.6958 entropy=0.0000
[step=821] episode=821.0000 return=-115.8831 length=13.0000 global_step=19964.0000 loss=14.0661 policy_loss=-0.0000 value_loss=28.1321 entropy=0.0000
[step=822] episode=822.0000 return=-115.8643 length=20.0000 global_step=19984.0000 loss=13.3698 policy_loss=-0.0000 value_loss=26.7397 entropy=0.0000
[step=823] episode=823.0000 return=-115.8643 length=27.0000 global_step=20011.0000 loss=6.6214 policy_loss=-0.0000 value_loss=13.2429 entropy=0.0000
[step=824] episode=824.0000 return=-115.9963 length=46.0000 global_step=20057.0000 loss=102.1140 policy_loss=-0.0000 value_loss=204.2281 entropy=0.0000
[step=825] episode=825.0000 return=-115.9977 length=29.0000 global_step=20086.0000 loss=10.6677 policy_loss=0.0000 value_loss=21.3355 entropy=0.0000
[step=826] episode=826.0000 return=-115.1316 length=11.0000 global_step=20097.0000 loss=114.3432 policy_loss=-0.0000 value_loss=228.6864 entropy=0.0000
[step=827] episode=827.0000 return=-115.9445 length=26.0000 global_step=20123.0000 loss=18.5572 policy_loss=-0.0000 value_loss=37.1144 entropy=0.0000
[step=828] episode=828.0000 return=-115.9932 length=28.0000 global_step=20151.0000 loss=23.1795 policy_loss=-0.0000 value_loss=46.3590 entropy=0.0000
[step=829] episode=829.0000 return=-115.9815 length=36.0000 global_step=20187.0000 loss=84.3887 policy_loss=-0.0000 value_loss=168.7773 entropy=0.0000
[step=830] episode=830.0000 return=-115.9986 length=20.0000 global_step=20207.0000 loss=7.4487 policy_loss=-0.0000 value_loss=14.8974 entropy=0.0000
[step=831] episode=831.0000 return=-115.9998 length=37.0000 global_step=20244.0000 loss=60.8573 policy_loss=-0.0000 value_loss=121.7146 entropy=0.0000
[step=832] episode=832.0000 return=-115.9939 length=13.0000 global_step=20257.0000 loss=61.3466 policy_loss=-0.0000 value_loss=122.6932 entropy=0.0000
[step=833] episode=833.0000 return=-115.9936 length=29.0000 global_step=20286.0000 loss=13.1840 policy_loss=0.0000 value_loss=26.3680 entropy=0.0000
[step=834] episode=834.0000 return=-115.9972 length=21.0000 global_step=20307.0000 loss=18.5231 policy_loss=0.0000 value_loss=37.0461 entropy=0.0000
[step=835] episode=835.0000 return=-115.9801 length=20.0000 global_step=20327.0000 loss=13.8689 policy_loss=0.0000 value_loss=27.7377 entropy=0.0000
[step=836] episode=836.0000 return=-115.9925 length=43.0000 global_step=20370.0000 loss=109.2998 policy_loss=0.0000 value_loss=218.5995 entropy=0.0000
[step=837] episode=837.0000 return=-115.9996 length=33.0000 global_step=20403.0000 loss=38.1350 policy_loss=0.0000 value_loss=76.2701 entropy=0.0000
[step=838] episode=838.0000 return=-115.9465 length=20.0000 global_step=20423.0000 loss=20.6180 policy_loss=0.0000 value_loss=41.2360 entropy=0.0000
[step=839] episode=839.0000 return=-115.9585 length=22.0000 global_step=20445.0000 loss=23.0920 policy_loss=-0.0000 value_loss=46.1841 entropy=0.0000
[step=840] episode=840.0000 return=-115.9860 length=37.0000 global_step=20482.0000 loss=40.3381 policy_loss=0.0000 value_loss=80.6762 entropy=0.0000
[step=841] episode=841.0000 return=-115.7608 length=12.0000 global_step=20494.0000 loss=63.6413 policy_loss=-0.0000 value_loss=127.2827 entropy=0.0000
[step=842] episode=842.0000 return=-115.9996 length=28.0000 global_step=20522.0000 loss=22.3959 policy_loss=0.0000 value_loss=44.7919 entropy=0.0000
[step=843] episode=843.0000 return=-115.9759 length=12.0000 global_step=20534.0000 loss=31.7791 policy_loss=-0.0000 value_loss=63.5582 entropy=0.0000
[step=844] episode=844.0000 return=-115.8688 length=20.0000 global_step=20554.0000 loss=13.0217 policy_loss=0.0000 value_loss=26.0434 entropy=0.0000
[step=845] episode=845.0000 return=-115.9939 length=12.0000 global_step=20566.0000 loss=8.5792 policy_loss=0.0000 value_loss=17.1583 entropy=0.0000
[step=846] episode=846.0000 return=-115.9955 length=27.0000 global_step=20593.0000 loss=45.5676 policy_loss=0.0000 value_loss=91.1352 entropy=0.0000
[step=847] episode=847.0000 return=-115.9896 length=27.0000 global_step=20620.0000 loss=6.0626 policy_loss=0.0000 value_loss=12.1252 entropy=0.0000
[step=848] episode=848.0000 return=-115.9574 length=18.0000 global_step=20638.0000 loss=41.8249 policy_loss=-0.0000 value_loss=83.6499 entropy=0.0000
[step=849] episode=849.0000 return=-115.8364 length=13.0000 global_step=20651.0000 loss=82.8332 policy_loss=-0.0000 value_loss=165.6665 entropy=0.0000
[step=850] episode=850.0000 return=-115.8870 length=28.0000 global_step=20679.0000 loss=12.9165 policy_loss=0.0000 value_loss=25.8330 entropy=0.0000
[step=851] episode=851.0000 return=-115.9995 length=20.0000 global_step=20699.0000 loss=7.2308 policy_loss=-0.0000 value_loss=14.4616 entropy=0.0000
[step=852] episode=852.0000 return=-115.9840 length=29.0000 global_step=20728.0000 loss=33.3473 policy_loss=0.0000 value_loss=66.6946 entropy=0.0000
[step=853] episode=853.0000 return=-115.9996 length=21.0000 global_step=20749.0000 loss=9.0340 policy_loss=0.0000 value_loss=18.0680 entropy=0.0000
[step=854] episode=854.0000 return=-115.9384 length=29.0000 global_step=20778.0000 loss=15.1364 policy_loss=0.0000 value_loss=30.2727 entropy=0.0000
[step=855] episode=855.0000 return=-115.8715 length=21.0000 global_step=20799.0000 loss=16.2227 policy_loss=-0.0000 value_loss=32.4453 entropy=0.0000
[step=856] episode=856.0000 return=-115.9880 length=30.0000 global_step=20829.0000 loss=17.1612 policy_loss=-0.0000 value_loss=34.3224 entropy=0.0000
[step=857] episode=857.0000 return=-115.9968 length=21.0000 global_step=20850.0000 loss=24.9667 policy_loss=-0.0000 value_loss=49.9333 entropy=0.0000
[step=858] episode=858.0000 return=-115.9968 length=36.0000 global_step=20886.0000 loss=41.9024 policy_loss=0.0000 value_loss=83.8048 entropy=0.0000
[step=859] episode=859.0000 return=-115.9928 length=19.0000 global_step=20905.0000 loss=12.3756 policy_loss=-0.0000 value_loss=24.7513 entropy=0.0000
[step=860] episode=860.0000 return=-115.9885 length=21.0000 global_step=20926.0000 loss=8.5393 policy_loss=-0.0000 value_loss=17.0786 entropy=0.0000
[step=861] episode=861.0000 return=-115.9978 length=28.0000 global_step=20954.0000 loss=34.6630 policy_loss=0.0000 value_loss=69.3260 entropy=0.0000
[step=862] episode=862.0000 return=-116.0000 length=35.0000 global_step=20989.0000 loss=82.4641 policy_loss=0.0000 value_loss=164.9281 entropy=0.0000
[step=863] episode=863.0000 return=-115.9052 length=21.0000 global_step=21010.0000 loss=8.6575 policy_loss=0.0000 value_loss=17.3149 entropy=0.0000
[step=864] episode=864.0000 return=-115.9999 length=33.0000 global_step=21043.0000 loss=19.3654 policy_loss=0.0000 value_loss=38.7308 entropy=0.0000
[step=865] episode=865.0000 return=-115.8197 length=19.0000 global_step=21062.0000 loss=89.0426 policy_loss=-0.0001 value_loss=178.0854 entropy=0.0000
[step=866] episode=866.0000 return=-115.9783 length=35.0000 global_step=21097.0000 loss=33.5944 policy_loss=-0.0000 value_loss=67.1888 entropy=0.0000
a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 867/3000 [23:56<1:02:05,  1.75s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 868/3000 [23:59<1:10:19,  1.98s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 869/3000 [24:01<1:09:13,  1.95s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 870/3000 [24:02<1:02:44,  1.77s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 871/3000 [24:04<1:04:33,  1.82s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 872/3000 [24:06<1:04:21,  1.81s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 873/3000 [24:06<53:38,  1.51s/it]  a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 874/3000 [24:08<52:09,  1.47s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 875/3000 [24:09<51:17,  1.45s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 876/3000 [24:10<49:16,  1.39s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 877/3000 [24:12<52:18,  1.48s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 878/3000 [24:13<50:50,  1.44s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 879/3000 [24:15<50:18,  1.42s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 880/3000 [24:15<38:50,  1.10s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 881/3000 [24:16<35:28,  1.00s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 882/3000 [24:17<33:08,  1.07it/s]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 883/3000 [24:18<37:50,  1.07s/it]a2c_tuned train:  29%|‚ñà‚ñà‚ñâ       | 884/3000 [24:20<45:04,  1.28s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 885/3000 [24:22<51:53,  1.47s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 886/3000 [24:23<50:23,  1.43s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 887/3000 [24:25<53:58,  1.53s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 888/3000 [24:26<52:25,  1.49s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 889/3000 [24:28<50:10,  1.43s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 890/3000 [24:29<44:45,  1.27s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 891/3000 [24:31<52:27,  1.49s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 892/3000 [24:33<57:47,  1.64s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 893/3000 [24:34<54:19,  1.55s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 894/3000 [24:36<57:57,  1.65s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 895/3000 [24:38<1:01:47,  1.76s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 896/3000 [24:39<51:55,  1.48s/it]  a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 897/3000 [24:41<57:11,  1.63s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 898/3000 [24:42<59:33,  1.70s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñâ       | 899/3000 [24:45<1:07:13,  1.92s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 900/3000 [24:46<56:05,  1.60s/it]  a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 901/3000 [24:48<58:14,  1.66s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 902/3000 [24:49<1:00:05,  1.72s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 903/3000 [24:50<51:25,  1.47s/it]  a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 904/3000 [24:52<50:25,  1.44s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 905/3000 [24:54<55:34,  1.59s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 906/3000 [24:55<53:32,  1.53s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 907/3000 [24:56<51:54,  1.49s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 908/3000 [24:58<51:33,  1.48s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 909/3000 [25:00<56:48,  1.63s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 910/3000 [25:01<55:11,  1.58s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 911/3000 [25:03<54:02,  1.55s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 912/3000 [25:04<53:17,  1.53s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 913/3000 [25:06<55:46,  1.60s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 914/3000 [25:07<53:57,  1.55s/it]a2c_tuned train:  30%|‚ñà‚ñà‚ñà       | 915/3000 [25:08<47:35,  1.37s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 916/3000 [25:10<51:55,  1.50s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 917/3000 [25:11<45:30,  1.31s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 918/3000 [25:12<45:31,  1.31s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 919/3000 [25:13<40:28,  1.17s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 920/3000 [25:14<36:15,  1.05s/it][step=867] episode=867.0000 return=-115.9930 length=20.0000 global_step=21117.0000 loss=77.6914 policy_loss=-0.0000 value_loss=155.3829 entropy=0.0000
[step=868] episode=868.0000 return=-115.9999 length=37.0000 global_step=21154.0000 loss=25.3352 policy_loss=0.0000 value_loss=50.6703 entropy=0.0000
[step=869] episode=869.0000 return=-116.0000 length=28.0000 global_step=21182.0000 loss=13.3664 policy_loss=-0.0000 value_loss=26.7328 entropy=0.0000
[step=870] episode=870.0000 return=-115.9948 length=20.0000 global_step=21202.0000 loss=8.5573 policy_loss=-0.0000 value_loss=17.1146 entropy=0.0000
[step=871] episode=871.0000 return=-115.9999 length=28.0000 global_step=21230.0000 loss=59.3501 policy_loss=0.0000 value_loss=118.7001 entropy=0.0000
[step=872] episode=872.0000 return=-115.9941 length=27.0000 global_step=21257.0000 loss=56.1475 policy_loss=0.0000 value_loss=112.2950 entropy=0.0000
[step=873] episode=873.0000 return=-115.7346 length=12.0000 global_step=21269.0000 loss=16.1412 policy_loss=-0.0000 value_loss=32.2823 entropy=0.0000
[step=874] episode=874.0000 return=-115.9886 length=20.0000 global_step=21289.0000 loss=16.0430 policy_loss=0.0000 value_loss=32.0860 entropy=0.0000
[step=875] episode=875.0000 return=-115.9845 length=20.0000 global_step=21309.0000 loss=7.4701 policy_loss=0.0000 value_loss=14.9401 entropy=0.0001
[step=876] episode=876.0000 return=-115.9925 length=18.0000 global_step=21327.0000 loss=11.8132 policy_loss=-0.0000 value_loss=23.6264 entropy=0.0001
[step=877] episode=877.0000 return=-115.9945 length=25.0000 global_step=21352.0000 loss=7.3204 policy_loss=-0.0000 value_loss=14.6408 entropy=0.0001
[step=878] episode=878.0000 return=-115.9742 length=20.0000 global_step=21372.0000 loss=11.1539 policy_loss=-0.0000 value_loss=22.3078 entropy=0.0001
[step=879] episode=879.0000 return=-115.9402 length=21.0000 global_step=21393.0000 loss=3.2706 policy_loss=-0.0000 value_loss=6.5411 entropy=0.0001
[step=880] episode=880.0000 return=-115.7152 length=5.0000 global_step=21398.0000 loss=64.9499 policy_loss=-0.0000 value_loss=129.8998 entropy=0.0000
[step=881] episode=881.0000 return=-115.9990 length=12.0000 global_step=21410.0000 loss=47.9025 policy_loss=0.0000 value_loss=95.8048 entropy=0.0000
[step=882] episode=882.0000 return=-115.9940 length=12.0000 global_step=21422.0000 loss=93.1282 policy_loss=0.0000 value_loss=186.2563 entropy=0.0000
[step=883] episode=883.0000 return=-115.9976 length=20.0000 global_step=21442.0000 loss=150.4103 policy_loss=0.0001 value_loss=300.8205 entropy=0.0000
[step=884] episode=884.0000 return=-115.9837 length=27.0000 global_step=21469.0000 loss=105.1659 policy_loss=0.0001 value_loss=210.3318 entropy=0.0000
[step=885] episode=885.0000 return=-115.9945 length=29.0000 global_step=21498.0000 loss=5.4562 policy_loss=0.0000 value_loss=10.9125 entropy=0.0000
[step=886] episode=886.0000 return=-115.9833 length=20.0000 global_step=21518.0000 loss=81.0401 policy_loss=-0.0000 value_loss=162.0802 entropy=0.0000
[step=887] episode=887.0000 return=-115.9990 length=26.0000 global_step=21544.0000 loss=105.1775 policy_loss=-0.0001 value_loss=210.3552 entropy=0.0001
[step=888] episode=888.0000 return=-115.9955 length=21.0000 global_step=21565.0000 loss=175.6502 policy_loss=-0.0001 value_loss=351.3005 entropy=0.0001
[step=889] episode=889.0000 return=-115.9765 length=19.0000 global_step=21584.0000 loss=114.4004 policy_loss=-0.0001 value_loss=228.8010 entropy=0.0001
[step=890] episode=890.0000 return=-115.7972 length=13.0000 global_step=21597.0000 loss=62.8888 policy_loss=-0.0001 value_loss=125.7777 entropy=0.0001
[step=891] episode=891.0000 return=-115.9995 length=30.0000 global_step=21627.0000 loss=72.4736 policy_loss=0.0001 value_loss=144.9469 entropy=0.0001
[step=892] episode=892.0000 return=-115.9808 length=29.0000 global_step=21656.0000 loss=202.4212 policy_loss=0.0003 value_loss=404.8417 entropy=0.0002
[step=893] episode=893.0000 return=-115.9758 length=20.0000 global_step=21676.0000 loss=118.7110 policy_loss=0.0002 value_loss=237.4214 entropy=0.0002
[step=894] episode=894.0000 return=-115.9984 length=29.0000 global_step=21705.0000 loss=96.8053 policy_loss=0.0002 value_loss=193.6101 entropy=0.0002
[step=895] episode=895.0000 return=-115.9757 length=30.0000 global_step=21735.0000 loss=23.6168 policy_loss=0.0001 value_loss=47.2336 entropy=0.0002
[step=896] episode=896.0000 return=-115.9983 length=12.0000 global_step=21747.0000 loss=166.9961 policy_loss=-0.0002 value_loss=333.9926 entropy=0.0002
[step=897] episode=897.0000 return=-115.9011 length=29.0000 global_step=21776.0000 loss=78.9990 policy_loss=-0.0002 value_loss=157.9984 entropy=0.0002
[step=898] episode=898.0000 return=-115.9841 length=29.0000 global_step=21805.0000 loss=62.7457 policy_loss=-0.0002 value_loss=125.4916 entropy=0.0002
[step=899] episode=899.0000 return=-115.9567 length=37.0000 global_step=21842.0000 loss=25.0578 policy_loss=-0.0001 value_loss=50.1158 entropy=0.0003
[step=900] episode=900.0000 return=-115.8418 length=12.0000 global_step=21854.0000 loss=66.5152 policy_loss=-0.0003 value_loss=133.0311 entropy=0.0003
[step=901] episode=901.0000 return=-115.9609 length=26.0000 global_step=21880.0000 loss=22.9250 policy_loss=0.0003 value_loss=45.8493 entropy=0.0006
[step=902] episode=902.0000 return=-115.9895 length=27.0000 global_step=21907.0000 loss=63.7206 policy_loss=0.0009 value_loss=127.4396 entropy=0.0008
[step=903] episode=903.0000 return=-115.9976 length=12.0000 global_step=21919.0000 loss=22.1547 policy_loss=0.0003 value_loss=44.3088 entropy=0.0007
[step=904] episode=904.0000 return=-115.9460 length=20.0000 global_step=21939.0000 loss=54.8511 policy_loss=0.0004 value_loss=109.7014 entropy=0.0005
[step=905] episode=905.0000 return=-115.9898 length=29.0000 global_step=21968.0000 loss=45.4525 policy_loss=0.0002 value_loss=90.9045 entropy=0.0003
[step=906] episode=906.0000 return=-115.9765 length=21.0000 global_step=21989.0000 loss=19.6366 policy_loss=-0.0001 value_loss=39.2734 entropy=0.0002
[step=907] episode=907.0000 return=-115.9991 length=21.0000 global_step=22010.0000 loss=52.7242 policy_loss=-0.0001 value_loss=105.4486 entropy=0.0002
[step=908] episode=908.0000 return=-115.9876 length=22.0000 global_step=22032.0000 loss=88.2039 policy_loss=-0.0001 value_loss=176.4081 entropy=0.0001
[step=909] episode=909.0000 return=-115.9986 length=30.0000 global_step=22062.0000 loss=13.8362 policy_loss=-0.0000 value_loss=27.6724 entropy=0.0001
[step=910] episode=910.0000 return=-115.9397 length=21.0000 global_step=22083.0000 loss=9.1877 policy_loss=-0.0000 value_loss=18.3753 entropy=0.0001
[step=911] episode=911.0000 return=-115.9998 length=22.0000 global_step=22105.0000 loss=23.1176 policy_loss=0.0000 value_loss=46.2352 entropy=0.0001
[step=912] episode=912.0000 return=-115.9840 length=21.0000 global_step=22126.0000 loss=33.4881 policy_loss=0.0000 value_loss=66.9761 entropy=0.0001
[step=913] episode=913.0000 return=-115.8869 length=27.0000 global_step=22153.0000 loss=73.5116 policy_loss=0.0000 value_loss=147.0231 entropy=0.0001
[step=914] episode=914.0000 return=-115.9421 length=21.0000 global_step=22174.0000 loss=14.1999 policy_loss=0.0000 value_loss=28.3999 entropy=0.0000
[step=915] episode=915.0000 return=-115.8414 length=14.0000 global_step=22188.0000 loss=61.4730 policy_loss=-0.0000 value_loss=122.9460 entropy=0.0000
[step=916] episode=916.0000 return=-115.9974 length=28.0000 global_step=22216.0000 loss=9.3717 policy_loss=-0.0000 value_loss=18.7435 entropy=0.0000
[step=917] episode=917.0000 return=-115.7706 length=12.0000 global_step=22228.0000 loss=59.4177 policy_loss=-0.0000 value_loss=118.8354 entropy=0.0000
[step=918] episode=918.0000 return=-115.9764 length=20.0000 global_step=22248.0000 loss=9.8608 policy_loss=-0.0000 value_loss=19.7215 entropy=0.0000
[step=919] episode=919.0000 return=-115.7978 length=13.0000 global_step=22261.0000 loss=10.7660 policy_loss=-0.0000 value_loss=21.5320 entropy=0.0000
[step=920] episode=920.0000 return=-115.8183 length=12.0000 global_step=22273.0000 loss=30.7151 policy_loss=0.0000 value_loss=61.4301 entropy=0.0000
a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 921/3000 [25:15<39:56,  1.15s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 922/3000 [25:17<41:52,  1.21s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 923/3000 [25:18<42:56,  1.24s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 924/3000 [25:20<54:53,  1.59s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 925/3000 [25:22<57:49,  1.67s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 926/3000 [25:23<49:15,  1.42s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 927/3000 [25:25<55:43,  1.61s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 928/3000 [25:27<58:07,  1.68s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 929/3000 [25:28<54:46,  1.59s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 930/3000 [25:31<1:02:58,  1.83s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 931/3000 [25:32<53:13,  1.54s/it]  a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 932/3000 [25:34<56:17,  1.63s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 933/3000 [25:35<58:53,  1.71s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 934/3000 [25:38<1:04:59,  1.89s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 935/3000 [25:40<1:09:09,  2.01s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 936/3000 [25:41<56:56,  1.66s/it]  a2c_tuned train:  31%|‚ñà‚ñà‚ñà       | 937/3000 [25:42<48:58,  1.42s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà‚ñè      | 938/3000 [25:43<48:39,  1.42s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà‚ñè      | 939/3000 [25:45<53:46,  1.57s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà‚ñè      | 940/3000 [25:47<52:47,  1.54s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà‚ñè      | 941/3000 [25:49<1:02:10,  1.81s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà‚ñè      | 942/3000 [25:50<56:34,  1.65s/it]  a2c_tuned train:  31%|‚ñà‚ñà‚ñà‚ñè      | 943/3000 [25:52<59:23,  1.73s/it]a2c_tuned train:  31%|‚ñà‚ñà‚ñà‚ñè      | 944/3000 [25:54<56:17,  1.64s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 945/3000 [25:55<48:52,  1.43s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 946/3000 [25:56<54:13,  1.58s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 947/3000 [25:57<46:57,  1.37s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 948/3000 [25:59<53:18,  1.56s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 949/3000 [26:01<55:15,  1.62s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 950/3000 [26:02<46:55,  1.37s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 951/3000 [26:05<1:02:04,  1.82s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 952/3000 [26:07<1:06:35,  1.95s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 953/3000 [26:10<1:20:54,  2.37s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 954/3000 [26:12<1:10:53,  2.08s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 955/3000 [26:13<58:08,  1.71s/it]  a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 956/3000 [26:14<54:43,  1.61s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 957/3000 [26:18<1:19:14,  2.33s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 958/3000 [26:19<1:03:35,  1.87s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 959/3000 [26:21<1:03:56,  1.88s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 960/3000 [26:23<1:04:45,  1.90s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 961/3000 [26:25<1:04:20,  1.89s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 962/3000 [26:26<1:04:02,  1.89s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 963/3000 [26:27<53:20,  1.57s/it]  a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 964/3000 [26:29<51:50,  1.53s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 965/3000 [26:31<55:19,  1.63s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 966/3000 [26:33<1:04:20,  1.90s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 967/3000 [26:34<59:46,  1.76s/it]  a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 968/3000 [26:36<56:51,  1.68s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 969/3000 [26:38<57:31,  1.70s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 970/3000 [26:39<48:47,  1.44s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 971/3000 [26:40<50:56,  1.51s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 972/3000 [26:42<54:17,  1.61s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 973/3000 [26:43<46:44,  1.38s/it]a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñè      | 974/3000 [26:45<52:29,  1.55s/it][step=921] episode=921.0000 return=-115.9999 length=20.0000 global_step=22293.0000 loss=113.2607 policy_loss=0.0000 value_loss=226.5214 entropy=0.0000
[step=922] episode=922.0000 return=-115.7395 length=21.0000 global_step=22314.0000 loss=34.3515 policy_loss=0.0000 value_loss=68.7030 entropy=0.0000
[step=923] episode=923.0000 return=-115.9797 length=19.0000 global_step=22333.0000 loss=14.3060 policy_loss=0.0000 value_loss=28.6120 entropy=0.0000
[step=924] episode=924.0000 return=-115.9921 length=35.0000 global_step=22368.0000 loss=24.9035 policy_loss=0.0000 value_loss=49.8070 entropy=0.0000
[step=925] episode=925.0000 return=-115.7301 length=28.0000 global_step=22396.0000 loss=82.2768 policy_loss=-0.0000 value_loss=164.5538 entropy=0.0000
[step=926] episode=926.0000 return=-115.9653 length=12.0000 global_step=22408.0000 loss=273.6634 policy_loss=-0.0001 value_loss=547.3269 entropy=0.0000
[step=927] episode=927.0000 return=-115.9840 length=30.0000 global_step=22438.0000 loss=52.9697 policy_loss=-0.0000 value_loss=105.9394 entropy=0.0000
[step=928] episode=928.0000 return=-115.9919 length=27.0000 global_step=22465.0000 loss=18.2191 policy_loss=-0.0000 value_loss=36.4382 entropy=0.0000
[step=929] episode=929.0000 return=-115.9948 length=20.0000 global_step=22485.0000 loss=8.8954 policy_loss=0.0000 value_loss=17.7909 entropy=0.0000
[step=930] episode=930.0000 return=-115.9944 length=36.0000 global_step=22521.0000 loss=144.1819 policy_loss=0.0001 value_loss=288.3636 entropy=0.0000
[step=931] episode=931.0000 return=-115.8340 length=12.0000 global_step=22533.0000 loss=8.6772 policy_loss=0.0000 value_loss=17.3543 entropy=0.0000
[step=932] episode=932.0000 return=-115.9990 length=28.0000 global_step=22561.0000 loss=38.0152 policy_loss=0.0000 value_loss=76.0303 entropy=0.0000
[step=933] episode=933.0000 return=-115.7874 length=27.0000 global_step=22588.0000 loss=4.0549 policy_loss=-0.0000 value_loss=8.1099 entropy=0.0001
[step=934] episode=934.0000 return=-115.9996 length=35.0000 global_step=22623.0000 loss=35.3212 policy_loss=0.0000 value_loss=70.6423 entropy=0.0001
[step=935] episode=935.0000 return=-115.9837 length=35.0000 global_step=22658.0000 loss=21.2296 policy_loss=-0.0000 value_loss=42.4592 entropy=0.0001
[step=936] episode=936.0000 return=-115.8951 length=12.0000 global_step=22670.0000 loss=126.0176 policy_loss=-0.0001 value_loss=252.0355 entropy=0.0001
[step=937] episode=937.0000 return=-115.8125 length=13.0000 global_step=22683.0000 loss=109.3755 policy_loss=-0.0001 value_loss=218.7513 entropy=0.0001
[step=938] episode=938.0000 return=-115.9951 length=20.0000 global_step=22703.0000 loss=8.6749 policy_loss=-0.0000 value_loss=17.3498 entropy=0.0001
[step=939] episode=939.0000 return=-115.9933 length=29.0000 global_step=22732.0000 loss=72.0718 policy_loss=0.0001 value_loss=144.1435 entropy=0.0001
[step=940] episode=940.0000 return=-115.9028 length=22.0000 global_step=22754.0000 loss=61.3847 policy_loss=0.0001 value_loss=122.7692 entropy=0.0001
[step=941] episode=941.0000 return=-115.9759 length=36.0000 global_step=22790.0000 loss=142.7565 policy_loss=0.0002 value_loss=285.5128 entropy=0.0001
[step=942] episode=942.0000 return=-115.9528 length=18.0000 global_step=22808.0000 loss=2.6043 policy_loss=-0.0000 value_loss=5.2087 entropy=0.0002
[step=943] episode=943.0000 return=-115.9995 length=29.0000 global_step=22837.0000 loss=16.9086 policy_loss=0.0000 value_loss=33.8172 entropy=0.0002
[step=944] episode=944.0000 return=-115.9979 length=21.0000 global_step=22858.0000 loss=38.0855 policy_loss=-0.0001 value_loss=76.1712 entropy=0.0002
[step=945] episode=945.0000 return=-115.9931 length=13.0000 global_step=22871.0000 loss=107.2384 policy_loss=-0.0002 value_loss=214.4771 entropy=0.0002
[step=946] episode=946.0000 return=-115.9986 length=28.0000 global_step=22899.0000 loss=18.3448 policy_loss=-0.0001 value_loss=36.6897 entropy=0.0002
[step=947] episode=947.0000 return=-115.9478 length=13.0000 global_step=22912.0000 loss=22.8458 policy_loss=-0.0001 value_loss=45.6919 entropy=0.0003
[step=948] episode=948.0000 return=-115.9986 length=30.0000 global_step=22942.0000 loss=90.0363 policy_loss=0.0008 value_loss=180.0708 entropy=0.0007
[step=949] episode=949.0000 return=-115.9567 length=27.0000 global_step=22969.0000 loss=103.6323 policy_loss=0.0006 value_loss=207.2635 entropy=0.0005
[step=950] episode=950.0000 return=-115.9974 length=12.0000 global_step=22981.0000 loss=15.0481 policy_loss=0.0000 value_loss=30.0960 entropy=0.0002
[step=951] episode=951.0000 return=-115.9994 length=43.0000 global_step=23024.0000 loss=92.5998 policy_loss=0.0001 value_loss=185.1994 entropy=0.0001
[step=952] episode=952.0000 return=-115.9998 length=36.0000 global_step=23060.0000 loss=27.8214 policy_loss=0.0000 value_loss=55.6428 entropy=0.0001
[step=953] episode=953.0000 return=-115.9840 length=50.0000 global_step=23110.0000 loss=37.4309 policy_loss=-0.0000 value_loss=74.8618 entropy=0.0001
[step=954] episode=954.0000 return=-115.8299 length=20.0000 global_step=23130.0000 loss=293.0021 policy_loss=-0.0001 value_loss=586.0045 entropy=0.0001
[step=955] episode=955.0000 return=-115.7489 length=12.0000 global_step=23142.0000 loss=360.7264 policy_loss=-0.0001 value_loss=721.4530 entropy=0.0001
[step=956] episode=956.0000 return=-115.9926 length=21.0000 global_step=23163.0000 loss=83.2358 policy_loss=-0.0000 value_loss=166.4716 entropy=0.0001
[step=957] episode=957.0000 return=-115.9985 length=60.0000 global_step=23223.0000 loss=172.0055 policy_loss=0.0001 value_loss=344.0109 entropy=0.0001
[step=958] episode=958.0000 return=-115.9990 length=12.0000 global_step=23235.0000 loss=10.5921 policy_loss=-0.0000 value_loss=21.1843 entropy=0.0001
[step=959] episode=959.0000 return=-115.9736 length=28.0000 global_step=23263.0000 loss=104.3808 policy_loss=0.0001 value_loss=208.7614 entropy=0.0001
[step=960] episode=960.0000 return=-115.9944 length=29.0000 global_step=23292.0000 loss=162.4425 policy_loss=0.0001 value_loss=324.8848 entropy=0.0001
[step=961] episode=961.0000 return=-115.9979 length=28.0000 global_step=23320.0000 loss=86.5036 policy_loss=0.0001 value_loss=173.0070 entropy=0.0001
[step=962] episode=962.0000 return=-115.9811 length=28.0000 global_step=23348.0000 loss=5.3248 policy_loss=0.0000 value_loss=10.6496 entropy=0.0001
[step=963] episode=963.0000 return=-115.9778 length=12.0000 global_step=23360.0000 loss=124.8497 policy_loss=-0.0001 value_loss=249.6997 entropy=0.0001
[step=964] episode=964.0000 return=-115.9563 length=21.0000 global_step=23381.0000 loss=70.1681 policy_loss=-0.0001 value_loss=140.3364 entropy=0.0001
[step=965] episode=965.0000 return=-115.9999 length=29.0000 global_step=23410.0000 loss=33.0561 policy_loss=-0.0001 value_loss=66.1124 entropy=0.0002
[step=966] episode=966.0000 return=-115.9986 length=37.0000 global_step=23447.0000 loss=21.5725 policy_loss=0.0000 value_loss=43.1450 entropy=0.0002
[step=967] episode=967.0000 return=-115.9930 length=21.0000 global_step=23468.0000 loss=22.6528 policy_loss=-0.0001 value_loss=45.3059 entropy=0.0003
[step=968] episode=968.0000 return=-115.9955 length=21.0000 global_step=23489.0000 loss=8.5509 policy_loss=-0.0001 value_loss=17.1020 entropy=0.0004
[step=969] episode=969.0000 return=-115.9893 length=27.0000 global_step=23516.0000 loss=12.6769 policy_loss=0.0002 value_loss=25.3535 entropy=0.0005
[step=970] episode=970.0000 return=-115.9968 length=12.0000 global_step=23528.0000 loss=7.8404 policy_loss=0.0001 value_loss=15.6806 entropy=0.0006
[step=971] episode=971.0000 return=-115.9948 length=26.0000 global_step=23554.0000 loss=75.9898 policy_loss=0.0007 value_loss=151.9781 entropy=0.0007
[step=972] episode=972.0000 return=-115.9955 length=28.0000 global_step=23582.0000 loss=47.9074 policy_loss=0.0005 value_loss=95.8139 entropy=0.0006
[step=973] episode=973.0000 return=-115.7543 length=12.0000 global_step=23594.0000 loss=34.7796 policy_loss=-0.0003 value_loss=69.5598 entropy=0.0005
[step=974] episode=974.0000 return=-115.9930 length=29.0000 global_step=23623.0000 loss=12.8173 policy_loss=0.0000 value_loss=25.6346 entropy=0.0004
a2c_tuned train:  32%|‚ñà‚ñà‚ñà‚ñé      | 975/3000 [26:46<45:31,  1.35s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 976/3000 [26:47<45:48,  1.36s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 977/3000 [26:50<56:33,  1.68s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 978/3000 [26:50<47:21,  1.41s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 979/3000 [26:51<41:48,  1.24s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 980/3000 [26:53<47:14,  1.40s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 981/3000 [26:55<53:29,  1.59s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 982/3000 [26:57<53:08,  1.58s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 983/3000 [26:59<1:02:49,  1.87s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 984/3000 [27:01<1:03:20,  1.89s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 985/3000 [27:03<1:02:00,  1.85s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 986/3000 [27:04<52:47,  1.57s/it]  a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 987/3000 [27:05<45:24,  1.35s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 988/3000 [27:06<45:43,  1.36s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 989/3000 [27:07<46:53,  1.40s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 990/3000 [27:09<46:39,  1.39s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 991/3000 [27:11<50:58,  1.52s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 992/3000 [27:14<1:06:02,  1.97s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 993/3000 [27:15<1:00:16,  1.80s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 994/3000 [27:18<1:12:28,  2.17s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 995/3000 [27:19<1:03:31,  1.90s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 996/3000 [27:21<57:34,  1.72s/it]  a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 997/3000 [27:22<58:47,  1.76s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 998/3000 [27:24<59:04,  1.77s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 999/3000 [27:26<55:37,  1.67s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 1000/3000 [27:28<1:03:12,  1.90s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 1001/3000 [27:30<1:01:41,  1.85s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 1002/3000 [27:32<1:00:53,  1.83s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 1003/3000 [27:34<1:07:22,  2.02s/it]a2c_tuned train:  33%|‚ñà‚ñà‚ñà‚ñé      | 1004/3000 [27:37<1:17:36,  2.33s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñé      | 1005/3000 [27:40<1:17:53,  2.34s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñé      | 1006/3000 [27:42<1:20:28,  2.42s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñé      | 1007/3000 [27:43<1:09:30,  2.09s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñé      | 1008/3000 [27:45<1:02:06,  1.87s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñé      | 1009/3000 [27:46<57:58,  1.75s/it]  a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñé      | 1010/3000 [27:49<1:05:39,  1.98s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñé      | 1011/3000 [27:50<57:59,  1.75s/it]  a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñé      | 1012/3000 [27:52<58:23,  1.76s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1013/3000 [27:54<57:30,  1.74s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1014/3000 [27:57<1:15:14,  2.27s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1015/3000 [27:58<1:05:21,  1.98s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1016/3000 [27:59<53:26,  1.62s/it]  a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1017/3000 [28:01<51:55,  1.57s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1018/3000 [28:03<55:47,  1.69s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1019/3000 [28:04<58:33,  1.77s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1020/3000 [28:06<54:06,  1.64s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1021/3000 [28:08<1:01:44,  1.87s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1022/3000 [28:10<1:01:53,  1.88s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1023/3000 [28:12<1:03:10,  1.92s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1024/3000 [28:13<56:50,  1.73s/it]  a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1025/3000 [28:15<53:48,  1.63s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1026/3000 [28:17<57:25,  1.75s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1027/3000 [28:18<53:38,  1.63s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1028/3000 [28:20<50:46,  1.54s/it][step=975] episode=975.0000 return=-115.8168 length=13.0000 global_step=23636.0000 loss=95.7836 policy_loss=-0.0004 value_loss=191.5680 entropy=0.0004
[step=976] episode=976.0000 return=-115.9955 length=20.0000 global_step=23656.0000 loss=34.6489 policy_loss=-0.0002 value_loss=69.2984 entropy=0.0004
[step=977] episode=977.0000 return=-115.9992 length=37.0000 global_step=23693.0000 loss=39.6301 policy_loss=0.0002 value_loss=79.2599 entropy=0.0004
[step=978] episode=978.0000 return=-115.9982 length=12.0000 global_step=23705.0000 loss=34.3961 policy_loss=-0.0002 value_loss=68.7927 entropy=0.0004
[step=979] episode=979.0000 return=-115.8870 length=13.0000 global_step=23718.0000 loss=14.9183 policy_loss=-0.0001 value_loss=29.8369 entropy=0.0004
[step=980] episode=980.0000 return=-115.9837 length=27.0000 global_step=23745.0000 loss=42.4471 policy_loss=0.0003 value_loss=84.8935 entropy=0.0005
[step=981] episode=981.0000 return=-115.9954 length=30.0000 global_step=23775.0000 loss=85.2589 policy_loss=0.0004 value_loss=170.5169 entropy=0.0004
[step=982] episode=982.0000 return=-115.6950 length=22.0000 global_step=23797.0000 loss=3.0684 policy_loss=0.0000 value_loss=6.1368 entropy=0.0005
[step=983] episode=983.0000 return=-115.9764 length=37.0000 global_step=23834.0000 loss=54.2565 policy_loss=0.0003 value_loss=108.5125 entropy=0.0005
[step=984] episode=984.0000 return=-115.9952 length=28.0000 global_step=23862.0000 loss=12.7579 policy_loss=-0.0002 value_loss=25.5162 entropy=0.0005
[step=985] episode=985.0000 return=-115.9004 length=27.0000 global_step=23889.0000 loss=41.5527 policy_loss=-0.0004 value_loss=83.1060 entropy=0.0005
[step=986] episode=986.0000 return=-115.9825 length=13.0000 global_step=23902.0000 loss=88.9181 policy_loss=-0.0005 value_loss=177.8373 entropy=0.0005
[step=987] episode=987.0000 return=-115.8352 length=13.0000 global_step=23915.0000 loss=64.1899 policy_loss=-0.0005 value_loss=128.3808 entropy=0.0005
[step=988] episode=988.0000 return=-115.9899 length=21.0000 global_step=23936.0000 loss=6.9937 policy_loss=0.0001 value_loss=13.9872 entropy=0.0006
[step=989] episode=989.0000 return=-115.9890 length=21.0000 global_step=23957.0000 loss=21.0625 policy_loss=0.0004 value_loss=42.1243 entropy=0.0007
[step=990] episode=990.0000 return=-115.9840 length=19.0000 global_step=23976.0000 loss=13.5731 policy_loss=0.0003 value_loss=27.1455 entropy=0.0009
[step=991] episode=991.0000 return=-115.9949 length=28.0000 global_step=24004.0000 loss=64.2338 policy_loss=0.0009 value_loss=128.4659 entropy=0.0010
[step=992] episode=992.0000 return=-115.9883 length=46.0000 global_step=24050.0000 loss=96.6602 policy_loss=0.0012 value_loss=193.3180 entropy=0.0011
[step=993] episode=993.0000 return=-115.9974 length=21.0000 global_step=24071.0000 loss=21.7339 policy_loss=-0.0004 value_loss=43.4686 entropy=0.0009
[step=994] episode=994.0000 return=-115.8870 length=44.0000 global_step=24115.0000 loss=21.2180 policy_loss=-0.0001 value_loss=42.4362 entropy=0.0009
[step=995] episode=995.0000 return=-115.9952 length=19.0000 global_step=24134.0000 loss=63.9946 policy_loss=-0.0006 value_loss=127.9903 entropy=0.0006
[step=996] episode=996.0000 return=-115.9972 length=20.0000 global_step=24154.0000 loss=51.2161 policy_loss=-0.0004 value_loss=102.4331 entropy=0.0005
[step=997] episode=997.0000 return=-115.9986 length=26.0000 global_step=24180.0000 loss=15.8321 policy_loss=-0.0002 value_loss=31.6647 entropy=0.0005
[step=998] episode=998.0000 return=-115.9096 length=27.0000 global_step=24207.0000 loss=5.4452 policy_loss=-0.0000 value_loss=10.8905 entropy=0.0004
[step=999] episode=999.0000 return=-115.9384 length=21.0000 global_step=24228.0000 loss=14.8179 policy_loss=0.0001 value_loss=29.6357 entropy=0.0002
[step=1000] episode=1000.0000 return=-116.0000 length=37.0000 global_step=24265.0000 loss=173.5720 policy_loss=0.0003 value_loss=347.1434 entropy=0.0002
[step=1001] episode=1001.0000 return=-115.9810 length=26.0000 global_step=24291.0000 loss=35.5429 policy_loss=0.0001 value_loss=71.0856 entropy=0.0002
[step=1002] episode=1002.0000 return=-115.9760 length=27.0000 global_step=24318.0000 loss=33.4021 policy_loss=0.0001 value_loss=66.8040 entropy=0.0002
[step=1003] episode=1003.0000 return=-115.9976 length=38.0000 global_step=24356.0000 loss=16.6321 policy_loss=0.0001 value_loss=33.2640 entropy=0.0002
[step=1004] episode=1004.0000 return=-116.0000 length=46.0000 global_step=24402.0000 loss=53.1143 policy_loss=0.0001 value_loss=106.2285 entropy=0.0002
[step=1005] episode=1005.0000 return=-115.9951 length=35.0000 global_step=24437.0000 loss=52.4064 policy_loss=-0.0002 value_loss=104.8132 entropy=0.0003
[step=1006] episode=1006.0000 return=-115.9986 length=41.0000 global_step=24478.0000 loss=79.7449 policy_loss=-0.0003 value_loss=159.4903 entropy=0.0004
[step=1007] episode=1007.0000 return=-115.9583 length=19.0000 global_step=24497.0000 loss=231.8488 policy_loss=-0.0007 value_loss=463.6991 entropy=0.0004
[step=1008] episode=1008.0000 return=-115.9987 length=21.0000 global_step=24518.0000 loss=188.5695 policy_loss=-0.0009 value_loss=377.1407 entropy=0.0006
[step=1009] episode=1009.0000 return=-115.9698 length=21.0000 global_step=24539.0000 loss=102.1196 policy_loss=-0.0009 value_loss=204.2411 entropy=0.0008
[step=1010] episode=1010.0000 return=-115.9952 length=39.0000 global_step=24578.0000 loss=11.2137 policy_loss=0.0000 value_loss=22.4273 entropy=0.0013
[step=1011] episode=1011.0000 return=-115.7169 length=18.0000 global_step=24596.0000 loss=23.0609 policy_loss=-0.0015 value_loss=46.1249 entropy=0.0026
[step=1012] episode=1012.0000 return=-115.9965 length=28.0000 global_step=24624.0000 loss=98.1457 policy_loss=0.0117 value_loss=196.2680 entropy=0.0073
[step=1013] episode=1013.0000 return=-115.9837 length=26.0000 global_step=24650.0000 loss=145.6313 policy_loss=0.0005 value_loss=291.2617 entropy=0.0003
[step=1014] episode=1014.0000 return=-115.9999 length=53.0000 global_step=24703.0000 loss=403.7051 policy_loss=0.0002 value_loss=807.4099 entropy=0.0001
[step=1015] episode=1015.0000 return=-115.9385 length=19.0000 global_step=24722.0000 loss=17.7501 policy_loss=0.0000 value_loss=35.5002 entropy=0.0000
[step=1016] episode=1016.0000 return=-115.9739 length=11.0000 global_step=24733.0000 loss=23.7976 policy_loss=-0.0000 value_loss=47.5953 entropy=0.0000
[step=1017] episode=1017.0000 return=-115.9690 length=21.0000 global_step=24754.0000 loss=10.1391 policy_loss=-0.0000 value_loss=20.2781 entropy=0.0000
[step=1018] episode=1018.0000 return=-115.9896 length=29.0000 global_step=24783.0000 loss=17.3417 policy_loss=-0.0000 value_loss=34.6834 entropy=0.0000
[step=1019] episode=1019.0000 return=-115.9978 length=30.0000 global_step=24813.0000 loss=19.8878 policy_loss=-0.0000 value_loss=39.7756 entropy=0.0000
[step=1020] episode=1020.0000 return=-115.7815 length=20.0000 global_step=24833.0000 loss=65.2435 policy_loss=-0.0000 value_loss=130.4870 entropy=0.0000
[step=1021] episode=1021.0000 return=-115.9982 length=35.0000 global_step=24868.0000 loss=21.4328 policy_loss=-0.0000 value_loss=42.8657 entropy=0.0000
[step=1022] episode=1022.0000 return=-115.9992 length=29.0000 global_step=24897.0000 loss=15.5259 policy_loss=-0.0000 value_loss=31.0519 entropy=0.0000
[step=1023] episode=1023.0000 return=-115.9980 length=28.0000 global_step=24925.0000 loss=15.4306 policy_loss=-0.0000 value_loss=30.8612 entropy=0.0000
[step=1024] episode=1024.0000 return=-115.9927 length=19.0000 global_step=24944.0000 loss=11.2134 policy_loss=-0.0000 value_loss=22.4267 entropy=0.0000
[step=1025] episode=1025.0000 return=-115.8870 length=22.0000 global_step=24966.0000 loss=14.9518 policy_loss=-0.0000 value_loss=29.9035 entropy=0.0000
[step=1026] episode=1026.0000 return=-115.9959 length=29.0000 global_step=24995.0000 loss=29.9837 policy_loss=-0.0000 value_loss=59.9674 entropy=0.0000
[step=1027] episode=1027.0000 return=-115.9196 length=20.0000 global_step=25015.0000 loss=7.0023 policy_loss=-0.0000 value_loss=14.0046 entropy=0.0000
[step=1028] episode=1028.0000 return=-115.9968 length=20.0000 global_step=25035.0000 loss=14.1376 policy_loss=-0.0000 value_loss=28.2753 entropy=0.0000
a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1029/3000 [28:21<49:13,  1.50s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1030/3000 [28:23<53:40,  1.63s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1031/3000 [28:24<46:01,  1.40s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1032/3000 [28:26<49:34,  1.51s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1033/3000 [28:26<42:46,  1.30s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1034/3000 [28:28<42:26,  1.30s/it]a2c_tuned train:  34%|‚ñà‚ñà‚ñà‚ñç      | 1035/3000 [28:29<42:09,  1.29s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1036/3000 [28:31<47:07,  1.44s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1037/3000 [28:32<41:41,  1.27s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1038/3000 [28:33<45:56,  1.40s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1039/3000 [28:35<45:58,  1.41s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1040/3000 [28:37<50:43,  1.55s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1041/3000 [28:38<52:49,  1.62s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1042/3000 [28:40<54:03,  1.66s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1043/3000 [28:41<51:07,  1.57s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1044/3000 [28:44<1:04:21,  1.97s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1045/3000 [28:46<1:04:50,  1.99s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1046/3000 [28:48<59:17,  1.82s/it]  a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1047/3000 [28:49<56:26,  1.73s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1048/3000 [28:51<59:23,  1.83s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñç      | 1049/3000 [28:53<54:17,  1.67s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1050/3000 [28:55<56:03,  1.72s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1051/3000 [28:56<53:47,  1.66s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1052/3000 [28:58<1:01:24,  1.89s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1053/3000 [29:01<1:06:09,  2.04s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1054/3000 [29:03<1:05:09,  2.01s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1055/3000 [29:04<1:00:04,  1.85s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1056/3000 [29:07<1:04:24,  1.99s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1057/3000 [29:08<58:34,  1.81s/it]  a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1058/3000 [29:09<54:32,  1.68s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1059/3000 [29:11<51:37,  1.60s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1060/3000 [29:12<47:59,  1.48s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1061/3000 [29:13<46:17,  1.43s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1062/3000 [29:15<44:11,  1.37s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1063/3000 [29:16<49:04,  1.52s/it]a2c_tuned train:  35%|‚ñà‚ñà‚ñà‚ñå      | 1064/3000 [29:18<52:10,  1.62s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1065/3000 [29:19<45:11,  1.40s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1066/3000 [29:20<39:34,  1.23s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1067/3000 [29:22<45:33,  1.41s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1068/3000 [29:23<39:32,  1.23s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1069/3000 [29:24<40:00,  1.24s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1070/3000 [29:25<41:42,  1.30s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1071/3000 [29:27<43:00,  1.34s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1072/3000 [29:29<53:37,  1.67s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1073/3000 [29:30<45:04,  1.40s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1074/3000 [29:32<50:29,  1.57s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1075/3000 [29:33<49:00,  1.53s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1076/3000 [29:36<1:02:44,  1.96s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1077/3000 [29:37<52:15,  1.63s/it]  a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1078/3000 [29:39<52:41,  1.65s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1079/3000 [29:41<1:01:04,  1.91s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1080/3000 [29:42<51:38,  1.61s/it]  a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1081/3000 [29:44<51:52,  1.62s/it][step=1029] episode=1029.0000 return=-115.9913 length=20.0000 global_step=25055.0000 loss=7.1994 policy_loss=-0.0000 value_loss=14.3988 entropy=0.0000
[step=1030] episode=1030.0000 return=-115.9989 length=28.0000 global_step=25083.0000 loss=18.6242 policy_loss=-0.0000 value_loss=37.2485 entropy=0.0000
[step=1031] episode=1031.0000 return=-115.7638 length=13.0000 global_step=25096.0000 loss=80.0123 policy_loss=-0.0000 value_loss=160.0246 entropy=0.0000
[step=1032] episode=1032.0000 return=-115.9947 length=27.0000 global_step=25123.0000 loss=17.2826 policy_loss=-0.0000 value_loss=34.5652 entropy=0.0000
[step=1033] episode=1033.0000 return=-115.6125 length=12.0000 global_step=25135.0000 loss=69.2994 policy_loss=-0.0000 value_loss=138.5988 entropy=0.0000
[step=1034] episode=1034.0000 return=-115.9964 length=19.0000 global_step=25154.0000 loss=9.9026 policy_loss=-0.0000 value_loss=19.8051 entropy=0.0000
[step=1035] episode=1035.0000 return=-115.8880 length=18.0000 global_step=25172.0000 loss=13.8388 policy_loss=-0.0000 value_loss=27.6775 entropy=0.0000
[step=1036] episode=1036.0000 return=-115.9931 length=27.0000 global_step=25199.0000 loss=9.2982 policy_loss=-0.0000 value_loss=18.5964 entropy=0.0000
[step=1037] episode=1037.0000 return=-115.9941 length=13.0000 global_step=25212.0000 loss=14.3418 policy_loss=-0.0000 value_loss=28.6837 entropy=0.0000
[step=1038] episode=1038.0000 return=-115.9384 length=26.0000 global_step=25238.0000 loss=22.7733 policy_loss=-0.0000 value_loss=45.5466 entropy=0.0000
[step=1039] episode=1039.0000 return=-115.9979 length=21.0000 global_step=25259.0000 loss=9.7263 policy_loss=-0.0000 value_loss=19.4526 entropy=0.0000
[step=1040] episode=1040.0000 return=-115.9096 length=28.0000 global_step=25287.0000 loss=7.9745 policy_loss=-0.0000 value_loss=15.9490 entropy=0.0000
[step=1041] episode=1041.0000 return=-115.9817 length=26.0000 global_step=25313.0000 loss=15.6240 policy_loss=-0.0000 value_loss=31.2480 entropy=0.0000
[step=1042] episode=1042.0000 return=-115.9775 length=27.0000 global_step=25340.0000 loss=38.7581 policy_loss=-0.0000 value_loss=77.5161 entropy=0.0000
[step=1043] episode=1043.0000 return=-115.8865 length=21.0000 global_step=25361.0000 loss=45.7769 policy_loss=-0.0000 value_loss=91.5537 entropy=0.0000
[step=1044] episode=1044.0000 return=-115.9963 length=45.0000 global_step=25406.0000 loss=36.3467 policy_loss=-0.0000 value_loss=72.6934 entropy=0.0000
[step=1045] episode=1045.0000 return=-115.9894 length=30.0000 global_step=25436.0000 loss=17.0036 policy_loss=-0.0000 value_loss=34.0071 entropy=0.0000
[step=1046] episode=1046.0000 return=-115.9959 length=22.0000 global_step=25458.0000 loss=18.3388 policy_loss=-0.0000 value_loss=36.6775 entropy=0.0000
[step=1047] episode=1047.0000 return=-115.9903 length=21.0000 global_step=25479.0000 loss=17.1997 policy_loss=-0.0000 value_loss=34.3994 entropy=0.0000
[step=1048] episode=1048.0000 return=-115.9096 length=30.0000 global_step=25509.0000 loss=21.7235 policy_loss=-0.0000 value_loss=43.4470 entropy=0.0000
[step=1049] episode=1049.0000 return=-115.9990 length=20.0000 global_step=25529.0000 loss=8.2046 policy_loss=-0.0000 value_loss=16.4092 entropy=0.0000
[step=1050] episode=1050.0000 return=-115.9985 length=27.0000 global_step=25556.0000 loss=33.8350 policy_loss=-0.0000 value_loss=67.6700 entropy=0.0000
[step=1051] episode=1051.0000 return=-115.9332 length=21.0000 global_step=25577.0000 loss=5.8437 policy_loss=-0.0000 value_loss=11.6873 entropy=0.0000
[step=1052] episode=1052.0000 return=-115.9979 length=37.0000 global_step=25614.0000 loss=41.5705 policy_loss=-0.0000 value_loss=83.1410 entropy=0.0000
[step=1053] episode=1053.0000 return=-115.9851 length=37.0000 global_step=25651.0000 loss=38.5877 policy_loss=-0.0000 value_loss=77.1754 entropy=0.0000
[step=1054] episode=1054.0000 return=-115.9991 length=28.0000 global_step=25679.0000 loss=8.2005 policy_loss=-0.0000 value_loss=16.4010 entropy=0.0000
[step=1055] episode=1055.0000 return=-115.9834 length=22.0000 global_step=25701.0000 loss=24.2819 policy_loss=-0.0000 value_loss=48.5638 entropy=0.0000
[step=1056] episode=1056.0000 return=-115.9984 length=34.0000 global_step=25735.0000 loss=17.0949 policy_loss=-0.0000 value_loss=34.1898 entropy=0.0000
[step=1057] episode=1057.0000 return=-115.9786 length=20.0000 global_step=25755.0000 loss=37.5658 policy_loss=-0.0000 value_loss=75.1316 entropy=0.0000
[step=1058] episode=1058.0000 return=-115.8870 length=19.0000 global_step=25774.0000 loss=24.4399 policy_loss=-0.0000 value_loss=48.8798 entropy=0.0000
[step=1059] episode=1059.0000 return=-115.9998 length=20.0000 global_step=25794.0000 loss=10.3541 policy_loss=-0.0000 value_loss=20.7081 entropy=0.0000
[step=1060] episode=1060.0000 return=-115.9994 length=18.0000 global_step=25812.0000 loss=5.9743 policy_loss=-0.0000 value_loss=11.9486 entropy=0.0000
[step=1061] episode=1061.0000 return=-115.9182 length=20.0000 global_step=25832.0000 loss=35.8374 policy_loss=-0.0000 value_loss=71.6747 entropy=0.0000
[step=1062] episode=1062.0000 return=-115.9953 length=18.0000 global_step=25850.0000 loss=21.4362 policy_loss=-0.0000 value_loss=42.8724 entropy=0.0000
[step=1063] episode=1063.0000 return=-115.9894 length=28.0000 global_step=25878.0000 loss=58.9136 policy_loss=-0.0000 value_loss=117.8273 entropy=0.0000
[step=1064] episode=1064.0000 return=-115.8865 length=28.0000 global_step=25906.0000 loss=26.1418 policy_loss=-0.0000 value_loss=52.2836 entropy=0.0000
[step=1065] episode=1065.0000 return=-115.9870 length=13.0000 global_step=25919.0000 loss=64.6699 policy_loss=-0.0000 value_loss=129.3398 entropy=0.0000
[step=1066] episode=1066.0000 return=-115.8177 length=12.0000 global_step=25931.0000 loss=87.9851 policy_loss=-0.0000 value_loss=175.9703 entropy=0.0000
[step=1067] episode=1067.0000 return=-115.9854 length=28.0000 global_step=25959.0000 loss=17.2155 policy_loss=-0.0000 value_loss=34.4311 entropy=0.0000
[step=1068] episode=1068.0000 return=-115.9921 length=12.0000 global_step=25971.0000 loss=54.8948 policy_loss=-0.0000 value_loss=109.7896 entropy=0.0000
[step=1069] episode=1069.0000 return=-115.9731 length=18.0000 global_step=25989.0000 loss=8.2094 policy_loss=-0.0000 value_loss=16.4188 entropy=0.0000
[step=1070] episode=1070.0000 return=-115.8437 length=21.0000 global_step=26010.0000 loss=8.5524 policy_loss=-0.0000 value_loss=17.1048 entropy=0.0000
[step=1071] episode=1071.0000 return=-115.9978 length=21.0000 global_step=26031.0000 loss=48.3712 policy_loss=-0.0000 value_loss=96.7424 entropy=0.0000
[step=1072] episode=1072.0000 return=-115.9439 length=37.0000 global_step=26068.0000 loss=160.5025 policy_loss=-0.0000 value_loss=321.0050 entropy=0.0000
[step=1073] episode=1073.0000 return=-115.9664 length=12.0000 global_step=26080.0000 loss=8.6625 policy_loss=-0.0000 value_loss=17.3250 entropy=0.0000
[step=1074] episode=1074.0000 return=-115.9661 length=29.0000 global_step=26109.0000 loss=33.3224 policy_loss=-0.0000 value_loss=66.6448 entropy=0.0000
[step=1075] episode=1075.0000 return=-115.8765 length=22.0000 global_step=26131.0000 loss=17.3338 policy_loss=-0.0000 value_loss=34.6677 entropy=0.0000
[step=1076] episode=1076.0000 return=-115.9971 length=44.0000 global_step=26175.0000 loss=52.0029 policy_loss=-0.0000 value_loss=104.0058 entropy=0.0000
[step=1077] episode=1077.0000 return=-115.9968 length=13.0000 global_step=26188.0000 loss=171.3470 policy_loss=-0.0000 value_loss=342.6940 entropy=0.0000
[step=1078] episode=1078.0000 return=-115.9762 length=26.0000 global_step=26214.0000 loss=80.9097 policy_loss=-0.0000 value_loss=161.8193 entropy=0.0000
[step=1079] episode=1079.0000 return=-115.9914 length=37.0000 global_step=26251.0000 loss=42.3787 policy_loss=-0.0000 value_loss=84.7573 entropy=0.0000
[step=1080] episode=1080.0000 return=-115.9705 length=13.0000 global_step=26264.0000 loss=110.7037 policy_loss=-0.0000 value_loss=221.4073 entropy=0.0000
[step=1081] episode=1081.0000 return=-115.8869 length=25.0000 global_step=26289.0000 loss=9.9158 policy_loss=-0.0000 value_loss=19.8316 entropy=0.0000
a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1082/3000 [29:45<44:38,  1.40s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1083/3000 [29:46<44:51,  1.40s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1084/3000 [29:48<44:37,  1.40s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1085/3000 [29:49<44:23,  1.39s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1086/3000 [29:50<44:03,  1.38s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñå      | 1087/3000 [29:53<54:59,  1.72s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñã      | 1088/3000 [29:54<46:13,  1.45s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñã      | 1089/3000 [29:56<54:36,  1.71s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñã      | 1090/3000 [29:57<51:09,  1.61s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñã      | 1091/3000 [30:00<57:45,  1.82s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñã      | 1092/3000 [30:02<1:03:12,  1.99s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñã      | 1093/3000 [30:05<1:13:18,  2.31s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñã      | 1094/3000 [30:07<1:04:17,  2.02s/it]a2c_tuned train:  36%|‚ñà‚ñà‚ñà‚ñã      | 1095/3000 [30:07<52:39,  1.66s/it]  a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1096/3000 [30:09<54:37,  1.72s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1097/3000 [30:12<1:00:49,  1.92s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1098/3000 [30:13<55:24,  1.75s/it]  a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1099/3000 [30:14<50:46,  1.60s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1100/3000 [30:16<53:48,  1.70s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1101/3000 [30:17<45:58,  1.45s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1102/3000 [30:18<44:55,  1.42s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1103/3000 [30:19<38:33,  1.22s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1104/3000 [30:20<35:31,  1.12s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1105/3000 [30:21<38:28,  1.22s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1106/3000 [30:23<43:26,  1.38s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1107/3000 [30:24<43:05,  1.37s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1108/3000 [30:26<43:41,  1.39s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1109/3000 [30:27<43:17,  1.37s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1110/3000 [30:29<42:56,  1.36s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1111/3000 [30:30<44:20,  1.41s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1112/3000 [30:31<43:49,  1.39s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1113/3000 [30:33<43:41,  1.39s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1114/3000 [30:34<43:48,  1.39s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1115/3000 [30:36<48:26,  1.54s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1116/3000 [30:37<46:08,  1.47s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1117/3000 [30:39<49:08,  1.57s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1118/3000 [30:40<42:13,  1.35s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1119/3000 [30:41<41:46,  1.33s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1120/3000 [30:42<37:33,  1.20s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1121/3000 [30:44<38:20,  1.22s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1122/3000 [30:45<44:31,  1.42s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1123/3000 [30:48<53:55,  1.72s/it]a2c_tuned train:  37%|‚ñà‚ñà‚ñà‚ñã      | 1124/3000 [30:49<51:11,  1.64s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1125/3000 [30:50<43:48,  1.40s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1126/3000 [30:52<47:30,  1.52s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1127/3000 [30:54<50:54,  1.63s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1128/3000 [30:55<46:50,  1.50s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1129/3000 [30:56<45:54,  1.47s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1130/3000 [30:58<48:20,  1.55s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1131/3000 [31:01<56:08,  1.80s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1132/3000 [31:02<52:06,  1.67s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1133/3000 [31:03<49:45,  1.60s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1134/3000 [31:05<46:10,  1.48s/it][step=1082] episode=1082.0000 return=-115.9925 length=12.0000 global_step=26301.0000 loss=9.6596 policy_loss=-0.0000 value_loss=19.3192 entropy=0.0000
[step=1083] episode=1083.0000 return=-115.9464 length=22.0000 global_step=26323.0000 loss=100.5730 policy_loss=-0.0000 value_loss=201.1460 entropy=0.0000
[step=1084] episode=1084.0000 return=-115.9703 length=20.0000 global_step=26343.0000 loss=156.1290 policy_loss=-0.0000 value_loss=312.2580 entropy=0.0000
[step=1085] episode=1085.0000 return=-115.9763 length=20.0000 global_step=26363.0000 loss=199.2149 policy_loss=-0.0000 value_loss=398.4298 entropy=0.0000
[step=1086] episode=1086.0000 return=-115.9939 length=20.0000 global_step=26383.0000 loss=124.7749 policy_loss=-0.0000 value_loss=249.5498 entropy=0.0000
[step=1087] episode=1087.0000 return=-115.9989 length=38.0000 global_step=26421.0000 loss=142.5449 policy_loss=-0.0000 value_loss=285.0898 entropy=0.0000
[step=1088] episode=1088.0000 return=-115.9857 length=12.0000 global_step=26433.0000 loss=33.7086 policy_loss=-0.0000 value_loss=67.4172 entropy=0.0000
[step=1089] episode=1089.0000 return=-115.9096 length=36.0000 global_step=26469.0000 loss=21.6250 policy_loss=-0.0000 value_loss=43.2501 entropy=0.0000
[step=1090] episode=1090.0000 return=-115.9961 length=20.0000 global_step=26489.0000 loss=180.7350 policy_loss=-0.0000 value_loss=361.4699 entropy=0.0000
[step=1091] episode=1091.0000 return=-115.9990 length=36.0000 global_step=26525.0000 loss=60.8851 policy_loss=-0.0000 value_loss=121.7702 entropy=0.0000
[step=1092] episode=1092.0000 return=-115.9783 length=36.0000 global_step=26561.0000 loss=63.8832 policy_loss=-0.0000 value_loss=127.7664 entropy=0.0000
[step=1093] episode=1093.0000 return=-115.9997 length=46.0000 global_step=26607.0000 loss=42.6674 policy_loss=-0.0000 value_loss=85.3348 entropy=0.0000
[step=1094] episode=1094.0000 return=-115.9840 length=21.0000 global_step=26628.0000 loss=72.3531 policy_loss=-0.0000 value_loss=144.7062 entropy=0.0000
[step=1095] episode=1095.0000 return=-115.8880 length=11.0000 global_step=26639.0000 loss=60.4960 policy_loss=-0.0000 value_loss=120.9920 entropy=0.0000
[step=1096] episode=1096.0000 return=-115.9990 length=28.0000 global_step=26667.0000 loss=38.7173 policy_loss=-0.0000 value_loss=77.4346 entropy=0.0000
[step=1097] episode=1097.0000 return=-115.9998 length=35.0000 global_step=26702.0000 loss=171.3445 policy_loss=-0.0000 value_loss=342.6889 entropy=0.0000
[step=1098] episode=1098.0000 return=-115.9555 length=20.0000 global_step=26722.0000 loss=47.5860 policy_loss=-0.0000 value_loss=95.1719 entropy=0.0000
[step=1099] episode=1099.0000 return=-115.8428 length=20.0000 global_step=26742.0000 loss=9.6686 policy_loss=-0.0000 value_loss=19.3371 entropy=0.0000
[step=1100] episode=1100.0000 return=-115.9918 length=29.0000 global_step=26771.0000 loss=29.1704 policy_loss=-0.0000 value_loss=58.3408 entropy=0.0000
[step=1101] episode=1101.0000 return=-115.9602 length=13.0000 global_step=26784.0000 loss=41.4020 policy_loss=-0.0000 value_loss=82.8040 entropy=0.0000
[step=1102] episode=1102.0000 return=-115.9998 length=20.0000 global_step=26804.0000 loss=22.2782 policy_loss=-0.0000 value_loss=44.5564 entropy=0.0000
[step=1103] episode=1103.0000 return=-115.7816 length=11.0000 global_step=26815.0000 loss=67.8096 policy_loss=-0.0000 value_loss=135.6192 entropy=0.0000
[step=1104] episode=1104.0000 return=-115.8168 length=13.0000 global_step=26828.0000 loss=47.3513 policy_loss=-0.0000 value_loss=94.7025 entropy=0.0000
[step=1105] episode=1105.0000 return=-115.9178 length=21.0000 global_step=26849.0000 loss=1.9944 policy_loss=-0.0000 value_loss=3.9889 entropy=0.0000
[step=1106] episode=1106.0000 return=-115.9357 length=26.0000 global_step=26875.0000 loss=32.8478 policy_loss=-0.0000 value_loss=65.6955 entropy=0.0000
[step=1107] episode=1107.0000 return=-115.9764 length=20.0000 global_step=26895.0000 loss=28.9463 policy_loss=-0.0000 value_loss=57.8927 entropy=0.0000
[step=1108] episode=1108.0000 return=-115.9892 length=21.0000 global_step=26916.0000 loss=18.5360 policy_loss=-0.0000 value_loss=37.0720 entropy=0.0000
[step=1109] episode=1109.0000 return=-115.9576 length=20.0000 global_step=26936.0000 loss=6.4724 policy_loss=-0.0000 value_loss=12.9447 entropy=0.0000
[step=1110] episode=1110.0000 return=-115.9996 length=20.0000 global_step=26956.0000 loss=10.8758 policy_loss=-0.0000 value_loss=21.7517 entropy=0.0000
[step=1111] episode=1111.0000 return=-115.9794 length=21.0000 global_step=26977.0000 loss=8.9407 policy_loss=-0.0000 value_loss=17.8814 entropy=0.0000
[step=1112] episode=1112.0000 return=-115.9096 length=20.0000 global_step=26997.0000 loss=9.2703 policy_loss=-0.0000 value_loss=18.5406 entropy=0.0000
[step=1113] episode=1113.0000 return=-115.9764 length=20.0000 global_step=27017.0000 loss=6.5809 policy_loss=-0.0000 value_loss=13.1618 entropy=0.0000
[step=1114] episode=1114.0000 return=-115.9953 length=21.0000 global_step=27038.0000 loss=8.8327 policy_loss=-0.0000 value_loss=17.6654 entropy=0.0000
[step=1115] episode=1115.0000 return=-115.9096 length=28.0000 global_step=27066.0000 loss=35.3747 policy_loss=-0.0000 value_loss=70.7493 entropy=0.0000
[step=1116] episode=1116.0000 return=-115.7962 length=20.0000 global_step=27086.0000 loss=7.6396 policy_loss=-0.0000 value_loss=15.2792 entropy=0.0000
[step=1117] episode=1117.0000 return=-116.0000 length=28.0000 global_step=27114.0000 loss=23.7747 policy_loss=-0.0000 value_loss=47.5494 entropy=0.0000
[step=1118] episode=1118.0000 return=-115.9803 length=12.0000 global_step=27126.0000 loss=52.9415 policy_loss=-0.0000 value_loss=105.8830 entropy=0.0000
[step=1119] episode=1119.0000 return=-115.9990 length=19.0000 global_step=27145.0000 loss=12.3833 policy_loss=-0.0000 value_loss=24.7666 entropy=0.0000
[step=1120] episode=1120.0000 return=-115.9784 length=13.0000 global_step=27158.0000 loss=27.9210 policy_loss=-0.0000 value_loss=55.8419 entropy=0.0000
[step=1121] episode=1121.0000 return=-115.9968 length=19.0000 global_step=27177.0000 loss=15.0191 policy_loss=-0.0000 value_loss=30.0382 entropy=0.0000
[step=1122] episode=1122.0000 return=-115.9966 length=29.0000 global_step=27206.0000 loss=79.9203 policy_loss=-0.0000 value_loss=159.8405 entropy=0.0000
[step=1123] episode=1123.0000 return=-115.9968 length=36.0000 global_step=27242.0000 loss=121.2324 policy_loss=-0.0000 value_loss=242.4648 entropy=0.0000
[step=1124] episode=1124.0000 return=-115.9968 length=21.0000 global_step=27263.0000 loss=7.5368 policy_loss=-0.0000 value_loss=15.0736 entropy=0.0000
[step=1125] episode=1125.0000 return=-115.9564 length=12.0000 global_step=27275.0000 loss=77.1290 policy_loss=-0.0000 value_loss=154.2580 entropy=0.0000
[step=1126] episode=1126.0000 return=-115.9954 length=27.0000 global_step=27302.0000 loss=21.0898 policy_loss=-0.0000 value_loss=42.1795 entropy=0.0000
[step=1127] episode=1127.0000 return=-115.9986 length=30.0000 global_step=27332.0000 loss=15.8447 policy_loss=-0.0000 value_loss=31.6895 entropy=0.0000
[step=1128] episode=1128.0000 return=-115.9862 length=18.0000 global_step=27350.0000 loss=25.8964 policy_loss=-0.0000 value_loss=51.7927 entropy=0.0000
[step=1129] episode=1129.0000 return=-115.9555 length=20.0000 global_step=27370.0000 loss=8.4335 policy_loss=-0.0000 value_loss=16.8670 entropy=0.0000
[step=1130] episode=1130.0000 return=-115.9986 length=25.0000 global_step=27395.0000 loss=22.6529 policy_loss=-0.0000 value_loss=45.3059 entropy=0.0000
[step=1131] episode=1131.0000 return=-115.9995 length=35.0000 global_step=27430.0000 loss=118.5506 policy_loss=-0.0000 value_loss=237.1011 entropy=0.0000
[step=1132] episode=1132.0000 return=-115.9713 length=20.0000 global_step=27450.0000 loss=3.2917 policy_loss=-0.0000 value_loss=6.5834 entropy=0.0000
[step=1133] episode=1133.0000 return=-115.8644 length=22.0000 global_step=27472.0000 loss=10.9844 policy_loss=-0.0000 value_loss=21.9687 entropy=0.0000
[step=1134] episode=1134.0000 return=-115.9939 length=18.0000 global_step=27490.0000 loss=13.2642 policy_loss=-0.0000 value_loss=26.5285 entropy=0.0000
a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1135/3000 [31:06<45:22,  1.46s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1136/3000 [31:07<43:43,  1.41s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1137/3000 [31:09<43:05,  1.39s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1138/3000 [31:11<48:30,  1.56s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1139/3000 [31:12<47:38,  1.54s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1140/3000 [31:14<54:08,  1.75s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1141/3000 [31:16<54:22,  1.75s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1142/3000 [31:18<55:17,  1.79s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1143/3000 [31:19<52:06,  1.68s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1144/3000 [31:21<49:49,  1.61s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1145/3000 [31:22<47:01,  1.52s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1146/3000 [31:24<50:26,  1.63s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1147/3000 [31:25<47:51,  1.55s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1148/3000 [31:26<36:27,  1.18s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1149/3000 [31:27<34:06,  1.11s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1150/3000 [31:28<36:47,  1.19s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1151/3000 [31:30<43:36,  1.41s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1152/3000 [31:32<46:57,  1.52s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1153/3000 [31:34<49:57,  1.62s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1154/3000 [31:35<51:36,  1.68s/it]a2c_tuned train:  38%|‚ñà‚ñà‚ñà‚ñä      | 1155/3000 [31:37<50:04,  1.63s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñä      | 1156/3000 [31:38<48:20,  1.57s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñä      | 1157/3000 [31:40<46:20,  1.51s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñä      | 1158/3000 [31:41<48:38,  1.58s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñä      | 1159/3000 [31:44<55:50,  1.82s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñä      | 1160/3000 [31:45<52:14,  1.70s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñä      | 1161/3000 [31:47<50:09,  1.64s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñä      | 1162/3000 [31:48<47:42,  1.56s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1163/3000 [31:50<50:56,  1.66s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1164/3000 [31:52<53:30,  1.75s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1165/3000 [31:53<50:09,  1.64s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1166/3000 [31:55<48:13,  1.58s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1167/3000 [31:56<45:07,  1.48s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1168/3000 [31:58<49:48,  1.63s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1169/3000 [31:59<46:49,  1.53s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1170/3000 [32:01<49:33,  1.63s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1171/3000 [32:02<41:47,  1.37s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1172/3000 [32:04<47:20,  1.55s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1173/3000 [32:05<41:24,  1.36s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1174/3000 [32:06<42:14,  1.39s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1175/3000 [32:07<37:39,  1.24s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1176/3000 [32:09<39:40,  1.30s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1177/3000 [32:11<45:01,  1.48s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1178/3000 [32:12<47:42,  1.57s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1179/3000 [32:13<40:35,  1.34s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1180/3000 [32:15<45:05,  1.49s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1181/3000 [32:16<44:04,  1.45s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1182/3000 [32:18<43:27,  1.43s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1183/3000 [32:19<43:21,  1.43s/it]a2c_tuned train:  39%|‚ñà‚ñà‚ñà‚ñâ      | 1184/3000 [32:21<47:54,  1.58s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1185/3000 [32:23<52:40,  1.74s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1186/3000 [32:25<50:08,  1.66s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1187/3000 [32:26<51:17,  1.70s/it][step=1135] episode=1135.0000 return=-115.7697 length=21.0000 global_step=27511.0000 loss=20.7327 policy_loss=-0.0000 value_loss=41.4654 entropy=0.0000
[step=1136] episode=1136.0000 return=-115.9919 length=18.0000 global_step=27529.0000 loss=23.4306 policy_loss=-0.0000 value_loss=46.8611 entropy=0.0000
[step=1137] episode=1137.0000 return=-115.9989 length=20.0000 global_step=27549.0000 loss=10.4612 policy_loss=-0.0000 value_loss=20.9223 entropy=0.0000
[step=1138] episode=1138.0000 return=-115.9988 length=28.0000 global_step=27577.0000 loss=24.5003 policy_loss=-0.0000 value_loss=49.0006 entropy=0.0000
[step=1139] episode=1139.0000 return=-115.8739 length=22.0000 global_step=27599.0000 loss=8.6198 policy_loss=-0.0000 value_loss=17.2395 entropy=0.0000
[step=1140] episode=1140.0000 return=-115.9964 length=33.0000 global_step=27632.0000 loss=32.3946 policy_loss=-0.0000 value_loss=64.7893 entropy=0.0000
[step=1141] episode=1141.0000 return=-115.9748 length=26.0000 global_step=27658.0000 loss=16.3805 policy_loss=-0.0000 value_loss=32.7610 entropy=0.0000
[step=1142] episode=1142.0000 return=-115.8705 length=28.0000 global_step=27686.0000 loss=18.6900 policy_loss=-0.0000 value_loss=37.3800 entropy=0.0000
[step=1143] episode=1143.0000 return=-115.9968 length=21.0000 global_step=27707.0000 loss=110.4491 policy_loss=-0.0000 value_loss=220.8983 entropy=0.0000
[step=1144] episode=1144.0000 return=-115.9941 length=22.0000 global_step=27729.0000 loss=33.0149 policy_loss=-0.0000 value_loss=66.0299 entropy=0.0000
[step=1145] episode=1145.0000 return=-115.9998 length=19.0000 global_step=27748.0000 loss=15.1494 policy_loss=-0.0000 value_loss=30.2989 entropy=0.0000
[step=1146] episode=1146.0000 return=-115.9958 length=29.0000 global_step=27777.0000 loss=42.2583 policy_loss=-0.0000 value_loss=84.5166 entropy=0.0000
[step=1147] episode=1147.0000 return=-115.9703 length=21.0000 global_step=27798.0000 loss=26.6419 policy_loss=-0.0000 value_loss=53.2837 entropy=0.0000
[step=1148] episode=1148.0000 return=-106.9557 length=4.0000 global_step=27802.0000 loss=7.8612 policy_loss=-0.0000 value_loss=15.7224 entropy=0.0000
[step=1149] episode=1149.0000 return=-115.8370 length=13.0000 global_step=27815.0000 loss=8.6745 policy_loss=-0.0000 value_loss=17.3489 entropy=0.0000
[step=1150] episode=1150.0000 return=-115.9990 length=20.0000 global_step=27835.0000 loss=33.3677 policy_loss=-0.0000 value_loss=66.7354 entropy=0.0000
[step=1151] episode=1151.0000 return=-115.9840 length=29.0000 global_step=27864.0000 loss=46.6144 policy_loss=-0.0000 value_loss=93.2287 entropy=0.0000
[step=1152] episode=1152.0000 return=-115.9968 length=27.0000 global_step=27891.0000 loss=13.9031 policy_loss=-0.0000 value_loss=27.8063 entropy=0.0000
[step=1153] episode=1153.0000 return=-115.9969 length=28.0000 global_step=27919.0000 loss=23.4359 policy_loss=-0.0000 value_loss=46.8717 entropy=0.0000
[step=1154] episode=1154.0000 return=-115.8437 length=28.0000 global_step=27947.0000 loss=91.6534 policy_loss=-0.0000 value_loss=183.3067 entropy=0.0000
[step=1155] episode=1155.0000 return=-115.9691 length=22.0000 global_step=27969.0000 loss=68.5550 policy_loss=-0.0000 value_loss=137.1099 entropy=0.0000
[step=1156] episode=1156.0000 return=-115.9443 length=21.0000 global_step=27990.0000 loss=37.9148 policy_loss=-0.0000 value_loss=75.8297 entropy=0.0000
[step=1157] episode=1157.0000 return=-115.9976 length=20.0000 global_step=28010.0000 loss=9.3682 policy_loss=-0.0000 value_loss=18.7363 entropy=0.0000
[step=1158] episode=1158.0000 return=-115.9968 length=26.0000 global_step=28036.0000 loss=18.1393 policy_loss=-0.0000 value_loss=36.2785 entropy=0.0000
[step=1159] episode=1159.0000 return=-115.9996 length=36.0000 global_step=28072.0000 loss=199.1719 policy_loss=-0.0000 value_loss=398.3438 entropy=0.0000
[step=1160] episode=1160.0000 return=-115.9953 length=21.0000 global_step=28093.0000 loss=48.0916 policy_loss=-0.0000 value_loss=96.1831 entropy=0.0000
[step=1161] episode=1161.0000 return=-115.9855 length=22.0000 global_step=28115.0000 loss=20.4384 policy_loss=-0.0000 value_loss=40.8769 entropy=0.0000
[step=1162] episode=1162.0000 return=-115.9297 length=21.0000 global_step=28136.0000 loss=10.8435 policy_loss=-0.0000 value_loss=21.6869 entropy=0.0000
[step=1163] episode=1163.0000 return=-115.9799 length=28.0000 global_step=28164.0000 loss=17.5517 policy_loss=-0.0000 value_loss=35.1033 entropy=0.0000
[step=1164] episode=1164.0000 return=-115.9995 length=29.0000 global_step=28193.0000 loss=16.5105 policy_loss=-0.0000 value_loss=33.0210 entropy=0.0000
[step=1165] episode=1165.0000 return=-115.9968 length=21.0000 global_step=28214.0000 loss=28.4724 policy_loss=-0.0000 value_loss=56.9447 entropy=0.0000
[step=1166] episode=1166.0000 return=-115.8504 length=20.0000 global_step=28234.0000 loss=30.9724 policy_loss=-0.0000 value_loss=61.9447 entropy=0.0000
[step=1167] episode=1167.0000 return=-115.9997 length=18.0000 global_step=28252.0000 loss=8.5637 policy_loss=-0.0000 value_loss=17.1275 entropy=0.0000
[step=1168] episode=1168.0000 return=-115.9989 length=29.0000 global_step=28281.0000 loss=32.4922 policy_loss=-0.0000 value_loss=64.9844 entropy=0.0000
[step=1169] episode=1169.0000 return=-115.8863 length=19.0000 global_step=28300.0000 loss=34.4173 policy_loss=-0.0000 value_loss=68.8346 entropy=0.0000
[step=1170] episode=1170.0000 return=-115.9921 length=28.0000 global_step=28328.0000 loss=56.9868 policy_loss=-0.0000 value_loss=113.9737 entropy=0.0000
[step=1171] episode=1171.0000 return=-112.7972 length=12.0000 global_step=28340.0000 loss=75.1782 policy_loss=-0.0000 value_loss=150.3564 entropy=0.0000
[step=1172] episode=1172.0000 return=-115.9672 length=29.0000 global_step=28369.0000 loss=7.3700 policy_loss=-0.0000 value_loss=14.7400 entropy=0.0000
[step=1173] episode=1173.0000 return=-115.8080 length=14.0000 global_step=28383.0000 loss=31.9528 policy_loss=-0.0000 value_loss=63.9056 entropy=0.0000
[step=1174] episode=1174.0000 return=-115.9850 length=22.0000 global_step=28405.0000 loss=6.0587 policy_loss=-0.0000 value_loss=12.1174 entropy=0.0000
[step=1175] episode=1175.0000 return=-115.7972 length=13.0000 global_step=28418.0000 loss=9.4294 policy_loss=-0.0000 value_loss=18.8589 entropy=0.0000
[step=1176] episode=1176.0000 return=-115.9941 length=21.0000 global_step=28439.0000 loss=53.3698 policy_loss=-0.0000 value_loss=106.7397 entropy=0.0000
[step=1177] episode=1177.0000 return=-115.9939 length=29.0000 global_step=28468.0000 loss=143.7660 policy_loss=-0.0000 value_loss=287.5319 entropy=0.0000
[step=1178] episode=1178.0000 return=-115.9096 length=26.0000 global_step=28494.0000 loss=24.2195 policy_loss=-0.0000 value_loss=48.4390 entropy=0.0000
[step=1179] episode=1179.0000 return=-115.7328 length=11.0000 global_step=28505.0000 loss=44.8762 policy_loss=-0.0000 value_loss=89.7525 entropy=0.0000
[step=1180] episode=1180.0000 return=-116.0000 length=27.0000 global_step=28532.0000 loss=15.6305 policy_loss=-0.0000 value_loss=31.2610 entropy=0.0000
[step=1181] episode=1181.0000 return=-115.9916 length=20.0000 global_step=28552.0000 loss=78.6543 policy_loss=-0.0000 value_loss=157.3086 entropy=0.0000
[step=1182] episode=1182.0000 return=-115.9764 length=20.0000 global_step=28572.0000 loss=24.1367 policy_loss=-0.0000 value_loss=48.2734 entropy=0.0000
[step=1183] episode=1183.0000 return=-115.9894 length=21.0000 global_step=28593.0000 loss=7.7517 policy_loss=-0.0000 value_loss=15.5034 entropy=0.0000
[step=1184] episode=1184.0000 return=-115.9993 length=29.0000 global_step=28622.0000 loss=61.6534 policy_loss=-0.0000 value_loss=123.3068 entropy=0.0000
[step=1185] episode=1185.0000 return=-115.9971 length=30.0000 global_step=28652.0000 loss=64.0196 policy_loss=-0.0000 value_loss=128.0393 entropy=0.0000
[step=1186] episode=1186.0000 return=-115.9885 length=21.0000 global_step=28673.0000 loss=9.9553 policy_loss=-0.0000 value_loss=19.9105 entropy=0.0000
[step=1187] episode=1187.0000 return=-115.9954 length=28.0000 global_step=28701.0000 loss=16.2503 policy_loss=-0.0000 value_loss=32.5006 entropy=0.0000
a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1188/3000 [32:27<42:46,  1.42s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1189/3000 [32:29<42:41,  1.41s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1190/3000 [32:30<41:42,  1.38s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1191/3000 [32:31<41:25,  1.37s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1192/3000 [32:32<35:52,  1.19s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1193/3000 [32:34<42:58,  1.43s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1194/3000 [32:36<46:46,  1.55s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1195/3000 [32:38<48:33,  1.61s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1196/3000 [32:38<41:32,  1.38s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1197/3000 [32:39<36:26,  1.21s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1198/3000 [32:41<36:38,  1.22s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñâ      | 1199/3000 [32:41<33:38,  1.12s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1200/3000 [32:42<31:31,  1.05s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1201/3000 [32:45<47:06,  1.57s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1202/3000 [32:47<45:57,  1.53s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1203/3000 [32:48<45:13,  1.51s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1204/3000 [32:49<43:06,  1.44s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1205/3000 [32:51<46:36,  1.56s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1206/3000 [32:52<39:20,  1.32s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1207/3000 [32:55<55:23,  1.85s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1208/3000 [32:57<55:31,  1.86s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1209/3000 [32:59<1:01:05,  2.05s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1210/3000 [33:00<50:06,  1.68s/it]  a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1211/3000 [33:03<57:40,  1.93s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1212/3000 [33:05<57:35,  1.93s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1213/3000 [33:06<53:29,  1.80s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1214/3000 [33:07<45:27,  1.53s/it]a2c_tuned train:  40%|‚ñà‚ñà‚ñà‚ñà      | 1215/3000 [33:08<43:27,  1.46s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1216/3000 [33:10<41:47,  1.41s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1217/3000 [33:10<37:38,  1.27s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1218/3000 [33:12<38:22,  1.29s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1219/3000 [33:14<42:52,  1.44s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1220/3000 [33:16<47:28,  1.60s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1221/3000 [33:18<50:53,  1.72s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1222/3000 [33:18<42:16,  1.43s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1223/3000 [33:20<46:11,  1.56s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1224/3000 [33:22<49:24,  1.67s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1225/3000 [33:24<52:42,  1.78s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1226/3000 [33:26<53:11,  1.80s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1227/3000 [33:27<49:36,  1.68s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1228/3000 [33:29<46:40,  1.58s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1229/3000 [33:30<39:52,  1.35s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1230/3000 [33:32<46:11,  1.57s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1231/3000 [33:33<44:27,  1.51s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1232/3000 [33:34<43:42,  1.48s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1233/3000 [33:36<42:42,  1.45s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1234/3000 [33:38<51:27,  1.75s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1235/3000 [33:39<43:10,  1.47s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1236/3000 [33:40<42:08,  1.43s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà      | 1237/3000 [33:41<36:19,  1.24s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1238/3000 [33:43<37:03,  1.26s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1239/3000 [33:45<47:46,  1.63s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1240/3000 [33:46<45:44,  1.56s/it][step=1188] episode=1188.0000 return=-115.9986 length=11.0000 global_step=28712.0000 loss=145.1602 policy_loss=-0.0000 value_loss=290.3205 entropy=0.0000
[step=1189] episode=1189.0000 return=-115.8788 length=21.0000 global_step=28733.0000 loss=73.7045 policy_loss=-0.0000 value_loss=147.4090 entropy=0.0000
[step=1190] episode=1190.0000 return=-115.9707 length=19.0000 global_step=28752.0000 loss=17.2278 policy_loss=-0.0000 value_loss=34.4557 entropy=0.0000
[step=1191] episode=1191.0000 return=-115.9984 length=20.0000 global_step=28772.0000 loss=16.4935 policy_loss=-0.0000 value_loss=32.9871 entropy=0.0000
[step=1192] episode=1192.0000 return=-115.9926 length=12.0000 global_step=28784.0000 loss=12.4697 policy_loss=-0.0000 value_loss=24.9393 entropy=0.0000
[step=1193] episode=1193.0000 return=-115.9890 length=29.0000 global_step=28813.0000 loss=131.5568 policy_loss=-0.0000 value_loss=263.1136 entropy=0.0000
[step=1194] episode=1194.0000 return=-115.9915 length=28.0000 global_step=28841.0000 loss=67.0547 policy_loss=-0.0000 value_loss=134.1094 entropy=0.0000
[step=1195] episode=1195.0000 return=-115.9932 length=26.0000 global_step=28867.0000 loss=12.6235 policy_loss=-0.0000 value_loss=25.2471 entropy=0.0000
[step=1196] episode=1196.0000 return=-115.9996 length=12.0000 global_step=28879.0000 loss=142.3248 policy_loss=-0.0000 value_loss=284.6497 entropy=0.0000
[step=1197] episode=1197.0000 return=-115.6729 length=12.0000 global_step=28891.0000 loss=130.5927 policy_loss=-0.0000 value_loss=261.1853 entropy=0.0000
[step=1198] episode=1198.0000 return=-115.9970 length=18.0000 global_step=28909.0000 loss=18.6169 policy_loss=-0.0000 value_loss=37.2339 entropy=0.0000
[step=1199] episode=1199.0000 return=-115.8003 length=13.0000 global_step=28922.0000 loss=9.0996 policy_loss=-0.0000 value_loss=18.1992 entropy=0.0000
[step=1200] episode=1200.0000 return=-115.9966 length=12.0000 global_step=28934.0000 loss=33.7851 policy_loss=-0.0000 value_loss=67.5703 entropy=0.0000
[step=1201] episode=1201.0000 return=-115.9357 length=42.0000 global_step=28976.0000 loss=429.5341 policy_loss=-0.0000 value_loss=859.0682 entropy=0.0000
[step=1202] episode=1202.0000 return=-115.9988 length=21.0000 global_step=28997.0000 loss=82.4696 policy_loss=-0.0000 value_loss=164.9392 entropy=0.0000
[step=1203] episode=1203.0000 return=-115.9999 length=20.0000 global_step=29017.0000 loss=10.2225 policy_loss=-0.0000 value_loss=20.4450 entropy=0.0000
[step=1204] episode=1204.0000 return=-115.8870 length=19.0000 global_step=29036.0000 loss=65.5446 policy_loss=-0.0000 value_loss=131.0892 entropy=0.0000
[step=1205] episode=1205.0000 return=-115.9785 length=26.0000 global_step=29062.0000 loss=104.3828 policy_loss=-0.0000 value_loss=208.7657 entropy=0.0000
[step=1206] episode=1206.0000 return=-115.9692 length=12.0000 global_step=29074.0000 loss=250.4578 policy_loss=-0.0000 value_loss=500.9156 entropy=0.0000
[step=1207] episode=1207.0000 return=-115.9895 length=45.0000 global_step=29119.0000 loss=47.7217 policy_loss=-0.0000 value_loss=95.4434 entropy=0.0000
[step=1208] episode=1208.0000 return=-115.9973 length=28.0000 global_step=29147.0000 loss=13.6972 policy_loss=-0.0000 value_loss=27.3944 entropy=0.0000
[step=1209] episode=1209.0000 return=-115.9995 length=38.0000 global_step=29185.0000 loss=31.1962 policy_loss=-0.0000 value_loss=62.3924 entropy=0.0000
[step=1210] episode=1210.0000 return=-115.9826 length=12.0000 global_step=29197.0000 loss=28.2610 policy_loss=-0.0000 value_loss=56.5219 entropy=0.0000
[step=1211] episode=1211.0000 return=-115.9974 length=38.0000 global_step=29235.0000 loss=84.2926 policy_loss=-0.0000 value_loss=168.5853 entropy=0.0000
[step=1212] episode=1212.0000 return=-115.9964 length=28.0000 global_step=29263.0000 loss=10.2739 policy_loss=-0.0000 value_loss=20.5477 entropy=0.0000
[step=1213] episode=1213.0000 return=-115.9978 length=21.0000 global_step=29284.0000 loss=15.1714 policy_loss=-0.0000 value_loss=30.3428 entropy=0.0000
[step=1214] episode=1214.0000 return=-115.8559 length=13.0000 global_step=29297.0000 loss=48.2169 policy_loss=-0.0000 value_loss=96.4339 entropy=0.0000
[step=1215] episode=1215.0000 return=-115.9995 length=19.0000 global_step=29316.0000 loss=9.6438 policy_loss=-0.0000 value_loss=19.2876 entropy=0.0000
[step=1216] episode=1216.0000 return=-115.9987 length=19.0000 global_step=29335.0000 loss=7.3491 policy_loss=-0.0000 value_loss=14.6982 entropy=0.0000
[step=1217] episode=1217.0000 return=-115.8156 length=14.0000 global_step=29349.0000 loss=7.0024 policy_loss=-0.0000 value_loss=14.0048 entropy=0.0000
[step=1218] episode=1218.0000 return=-115.9930 length=19.0000 global_step=29368.0000 loss=27.6399 policy_loss=-0.0000 value_loss=55.2798 entropy=0.0000
[step=1219] episode=1219.0000 return=-115.9985 length=26.0000 global_step=29394.0000 loss=36.2955 policy_loss=-0.0000 value_loss=72.5910 entropy=0.0000
[step=1220] episode=1220.0000 return=-115.9904 length=29.0000 global_step=29423.0000 loss=59.2259 policy_loss=-0.0000 value_loss=118.4519 entropy=0.0000
[step=1221] episode=1221.0000 return=-115.9992 length=28.0000 global_step=29451.0000 loss=5.5331 policy_loss=-0.0000 value_loss=11.0661 entropy=0.0000
[step=1222] episode=1222.0000 return=-115.9722 length=11.0000 global_step=29462.0000 loss=86.6233 policy_loss=-0.0000 value_loss=173.2467 entropy=0.0000
[step=1223] episode=1223.0000 return=-115.9781 length=29.0000 global_step=29491.0000 loss=12.3664 policy_loss=-0.0000 value_loss=24.7328 entropy=0.0000
[step=1224] episode=1224.0000 return=-115.9679 length=28.0000 global_step=29519.0000 loss=10.1331 policy_loss=-0.0000 value_loss=20.2662 entropy=0.0000
[step=1225] episode=1225.0000 return=-115.8869 length=29.0000 global_step=29548.0000 loss=26.9739 policy_loss=-0.0000 value_loss=53.9478 entropy=0.0000
[step=1226] episode=1226.0000 return=-115.9998 length=28.0000 global_step=29576.0000 loss=33.5680 policy_loss=-0.0000 value_loss=67.1359 entropy=0.0000
[step=1227] episode=1227.0000 return=-115.8808 length=20.0000 global_step=29596.0000 loss=10.9709 policy_loss=-0.0000 value_loss=21.9417 entropy=0.0000
[step=1228] episode=1228.0000 return=-115.9989 length=20.0000 global_step=29616.0000 loss=8.6600 policy_loss=-0.0000 value_loss=17.3199 entropy=0.0000
[step=1229] episode=1229.0000 return=-115.8765 length=13.0000 global_step=29629.0000 loss=26.4782 policy_loss=-0.0000 value_loss=52.9563 entropy=0.0000
[step=1230] episode=1230.0000 return=-113.1842 length=30.0000 global_step=29659.0000 loss=50.6502 policy_loss=-0.0000 value_loss=101.3004 entropy=0.0000
[step=1231] episode=1231.0000 return=-115.9961 length=21.0000 global_step=29680.0000 loss=5.6497 policy_loss=-0.0000 value_loss=11.2993 entropy=0.0000
[step=1232] episode=1232.0000 return=-115.8251 length=21.0000 global_step=29701.0000 loss=12.7016 policy_loss=-0.0000 value_loss=25.4032 entropy=0.0000
[step=1233] episode=1233.0000 return=-115.8865 length=20.0000 global_step=29721.0000 loss=5.2276 policy_loss=-0.0000 value_loss=10.4551 entropy=0.0000
[step=1234] episode=1234.0000 return=-115.9986 length=38.0000 global_step=29759.0000 loss=79.8396 policy_loss=-0.0000 value_loss=159.6792 entropy=0.0000
[step=1235] episode=1235.0000 return=-115.9980 length=11.0000 global_step=29770.0000 loss=31.6205 policy_loss=-0.0000 value_loss=63.2410 entropy=0.0000
[step=1236] episode=1236.0000 return=-115.9973 length=20.0000 global_step=29790.0000 loss=8.5691 policy_loss=-0.0000 value_loss=17.1383 entropy=0.0000
[step=1237] episode=1237.0000 return=-115.8198 length=11.0000 global_step=29801.0000 loss=22.7477 policy_loss=-0.0000 value_loss=45.4953 entropy=0.0000
[step=1238] episode=1238.0000 return=-115.9878 length=20.0000 global_step=29821.0000 loss=18.1518 policy_loss=-0.0000 value_loss=36.3036 entropy=0.0000
[step=1239] episode=1239.0000 return=-115.9983 length=36.0000 global_step=29857.0000 loss=105.8928 policy_loss=-0.0000 value_loss=211.7856 entropy=0.0000
[step=1240] episode=1240.0000 return=-115.9837 length=21.0000 global_step=29878.0000 loss=6.0665 policy_loss=-0.0000 value_loss=12.1330 entropy=0.0000
a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1241/3000 [33:49<54:27,  1.86s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1242/3000 [33:50<50:20,  1.72s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1243/3000 [33:53<56:37,  1.93s/it]a2c_tuned train:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1244/3000 [33:54<51:06,  1.75s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1245/3000 [33:55<48:05,  1.64s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1246/3000 [33:57<50:20,  1.72s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1247/3000 [33:59<48:00,  1.64s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1248/3000 [34:01<50:59,  1.75s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1249/3000 [34:02<48:22,  1.66s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1250/3000 [34:05<56:18,  1.93s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1251/3000 [34:07<55:57,  1.92s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1252/3000 [34:09<55:20,  1.90s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1253/3000 [34:10<49:52,  1.71s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1254/3000 [34:11<46:08,  1.59s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1255/3000 [34:12<43:02,  1.48s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1256/3000 [34:14<47:05,  1.62s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1257/3000 [34:16<49:07,  1.69s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1258/3000 [34:18<47:13,  1.63s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1259/3000 [34:21<57:34,  1.98s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1260/3000 [34:22<56:51,  1.96s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1261/3000 [34:25<1:02:07,  2.14s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1262/3000 [34:27<58:38,  2.02s/it]  a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1263/3000 [34:28<53:15,  1.84s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1264/3000 [34:30<49:09,  1.70s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1265/3000 [34:32<51:53,  1.79s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1266/3000 [34:32<43:37,  1.51s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1267/3000 [34:36<1:00:33,  2.10s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1268/3000 [34:37<53:47,  1.86s/it]  a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1269/3000 [34:39<50:06,  1.74s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1270/3000 [34:42<1:00:21,  2.09s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1271/3000 [34:44<1:06:48,  2.32s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1272/3000 [34:45<54:30,  1.89s/it]  a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1273/3000 [34:46<45:56,  1.60s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1274/3000 [34:47<43:24,  1.51s/it]a2c_tuned train:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1275/3000 [34:48<37:50,  1.32s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1276/3000 [34:50<42:11,  1.47s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1277/3000 [34:52<45:35,  1.59s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1278/3000 [34:54<47:45,  1.66s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1279/3000 [34:56<55:12,  1.92s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1280/3000 [34:58<54:43,  1.91s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1281/3000 [35:00<55:04,  1.92s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1282/3000 [35:02<49:53,  1.74s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1283/3000 [35:03<45:53,  1.60s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1284/3000 [35:05<48:09,  1.68s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1285/3000 [35:07<50:29,  1.77s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1286/3000 [35:09<56:51,  1.99s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1287/3000 [35:11<55:29,  1.94s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1288/3000 [35:12<46:28,  1.63s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1289/3000 [35:14<49:11,  1.73s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1290/3000 [35:15<41:25,  1.45s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1291/3000 [35:16<43:40,  1.53s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1292/3000 [35:19<53:31,  1.88s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1293/3000 [35:21<49:46,  1.75s/it][step=1241] episode=1241.0000 return=-115.9966 length=38.0000 global_step=29916.0000 loss=37.1657 policy_loss=-0.0000 value_loss=74.3314 entropy=0.0000
[step=1242] episode=1242.0000 return=-115.8644 length=21.0000 global_step=29937.0000 loss=81.8846 policy_loss=-0.0000 value_loss=163.7691 entropy=0.0000
[step=1243] episode=1243.0000 return=-115.9991 length=36.0000 global_step=29973.0000 loss=44.2488 policy_loss=-0.0000 value_loss=88.4975 entropy=0.0000
[step=1244] episode=1244.0000 return=-115.9608 length=20.0000 global_step=29993.0000 loss=71.4756 policy_loss=-0.0000 value_loss=142.9512 entropy=0.0000
[step=1245] episode=1245.0000 return=-115.9998 length=21.0000 global_step=30014.0000 loss=19.6171 policy_loss=-0.0000 value_loss=39.2341 entropy=0.0000
[step=1246] episode=1246.0000 return=-115.9978 length=27.0000 global_step=30041.0000 loss=11.6165 policy_loss=-0.0000 value_loss=23.2331 entropy=0.0000
[step=1247] episode=1247.0000 return=-115.7737 length=21.0000 global_step=30062.0000 loss=35.1640 policy_loss=-0.0000 value_loss=70.3280 entropy=0.0000
[step=1248] episode=1248.0000 return=-115.9928 length=30.0000 global_step=30092.0000 loss=140.8997 policy_loss=-0.0000 value_loss=281.7994 entropy=0.0000
[step=1249] episode=1249.0000 return=-115.9912 length=21.0000 global_step=30113.0000 loss=9.0904 policy_loss=-0.0000 value_loss=18.1809 entropy=0.0000
[step=1250] episode=1250.0000 return=-115.9962 length=37.0000 global_step=30150.0000 loss=13.6288 policy_loss=-0.0000 value_loss=27.2576 entropy=0.0000
[step=1251] episode=1251.0000 return=-115.9975 length=28.0000 global_step=30178.0000 loss=27.3715 policy_loss=-0.0000 value_loss=54.7430 entropy=0.0000
[step=1252] episode=1252.0000 return=-115.9890 length=28.0000 global_step=30206.0000 loss=50.8693 policy_loss=-0.0000 value_loss=101.7385 entropy=0.0000
[step=1253] episode=1253.0000 return=-115.9962 length=19.0000 global_step=30225.0000 loss=114.8910 policy_loss=-0.0000 value_loss=229.7819 entropy=0.0000
[step=1254] episode=1254.0000 return=-115.9840 length=19.0000 global_step=30244.0000 loss=62.5253 policy_loss=-0.0000 value_loss=125.0505 entropy=0.0000
[step=1255] episode=1255.0000 return=-115.9732 length=18.0000 global_step=30262.0000 loss=6.2276 policy_loss=-0.0000 value_loss=12.4553 entropy=0.0000
[step=1256] episode=1256.0000 return=-115.9361 length=29.0000 global_step=30291.0000 loss=119.8365 policy_loss=-0.0000 value_loss=239.6730 entropy=0.0000
[step=1257] episode=1257.0000 return=-115.9955 length=28.0000 global_step=30319.0000 loss=143.0420 policy_loss=-0.0000 value_loss=286.0839 entropy=0.0000
[step=1258] episode=1258.0000 return=-115.9997 length=22.0000 global_step=30341.0000 loss=55.1346 policy_loss=-0.0000 value_loss=110.2692 entropy=0.0000
[step=1259] episode=1259.0000 return=-115.9943 length=42.0000 global_step=30383.0000 loss=107.2073 policy_loss=-0.0000 value_loss=214.4146 entropy=0.0000
[step=1260] episode=1260.0000 return=-115.9941 length=29.0000 global_step=30412.0000 loss=26.0582 policy_loss=-0.0000 value_loss=52.1164 entropy=0.0000
[step=1261] episode=1261.0000 return=-116.0000 length=38.0000 global_step=30450.0000 loss=58.2408 policy_loss=-0.0000 value_loss=116.4816 entropy=0.0000
[step=1262] episode=1262.0000 return=-115.9960 length=26.0000 global_step=30476.0000 loss=151.6488 policy_loss=-0.0000 value_loss=303.2977 entropy=0.0000
[step=1263] episode=1263.0000 return=-115.8197 length=21.0000 global_step=30497.0000 loss=241.8445 policy_loss=-0.0000 value_loss=483.6890 entropy=0.0000
[step=1264] episode=1264.0000 return=-115.8367 length=20.0000 global_step=30517.0000 loss=41.0585 policy_loss=-0.0000 value_loss=82.1170 entropy=0.0000
[step=1265] episode=1265.0000 return=-115.9995 length=29.0000 global_step=30546.0000 loss=76.5486 policy_loss=-0.0000 value_loss=153.0972 entropy=0.0000
[step=1266] episode=1266.0000 return=-115.9384 length=12.0000 global_step=30558.0000 loss=24.4962 policy_loss=-0.0000 value_loss=48.9924 entropy=0.0000
[step=1267] episode=1267.0000 return=-115.9999 length=53.0000 global_step=30611.0000 loss=509.1432 policy_loss=-0.0000 value_loss=1018.2864 entropy=0.0000
[step=1268] episode=1268.0000 return=-115.9990 length=19.0000 global_step=30630.0000 loss=51.8312 policy_loss=-0.0000 value_loss=103.6623 entropy=0.0000
[step=1269] episode=1269.0000 return=-115.9834 length=20.0000 global_step=30650.0000 loss=29.2742 policy_loss=-0.0000 value_loss=58.5485 entropy=0.0000
[step=1270] episode=1270.0000 return=-115.9964 length=44.0000 global_step=30694.0000 loss=44.3410 policy_loss=-0.0000 value_loss=88.6820 entropy=0.0000
[step=1271] episode=1271.0000 return=-115.9977 length=44.0000 global_step=30738.0000 loss=55.8726 policy_loss=-0.0000 value_loss=111.7451 entropy=0.0000
[step=1272] episode=1272.0000 return=-115.7447 length=12.0000 global_step=30750.0000 loss=379.2047 policy_loss=-0.0000 value_loss=758.4094 entropy=0.0000
[step=1273] episode=1273.0000 return=-115.8033 length=13.0000 global_step=30763.0000 loss=232.3342 policy_loss=-0.0000 value_loss=464.6685 entropy=0.0000
[step=1274] episode=1274.0000 return=-115.9949 length=20.0000 global_step=30783.0000 loss=17.9532 policy_loss=-0.0000 value_loss=35.9065 entropy=0.0000
[step=1275] episode=1275.0000 return=-115.9941 length=13.0000 global_step=30796.0000 loss=9.1688 policy_loss=-0.0000 value_loss=18.3377 entropy=0.0000
[step=1276] episode=1276.0000 return=-115.9968 length=27.0000 global_step=30823.0000 loss=242.9745 policy_loss=-0.0000 value_loss=485.9491 entropy=0.0000
[step=1277] episode=1277.0000 return=-115.9644 length=28.0000 global_step=30851.0000 loss=310.5808 policy_loss=-0.0000 value_loss=621.1616 entropy=0.0000
[step=1278] episode=1278.0000 return=-115.9972 length=28.0000 global_step=30879.0000 loss=140.7930 policy_loss=-0.0000 value_loss=281.5861 entropy=0.0000
[step=1279] episode=1279.0000 return=-115.9756 length=38.0000 global_step=30917.0000 loss=34.7847 policy_loss=-0.0000 value_loss=69.5694 entropy=0.0000
[step=1280] episode=1280.0000 return=-115.8870 length=29.0000 global_step=30946.0000 loss=79.6451 policy_loss=-0.0000 value_loss=159.2903 entropy=0.0000
[step=1281] episode=1281.0000 return=-115.9787 length=29.0000 global_step=30975.0000 loss=234.2041 policy_loss=-0.0000 value_loss=468.4081 entropy=0.0000
[step=1282] episode=1282.0000 return=-115.9808 length=20.0000 global_step=30995.0000 loss=322.6723 policy_loss=-0.0000 value_loss=645.3446 entropy=0.0000
[step=1283] episode=1283.0000 return=-115.9999 length=18.0000 global_step=31013.0000 loss=196.6131 policy_loss=-0.0000 value_loss=393.2263 entropy=0.0000
[step=1284] episode=1284.0000 return=-115.9840 length=28.0000 global_step=31041.0000 loss=23.1924 policy_loss=-0.0000 value_loss=46.3849 entropy=0.0001
[step=1285] episode=1285.0000 return=-115.9990 length=28.0000 global_step=31069.0000 loss=105.5649 policy_loss=0.0001 value_loss=211.1297 entropy=0.0001
[step=1286] episode=1286.0000 return=-115.9369 length=37.0000 global_step=31106.0000 loss=252.3580 policy_loss=0.0002 value_loss=504.7157 entropy=0.0001
[step=1287] episode=1287.0000 return=-115.9960 length=28.0000 global_step=31134.0000 loss=192.3450 policy_loss=0.0001 value_loss=384.6900 entropy=0.0001
[step=1288] episode=1288.0000 return=-115.9804 length=12.0000 global_step=31146.0000 loss=8.2335 policy_loss=0.0000 value_loss=16.4671 entropy=0.0000
[step=1289] episode=1289.0000 return=-115.9714 length=29.0000 global_step=31175.0000 loss=4.6692 policy_loss=0.0000 value_loss=9.3385 entropy=0.0000
[step=1290] episode=1290.0000 return=-115.7972 length=12.0000 global_step=31187.0000 loss=94.4245 policy_loss=-0.0000 value_loss=188.8490 entropy=0.0000
[step=1291] episode=1291.0000 return=-115.7980 length=26.0000 global_step=31213.0000 loss=56.7908 policy_loss=-0.0000 value_loss=113.5816 entropy=0.0000
[step=1292] episode=1292.0000 return=-115.9765 length=40.0000 global_step=31253.0000 loss=22.2188 policy_loss=-0.0000 value_loss=44.4377 entropy=0.0000
[step=1293] episode=1293.0000 return=-115.9837 length=21.0000 global_step=31274.0000 loss=36.9157 policy_loss=-0.0000 value_loss=73.8314 entropy=0.0000
a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1294/3000 [35:23<52:08,  1.83s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1295/3000 [35:24<51:17,  1.81s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1296/3000 [35:26<53:08,  1.87s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1297/3000 [35:27<44:39,  1.57s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1298/3000 [35:30<57:07,  2.01s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1299/3000 [35:32<52:13,  1.84s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1300/3000 [35:33<44:14,  1.56s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1301/3000 [35:34<42:48,  1.51s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1302/3000 [35:35<41:57,  1.48s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1303/3000 [35:37<41:03,  1.45s/it]a2c_tuned train:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1304/3000 [35:38<39:54,  1.41s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1305/3000 [35:39<35:30,  1.26s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1306/3000 [35:40<32:33,  1.15s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1307/3000 [35:42<43:35,  1.54s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1308/3000 [35:44<46:36,  1.65s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1309/3000 [35:46<48:51,  1.73s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1310/3000 [35:49<59:49,  2.12s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1311/3000 [35:51<57:05,  2.03s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1312/3000 [35:53<55:27,  1.97s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1313/3000 [35:54<50:02,  1.78s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1314/3000 [35:57<58:31,  2.08s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1315/3000 [35:58<53:00,  1.89s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1316/3000 [36:00<53:21,  1.90s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1317/3000 [36:03<58:20,  2.08s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1318/3000 [36:05<56:14,  2.01s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1319/3000 [36:07<1:00:11,  2.15s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1320/3000 [36:10<1:02:52,  2.25s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1321/3000 [36:11<56:35,  2.02s/it]  a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1322/3000 [36:13<55:03,  1.97s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1323/3000 [36:15<59:20,  2.12s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1324/3000 [36:17<53:08,  1.90s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1325/3000 [36:18<48:17,  1.73s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1326/3000 [36:20<45:58,  1.65s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1327/3000 [36:22<51:29,  1.85s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1328/3000 [36:24<55:54,  2.01s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1329/3000 [36:26<50:37,  1.82s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1330/3000 [36:28<50:51,  1.83s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1331/3000 [36:28<42:20,  1.52s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1332/3000 [36:30<46:53,  1.69s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1333/3000 [36:32<44:41,  1.61s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1334/3000 [36:34<52:39,  1.90s/it]a2c_tuned train:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1335/3000 [36:36<53:19,  1.92s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1336/3000 [36:38<49:43,  1.79s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1337/3000 [36:40<50:23,  1.82s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1338/3000 [36:42<51:30,  1.86s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1339/3000 [36:44<56:22,  2.04s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1340/3000 [36:47<1:00:27,  2.19s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1341/3000 [36:48<53:22,  1.93s/it]  a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1342/3000 [36:51<1:01:39,  2.23s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1343/3000 [36:52<55:10,  2.00s/it]  a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1344/3000 [36:54<50:04,  1.81s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1345/3000 [36:55<45:44,  1.66s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1346/3000 [36:57<48:54,  1.77s/it][step=1294] episode=1294.0000 return=-115.9997 length=30.0000 global_step=31304.0000 loss=7.1062 policy_loss=-0.0000 value_loss=14.2125 entropy=0.0000
[step=1295] episode=1295.0000 return=-115.9997 length=26.0000 global_step=31330.0000 loss=19.6957 policy_loss=-0.0000 value_loss=39.3914 entropy=0.0000
[step=1296] episode=1296.0000 return=-115.9960 length=30.0000 global_step=31360.0000 loss=23.9237 policy_loss=-0.0000 value_loss=47.8473 entropy=0.0000
[step=1297] episode=1297.0000 return=-115.8160 length=13.0000 global_step=31373.0000 loss=21.2721 policy_loss=-0.0000 value_loss=42.5441 entropy=0.0000
[step=1298] episode=1298.0000 return=-115.9939 length=46.0000 global_step=31419.0000 loss=120.0276 policy_loss=-0.0000 value_loss=240.0551 entropy=0.0000
[step=1299] episode=1299.0000 return=-115.8417 length=21.0000 global_step=31440.0000 loss=12.5443 policy_loss=-0.0000 value_loss=25.0886 entropy=0.0000
[step=1300] episode=1300.0000 return=-115.7165 length=13.0000 global_step=31453.0000 loss=45.9352 policy_loss=-0.0000 value_loss=91.8703 entropy=0.0000
[step=1301] episode=1301.0000 return=-115.9998 length=21.0000 global_step=31474.0000 loss=7.4067 policy_loss=-0.0000 value_loss=14.8135 entropy=0.0000
[step=1302] episode=1302.0000 return=-115.9358 length=21.0000 global_step=31495.0000 loss=1.0569 policy_loss=-0.0000 value_loss=2.1138 entropy=0.0000
[step=1303] episode=1303.0000 return=-115.9886 length=20.0000 global_step=31515.0000 loss=20.1836 policy_loss=-0.0000 value_loss=40.3672 entropy=0.0000
[step=1304] episode=1304.0000 return=-115.9915 length=20.0000 global_step=31535.0000 loss=50.2304 policy_loss=-0.0000 value_loss=100.4608 entropy=0.0000
[step=1305] episode=1305.0000 return=-115.8393 length=12.0000 global_step=31547.0000 loss=6.6189 policy_loss=-0.0000 value_loss=13.2378 entropy=0.0000
[step=1306] episode=1306.0000 return=-115.8358 length=13.0000 global_step=31560.0000 loss=11.9356 policy_loss=-0.0000 value_loss=23.8711 entropy=0.0000
[step=1307] episode=1307.0000 return=-115.9924 length=36.0000 global_step=31596.0000 loss=65.2463 policy_loss=-0.0000 value_loss=130.4926 entropy=0.0000
[step=1308] episode=1308.0000 return=-115.9895 length=28.0000 global_step=31624.0000 loss=14.3878 policy_loss=-0.0000 value_loss=28.7755 entropy=0.0000
[step=1309] episode=1309.0000 return=-115.9957 length=29.0000 global_step=31653.0000 loss=34.5312 policy_loss=-0.0000 value_loss=69.0625 entropy=0.0000
[step=1310] episode=1310.0000 return=-115.9767 length=46.0000 global_step=31699.0000 loss=40.5934 policy_loss=-0.0000 value_loss=81.1867 entropy=0.0000
[step=1311] episode=1311.0000 return=-115.9971 length=28.0000 global_step=31727.0000 loss=54.5009 policy_loss=-0.0000 value_loss=109.0017 entropy=0.0000
[step=1312] episode=1312.0000 return=-115.9872 length=29.0000 global_step=31756.0000 loss=15.6728 policy_loss=-0.0000 value_loss=31.3456 entropy=0.0000
[step=1313] episode=1313.0000 return=-115.9380 length=20.0000 global_step=31776.0000 loss=9.1326 policy_loss=-0.0000 value_loss=18.2652 entropy=0.0000
[step=1314] episode=1314.0000 return=-115.9999 length=43.0000 global_step=31819.0000 loss=164.5587 policy_loss=-0.0000 value_loss=329.1174 entropy=0.0000
[step=1315] episode=1315.0000 return=-115.9379 length=21.0000 global_step=31840.0000 loss=22.2053 policy_loss=-0.0000 value_loss=44.4105 entropy=0.0000
[step=1316] episode=1316.0000 return=-115.9994 length=29.0000 global_step=31869.0000 loss=41.8423 policy_loss=-0.0000 value_loss=83.6847 entropy=0.0000
[step=1317] episode=1317.0000 return=-115.9837 length=38.0000 global_step=31907.0000 loss=33.1540 policy_loss=-0.0000 value_loss=66.3080 entropy=0.0000
[step=1318] episode=1318.0000 return=-115.9939 length=26.0000 global_step=31933.0000 loss=72.2112 policy_loss=-0.0000 value_loss=144.4224 entropy=0.0000
[step=1319] episode=1319.0000 return=-115.9993 length=37.0000 global_step=31970.0000 loss=48.6703 policy_loss=-0.0000 value_loss=97.3406 entropy=0.0000
[step=1320] episode=1320.0000 return=-115.9840 length=38.0000 global_step=32008.0000 loss=41.7234 policy_loss=-0.0000 value_loss=83.4468 entropy=0.0000
[step=1321] episode=1321.0000 return=-115.8777 length=22.0000 global_step=32030.0000 loss=59.8334 policy_loss=-0.0000 value_loss=119.6667 entropy=0.0000
[step=1322] episode=1322.0000 return=-115.9840 length=28.0000 global_step=32058.0000 loss=8.6500 policy_loss=-0.0000 value_loss=17.2999 entropy=0.0000
[step=1323] episode=1323.0000 return=-115.9991 length=37.0000 global_step=32095.0000 loss=95.6874 policy_loss=-0.0000 value_loss=191.3748 entropy=0.0000
[step=1324] episode=1324.0000 return=-115.9998 length=20.0000 global_step=32115.0000 loss=56.0907 policy_loss=-0.0000 value_loss=112.1814 entropy=0.0000
[step=1325] episode=1325.0000 return=-115.8869 length=19.0000 global_step=32134.0000 loss=30.2753 policy_loss=-0.0000 value_loss=60.5505 entropy=0.0000
[step=1326] episode=1326.0000 return=-115.9653 length=21.0000 global_step=32155.0000 loss=9.1600 policy_loss=-0.0000 value_loss=18.3199 entropy=0.0000
[step=1327] episode=1327.0000 return=-115.9350 length=34.0000 global_step=32189.0000 loss=22.4702 policy_loss=-0.0000 value_loss=44.9404 entropy=0.0000
[step=1328] episode=1328.0000 return=-115.9988 length=36.0000 global_step=32225.0000 loss=43.7516 policy_loss=-0.0000 value_loss=87.5033 entropy=0.0000
[step=1329] episode=1329.0000 return=-115.9072 length=20.0000 global_step=32245.0000 loss=260.9764 policy_loss=-0.0000 value_loss=521.9528 entropy=0.0000
[step=1330] episode=1330.0000 return=-115.9932 length=28.0000 global_step=32273.0000 loss=45.9415 policy_loss=-0.0000 value_loss=91.8830 entropy=0.0000
[step=1331] episode=1331.0000 return=-115.7427 length=12.0000 global_step=32285.0000 loss=57.4775 policy_loss=-0.0000 value_loss=114.9550 entropy=0.0000
[step=1332] episode=1332.0000 return=-113.0580 length=29.0000 global_step=32314.0000 loss=158.6306 policy_loss=-0.0000 value_loss=317.2613 entropy=0.0000
[step=1333] episode=1333.0000 return=-115.8414 length=22.0000 global_step=32336.0000 loss=82.9093 policy_loss=-0.0000 value_loss=165.8186 entropy=0.0000
[step=1334] episode=1334.0000 return=-115.9939 length=38.0000 global_step=32374.0000 loss=242.9798 policy_loss=-0.0000 value_loss=485.9596 entropy=0.0000
[step=1335] episode=1335.0000 return=-115.9978 length=29.0000 global_step=32403.0000 loss=9.6188 policy_loss=-0.0000 value_loss=19.2376 entropy=0.0000
[step=1336] episode=1336.0000 return=-115.9915 length=21.0000 global_step=32424.0000 loss=53.9118 policy_loss=-0.0000 value_loss=107.8237 entropy=0.0000
[step=1337] episode=1337.0000 return=-115.9955 length=28.0000 global_step=32452.0000 loss=79.1752 policy_loss=-0.0000 value_loss=158.3505 entropy=0.0000
[step=1338] episode=1338.0000 return=-115.9995 length=28.0000 global_step=32480.0000 loss=73.9672 policy_loss=-0.0000 value_loss=147.9345 entropy=0.0000
[step=1339] episode=1339.0000 return=-115.9993 length=36.0000 global_step=32516.0000 loss=22.1180 policy_loss=-0.0000 value_loss=44.2361 entropy=0.0000
[step=1340] episode=1340.0000 return=-115.9984 length=38.0000 global_step=32554.0000 loss=13.1359 policy_loss=-0.0000 value_loss=26.2718 entropy=0.0000
[step=1341] episode=1341.0000 return=-115.9933 length=20.0000 global_step=32574.0000 loss=6.6730 policy_loss=-0.0000 value_loss=13.3460 entropy=0.0000
[step=1342] episode=1342.0000 return=-115.9971 length=45.0000 global_step=32619.0000 loss=165.8148 policy_loss=-0.0000 value_loss=331.6296 entropy=0.0000
[step=1343] episode=1343.0000 return=-115.9371 length=21.0000 global_step=32640.0000 loss=7.4208 policy_loss=-0.0000 value_loss=14.8415 entropy=0.0000
[step=1344] episode=1344.0000 return=-115.9376 length=19.0000 global_step=32659.0000 loss=28.6731 policy_loss=-0.0000 value_loss=57.3462 entropy=0.0000
[step=1345] episode=1345.0000 return=-115.9941 length=19.0000 global_step=32678.0000 loss=36.4682 policy_loss=-0.0000 value_loss=72.9364 entropy=0.0000
[step=1346] episode=1346.0000 return=-115.9988 length=30.0000 global_step=32708.0000 loss=15.2603 policy_loss=-0.0000 value_loss=30.5205 entropy=0.0000
a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1347/3000 [36:58<41:03,  1.49s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1348/3000 [36:59<39:15,  1.43s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1349/3000 [37:01<42:42,  1.55s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1350/3000 [37:04<50:38,  1.84s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1351/3000 [37:05<46:49,  1.70s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1352/3000 [37:06<44:15,  1.61s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1353/3000 [37:08<41:26,  1.51s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1354/3000 [37:09<36:50,  1.34s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1355/3000 [37:10<36:22,  1.33s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1356/3000 [37:13<46:51,  1.71s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1357/3000 [37:14<43:03,  1.57s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1358/3000 [37:15<41:42,  1.52s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1359/3000 [37:18<48:52,  1.79s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1360/3000 [37:19<44:02,  1.61s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1361/3000 [37:21<47:11,  1.73s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1362/3000 [37:22<44:10,  1.62s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1363/3000 [37:24<42:03,  1.54s/it]a2c_tuned train:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1364/3000 [37:25<44:59,  1.65s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1365/3000 [37:27<45:57,  1.69s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1366/3000 [37:29<47:42,  1.75s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1367/3000 [37:31<52:36,  1.93s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1368/3000 [37:33<52:48,  1.94s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1369/3000 [37:34<44:17,  1.63s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1370/3000 [37:36<47:32,  1.75s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1371/3000 [37:38<49:23,  1.82s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1372/3000 [37:40<48:47,  1.80s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1373/3000 [37:43<57:39,  2.13s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1374/3000 [37:44<51:05,  1.88s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1375/3000 [37:47<58:49,  2.17s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1376/3000 [37:49<57:01,  2.11s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1377/3000 [37:50<50:39,  1.87s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1378/3000 [37:52<46:41,  1.73s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1379/3000 [37:54<48:29,  1.79s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1380/3000 [37:56<50:38,  1.88s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1381/3000 [37:57<46:36,  1.73s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1382/3000 [38:00<56:00,  2.08s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1383/3000 [38:01<50:18,  1.87s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1384/3000 [38:04<59:16,  2.20s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1385/3000 [38:07<1:03:46,  2.37s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1386/3000 [38:09<55:56,  2.08s/it]  a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1387/3000 [38:10<49:48,  1.85s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1388/3000 [38:11<45:58,  1.71s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1389/3000 [38:13<43:18,  1.61s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1390/3000 [38:15<46:30,  1.73s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1391/3000 [38:16<43:21,  1.62s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1392/3000 [38:18<45:45,  1.71s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1393/3000 [38:19<42:58,  1.60s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1394/3000 [38:21<44:06,  1.65s/it]a2c_tuned train:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1395/3000 [38:24<56:00,  2.09s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1396/3000 [38:26<50:53,  1.90s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1397/3000 [38:28<54:02,  2.02s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1398/3000 [38:29<49:21,  1.85s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1399/3000 [38:30<41:25,  1.55s/it][step=1347] episode=1347.0000 return=-115.8341 length=12.0000 global_step=32720.0000 loss=45.1574 policy_loss=-0.0000 value_loss=90.3149 entropy=0.0000
[step=1348] episode=1348.0000 return=-115.9921 length=19.0000 global_step=32739.0000 loss=5.7429 policy_loss=-0.0000 value_loss=11.4857 entropy=0.0000
[step=1349] episode=1349.0000 return=-114.0009 length=28.0000 global_step=32767.0000 loss=73.4167 policy_loss=-0.0000 value_loss=146.8334 entropy=0.0000
[step=1350] episode=1350.0000 return=-115.9932 length=37.0000 global_step=32804.0000 loss=70.7295 policy_loss=-0.0000 value_loss=141.4590 entropy=0.0000
[step=1351] episode=1351.0000 return=-115.9814 length=20.0000 global_step=32824.0000 loss=14.6955 policy_loss=-0.0000 value_loss=29.3909 entropy=0.0000
[step=1352] episode=1352.0000 return=-115.9999 length=21.0000 global_step=32845.0000 loss=25.7872 policy_loss=-0.0000 value_loss=51.5745 entropy=0.0000
[step=1353] episode=1353.0000 return=-115.9951 length=18.0000 global_step=32863.0000 loss=28.8746 policy_loss=-0.0000 value_loss=57.7493 entropy=0.0000
[step=1354] episode=1354.0000 return=-115.7829 length=13.0000 global_step=32876.0000 loss=41.1240 policy_loss=-0.0000 value_loss=82.2480 entropy=0.0000
[step=1355] episode=1355.0000 return=-115.9096 length=19.0000 global_step=32895.0000 loss=11.3170 policy_loss=-0.0000 value_loss=22.6340 entropy=0.0000
[step=1356] episode=1356.0000 return=-115.9840 length=38.0000 global_step=32933.0000 loss=159.5664 policy_loss=-0.0000 value_loss=319.1327 entropy=0.0000
[step=1357] episode=1357.0000 return=-115.9996 length=19.0000 global_step=32952.0000 loss=21.8690 policy_loss=-0.0000 value_loss=43.7380 entropy=0.0000
[step=1358] episode=1358.0000 return=-115.9996 length=20.0000 global_step=32972.0000 loss=8.5417 policy_loss=-0.0000 value_loss=17.0833 entropy=0.0000
[step=1359] episode=1359.0000 return=-115.9895 length=36.0000 global_step=33008.0000 loss=29.1549 policy_loss=-0.0000 value_loss=58.3097 entropy=0.0000
[step=1360] episode=1360.0000 return=-115.7895 length=18.0000 global_step=33026.0000 loss=129.5202 policy_loss=-0.0000 value_loss=259.0404 entropy=0.0000
[step=1361] episode=1361.0000 return=-115.9568 length=30.0000 global_step=33056.0000 loss=52.2023 policy_loss=-0.0000 value_loss=104.4046 entropy=0.0000
[step=1362] episode=1362.0000 return=-115.9973 length=20.0000 global_step=33076.0000 loss=55.9500 policy_loss=-0.0000 value_loss=111.9000 entropy=0.0000
[step=1363] episode=1363.0000 return=-115.8807 length=20.0000 global_step=33096.0000 loss=28.9558 policy_loss=-0.0000 value_loss=57.9117 entropy=0.0000
[step=1364] episode=1364.0000 return=-115.9997 length=30.0000 global_step=33126.0000 loss=30.9209 policy_loss=-0.0000 value_loss=61.8417 entropy=0.0000
[step=1365] episode=1365.0000 return=-115.9894 length=26.0000 global_step=33152.0000 loss=74.3284 policy_loss=-0.0000 value_loss=148.6568 entropy=0.0000
[step=1366] episode=1366.0000 return=-115.9993 length=28.0000 global_step=33180.0000 loss=90.7257 policy_loss=-0.0000 value_loss=181.4515 entropy=0.0000
[step=1367] episode=1367.0000 return=-115.9884 length=35.0000 global_step=33215.0000 loss=55.1247 policy_loss=-0.0000 value_loss=110.2494 entropy=0.0000
[step=1368] episode=1368.0000 return=-115.9941 length=30.0000 global_step=33245.0000 loss=16.1984 policy_loss=-0.0000 value_loss=32.3968 entropy=0.0000
[step=1369] episode=1369.0000 return=-115.7858 length=13.0000 global_step=33258.0000 loss=109.7655 policy_loss=-0.0000 value_loss=219.5310 entropy=0.0000
[step=1370] episode=1370.0000 return=-115.9978 length=30.0000 global_step=33288.0000 loss=46.2419 policy_loss=-0.0000 value_loss=92.4838 entropy=0.0000
[step=1371] episode=1371.0000 return=-116.0000 length=29.0000 global_step=33317.0000 loss=48.2865 policy_loss=-0.0000 value_loss=96.5731 entropy=0.0000
[step=1372] episode=1372.0000 return=-115.9996 length=27.0000 global_step=33344.0000 loss=33.8530 policy_loss=-0.0000 value_loss=67.7059 entropy=0.0000
[step=1373] episode=1373.0000 return=-115.9941 length=42.0000 global_step=33386.0000 loss=25.9637 policy_loss=-0.0000 value_loss=51.9275 entropy=0.0000
[step=1374] episode=1374.0000 return=-115.9944 length=21.0000 global_step=33407.0000 loss=7.5961 policy_loss=-0.0000 value_loss=15.1921 entropy=0.0000
[step=1375] episode=1375.0000 return=-115.9986 length=42.0000 global_step=33449.0000 loss=96.0818 policy_loss=-0.0000 value_loss=192.1636 entropy=0.0000
[step=1376] episode=1376.0000 return=-115.9977 length=29.0000 global_step=33478.0000 loss=14.8177 policy_loss=-0.0000 value_loss=29.6354 entropy=0.0000
[step=1377] episode=1377.0000 return=-115.9975 length=20.0000 global_step=33498.0000 loss=6.4671 policy_loss=-0.0000 value_loss=12.9341 entropy=0.0000
[step=1378] episode=1378.0000 return=-115.9086 length=20.0000 global_step=33518.0000 loss=4.0651 policy_loss=-0.0000 value_loss=8.1302 entropy=0.0000
[step=1379] episode=1379.0000 return=-115.9096 length=29.0000 global_step=33547.0000 loss=35.7715 policy_loss=-0.0000 value_loss=71.5430 entropy=0.0000
[step=1380] episode=1380.0000 return=-115.8870 length=29.0000 global_step=33576.0000 loss=10.1832 policy_loss=-0.0000 value_loss=20.3663 entropy=0.0000
[step=1381] episode=1381.0000 return=-115.8156 length=21.0000 global_step=33597.0000 loss=11.1139 policy_loss=-0.0000 value_loss=22.2277 entropy=0.0000
[step=1382] episode=1382.0000 return=-115.9942 length=43.0000 global_step=33640.0000 loss=41.1773 policy_loss=-0.0000 value_loss=82.3546 entropy=0.0000
[step=1383] episode=1383.0000 return=-115.9948 length=20.0000 global_step=33660.0000 loss=29.8833 policy_loss=-0.0000 value_loss=59.7666 entropy=0.0000
[step=1384] episode=1384.0000 return=-115.9645 length=45.0000 global_step=33705.0000 loss=27.1950 policy_loss=-0.0000 value_loss=54.3900 entropy=0.0000
[step=1385] episode=1385.0000 return=-115.9998 length=42.0000 global_step=33747.0000 loss=36.0670 policy_loss=-0.0000 value_loss=72.1341 entropy=0.0000
[step=1386] episode=1386.0000 return=-115.9969 length=20.0000 global_step=33767.0000 loss=79.8076 policy_loss=-0.0000 value_loss=159.6151 entropy=0.0000
[step=1387] episode=1387.0000 return=-115.8941 length=20.0000 global_step=33787.0000 loss=142.3659 policy_loss=-0.0000 value_loss=284.7318 entropy=0.0000
[step=1388] episode=1388.0000 return=-115.9987 length=20.0000 global_step=33807.0000 loss=79.9525 policy_loss=-0.0000 value_loss=159.9050 entropy=0.0000
[step=1389] episode=1389.0000 return=-115.9643 length=20.0000 global_step=33827.0000 loss=6.6881 policy_loss=-0.0000 value_loss=13.3761 entropy=0.0000
[step=1390] episode=1390.0000 return=-115.9840 length=30.0000 global_step=33857.0000 loss=74.3354 policy_loss=-0.0000 value_loss=148.6709 entropy=0.0000
[step=1391] episode=1391.0000 return=-115.9972 length=19.0000 global_step=33876.0000 loss=43.4021 policy_loss=-0.0000 value_loss=86.8042 entropy=0.0000
[step=1392] episode=1392.0000 return=-115.9948 length=28.0000 global_step=33904.0000 loss=72.9930 policy_loss=-0.0000 value_loss=145.9861 entropy=0.0000
[step=1393] episode=1393.0000 return=-115.9824 length=20.0000 global_step=33924.0000 loss=11.0281 policy_loss=-0.0000 value_loss=22.0562 entropy=0.0000
[step=1394] episode=1394.0000 return=-115.9999 length=25.0000 global_step=33949.0000 loss=15.3796 policy_loss=-0.0000 value_loss=30.7591 entropy=0.0000
[step=1395] episode=1395.0000 return=-116.0000 length=47.0000 global_step=33996.0000 loss=76.1577 policy_loss=-0.0000 value_loss=152.3154 entropy=0.0000
[step=1396] episode=1396.0000 return=-115.8340 length=21.0000 global_step=34017.0000 loss=51.8035 policy_loss=-0.0000 value_loss=103.6070 entropy=0.0000
[step=1397] episode=1397.0000 return=-115.9980 length=34.0000 global_step=34051.0000 loss=32.1564 policy_loss=-0.0000 value_loss=64.3128 entropy=0.0000
[step=1398] episode=1398.0000 return=-115.9851 length=21.0000 global_step=34072.0000 loss=81.8410 policy_loss=-0.0000 value_loss=163.6819 entropy=0.0000
[step=1399] episode=1399.0000 return=-115.8783 length=13.0000 global_step=34085.0000 loss=123.9679 policy_loss=-0.0000 value_loss=247.9358 entropy=0.0000
a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1400/3000 [38:31<35:15,  1.32s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1401/3000 [38:33<42:20,  1.59s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1402/3000 [38:37<58:28,  2.20s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1403/3000 [38:39<1:00:42,  2.28s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1404/3000 [38:41<52:27,  1.97s/it]  a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1405/3000 [38:42<43:41,  1.64s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1406/3000 [38:44<48:03,  1.81s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1407/3000 [38:45<40:29,  1.52s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1408/3000 [38:47<43:48,  1.65s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1409/3000 [38:48<41:30,  1.57s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1410/3000 [38:50<47:58,  1.81s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1411/3000 [38:52<48:35,  1.83s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1412/3000 [38:53<44:03,  1.66s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1413/3000 [38:55<41:09,  1.56s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1414/3000 [38:56<40:36,  1.54s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1415/3000 [38:58<38:37,  1.46s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1416/3000 [38:59<41:47,  1.58s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1417/3000 [39:00<36:03,  1.37s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1418/3000 [39:02<35:50,  1.36s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1419/3000 [39:03<39:23,  1.50s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1420/3000 [39:05<41:34,  1.58s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1421/3000 [39:07<40:47,  1.55s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1422/3000 [39:10<52:35,  2.00s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1423/3000 [39:12<56:40,  2.16s/it]a2c_tuned train:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1424/3000 [39:15<58:20,  2.22s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1425/3000 [39:17<1:00:12,  2.29s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1426/3000 [39:19<57:18,  2.18s/it]  a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1427/3000 [39:20<50:49,  1.94s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1428/3000 [39:22<46:14,  1.77s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1429/3000 [39:23<42:43,  1.63s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1430/3000 [39:24<36:35,  1.40s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1431/3000 [39:25<33:05,  1.27s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1432/3000 [39:26<30:10,  1.15s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1433/3000 [39:27<31:31,  1.21s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1434/3000 [39:28<32:08,  1.23s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1435/3000 [39:29<28:35,  1.10s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1436/3000 [39:30<30:31,  1.17s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1437/3000 [39:34<45:31,  1.75s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1438/3000 [39:37<54:42,  2.10s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1439/3000 [39:39<58:45,  2.26s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1440/3000 [39:41<56:47,  2.18s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1441/3000 [39:44<58:23,  2.25s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1442/3000 [39:44<47:14,  1.82s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1443/3000 [39:47<52:58,  2.04s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1444/3000 [39:49<52:01,  2.01s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1445/3000 [39:50<46:06,  1.78s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1446/3000 [39:52<43:45,  1.69s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1447/3000 [39:55<54:28,  2.10s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1448/3000 [39:55<44:02,  1.70s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1449/3000 [39:57<46:20,  1.79s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1450/3000 [39:59<47:05,  1.82s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1451/3000 [40:00<39:15,  1.52s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1452/3000 [40:01<38:04,  1.48s/it][step=1400] episode=1400.0000 return=-115.1325 length=12.0000 global_step=34097.0000 loss=80.6183 policy_loss=-0.0000 value_loss=161.2366 entropy=0.0000
[step=1401] episode=1401.0000 return=-115.9734 length=34.0000 global_step=34131.0000 loss=49.3533 policy_loss=-0.0000 value_loss=98.7066 entropy=0.0000
[step=1402] episode=1402.0000 return=-115.7968 length=54.0000 global_step=34185.0000 loss=253.5253 policy_loss=-0.0000 value_loss=507.0506 entropy=0.0000
[step=1403] episode=1403.0000 return=-115.9887 length=36.0000 global_step=34221.0000 loss=135.8745 policy_loss=-0.0000 value_loss=271.7490 entropy=0.0000
[step=1404] episode=1404.0000 return=-115.9967 length=18.0000 global_step=34239.0000 loss=19.2066 policy_loss=-0.0000 value_loss=38.4131 entropy=0.0000
[step=1405] episode=1405.0000 return=-115.9939 length=13.0000 global_step=34252.0000 loss=19.8737 policy_loss=-0.0000 value_loss=39.7473 entropy=0.0000
[step=1406] episode=1406.0000 return=-115.9855 length=33.0000 global_step=34285.0000 loss=12.0086 policy_loss=-0.0000 value_loss=24.0172 entropy=0.0000
[step=1407] episode=1407.0000 return=-115.8116 length=12.0000 global_step=34297.0000 loss=69.4229 policy_loss=-0.0000 value_loss=138.8457 entropy=0.0000
[step=1408] episode=1408.0000 return=-115.9936 length=29.0000 global_step=34326.0000 loss=27.6094 policy_loss=-0.0000 value_loss=55.2189 entropy=0.0000
[step=1409] episode=1409.0000 return=-115.9945 length=20.0000 global_step=34346.0000 loss=18.6088 policy_loss=-0.0000 value_loss=37.2176 entropy=0.0000
[step=1410] episode=1410.0000 return=-115.9754 length=36.0000 global_step=34382.0000 loss=11.7845 policy_loss=-0.0000 value_loss=23.5690 entropy=0.0000
[step=1411] episode=1411.0000 return=-115.9945 length=29.0000 global_step=34411.0000 loss=23.8938 policy_loss=-0.0000 value_loss=47.7876 entropy=0.0000
[step=1412] episode=1412.0000 return=-115.9611 length=19.0000 global_step=34430.0000 loss=9.6528 policy_loss=-0.0000 value_loss=19.3057 entropy=0.0000
[step=1413] episode=1413.0000 return=-115.9873 length=20.0000 global_step=34450.0000 loss=20.7407 policy_loss=-0.0000 value_loss=41.4815 entropy=0.0000
[step=1414] episode=1414.0000 return=-115.9427 length=21.0000 global_step=34471.0000 loss=5.1205 policy_loss=-0.0000 value_loss=10.2410 entropy=0.0000
[step=1415] episode=1415.0000 return=-115.8911 length=18.0000 global_step=34489.0000 loss=12.3702 policy_loss=-0.0000 value_loss=24.7404 entropy=0.0000
[step=1416] episode=1416.0000 return=-115.9920 length=28.0000 global_step=34517.0000 loss=10.2377 policy_loss=-0.0000 value_loss=20.4754 entropy=0.0000
[step=1417] episode=1417.0000 return=-115.8180 length=13.0000 global_step=34530.0000 loss=23.6039 policy_loss=-0.0000 value_loss=47.2078 entropy=0.0000
[step=1418] episode=1418.0000 return=-115.8636 length=20.0000 global_step=34550.0000 loss=4.4598 policy_loss=-0.0000 value_loss=8.9197 entropy=0.0000
[step=1419] episode=1419.0000 return=-115.9999 length=28.0000 global_step=34578.0000 loss=21.6959 policy_loss=-0.0000 value_loss=43.3917 entropy=0.0000
[step=1420] episode=1420.0000 return=-115.7283 length=26.0000 global_step=34604.0000 loss=8.8143 policy_loss=-0.0000 value_loss=17.6286 entropy=0.0000
[step=1421] episode=1421.0000 return=-115.7373 length=21.0000 global_step=34625.0000 loss=10.2955 policy_loss=-0.0000 value_loss=20.5910 entropy=0.0000
[step=1422] episode=1422.0000 return=-115.9971 length=46.0000 global_step=34671.0000 loss=83.4645 policy_loss=-0.0000 value_loss=166.9289 entropy=0.0000
[step=1423] episode=1423.0000 return=-115.9803 length=38.0000 global_step=34709.0000 loss=13.5971 policy_loss=-0.0000 value_loss=27.1942 entropy=0.0000
[step=1424] episode=1424.0000 return=-115.9859 length=36.0000 global_step=34745.0000 loss=27.0727 policy_loss=-0.0000 value_loss=54.1455 entropy=0.0000
[step=1425] episode=1425.0000 return=-115.9959 length=37.0000 global_step=34782.0000 loss=21.8471 policy_loss=-0.0000 value_loss=43.6942 entropy=0.0000
[step=1426] episode=1426.0000 return=-115.9998 length=29.0000 global_step=34811.0000 loss=26.5814 policy_loss=-0.0000 value_loss=53.1627 entropy=0.0000
[step=1427] episode=1427.0000 return=-115.9233 length=21.0000 global_step=34832.0000 loss=49.8296 policy_loss=-0.0000 value_loss=99.6592 entropy=0.0000
[step=1428] episode=1428.0000 return=-115.9555 length=21.0000 global_step=34853.0000 loss=17.0270 policy_loss=-0.0000 value_loss=34.0540 entropy=0.0000
[step=1429] episode=1429.0000 return=-115.9338 length=19.0000 global_step=34872.0000 loss=3.1317 policy_loss=-0.0000 value_loss=6.2634 entropy=0.0000
[step=1430] episode=1430.0000 return=-115.7899 length=12.0000 global_step=34884.0000 loss=8.7123 policy_loss=-0.0000 value_loss=17.4245 entropy=0.0000
[step=1431] episode=1431.0000 return=-115.9385 length=13.0000 global_step=34897.0000 loss=11.4928 policy_loss=-0.0000 value_loss=22.9857 entropy=0.0000
[step=1432] episode=1432.0000 return=-115.9944 length=12.0000 global_step=34909.0000 loss=31.9313 policy_loss=-0.0000 value_loss=63.8627 entropy=0.0000
[step=1433] episode=1433.0000 return=-115.9095 length=20.0000 global_step=34929.0000 loss=64.0918 policy_loss=-0.0000 value_loss=128.1835 entropy=0.0000
[step=1434] episode=1434.0000 return=-115.9096 length=18.0000 global_step=34947.0000 loss=26.5495 policy_loss=-0.0000 value_loss=53.0990 entropy=0.0000
[step=1435] episode=1435.0000 return=-115.8686 length=11.0000 global_step=34958.0000 loss=10.7528 policy_loss=-0.0000 value_loss=21.5055 entropy=0.0000
[step=1436] episode=1436.0000 return=-115.9840 length=21.0000 global_step=34979.0000 loss=5.5137 policy_loss=-0.0000 value_loss=11.0275 entropy=0.0000
[step=1437] episode=1437.0000 return=-115.9997 length=46.0000 global_step=35025.0000 loss=87.9575 policy_loss=-0.0000 value_loss=175.9149 entropy=0.0000
[step=1438] episode=1438.0000 return=-115.9992 length=45.0000 global_step=35070.0000 loss=29.5496 policy_loss=-0.0000 value_loss=59.0992 entropy=0.0000
[step=1439] episode=1439.0000 return=-116.0000 length=41.0000 global_step=35111.0000 loss=30.5602 policy_loss=-0.0000 value_loss=61.1205 entropy=0.0000
[step=1440] episode=1440.0000 return=-115.8525 length=29.0000 global_step=35140.0000 loss=69.1781 policy_loss=-0.0000 value_loss=138.3561 entropy=0.0000
[step=1441] episode=1441.0000 return=-115.7519 length=36.0000 global_step=35176.0000 loss=80.1631 policy_loss=-0.0000 value_loss=160.3262 entropy=0.0000
[step=1442] episode=1442.0000 return=-115.9572 length=13.0000 global_step=35189.0000 loss=152.5696 policy_loss=-0.0000 value_loss=305.1392 entropy=0.0000
[step=1443] episode=1443.0000 return=-115.9955 length=38.0000 global_step=35227.0000 loss=29.6166 policy_loss=-0.0000 value_loss=59.2332 entropy=0.0000
[step=1444] episode=1444.0000 return=-115.9725 length=29.0000 global_step=35256.0000 loss=16.6208 policy_loss=-0.0000 value_loss=33.2416 entropy=0.0000
[step=1445] episode=1445.0000 return=-115.9881 length=19.0000 global_step=35275.0000 loss=4.7668 policy_loss=-0.0000 value_loss=9.5336 entropy=0.0000
[step=1446] episode=1446.0000 return=-116.0000 length=22.0000 global_step=35297.0000 loss=11.9201 policy_loss=-0.0000 value_loss=23.8402 entropy=0.0000
[step=1447] episode=1447.0000 return=-115.9955 length=46.0000 global_step=35343.0000 loss=117.3054 policy_loss=-0.0000 value_loss=234.6109 entropy=0.0000
[step=1448] episode=1448.0000 return=-115.9997 length=12.0000 global_step=35355.0000 loss=10.0232 policy_loss=-0.0000 value_loss=20.0464 entropy=0.0000
[step=1449] episode=1449.0000 return=-115.9515 length=29.0000 global_step=35384.0000 loss=14.2703 policy_loss=-0.0000 value_loss=28.5406 entropy=0.0000
[step=1450] episode=1450.0000 return=-115.9946 length=28.0000 global_step=35412.0000 loss=17.8361 policy_loss=-0.0000 value_loss=35.6723 entropy=0.0000
[step=1451] episode=1451.0000 return=-115.9796 length=12.0000 global_step=35424.0000 loss=57.2479 policy_loss=-0.0000 value_loss=114.4957 entropy=0.0000
[step=1452] episode=1452.0000 return=-115.9867 length=19.0000 global_step=35443.0000 loss=27.5318 policy_loss=-0.0000 value_loss=55.0635 entropy=0.0000
a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1453/3000 [40:03<40:36,  1.57s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1454/3000 [40:04<34:56,  1.36s/it]a2c_tuned train:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1455/3000 [40:06<35:05,  1.36s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1456/3000 [40:07<38:36,  1.50s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1457/3000 [40:10<47:29,  1.85s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1458/3000 [40:11<43:21,  1.69s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1459/3000 [40:14<48:55,  1.90s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1460/3000 [40:15<40:56,  1.60s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1461/3000 [40:17<43:35,  1.70s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1462/3000 [40:18<45:25,  1.77s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1463/3000 [40:20<47:04,  1.84s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1464/3000 [40:22<43:38,  1.70s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1465/3000 [40:23<37:13,  1.46s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1466/3000 [40:24<37:03,  1.45s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1467/3000 [40:26<36:22,  1.42s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1468/3000 [40:28<41:00,  1.61s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1469/3000 [40:29<42:22,  1.66s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1470/3000 [40:31<40:09,  1.58s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1471/3000 [40:33<43:14,  1.70s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1472/3000 [40:35<47:55,  1.88s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1473/3000 [40:36<40:47,  1.60s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1474/3000 [40:38<41:31,  1.63s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1475/3000 [40:39<38:54,  1.53s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1476/3000 [40:40<37:48,  1.49s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1477/3000 [40:42<35:54,  1.41s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1478/3000 [40:43<35:32,  1.40s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1479/3000 [40:44<34:18,  1.35s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1480/3000 [40:45<29:37,  1.17s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1481/3000 [40:46<27:13,  1.08s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1482/3000 [40:49<43:06,  1.70s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1483/3000 [40:50<39:29,  1.56s/it]a2c_tuned train:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1484/3000 [40:52<41:31,  1.64s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1485/3000 [40:53<38:24,  1.52s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1486/3000 [40:55<36:32,  1.45s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1487/3000 [40:56<35:46,  1.42s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1488/3000 [40:58<44:12,  1.75s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1489/3000 [41:00<40:51,  1.62s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1490/3000 [41:01<39:25,  1.57s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1491/3000 [41:04<46:44,  1.86s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1492/3000 [41:06<49:06,  1.95s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1493/3000 [41:07<41:06,  1.64s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1494/3000 [41:08<38:31,  1.53s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1495/3000 [41:10<42:05,  1.68s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1496/3000 [41:12<40:29,  1.62s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1497/3000 [41:12<34:44,  1.39s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1498/3000 [41:15<39:49,  1.59s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1499/3000 [41:16<40:54,  1.64s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1500/3000 [41:18<39:15,  1.57s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1501/3000 [41:18<33:21,  1.34s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1502/3000 [41:20<37:19,  1.49s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1503/3000 [41:23<45:11,  1.81s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1504/3000 [41:25<46:01,  1.85s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1505/3000 [41:28<54:22,  2.18s/it][step=1453] episode=1453.0000 return=-115.9850 length=28.0000 global_step=35471.0000 loss=18.1378 policy_loss=-0.0000 value_loss=36.2756 entropy=0.0000
[step=1454] episode=1454.0000 return=-115.9976 length=12.0000 global_step=35483.0000 loss=43.9901 policy_loss=-0.0000 value_loss=87.9802 entropy=0.0000
[step=1455] episode=1455.0000 return=-115.9286 length=20.0000 global_step=35503.0000 loss=8.2000 policy_loss=-0.0000 value_loss=16.4000 entropy=0.0000
[step=1456] episode=1456.0000 return=-115.8851 length=27.0000 global_step=35530.0000 loss=33.3494 policy_loss=-0.0000 value_loss=66.6988 entropy=0.0000
[step=1457] episode=1457.0000 return=-115.9099 length=40.0000 global_step=35570.0000 loss=108.3077 policy_loss=-0.0000 value_loss=216.6155 entropy=0.0000
[step=1458] episode=1458.0000 return=-115.9845 length=19.0000 global_step=35589.0000 loss=8.6607 policy_loss=-0.0000 value_loss=17.3214 entropy=0.0000
[step=1459] episode=1459.0000 return=-115.9885 length=36.0000 global_step=35625.0000 loss=56.5221 policy_loss=-0.0000 value_loss=113.0442 entropy=0.0000
[step=1460] episode=1460.0000 return=-115.8293 length=12.0000 global_step=35637.0000 loss=57.5871 policy_loss=-0.0000 value_loss=115.1742 entropy=0.0000
[step=1461] episode=1461.0000 return=-115.9948 length=28.0000 global_step=35665.0000 loss=17.6526 policy_loss=-0.0000 value_loss=35.3052 entropy=0.0000
[step=1462] episode=1462.0000 return=-115.9984 length=28.0000 global_step=35693.0000 loss=26.6286 policy_loss=-0.0000 value_loss=53.2572 entropy=0.0000
[step=1463] episode=1463.0000 return=-115.9994 length=30.0000 global_step=35723.0000 loss=14.8282 policy_loss=-0.0000 value_loss=29.6564 entropy=0.0000
[step=1464] episode=1464.0000 return=-115.9846 length=21.0000 global_step=35744.0000 loss=8.7003 policy_loss=-0.0000 value_loss=17.4006 entropy=0.0000
[step=1465] episode=1465.0000 return=-115.7013 length=13.0000 global_step=35757.0000 loss=21.0318 policy_loss=-0.0000 value_loss=42.0636 entropy=0.0000
[step=1466] episode=1466.0000 return=-115.9463 length=20.0000 global_step=35777.0000 loss=11.9226 policy_loss=-0.0000 value_loss=23.8451 entropy=0.0000
[step=1467] episode=1467.0000 return=-115.8831 length=21.0000 global_step=35798.0000 loss=37.9498 policy_loss=-0.0000 value_loss=75.8996 entropy=0.0000
[step=1468] episode=1468.0000 return=-115.9756 length=29.0000 global_step=35827.0000 loss=131.5655 policy_loss=-0.0000 value_loss=263.1310 entropy=0.0000
[step=1469] episode=1469.0000 return=-115.9939 length=26.0000 global_step=35853.0000 loss=95.5245 policy_loss=-0.0000 value_loss=191.0490 entropy=0.0000
[step=1470] episode=1470.0000 return=-115.9006 length=20.0000 global_step=35873.0000 loss=1.4436 policy_loss=-0.0000 value_loss=2.8872 entropy=0.0000
[step=1471] episode=1471.0000 return=-115.8870 length=29.0000 global_step=35902.0000 loss=13.6896 policy_loss=-0.0000 value_loss=27.3792 entropy=0.0000
[step=1472] episode=1472.0000 return=-115.9968 length=33.0000 global_step=35935.0000 loss=23.6221 policy_loss=-0.0000 value_loss=47.2442 entropy=0.0000
[step=1473] episode=1473.0000 return=-115.9883 length=14.0000 global_step=35949.0000 loss=184.8042 policy_loss=-0.0000 value_loss=369.6083 entropy=0.0000
[step=1474] episode=1474.0000 return=-115.9998 length=25.0000 global_step=35974.0000 loss=79.3112 policy_loss=-0.0000 value_loss=158.6225 entropy=0.0000
[step=1475] episode=1475.0000 return=-115.9903 length=20.0000 global_step=35994.0000 loss=82.4267 policy_loss=-0.0000 value_loss=164.8533 entropy=0.0000
[step=1476] episode=1476.0000 return=-115.9788 length=21.0000 global_step=36015.0000 loss=39.8903 policy_loss=-0.0000 value_loss=79.7805 entropy=0.0000
[step=1477] episode=1477.0000 return=-115.9941 length=19.0000 global_step=36034.0000 loss=11.3292 policy_loss=-0.0000 value_loss=22.6583 entropy=0.0000
[step=1478] episode=1478.0000 return=-115.8073 length=20.0000 global_step=36054.0000 loss=3.5357 policy_loss=-0.0000 value_loss=7.0713 entropy=0.0000
[step=1479] episode=1479.0000 return=-115.9231 length=19.0000 global_step=36073.0000 loss=41.8604 policy_loss=-0.0000 value_loss=83.7209 entropy=0.0000
[step=1480] episode=1480.0000 return=-115.7573 length=11.0000 global_step=36084.0000 loss=42.5620 policy_loss=-0.0000 value_loss=85.1239 entropy=0.0000
[step=1481] episode=1481.0000 return=-115.8378 length=13.0000 global_step=36097.0000 loss=43.4142 policy_loss=-0.0000 value_loss=86.8283 entropy=0.0000
[step=1482] episode=1482.0000 return=-115.9942 length=45.0000 global_step=36142.0000 loss=167.8163 policy_loss=-0.0000 value_loss=335.6326 entropy=0.0000
[step=1483] episode=1483.0000 return=-115.9325 length=18.0000 global_step=36160.0000 loss=5.1366 policy_loss=-0.0000 value_loss=10.2732 entropy=0.0000
[step=1484] episode=1484.0000 return=-115.9985 length=26.0000 global_step=36186.0000 loss=9.6813 policy_loss=-0.0000 value_loss=19.3626 entropy=0.0000
[step=1485] episode=1485.0000 return=-115.9996 length=18.0000 global_step=36204.0000 loss=52.0151 policy_loss=-0.0000 value_loss=104.0302 entropy=0.0000
[step=1486] episode=1486.0000 return=-115.9898 length=18.0000 global_step=36222.0000 loss=73.7566 policy_loss=-0.0000 value_loss=147.5133 entropy=0.0000
[step=1487] episode=1487.0000 return=-115.7550 length=20.0000 global_step=36242.0000 loss=104.8257 policy_loss=-0.0000 value_loss=209.6513 entropy=0.0000
[step=1488] episode=1488.0000 return=-115.9429 length=38.0000 global_step=36280.0000 loss=16.1609 policy_loss=-0.0000 value_loss=32.3218 entropy=0.0000
[step=1489] episode=1489.0000 return=-115.8783 length=20.0000 global_step=36300.0000 loss=18.3575 policy_loss=-0.0000 value_loss=36.7150 entropy=0.0000
[step=1490] episode=1490.0000 return=-115.9984 length=22.0000 global_step=36322.0000 loss=4.0355 policy_loss=-0.0000 value_loss=8.0709 entropy=0.0000
[step=1491] episode=1491.0000 return=-115.9837 length=38.0000 global_step=36360.0000 loss=109.9472 policy_loss=-0.0000 value_loss=219.8945 entropy=0.0000
[step=1492] episode=1492.0000 return=-115.9778 length=33.0000 global_step=36393.0000 loss=91.6347 policy_loss=-0.0000 value_loss=183.2695 entropy=0.0000
[step=1493] episode=1493.0000 return=-115.8180 length=13.0000 global_step=36406.0000 loss=9.2331 policy_loss=-0.0000 value_loss=18.4661 entropy=0.0000
[step=1494] episode=1494.0000 return=-115.9830 length=20.0000 global_step=36426.0000 loss=6.4206 policy_loss=-0.0000 value_loss=12.8413 entropy=0.0000
[step=1495] episode=1495.0000 return=-115.9828 length=30.0000 global_step=36456.0000 loss=6.5662 policy_loss=-0.0000 value_loss=13.1325 entropy=0.0000
[step=1496] episode=1496.0000 return=-115.9320 length=21.0000 global_step=36477.0000 loss=6.5425 policy_loss=-0.0000 value_loss=13.0850 entropy=0.0000
[step=1497] episode=1497.0000 return=-115.7779 length=12.0000 global_step=36489.0000 loss=41.3006 policy_loss=-0.0000 value_loss=82.6012 entropy=0.0000
[step=1498] episode=1498.0000 return=-115.9385 length=30.0000 global_step=36519.0000 loss=15.3265 policy_loss=-0.0000 value_loss=30.6531 entropy=0.0000
[step=1499] episode=1499.0000 return=-115.9995 length=26.0000 global_step=36545.0000 loss=15.1641 policy_loss=-0.0000 value_loss=30.3282 entropy=0.0000
[step=1500] episode=1500.0000 return=-115.9980 length=21.0000 global_step=36566.0000 loss=13.1821 policy_loss=-0.0000 value_loss=26.3642 entropy=0.0000
[step=1501] episode=1501.0000 return=-107.8080 length=11.0000 global_step=36577.0000 loss=52.6225 policy_loss=-0.0000 value_loss=105.2450 entropy=0.0000
[step=1502] episode=1502.0000 return=-115.8224 length=28.0000 global_step=36605.0000 loss=7.5522 policy_loss=-0.0000 value_loss=15.1045 entropy=0.0000
[step=1503] episode=1503.0000 return=-115.9096 length=38.0000 global_step=36643.0000 loss=75.5383 policy_loss=-0.0000 value_loss=151.0766 entropy=0.0000
[step=1504] episode=1504.0000 return=-115.9995 length=28.0000 global_step=36671.0000 loss=46.3372 policy_loss=-0.0000 value_loss=92.6743 entropy=0.0000
[step=1505] episode=1505.0000 return=-115.9998 length=44.0000 global_step=36715.0000 loss=115.8655 policy_loss=-0.0000 value_loss=231.7309 entropy=0.0000
a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1506/3000 [41:30<56:10,  2.26s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1507/3000 [41:31<48:51,  1.96s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1508/3000 [41:33<43:56,  1.77s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1509/3000 [41:37<1:00:28,  2.43s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1510/3000 [41:40<1:04:54,  2.61s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1511/3000 [41:42<58:57,  2.38s/it]  a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1512/3000 [41:43<48:32,  1.96s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1513/3000 [41:44<43:35,  1.76s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1514/3000 [41:45<38:53,  1.57s/it]a2c_tuned train:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1515/3000 [41:47<41:29,  1.68s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1516/3000 [41:48<40:06,  1.62s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1517/3000 [41:54<1:06:09,  2.68s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1518/3000 [41:55<56:52,  2.30s/it]  a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1519/3000 [41:56<50:21,  2.04s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1520/3000 [41:58<45:32,  1.85s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1521/3000 [41:59<37:43,  1.53s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1522/3000 [42:00<36:07,  1.47s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1523/3000 [42:01<31:28,  1.28s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1524/3000 [42:03<35:29,  1.44s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1525/3000 [42:04<34:01,  1.38s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1526/3000 [42:05<30:12,  1.23s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1527/3000 [42:06<31:00,  1.26s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1528/3000 [42:07<28:25,  1.16s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1529/3000 [42:08<25:24,  1.04s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1530/3000 [42:10<32:34,  1.33s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1531/3000 [42:11<32:13,  1.32s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1532/3000 [42:13<36:13,  1.48s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1533/3000 [42:15<39:42,  1.62s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1534/3000 [42:17<42:10,  1.73s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1535/3000 [42:19<48:07,  1.97s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1536/3000 [42:22<51:06,  2.09s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1537/3000 [42:23<47:00,  1.93s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1538/3000 [42:26<50:50,  2.09s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1539/3000 [42:27<47:48,  1.96s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1540/3000 [42:31<56:06,  2.31s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1541/3000 [42:31<44:46,  1.84s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1542/3000 [42:32<37:40,  1.55s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1543/3000 [42:34<36:34,  1.51s/it]a2c_tuned train:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1544/3000 [42:35<35:35,  1.47s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1545/3000 [42:37<39:10,  1.62s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1546/3000 [42:38<37:17,  1.54s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1547/3000 [42:40<39:34,  1.63s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1548/3000 [42:41<37:06,  1.53s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1549/3000 [42:42<32:00,  1.32s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1550/3000 [42:43<28:10,  1.17s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1551/3000 [42:45<33:45,  1.40s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1552/3000 [42:46<29:12,  1.21s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1553/3000 [42:47<30:09,  1.25s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1554/3000 [42:51<46:54,  1.95s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1555/3000 [42:52<42:43,  1.77s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1556/3000 [42:53<39:52,  1.66s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1557/3000 [42:54<34:00,  1.41s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1558/3000 [42:55<29:18,  1.22s/it][step=1506] episode=1506.0000 return=-115.9994 length=36.0000 global_step=36751.0000 loss=11.6805 policy_loss=-0.0000 value_loss=23.3610 entropy=0.0000
[step=1507] episode=1507.0000 return=-115.9940 length=20.0000 global_step=36771.0000 loss=51.3164 policy_loss=-0.0000 value_loss=102.6327 entropy=0.0000
[step=1508] episode=1508.0000 return=-115.8870 length=19.0000 global_step=36790.0000 loss=86.8124 policy_loss=-0.0000 value_loss=173.6247 entropy=0.0000
[step=1509] episode=1509.0000 return=-115.9999 length=61.0000 global_step=36851.0000 loss=46.8116 policy_loss=-0.0000 value_loss=93.6231 entropy=0.0000
[step=1510] episode=1510.0000 return=-116.0000 length=46.0000 global_step=36897.0000 loss=37.6044 policy_loss=-0.0000 value_loss=75.2088 entropy=0.0000
[step=1511] episode=1511.0000 return=-115.9503 length=28.0000 global_step=36925.0000 loss=49.3578 policy_loss=-0.0000 value_loss=98.7156 entropy=0.0000
[step=1512] episode=1512.0000 return=-115.9941 length=13.0000 global_step=36938.0000 loss=133.9853 policy_loss=-0.0000 value_loss=267.9706 entropy=0.0000
[step=1513] episode=1513.0000 return=-115.8516 length=20.0000 global_step=36958.0000 loss=19.5860 policy_loss=-0.0000 value_loss=39.1720 entropy=0.0000
[step=1514] episode=1514.0000 return=-115.9994 length=18.0000 global_step=36976.0000 loss=11.8721 policy_loss=-0.0000 value_loss=23.7442 entropy=0.0000
[step=1515] episode=1515.0000 return=-115.9781 length=28.0000 global_step=37004.0000 loss=105.0058 policy_loss=-0.0000 value_loss=210.0117 entropy=0.0000
[step=1516] episode=1516.0000 return=-115.9851 length=22.0000 global_step=37026.0000 loss=66.7240 policy_loss=-0.0000 value_loss=133.4480 entropy=0.0000
[step=1517] episode=1517.0000 return=-115.9997 length=79.0000 global_step=37105.0000 loss=578.4645 policy_loss=-0.0000 value_loss=1156.9291 entropy=0.0000
[step=1518] episode=1518.0000 return=-115.9921 length=20.0000 global_step=37125.0000 loss=6.8970 policy_loss=-0.0000 value_loss=13.7941 entropy=0.0000
[step=1519] episode=1519.0000 return=-115.9653 length=21.0000 global_step=37146.0000 loss=31.8317 policy_loss=-0.0000 value_loss=63.6634 entropy=0.0000
[step=1520] episode=1520.0000 return=-115.9993 length=20.0000 global_step=37166.0000 loss=90.7084 policy_loss=-0.0000 value_loss=181.4167 entropy=0.0000
[step=1521] episode=1521.0000 return=-115.8359 length=12.0000 global_step=37178.0000 loss=186.5529 policy_loss=-0.0000 value_loss=373.1059 entropy=0.0000
[step=1522] episode=1522.0000 return=-115.9939 length=19.0000 global_step=37197.0000 loss=85.9601 policy_loss=-0.0000 value_loss=171.9202 entropy=0.0000
[step=1523] episode=1523.0000 return=-115.8195 length=12.0000 global_step=37209.0000 loss=72.8745 policy_loss=-0.0000 value_loss=145.7490 entropy=0.0000
[step=1524] episode=1524.0000 return=-115.9695 length=28.0000 global_step=37237.0000 loss=29.6110 policy_loss=-0.0000 value_loss=59.2220 entropy=0.0000
[step=1525] episode=1525.0000 return=-115.7737 length=18.0000 global_step=37255.0000 loss=4.1449 policy_loss=-0.0000 value_loss=8.2899 entropy=0.0000
[step=1526] episode=1526.0000 return=-115.9996 length=12.0000 global_step=37267.0000 loss=19.3007 policy_loss=-0.0000 value_loss=38.6013 entropy=0.0000
[step=1527] episode=1527.0000 return=-115.9163 length=20.0000 global_step=37287.0000 loss=34.0240 policy_loss=-0.0000 value_loss=68.0480 entropy=0.0000
[step=1528] episode=1528.0000 return=-115.9584 length=13.0000 global_step=37300.0000 loss=7.7047 policy_loss=-0.0000 value_loss=15.4094 entropy=0.0000
[step=1529] episode=1529.0000 return=-115.9961 length=11.0000 global_step=37311.0000 loss=9.2581 policy_loss=-0.0000 value_loss=18.5162 entropy=0.0000
[step=1530] episode=1530.0000 return=-116.0000 length=29.0000 global_step=37340.0000 loss=37.8230 policy_loss=-0.0000 value_loss=75.6461 entropy=0.0000
[step=1531] episode=1531.0000 return=-115.8870 length=19.0000 global_step=37359.0000 loss=9.6587 policy_loss=-0.0000 value_loss=19.3174 entropy=0.0000
[step=1532] episode=1532.0000 return=-115.9986 length=27.0000 global_step=37386.0000 loss=8.7395 policy_loss=-0.0000 value_loss=17.4790 entropy=0.0000
[step=1533] episode=1533.0000 return=-115.9986 length=29.0000 global_step=37415.0000 loss=9.7434 policy_loss=-0.0000 value_loss=19.4868 entropy=0.0000
[step=1534] episode=1534.0000 return=-115.9886 length=29.0000 global_step=37444.0000 loss=12.5999 policy_loss=-0.0000 value_loss=25.1998 entropy=0.0000
[step=1535] episode=1535.0000 return=-116.0000 length=38.0000 global_step=37482.0000 loss=30.9723 policy_loss=-0.0000 value_loss=61.9445 entropy=0.0000
[step=1536] episode=1536.0000 return=-115.9991 length=35.0000 global_step=37517.0000 loss=12.4769 policy_loss=-0.0000 value_loss=24.9538 entropy=0.0000
[step=1537] episode=1537.0000 return=-115.8765 length=22.0000 global_step=37539.0000 loss=28.2626 policy_loss=-0.0000 value_loss=56.5251 entropy=0.0000
[step=1538] episode=1538.0000 return=-115.9939 length=36.0000 global_step=37575.0000 loss=13.2706 policy_loss=-0.0000 value_loss=26.5411 entropy=0.0000
[step=1539] episode=1539.0000 return=-115.9994 length=25.0000 global_step=37600.0000 loss=10.7580 policy_loss=-0.0000 value_loss=21.5160 entropy=0.0000
[step=1540] episode=1540.0000 return=-115.9959 length=46.0000 global_step=37646.0000 loss=70.0574 policy_loss=-0.0000 value_loss=140.1148 entropy=0.0000
[step=1541] episode=1541.0000 return=-115.9208 length=11.0000 global_step=37657.0000 loss=34.9180 policy_loss=-0.0000 value_loss=69.8361 entropy=0.0000
[step=1542] episode=1542.0000 return=-115.9792 length=12.0000 global_step=37669.0000 loss=35.9616 policy_loss=-0.0000 value_loss=71.9233 entropy=0.0000
[step=1543] episode=1543.0000 return=-115.9401 length=21.0000 global_step=37690.0000 loss=4.3823 policy_loss=-0.0000 value_loss=8.7647 entropy=0.0000
[step=1544] episode=1544.0000 return=-115.9976 length=20.0000 global_step=37710.0000 loss=17.4096 policy_loss=-0.0000 value_loss=34.8192 entropy=0.0000
[step=1545] episode=1545.0000 return=-115.9967 length=29.0000 global_step=37739.0000 loss=49.9392 policy_loss=-0.0000 value_loss=99.8783 entropy=0.0000
[step=1546] episode=1546.0000 return=-115.8424 length=20.0000 global_step=37759.0000 loss=2.7566 policy_loss=-0.0000 value_loss=5.5131 entropy=0.0000
[step=1547] episode=1547.0000 return=-115.9990 length=27.0000 global_step=37786.0000 loss=14.6079 policy_loss=-0.0000 value_loss=29.2158 entropy=0.0000
[step=1548] episode=1548.0000 return=-115.9983 length=19.0000 global_step=37805.0000 loss=9.4941 policy_loss=-0.0000 value_loss=18.9882 entropy=0.0000
[step=1549] episode=1549.0000 return=-115.7446 length=11.0000 global_step=37816.0000 loss=54.0318 policy_loss=-0.0000 value_loss=108.0635 entropy=0.0000
[step=1550] episode=1550.0000 return=-115.9703 length=12.0000 global_step=37828.0000 loss=26.0687 policy_loss=-0.0000 value_loss=52.1373 entropy=0.0000
[step=1551] episode=1551.0000 return=-115.9966 length=29.0000 global_step=37857.0000 loss=43.7521 policy_loss=-0.0000 value_loss=87.5043 entropy=0.0000
[step=1552] episode=1552.0000 return=-115.9960 length=12.0000 global_step=37869.0000 loss=8.1269 policy_loss=-0.0000 value_loss=16.2537 entropy=0.0000
[step=1553] episode=1553.0000 return=-115.9961 length=19.0000 global_step=37888.0000 loss=18.4377 policy_loss=-0.0000 value_loss=36.8754 entropy=0.0000
[step=1554] episode=1554.0000 return=-115.9884 length=53.0000 global_step=37941.0000 loss=204.6268 policy_loss=-0.0000 value_loss=409.2536 entropy=0.0000
[step=1555] episode=1555.0000 return=-115.8154 length=21.0000 global_step=37962.0000 loss=3.8390 policy_loss=-0.0000 value_loss=7.6779 entropy=0.0000
[step=1556] episode=1556.0000 return=-115.7963 length=21.0000 global_step=37983.0000 loss=9.4511 policy_loss=-0.0000 value_loss=18.9021 entropy=0.0000
[step=1557] episode=1557.0000 return=-115.9849 length=13.0000 global_step=37996.0000 loss=66.9250 policy_loss=-0.0000 value_loss=133.8501 entropy=0.0000
[step=1558] episode=1558.0000 return=-115.8693 length=11.0000 global_step=38007.0000 loss=51.4920 policy_loss=-0.0000 value_loss=102.9840 entropy=0.0000
a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1559/3000 [42:57<34:32,  1.44s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1560/3000 [42:58<30:29,  1.27s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1561/3000 [42:59<27:30,  1.15s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1562/3000 [43:00<28:51,  1.20s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1563/3000 [43:03<41:50,  1.75s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1564/3000 [43:04<35:36,  1.49s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1565/3000 [43:05<30:39,  1.28s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1566/3000 [43:07<35:31,  1.49s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1567/3000 [43:08<34:11,  1.43s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1568/3000 [43:10<40:57,  1.72s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1569/3000 [43:12<38:58,  1.63s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1570/3000 [43:12<29:36,  1.24s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1571/3000 [43:14<30:15,  1.27s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1572/3000 [43:15<34:18,  1.44s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1573/3000 [43:16<30:25,  1.28s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1574/3000 [43:18<35:15,  1.48s/it]a2c_tuned train:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1575/3000 [43:20<34:11,  1.44s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1576/3000 [43:21<37:17,  1.57s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1577/3000 [43:22<32:35,  1.37s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1578/3000 [43:24<32:03,  1.35s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1579/3000 [43:26<38:30,  1.63s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1580/3000 [43:27<36:40,  1.55s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1581/3000 [43:28<31:41,  1.34s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1582/3000 [43:30<32:42,  1.38s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1583/3000 [43:31<32:36,  1.38s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1584/3000 [43:32<28:14,  1.20s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1585/3000 [43:36<46:48,  1.98s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1586/3000 [43:37<41:52,  1.78s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1587/3000 [43:39<45:32,  1.93s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1588/3000 [43:40<41:04,  1.75s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1589/3000 [43:42<38:28,  1.64s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1590/3000 [43:43<32:59,  1.40s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1591/3000 [43:44<32:40,  1.39s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1592/3000 [43:46<35:15,  1.50s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1593/3000 [43:48<40:55,  1.75s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1594/3000 [43:50<40:19,  1.72s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1595/3000 [43:52<41:37,  1.78s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1596/3000 [43:53<39:22,  1.68s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1597/3000 [43:54<33:38,  1.44s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1598/3000 [43:55<29:19,  1.25s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1599/3000 [43:57<37:55,  1.62s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1600/3000 [43:58<33:05,  1.42s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1601/3000 [44:00<33:06,  1.42s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1602/3000 [44:00<28:24,  1.22s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1603/3000 [44:02<33:47,  1.45s/it]a2c_tuned train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1604/3000 [44:04<35:50,  1.54s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1605/3000 [44:06<34:09,  1.47s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1606/3000 [44:08<37:46,  1.63s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1607/3000 [44:11<47:57,  2.07s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1608/3000 [44:12<42:55,  1.85s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1609/3000 [44:13<36:16,  1.56s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1610/3000 [44:15<38:02,  1.64s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1611/3000 [44:17<40:22,  1.74s/it][step=1559] episode=1559.0000 return=-115.9857 length=29.0000 global_step=38036.0000 loss=5.8278 policy_loss=-0.0000 value_loss=11.6557 entropy=0.0000
[step=1560] episode=1560.0000 return=-115.8254 length=13.0000 global_step=38049.0000 loss=10.9341 policy_loss=-0.0000 value_loss=21.8682 entropy=0.0000
[step=1561] episode=1561.0000 return=-115.9990 length=12.0000 global_step=38061.0000 loss=11.6110 policy_loss=-0.0000 value_loss=23.2220 entropy=0.0000
[step=1562] episode=1562.0000 return=-115.8199 length=20.0000 global_step=38081.0000 loss=81.9006 policy_loss=-0.0000 value_loss=163.8011 entropy=0.0000
[step=1563] episode=1563.0000 return=-115.9882 length=45.0000 global_step=38126.0000 loss=312.3238 policy_loss=-0.0000 value_loss=624.6475 entropy=0.0000
[step=1564] episode=1564.0000 return=-115.7972 length=13.0000 global_step=38139.0000 loss=7.7208 policy_loss=-0.0000 value_loss=15.4416 entropy=0.0000
[step=1565] episode=1565.0000 return=-106.4357 length=12.0000 global_step=38151.0000 loss=8.2317 policy_loss=-0.0000 value_loss=16.4634 entropy=0.0000
[step=1566] episode=1566.0000 return=-115.9993 length=29.0000 global_step=38180.0000 loss=19.7901 policy_loss=-0.0000 value_loss=39.5802 entropy=0.0000
[step=1567] episode=1567.0000 return=-115.9951 length=20.0000 global_step=38200.0000 loss=48.4828 policy_loss=-0.0000 value_loss=96.9657 entropy=0.0000
[step=1568] episode=1568.0000 return=-115.9880 length=36.0000 global_step=38236.0000 loss=12.8151 policy_loss=-0.0000 value_loss=25.6302 entropy=0.0000
[step=1569] episode=1569.0000 return=-115.9218 length=21.0000 global_step=38257.0000 loss=32.0509 policy_loss=-0.0000 value_loss=64.1018 entropy=0.0000
[step=1570] episode=1570.0000 return=-115.7184 length=5.0000 global_step=38262.0000 loss=222.7821 policy_loss=-0.0000 value_loss=445.5643 entropy=0.0000
[step=1571] episode=1571.0000 return=-115.9899 length=20.0000 global_step=38282.0000 loss=4.5005 policy_loss=-0.0000 value_loss=9.0010 entropy=0.0000
[step=1572] episode=1572.0000 return=-115.9837 length=29.0000 global_step=38311.0000 loss=88.6992 policy_loss=-0.0000 value_loss=177.3983 entropy=0.0000
[step=1573] episode=1573.0000 return=-115.7701 length=14.0000 global_step=38325.0000 loss=23.4396 policy_loss=-0.0000 value_loss=46.8793 entropy=0.0000
[step=1574] episode=1574.0000 return=-115.9938 length=29.0000 global_step=38354.0000 loss=105.3801 policy_loss=-0.0000 value_loss=210.7601 entropy=0.0000
[step=1575] episode=1575.0000 return=-115.8870 length=19.0000 global_step=38373.0000 loss=22.7732 policy_loss=-0.0000 value_loss=45.5465 entropy=0.0000
[step=1576] episode=1576.0000 return=-115.9930 length=28.0000 global_step=38401.0000 loss=16.5857 policy_loss=-0.0000 value_loss=33.1714 entropy=0.0000
[step=1577] episode=1577.0000 return=-115.8847 length=13.0000 global_step=38414.0000 loss=123.1103 policy_loss=-0.0000 value_loss=246.2207 entropy=0.0000
[step=1578] episode=1578.0000 return=-115.8981 length=19.0000 global_step=38433.0000 loss=84.4850 policy_loss=-0.0000 value_loss=168.9700 entropy=0.0000
[step=1579] episode=1579.0000 return=-115.9641 length=34.0000 global_step=38467.0000 loss=31.5152 policy_loss=-0.0000 value_loss=63.0304 entropy=0.0000
[step=1580] episode=1580.0000 return=-115.9539 length=20.0000 global_step=38487.0000 loss=69.5661 policy_loss=-0.0000 value_loss=139.1322 entropy=0.0000
[step=1581] episode=1581.0000 return=-115.9331 length=12.0000 global_step=38499.0000 loss=20.5222 policy_loss=-0.0000 value_loss=41.0443 entropy=0.0000
[step=1582] episode=1582.0000 return=-115.8414 length=21.0000 global_step=38520.0000 loss=26.9840 policy_loss=-0.0000 value_loss=53.9680 entropy=0.0000
[step=1583] episode=1583.0000 return=-115.9958 length=21.0000 global_step=38541.0000 loss=118.0233 policy_loss=-0.0000 value_loss=236.0466 entropy=0.0000
[step=1584] episode=1584.0000 return=-115.7726 length=11.0000 global_step=38552.0000 loss=54.7845 policy_loss=-0.0000 value_loss=109.5689 entropy=0.0000
[step=1585] episode=1585.0000 return=-115.9964 length=56.0000 global_step=38608.0000 loss=305.0536 policy_loss=-0.0000 value_loss=610.1071 entropy=0.0000
[step=1586] episode=1586.0000 return=-115.9951 length=19.0000 global_step=38627.0000 loss=5.4500 policy_loss=-0.0000 value_loss=10.9000 entropy=0.0000
[step=1587] episode=1587.0000 return=-115.9953 length=34.0000 global_step=38661.0000 loss=19.9037 policy_loss=-0.0000 value_loss=39.8073 entropy=0.0000
[step=1588] episode=1588.0000 return=-115.8869 length=19.0000 global_step=38680.0000 loss=127.9691 policy_loss=-0.0000 value_loss=255.9382 entropy=0.0000
[step=1589] episode=1589.0000 return=-115.9840 length=21.0000 global_step=38701.0000 loss=163.9871 policy_loss=-0.0000 value_loss=327.9742 entropy=0.0000
[step=1590] episode=1590.0000 return=-115.9977 length=12.0000 global_step=38713.0000 loss=219.6681 policy_loss=-0.0000 value_loss=439.3361 entropy=0.0000
[step=1591] episode=1591.0000 return=-115.9925 length=20.0000 global_step=38733.0000 loss=26.6302 policy_loss=-0.0000 value_loss=53.2603 entropy=0.0000
[step=1592] episode=1592.0000 return=-115.9955 length=28.0000 global_step=38761.0000 loss=35.9639 policy_loss=-0.0000 value_loss=71.9278 entropy=0.0000
[step=1593] episode=1593.0000 return=-115.9744 length=34.0000 global_step=38795.0000 loss=115.6407 policy_loss=-0.0000 value_loss=231.2814 entropy=0.0000
[step=1594] episode=1594.0000 return=-115.9986 length=25.0000 global_step=38820.0000 loss=88.6217 policy_loss=-0.0000 value_loss=177.2434 entropy=0.0000
[step=1595] episode=1595.0000 return=-116.0000 length=29.0000 global_step=38849.0000 loss=89.7271 policy_loss=-0.0000 value_loss=179.4541 entropy=0.0000
[step=1596] episode=1596.0000 return=-115.9986 length=21.0000 global_step=38870.0000 loss=3.3240 policy_loss=-0.0000 value_loss=6.6480 entropy=0.0000
[step=1597] episode=1597.0000 return=-115.9221 length=12.0000 global_step=38882.0000 loss=58.7662 policy_loss=-0.0000 value_loss=117.5324 entropy=0.0000
[step=1598] episode=1598.0000 return=-111.6638 length=12.0000 global_step=38894.0000 loss=94.7643 policy_loss=-0.0000 value_loss=189.5287 entropy=0.0000
[step=1599] episode=1599.0000 return=-115.9502 length=37.0000 global_step=38931.0000 loss=16.3280 policy_loss=-0.0000 value_loss=32.6559 entropy=0.0000
[step=1600] episode=1600.0000 return=-114.6924 length=13.0000 global_step=38944.0000 loss=79.0390 policy_loss=-0.0000 value_loss=158.0781 entropy=0.0000
[step=1601] episode=1601.0000 return=-115.9916 length=22.0000 global_step=38966.0000 loss=7.9762 policy_loss=-0.0000 value_loss=15.9525 entropy=0.0000
[step=1602] episode=1602.0000 return=-115.9486 length=11.0000 global_step=38977.0000 loss=7.2019 policy_loss=-0.0000 value_loss=14.4038 entropy=0.0000
[step=1603] episode=1603.0000 return=-115.9941 length=29.0000 global_step=39006.0000 loss=92.6997 policy_loss=-0.0000 value_loss=185.3994 entropy=0.0000
[step=1604] episode=1604.0000 return=-115.9733 length=26.0000 global_step=39032.0000 loss=53.1587 policy_loss=-0.0000 value_loss=106.3174 entropy=0.0000
[step=1605] episode=1605.0000 return=-115.9036 length=19.0000 global_step=39051.0000 loss=6.5542 policy_loss=-0.0000 value_loss=13.1084 entropy=0.0000
[step=1606] episode=1606.0000 return=-115.9987 length=29.0000 global_step=39080.0000 loss=7.5075 policy_loss=-0.0000 value_loss=15.0151 entropy=0.0000
[step=1607] episode=1607.0000 return=-115.9941 length=46.0000 global_step=39126.0000 loss=50.5172 policy_loss=-0.0000 value_loss=101.0343 entropy=0.0000
[step=1608] episode=1608.0000 return=-115.9805 length=20.0000 global_step=39146.0000 loss=81.0962 policy_loss=-0.0000 value_loss=162.1924 entropy=0.0000
[step=1609] episode=1609.0000 return=-115.9384 length=13.0000 global_step=39159.0000 loss=222.6731 policy_loss=-0.0000 value_loss=445.3462 entropy=0.0000
[step=1610] episode=1610.0000 return=-115.9988 length=28.0000 global_step=39187.0000 loss=30.3983 policy_loss=-0.0000 value_loss=60.7965 entropy=0.0000
[step=1611] episode=1611.0000 return=-115.9385 length=29.0000 global_step=39216.0000 loss=11.0051 policy_loss=-0.0000 value_loss=22.0103 entropy=0.0000
a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1612/3000 [44:18<38:31,  1.67s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1613/3000 [44:20<40:02,  1.73s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1614/3000 [44:21<34:06,  1.48s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1615/3000 [44:25<51:36,  2.24s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1616/3000 [44:27<47:56,  2.08s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1617/3000 [44:29<51:08,  2.22s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1618/3000 [44:30<41:51,  1.82s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1619/3000 [44:32<42:42,  1.86s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1620/3000 [44:33<39:30,  1.72s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1621/3000 [44:35<36:32,  1.59s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1622/3000 [44:37<41:21,  1.80s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1623/3000 [44:39<41:52,  1.82s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1624/3000 [44:40<34:30,  1.50s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1625/3000 [44:41<34:06,  1.49s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1626/3000 [44:42<32:30,  1.42s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1627/3000 [44:45<39:10,  1.71s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1628/3000 [44:46<36:29,  1.60s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1629/3000 [44:49<45:31,  1.99s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1630/3000 [44:51<45:07,  1.98s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1631/3000 [44:52<41:35,  1.82s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1632/3000 [44:54<42:01,  1.84s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1633/3000 [44:56<42:21,  1.86s/it]a2c_tuned train:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1634/3000 [44:57<38:37,  1.70s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1635/3000 [44:59<40:09,  1.77s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1636/3000 [45:01<37:15,  1.64s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1637/3000 [45:03<38:52,  1.71s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1638/3000 [45:04<39:52,  1.76s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1639/3000 [45:06<41:03,  1.81s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1640/3000 [45:09<46:03,  2.03s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1641/3000 [45:10<42:18,  1.87s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1642/3000 [45:12<41:33,  1.84s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1643/3000 [45:13<35:02,  1.55s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1644/3000 [45:15<40:35,  1.80s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1645/3000 [45:17<41:05,  1.82s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1646/3000 [45:19<41:48,  1.85s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1647/3000 [45:20<35:08,  1.56s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1648/3000 [45:21<30:17,  1.34s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1649/3000 [45:22<30:20,  1.35s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1650/3000 [45:24<31:41,  1.41s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1651/3000 [45:25<31:46,  1.41s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1652/3000 [45:27<31:23,  1.40s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1653/3000 [45:29<35:32,  1.58s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1654/3000 [45:30<34:35,  1.54s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1655/3000 [45:31<33:06,  1.48s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1656/3000 [45:33<32:05,  1.43s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1657/3000 [45:35<40:07,  1.79s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1658/3000 [45:37<37:05,  1.66s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1659/3000 [45:38<35:53,  1.61s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1660/3000 [45:42<49:37,  2.22s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1661/3000 [45:43<42:58,  1.93s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1662/3000 [45:44<38:46,  1.74s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1663/3000 [45:46<35:58,  1.61s/it]a2c_tuned train:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1664/3000 [45:47<34:14,  1.54s/it][step=1612] episode=1612.0000 return=-115.9361 length=22.0000 global_step=39238.0000 loss=6.3943 policy_loss=-0.0000 value_loss=12.7886 entropy=0.0000
[step=1613] episode=1613.0000 return=-115.9096 length=28.0000 global_step=39266.0000 loss=34.2975 policy_loss=-0.0000 value_loss=68.5950 entropy=0.0000
[step=1614] episode=1614.0000 return=-115.7177 length=13.0000 global_step=39279.0000 loss=6.5018 policy_loss=-0.0000 value_loss=13.0035 entropy=0.0000
[step=1615] episode=1615.0000 return=-115.9998 length=61.0000 global_step=39340.0000 loss=389.6264 policy_loss=-0.0000 value_loss=779.2528 entropy=0.0000
[step=1616] episode=1616.0000 return=-115.9845 length=26.0000 global_step=39366.0000 loss=47.5094 policy_loss=-0.0000 value_loss=95.0189 entropy=0.0000
[step=1617] episode=1617.0000 return=-115.9793 length=38.0000 global_step=39404.0000 loss=56.1735 policy_loss=-0.0000 value_loss=112.3471 entropy=0.0000
[step=1618] episode=1618.0000 return=-115.9794 length=13.0000 global_step=39417.0000 loss=94.1810 policy_loss=-0.0000 value_loss=188.3620 entropy=0.0000
[step=1619] episode=1619.0000 return=-115.9982 length=28.0000 global_step=39445.0000 loss=34.4243 policy_loss=-0.0000 value_loss=68.8485 entropy=0.0000
[step=1620] episode=1620.0000 return=-115.9385 length=21.0000 global_step=39466.0000 loss=87.6229 policy_loss=-0.0000 value_loss=175.2458 entropy=0.0000
[step=1621] episode=1621.0000 return=-115.8650 length=19.0000 global_step=39485.0000 loss=52.0060 policy_loss=-0.0000 value_loss=104.0119 entropy=0.0000
[step=1622] episode=1622.0000 return=-115.9999 length=35.0000 global_step=39520.0000 loss=27.9568 policy_loss=-0.0000 value_loss=55.9136 entropy=0.0000
[step=1623] episode=1623.0000 return=-115.9948 length=28.0000 global_step=39548.0000 loss=15.9084 policy_loss=-0.0000 value_loss=31.8167 entropy=0.0000
[step=1624] episode=1624.0000 return=-115.9767 length=12.0000 global_step=39560.0000 loss=32.3765 policy_loss=-0.0000 value_loss=64.7531 entropy=0.0000
[step=1625] episode=1625.0000 return=-115.9940 length=21.0000 global_step=39581.0000 loss=7.7636 policy_loss=-0.0000 value_loss=15.5272 entropy=0.0000
[step=1626] episode=1626.0000 return=-115.9901 length=19.0000 global_step=39600.0000 loss=8.9976 policy_loss=-0.0000 value_loss=17.9953 entropy=0.0000
[step=1627] episode=1627.0000 return=-115.9925 length=35.0000 global_step=39635.0000 loss=71.7194 policy_loss=-0.0000 value_loss=143.4388 entropy=0.0000
[step=1628] episode=1628.0000 return=-115.9212 length=19.0000 global_step=39654.0000 loss=8.9157 policy_loss=-0.0000 value_loss=17.8314 entropy=0.0000
[step=1629] episode=1629.0000 return=-115.9939 length=45.0000 global_step=39699.0000 loss=88.4700 policy_loss=-0.0000 value_loss=176.9400 entropy=0.0000
[step=1630] episode=1630.0000 return=-115.9998 length=29.0000 global_step=39728.0000 loss=14.2540 policy_loss=-0.0000 value_loss=28.5079 entropy=0.0000
[step=1631] episode=1631.0000 return=-115.9936 length=21.0000 global_step=39749.0000 loss=33.2168 policy_loss=-0.0000 value_loss=66.4336 entropy=0.0000
[step=1632] episode=1632.0000 return=-115.9995 length=28.0000 global_step=39777.0000 loss=22.7198 policy_loss=-0.0000 value_loss=45.4396 entropy=0.0000
[step=1633] episode=1633.0000 return=-115.9385 length=29.0000 global_step=39806.0000 loss=10.2659 policy_loss=0.0000 value_loss=20.5318 entropy=0.0000
[step=1634] episode=1634.0000 return=-115.9747 length=20.0000 global_step=39826.0000 loss=6.8146 policy_loss=-0.0000 value_loss=13.6293 entropy=0.0000
[step=1635] episode=1635.0000 return=-115.9702 length=29.0000 global_step=39855.0000 loss=40.0959 policy_loss=-0.0000 value_loss=80.1917 entropy=0.0000
[step=1636] episode=1636.0000 return=-115.8457 length=20.0000 global_step=39875.0000 loss=5.8993 policy_loss=-0.0000 value_loss=11.7986 entropy=0.0000
[step=1637] episode=1637.0000 return=-115.9999 length=29.0000 global_step=39904.0000 loss=71.0421 policy_loss=-0.0000 value_loss=142.0842 entropy=0.0000
[step=1638] episode=1638.0000 return=-115.9892 length=28.0000 global_step=39932.0000 loss=13.8890 policy_loss=-0.0000 value_loss=27.7779 entropy=0.0000
[step=1639] episode=1639.0000 return=-115.9962 length=29.0000 global_step=39961.0000 loss=7.3550 policy_loss=-0.0000 value_loss=14.7101 entropy=0.0000
[step=1640] episode=1640.0000 return=-115.9837 length=38.0000 global_step=39999.0000 loss=35.4484 policy_loss=-0.0000 value_loss=70.8967 entropy=0.0000
[step=1641] episode=1641.0000 return=-115.9997 length=21.0000 global_step=40020.0000 loss=33.5006 policy_loss=-0.0000 value_loss=67.0012 entropy=0.0000
[step=1642] episode=1642.0000 return=-115.8644 length=26.0000 global_step=40046.0000 loss=70.3930 policy_loss=-0.0000 value_loss=140.7859 entropy=0.0000
[step=1643] episode=1643.0000 return=-115.9995 length=13.0000 global_step=40059.0000 loss=95.6105 policy_loss=-0.0000 value_loss=191.2211 entropy=0.0000
[step=1644] episode=1644.0000 return=-115.9999 length=37.0000 global_step=40096.0000 loss=17.1230 policy_loss=-0.0000 value_loss=34.2459 entropy=0.0000
[step=1645] episode=1645.0000 return=-115.9995 length=29.0000 global_step=40125.0000 loss=21.9153 policy_loss=-0.0000 value_loss=43.8306 entropy=0.0000
[step=1646] episode=1646.0000 return=-115.9956 length=30.0000 global_step=40155.0000 loss=23.0082 policy_loss=-0.0000 value_loss=46.0163 entropy=0.0000
[step=1647] episode=1647.0000 return=-115.9606 length=13.0000 global_step=40168.0000 loss=32.9726 policy_loss=-0.0000 value_loss=65.9452 entropy=0.0000
[step=1648] episode=1648.0000 return=-115.8341 length=12.0000 global_step=40180.0000 loss=25.0986 policy_loss=-0.0000 value_loss=50.1971 entropy=0.0000
[step=1649] episode=1649.0000 return=-115.9928 length=20.0000 global_step=40200.0000 loss=10.0163 policy_loss=-0.0000 value_loss=20.0325 entropy=0.0000
[step=1650] episode=1650.0000 return=-115.9990 length=21.0000 global_step=40221.0000 loss=5.6843 policy_loss=-0.0000 value_loss=11.3685 entropy=0.0000
[step=1651] episode=1651.0000 return=-115.9837 length=21.0000 global_step=40242.0000 loss=7.1306 policy_loss=-0.0000 value_loss=14.2612 entropy=0.0000
[step=1652] episode=1652.0000 return=-115.8188 length=20.0000 global_step=40262.0000 loss=4.3490 policy_loss=-0.0000 value_loss=8.6980 entropy=0.0000
[step=1653] episode=1653.0000 return=-115.9971 length=29.0000 global_step=40291.0000 loss=7.5731 policy_loss=-0.0000 value_loss=15.1461 entropy=0.0000
[step=1654] episode=1654.0000 return=-115.8014 length=21.0000 global_step=40312.0000 loss=11.8788 policy_loss=-0.0000 value_loss=23.7577 entropy=0.0000
[step=1655] episode=1655.0000 return=-115.8156 length=19.0000 global_step=40331.0000 loss=19.7424 policy_loss=-0.0000 value_loss=39.4848 entropy=0.0000
[step=1656] episode=1656.0000 return=-115.9096 length=19.0000 global_step=40350.0000 loss=9.0380 policy_loss=-0.0000 value_loss=18.0760 entropy=0.0000
[step=1657] episode=1657.0000 return=-115.9986 length=38.0000 global_step=40388.0000 loss=62.3704 policy_loss=0.0000 value_loss=124.7408 entropy=0.0000
[step=1658] episode=1658.0000 return=-115.9978 length=21.0000 global_step=40409.0000 loss=6.8779 policy_loss=0.0000 value_loss=13.7558 entropy=0.0000
[step=1659] episode=1659.0000 return=-115.8212 length=22.0000 global_step=40431.0000 loss=7.8391 policy_loss=-0.0000 value_loss=15.6782 entropy=0.0001
[step=1660] episode=1660.0000 return=-115.9956 length=54.0000 global_step=40485.0000 loss=129.8294 policy_loss=0.0000 value_loss=259.6588 entropy=0.0000
[step=1661] episode=1661.0000 return=-115.7229 length=18.0000 global_step=40503.0000 loss=11.3905 policy_loss=-0.0000 value_loss=22.7811 entropy=0.0000
[step=1662] episode=1662.0000 return=-115.9999 length=20.0000 global_step=40523.0000 loss=5.8586 policy_loss=-0.0000 value_loss=11.7172 entropy=0.0000
[step=1663] episode=1663.0000 return=-115.8789 length=21.0000 global_step=40544.0000 loss=7.2455 policy_loss=0.0000 value_loss=14.4910 entropy=0.0000
[step=1664] episode=1664.0000 return=-115.9998 length=20.0000 global_step=40564.0000 loss=5.1555 policy_loss=-0.0000 value_loss=10.3110 entropy=0.0000
a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1665/3000 [45:49<36:23,  1.64s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1666/3000 [45:51<37:16,  1.68s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1667/3000 [45:52<35:34,  1.60s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1668/3000 [45:54<37:05,  1.67s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1669/3000 [45:56<35:47,  1.61s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1670/3000 [45:56<30:41,  1.38s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1671/3000 [45:58<34:19,  1.55s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1672/3000 [46:00<33:05,  1.50s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1673/3000 [46:02<36:12,  1.64s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1674/3000 [46:03<34:27,  1.56s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1675/3000 [46:05<37:53,  1.72s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1676/3000 [46:06<31:58,  1.45s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1677/3000 [46:07<31:24,  1.42s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1678/3000 [46:10<42:43,  1.94s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1679/3000 [46:12<37:57,  1.72s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1680/3000 [46:13<35:56,  1.63s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1681/3000 [46:14<33:25,  1.52s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1682/3000 [46:16<32:32,  1.48s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1683/3000 [46:17<28:19,  1.29s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1684/3000 [46:19<36:25,  1.66s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1685/3000 [46:20<34:06,  1.56s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1686/3000 [46:21<29:27,  1.35s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1687/3000 [46:23<33:40,  1.54s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1688/3000 [46:25<36:39,  1.68s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1689/3000 [46:27<34:44,  1.59s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1690/3000 [46:28<34:02,  1.56s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1691/3000 [46:30<32:50,  1.51s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1692/3000 [46:30<28:21,  1.30s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1693/3000 [46:33<35:09,  1.61s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1694/3000 [46:33<29:27,  1.35s/it]a2c_tuned train:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1695/3000 [46:35<30:37,  1.41s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1696/3000 [46:36<30:20,  1.40s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1697/3000 [46:37<23:10,  1.07s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1698/3000 [46:38<24:57,  1.15s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1699/3000 [46:39<23:00,  1.06s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1700/3000 [46:42<33:42,  1.56s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1701/3000 [46:43<32:41,  1.51s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1702/3000 [46:46<40:45,  1.88s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1703/3000 [46:48<40:16,  1.86s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1704/3000 [46:50<44:43,  2.07s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1705/3000 [46:53<47:58,  2.22s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1706/3000 [46:54<39:27,  1.83s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1707/3000 [46:55<36:27,  1.69s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1708/3000 [46:56<33:44,  1.57s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1709/3000 [46:58<32:24,  1.51s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1710/3000 [46:59<30:50,  1.43s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1711/3000 [47:00<30:25,  1.42s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1712/3000 [47:02<35:39,  1.66s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1713/3000 [47:04<37:19,  1.74s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1714/3000 [47:07<43:57,  2.05s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1715/3000 [47:11<53:45,  2.51s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1716/3000 [47:12<46:32,  2.18s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1717/3000 [47:13<37:55,  1.77s/it][step=1665] episode=1665.0000 return=-115.9928 length=27.0000 global_step=40591.0000 loss=19.0840 policy_loss=-0.0000 value_loss=38.1681 entropy=0.0000
[step=1666] episode=1666.0000 return=-115.9915 length=26.0000 global_step=40617.0000 loss=6.2248 policy_loss=-0.0000 value_loss=12.4496 entropy=0.0000
[step=1667] episode=1667.0000 return=-115.9374 length=22.0000 global_step=40639.0000 loss=7.2662 policy_loss=-0.0000 value_loss=14.5324 entropy=0.0000
[step=1668] episode=1668.0000 return=-115.9935 length=28.0000 global_step=40667.0000 loss=24.6717 policy_loss=-0.0000 value_loss=49.3434 entropy=0.0000
[step=1669] episode=1669.0000 return=-115.9396 length=21.0000 global_step=40688.0000 loss=6.2843 policy_loss=-0.0000 value_loss=12.5687 entropy=0.0000
[step=1670] episode=1670.0000 return=-115.9877 length=13.0000 global_step=40701.0000 loss=38.0260 policy_loss=-0.0000 value_loss=76.0519 entropy=0.0000
[step=1671] episode=1671.0000 return=-115.9921 length=29.0000 global_step=40730.0000 loss=5.4291 policy_loss=-0.0000 value_loss=10.8583 entropy=0.0000
[step=1672] episode=1672.0000 return=-115.9768 length=20.0000 global_step=40750.0000 loss=6.5219 policy_loss=-0.0000 value_loss=13.0437 entropy=0.0000
[step=1673] episode=1673.0000 return=-115.9999 length=29.0000 global_step=40779.0000 loss=23.3793 policy_loss=0.0000 value_loss=46.7587 entropy=0.0000
[step=1674] episode=1674.0000 return=-115.9096 length=21.0000 global_step=40800.0000 loss=6.7073 policy_loss=0.0000 value_loss=13.4146 entropy=0.0000
[step=1675] episode=1675.0000 return=-115.8787 length=30.0000 global_step=40830.0000 loss=9.5071 policy_loss=0.0000 value_loss=19.0141 entropy=0.0000
[step=1676] episode=1676.0000 return=-115.9744 length=12.0000 global_step=40842.0000 loss=22.8825 policy_loss=-0.0000 value_loss=45.7650 entropy=0.0000
[step=1677] episode=1677.0000 return=-115.9824 length=20.0000 global_step=40862.0000 loss=5.7649 policy_loss=0.0000 value_loss=11.5298 entropy=0.0000
[step=1678] episode=1678.0000 return=-115.9933 length=46.0000 global_step=40908.0000 loss=106.8621 policy_loss=0.0000 value_loss=213.7241 entropy=0.0000
[step=1679] episode=1679.0000 return=-115.9997 length=18.0000 global_step=40926.0000 loss=8.8398 policy_loss=-0.0000 value_loss=17.6796 entropy=0.0000
[step=1680] episode=1680.0000 return=-115.9939 length=21.0000 global_step=40947.0000 loss=7.4829 policy_loss=-0.0000 value_loss=14.9659 entropy=0.0000
[step=1681] episode=1681.0000 return=-115.9988 length=19.0000 global_step=40966.0000 loss=7.1008 policy_loss=-0.0000 value_loss=14.2017 entropy=0.0000
[step=1682] episode=1682.0000 return=-115.9968 length=21.0000 global_step=40987.0000 loss=2.0769 policy_loss=-0.0000 value_loss=4.1537 entropy=0.0000
[step=1683] episode=1683.0000 return=-115.9986 length=12.0000 global_step=40999.0000 loss=7.6378 policy_loss=-0.0000 value_loss=15.2756 entropy=0.0000
[step=1684] episode=1684.0000 return=-115.9971 length=37.0000 global_step=41036.0000 loss=117.5021 policy_loss=-0.0000 value_loss=235.0042 entropy=0.0000
[step=1685] episode=1685.0000 return=-115.8850 length=19.0000 global_step=41055.0000 loss=31.2406 policy_loss=-0.0000 value_loss=62.4812 entropy=0.0000
[step=1686] episode=1686.0000 return=-115.9822 length=12.0000 global_step=41067.0000 loss=4.4027 policy_loss=-0.0000 value_loss=8.8055 entropy=0.0000
[step=1687] episode=1687.0000 return=-115.9886 length=29.0000 global_step=41096.0000 loss=39.1871 policy_loss=-0.0000 value_loss=78.3743 entropy=0.0000
[step=1688] episode=1688.0000 return=-115.7963 length=30.0000 global_step=41126.0000 loss=8.2381 policy_loss=-0.0000 value_loss=16.4761 entropy=0.0000
[step=1689] episode=1689.0000 return=-115.9837 length=21.0000 global_step=41147.0000 loss=10.0200 policy_loss=-0.0000 value_loss=20.0401 entropy=0.0000
[step=1690] episode=1690.0000 return=-115.9995 length=22.0000 global_step=41169.0000 loss=9.8666 policy_loss=-0.0000 value_loss=19.7332 entropy=0.0000
[step=1691] episode=1691.0000 return=-115.9830 length=21.0000 global_step=41190.0000 loss=7.3068 policy_loss=-0.0000 value_loss=14.6136 entropy=0.0000
[step=1692] episode=1692.0000 return=-115.7558 length=12.0000 global_step=41202.0000 loss=19.5404 policy_loss=-0.0000 value_loss=39.0808 entropy=0.0000
[step=1693] episode=1693.0000 return=-115.9823 length=35.0000 global_step=41237.0000 loss=116.2160 policy_loss=-0.0000 value_loss=232.4321 entropy=0.0000
[step=1694] episode=1694.0000 return=-115.9759 length=11.0000 global_step=41248.0000 loss=7.5006 policy_loss=-0.0000 value_loss=15.0011 entropy=0.0000
[step=1695] episode=1695.0000 return=-115.8675 length=22.0000 global_step=41270.0000 loss=6.9939 policy_loss=-0.0000 value_loss=13.9878 entropy=0.0000
[step=1696] episode=1696.0000 return=-115.9995 length=20.0000 global_step=41290.0000 loss=4.1944 policy_loss=-0.0000 value_loss=8.3888 entropy=0.0000
[step=1697] episode=1697.0000 return=-104.9161 length=4.0000 global_step=41294.0000 loss=40.3312 policy_loss=-0.0000 value_loss=80.6624 entropy=0.0000
[step=1698] episode=1698.0000 return=-115.9975 length=20.0000 global_step=41314.0000 loss=5.4876 policy_loss=-0.0000 value_loss=10.9752 entropy=0.0000
[step=1699] episode=1699.0000 return=-115.7948 length=13.0000 global_step=41327.0000 loss=5.9183 policy_loss=-0.0000 value_loss=11.8365 entropy=0.0000
[step=1700] episode=1700.0000 return=-115.9977 length=40.0000 global_step=41367.0000 loss=106.5098 policy_loss=-0.0000 value_loss=213.0196 entropy=0.0000
[step=1701] episode=1701.0000 return=-115.9970 length=21.0000 global_step=41388.0000 loss=23.3417 policy_loss=-0.0000 value_loss=46.6833 entropy=0.0000
[step=1702] episode=1702.0000 return=-115.9945 length=42.0000 global_step=41430.0000 loss=53.8291 policy_loss=-0.0000 value_loss=107.6582 entropy=0.0000
[step=1703] episode=1703.0000 return=-115.8634 length=28.0000 global_step=41458.0000 loss=66.7494 policy_loss=-0.0000 value_loss=133.4988 entropy=0.0000
[step=1704] episode=1704.0000 return=-115.9983 length=38.0000 global_step=41496.0000 loss=35.8776 policy_loss=-0.0000 value_loss=71.7551 entropy=0.0000
[step=1705] episode=1705.0000 return=-116.0000 length=38.0000 global_step=41534.0000 loss=31.9022 policy_loss=-0.0000 value_loss=63.8044 entropy=0.0000
[step=1706] episode=1706.0000 return=-115.7986 length=13.0000 global_step=41547.0000 loss=103.7969 policy_loss=-0.0000 value_loss=207.5939 entropy=0.0000
[step=1707] episode=1707.0000 return=-115.9978 length=20.0000 global_step=41567.0000 loss=8.0359 policy_loss=-0.0000 value_loss=16.0719 entropy=0.0000
[step=1708] episode=1708.0000 return=-115.8427 length=18.0000 global_step=41585.0000 loss=21.7822 policy_loss=-0.0000 value_loss=43.5645 entropy=0.0000
[step=1709] episode=1709.0000 return=-115.7959 length=20.0000 global_step=41605.0000 loss=45.6279 policy_loss=-0.0000 value_loss=91.2558 entropy=0.0000
[step=1710] episode=1710.0000 return=-115.9096 length=18.0000 global_step=41623.0000 loss=47.0875 policy_loss=-0.0000 value_loss=94.1750 entropy=0.0000
[step=1711] episode=1711.0000 return=-115.9096 length=21.0000 global_step=41644.0000 loss=8.0344 policy_loss=-0.0000 value_loss=16.0688 entropy=0.0000
[step=1712] episode=1712.0000 return=-115.9990 length=34.0000 global_step=41678.0000 loss=24.1526 policy_loss=-0.0000 value_loss=48.3053 entropy=0.0000
[step=1713] episode=1713.0000 return=-115.9963 length=29.0000 global_step=41707.0000 loss=95.5159 policy_loss=-0.0000 value_loss=191.0317 entropy=0.0000
[step=1714] episode=1714.0000 return=-115.9999 length=41.0000 global_step=41748.0000 loss=39.3104 policy_loss=-0.0000 value_loss=78.6209 entropy=0.0000
[step=1715] episode=1715.0000 return=-116.0000 length=54.0000 global_step=41802.0000 loss=69.0975 policy_loss=-0.0000 value_loss=138.1951 entropy=0.0000
[step=1716] episode=1716.0000 return=-115.9898 length=20.0000 global_step=41822.0000 loss=63.7768 policy_loss=-0.0000 value_loss=127.5535 entropy=0.0000
[step=1717] episode=1717.0000 return=-115.0594 length=12.0000 global_step=41834.0000 loss=89.5693 policy_loss=-0.0000 value_loss=179.1385 entropy=0.0000
[step=1718] episode=1718.0000 return=-115.9949 length=20.0000 global_step=41854.0000 loss=72.1678 policy_loss=-0.0000 value_loss=144.3356 entropy=0.0000
a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1718/3000 [47:14<35:39,  1.67s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1719/3000 [47:16<36:57,  1.73s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1720/3000 [47:18<35:13,  1.65s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1721/3000 [47:20<36:23,  1.71s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1722/3000 [47:21<36:57,  1.74s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1723/3000 [47:23<35:46,  1.68s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1724/3000 [47:24<33:41,  1.58s/it]a2c_tuned train:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1725/3000 [47:25<29:17,  1.38s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1726/3000 [47:27<29:11,  1.37s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1727/3000 [47:28<29:34,  1.39s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1728/3000 [47:30<32:54,  1.55s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1729/3000 [47:31<31:59,  1.51s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1730/3000 [47:34<38:59,  1.84s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1731/3000 [47:36<38:47,  1.83s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1732/3000 [47:38<41:48,  1.98s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1733/3000 [47:39<34:09,  1.62s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1734/3000 [47:41<39:39,  1.88s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1735/3000 [47:43<36:28,  1.73s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1736/3000 [47:44<34:06,  1.62s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1737/3000 [47:45<29:21,  1.39s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1738/3000 [47:47<35:56,  1.71s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1739/3000 [47:49<37:43,  1.79s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1740/3000 [47:51<35:09,  1.67s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1741/3000 [47:53<39:48,  1.90s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1742/3000 [47:55<37:00,  1.77s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1743/3000 [47:55<30:45,  1.47s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1744/3000 [47:57<30:24,  1.45s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1745/3000 [47:58<29:50,  1.43s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1746/3000 [48:01<39:20,  1.88s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1747/3000 [48:03<38:40,  1.85s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1748/3000 [48:04<35:18,  1.69s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1749/3000 [48:05<29:40,  1.42s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1750/3000 [48:06<28:18,  1.36s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1751/3000 [48:08<31:58,  1.54s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1752/3000 [48:10<33:17,  1.60s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1753/3000 [48:11<28:07,  1.35s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1754/3000 [48:12<27:39,  1.33s/it]a2c_tuned train:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1755/3000 [48:14<33:25,  1.61s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1756/3000 [48:16<35:54,  1.73s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1757/3000 [48:18<34:37,  1.67s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1758/3000 [48:20<36:22,  1.76s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1759/3000 [48:22<37:06,  1.79s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1760/3000 [48:22<31:18,  1.51s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1761/3000 [48:24<30:17,  1.47s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1762/3000 [48:25<29:28,  1.43s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1763/3000 [48:27<34:15,  1.66s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1764/3000 [48:28<28:52,  1.40s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1765/3000 [48:30<32:42,  1.59s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1766/3000 [48:32<30:48,  1.50s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1767/3000 [48:33<29:43,  1.45s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1768/3000 [48:35<33:25,  1.63s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1769/3000 [48:36<28:03,  1.37s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1770/3000 [48:38<34:46,  1.70s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1771/3000 [48:39<32:18,  1.58s/it][step=1719] episode=1719.0000 return=-115.9385 length=29.0000 global_step=41883.0000 loss=254.2173 policy_loss=-0.0000 value_loss=508.4345 entropy=0.0000
[step=1720] episode=1720.0000 return=-115.8274 length=21.0000 global_step=41904.0000 loss=29.0111 policy_loss=-0.0000 value_loss=58.0221 entropy=0.0000
[step=1721] episode=1721.0000 return=-115.9982 length=27.0000 global_step=41931.0000 loss=6.2167 policy_loss=-0.0000 value_loss=12.4335 entropy=0.0000
[step=1722] episode=1722.0000 return=-115.9837 length=27.0000 global_step=41958.0000 loss=33.7400 policy_loss=-0.0000 value_loss=67.4801 entropy=0.0000
[step=1723] episode=1723.0000 return=-115.9385 length=22.0000 global_step=41980.0000 loss=103.3036 policy_loss=-0.0000 value_loss=206.6071 entropy=0.0000
[step=1724] episode=1724.0000 return=-115.9995 length=20.0000 global_step=42000.0000 loss=44.3248 policy_loss=-0.0000 value_loss=88.6495 entropy=0.0000
[step=1725] episode=1725.0000 return=-115.7984 length=13.0000 global_step=42013.0000 loss=11.8626 policy_loss=-0.0000 value_loss=23.7253 entropy=0.0000
[step=1726] episode=1726.0000 return=-115.9901 length=20.0000 global_step=42033.0000 loss=109.8321 policy_loss=-0.0000 value_loss=219.6641 entropy=0.0000
[step=1727] episode=1727.0000 return=-115.9968 length=21.0000 global_step=42054.0000 loss=165.8470 policy_loss=-0.0000 value_loss=331.6940 entropy=0.0000
[step=1728] episode=1728.0000 return=-115.9919 length=28.0000 global_step=42082.0000 loss=72.7598 policy_loss=-0.0000 value_loss=145.5196 entropy=0.0000
[step=1729] episode=1729.0000 return=-115.9867 length=21.0000 global_step=42103.0000 loss=52.5602 policy_loss=-0.0000 value_loss=105.1204 entropy=0.0000
[step=1730] episode=1730.0000 return=-115.9923 length=38.0000 global_step=42141.0000 loss=85.1643 policy_loss=-0.0000 value_loss=170.3287 entropy=0.0000
[step=1731] episode=1731.0000 return=-115.9970 length=27.0000 global_step=42168.0000 loss=130.2491 policy_loss=-0.0000 value_loss=260.4983 entropy=0.0000
[step=1732] episode=1732.0000 return=-115.9997 length=33.0000 global_step=42201.0000 loss=16.3933 policy_loss=-0.0000 value_loss=32.7866 entropy=0.0000
[step=1733] episode=1733.0000 return=-115.8378 length=11.0000 global_step=42212.0000 loss=8.4648 policy_loss=-0.0000 value_loss=16.9295 entropy=0.0000
[step=1734] episode=1734.0000 return=-115.9994 length=36.0000 global_step=42248.0000 loss=270.2340 policy_loss=-0.0000 value_loss=540.4680 entropy=0.0000
[step=1735] episode=1735.0000 return=-115.9745 length=20.0000 global_step=42268.0000 loss=37.9980 policy_loss=-0.0000 value_loss=75.9960 entropy=0.0000
[step=1736] episode=1736.0000 return=-115.9988 length=20.0000 global_step=42288.0000 loss=31.1377 policy_loss=-0.0000 value_loss=62.2754 entropy=0.0000
[step=1737] episode=1737.0000 return=-115.7133 length=13.0000 global_step=42301.0000 loss=203.6271 policy_loss=-0.0000 value_loss=407.2542 entropy=0.0000
[step=1738] episode=1738.0000 return=-115.9948 length=36.0000 global_step=42337.0000 loss=32.7786 policy_loss=-0.0000 value_loss=65.5572 entropy=0.0000
[step=1739] episode=1739.0000 return=-115.7929 length=30.0000 global_step=42367.0000 loss=30.0124 policy_loss=-0.0000 value_loss=60.0248 entropy=0.0000
[step=1740] episode=1740.0000 return=-115.8165 length=20.0000 global_step=42387.0000 loss=16.1374 policy_loss=-0.0000 value_loss=32.2747 entropy=0.0000
[step=1741] episode=1741.0000 return=-115.9944 length=34.0000 global_step=42421.0000 loss=87.5021 policy_loss=-0.0000 value_loss=175.0041 entropy=0.0000
[step=1742] episode=1742.0000 return=-115.8994 length=22.0000 global_step=42443.0000 loss=7.9638 policy_loss=-0.0000 value_loss=15.9276 entropy=0.0000
[step=1743] episode=1743.0000 return=-115.9091 length=12.0000 global_step=42455.0000 loss=65.2455 policy_loss=-0.0000 value_loss=130.4910 entropy=0.0000
[step=1744] episode=1744.0000 return=-115.9886 length=21.0000 global_step=42476.0000 loss=5.3846 policy_loss=-0.0000 value_loss=10.7691 entropy=0.0000
[step=1745] episode=1745.0000 return=-115.9987 length=20.0000 global_step=42496.0000 loss=32.4805 policy_loss=-0.0000 value_loss=64.9611 entropy=0.0000
[step=1746] episode=1746.0000 return=-115.8870 length=45.0000 global_step=42541.0000 loss=83.8067 policy_loss=-0.0000 value_loss=167.6133 entropy=0.0000
[step=1747] episode=1747.0000 return=-115.9912 length=26.0000 global_step=42567.0000 loss=11.8310 policy_loss=-0.0000 value_loss=23.6621 entropy=0.0000
[step=1748] episode=1748.0000 return=-115.9974 length=20.0000 global_step=42587.0000 loss=62.1520 policy_loss=-0.0000 value_loss=124.3039 entropy=0.0000
[step=1749] episode=1749.0000 return=-115.9958 length=12.0000 global_step=42599.0000 loss=81.9916 policy_loss=-0.0000 value_loss=163.9832 entropy=0.0000
[step=1750] episode=1750.0000 return=-115.7690 length=18.0000 global_step=42617.0000 loss=7.8626 policy_loss=-0.0000 value_loss=15.7251 entropy=0.0000
[step=1751] episode=1751.0000 return=-115.9881 length=28.0000 global_step=42645.0000 loss=293.9308 policy_loss=-0.0000 value_loss=587.8616 entropy=0.0000
[step=1752] episode=1752.0000 return=-115.9471 length=26.0000 global_step=42671.0000 loss=40.9991 policy_loss=-0.0000 value_loss=81.9982 entropy=0.0000
[step=1753] episode=1753.0000 return=-115.8766 length=12.0000 global_step=42683.0000 loss=313.8846 policy_loss=-0.0000 value_loss=627.7692 entropy=0.0000
[step=1754] episode=1754.0000 return=-115.8870 length=19.0000 global_step=42702.0000 loss=88.5376 policy_loss=-0.0000 value_loss=177.0752 entropy=0.0000
[step=1755] episode=1755.0000 return=-115.9840 length=33.0000 global_step=42735.0000 loss=59.5315 policy_loss=-0.0000 value_loss=119.0629 entropy=0.0000
[step=1756] episode=1756.0000 return=-115.9847 length=30.0000 global_step=42765.0000 loss=187.0639 policy_loss=-0.0000 value_loss=374.1277 entropy=0.0000
[step=1757] episode=1757.0000 return=-115.9941 length=22.0000 global_step=42787.0000 loss=8.4470 policy_loss=-0.0000 value_loss=16.8940 entropy=0.0000
[step=1758] episode=1758.0000 return=-116.0000 length=29.0000 global_step=42816.0000 loss=52.9239 policy_loss=-0.0000 value_loss=105.8479 entropy=0.0000
[step=1759] episode=1759.0000 return=-115.9989 length=28.0000 global_step=42844.0000 loss=128.6622 policy_loss=-0.0000 value_loss=257.3245 entropy=0.0000
[step=1760] episode=1760.0000 return=-115.9657 length=12.0000 global_step=42856.0000 loss=64.8383 policy_loss=-0.0000 value_loss=129.6765 entropy=0.0000
[step=1761] episode=1761.0000 return=-115.9989 length=21.0000 global_step=42877.0000 loss=126.3626 policy_loss=-0.0000 value_loss=252.7252 entropy=0.0000
[step=1762] episode=1762.0000 return=-115.9992 length=21.0000 global_step=42898.0000 loss=152.3168 policy_loss=-0.0000 value_loss=304.6336 entropy=0.0000
[step=1763] episode=1763.0000 return=-115.9998 length=34.0000 global_step=42932.0000 loss=134.8327 policy_loss=-0.0000 value_loss=269.6655 entropy=0.0000
[step=1764] episode=1764.0000 return=-115.9991 length=12.0000 global_step=42944.0000 loss=213.0192 policy_loss=-0.0000 value_loss=426.0383 entropy=0.0000
[step=1765] episode=1765.0000 return=-115.9989 length=30.0000 global_step=42974.0000 loss=179.2169 policy_loss=-0.0000 value_loss=358.4337 entropy=0.0000
[step=1766] episode=1766.0000 return=-115.7345 length=18.0000 global_step=42992.0000 loss=91.3469 policy_loss=-0.0000 value_loss=182.6937 entropy=0.0000
[step=1767] episode=1767.0000 return=-115.9651 length=20.0000 global_step=43012.0000 loss=82.9048 policy_loss=-0.0000 value_loss=165.8095 entropy=0.0000
[step=1768] episode=1768.0000 return=-115.9840 length=31.0000 global_step=43043.0000 loss=354.2977 policy_loss=-0.0000 value_loss=708.5953 entropy=0.0000
[step=1769] episode=1769.0000 return=-115.9563 length=11.0000 global_step=43054.0000 loss=21.2786 policy_loss=-0.0000 value_loss=42.5572 entropy=0.0000
[step=1770] episode=1770.0000 return=-115.8870 length=36.0000 global_step=43090.0000 loss=14.9393 policy_loss=-0.0000 value_loss=29.8786 entropy=0.0000
[step=1771] episode=1771.0000 return=-115.8870 length=19.0000 global_step=43109.0000 loss=174.0945 policy_loss=-0.0000 value_loss=348.1889 entropy=0.0000
a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1772/3000 [48:41<33:52,  1.66s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1773/3000 [48:43<35:43,  1.75s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1774/3000 [48:44<30:13,  1.48s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1775/3000 [48:46<33:26,  1.64s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1776/3000 [48:48<32:22,  1.59s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1777/3000 [48:49<30:38,  1.50s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1778/3000 [48:51<32:50,  1.61s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1779/3000 [48:53<35:13,  1.73s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1780/3000 [48:54<32:51,  1.62s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1781/3000 [48:55<31:19,  1.54s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1782/3000 [48:56<27:19,  1.35s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1783/3000 [48:57<21:07,  1.04s/it]a2c_tuned train:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1784/3000 [48:58<23:17,  1.15s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1785/3000 [49:00<28:02,  1.38s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1786/3000 [49:01<28:29,  1.41s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1787/3000 [49:03<28:06,  1.39s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1788/3000 [49:05<31:48,  1.57s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1789/3000 [49:07<33:49,  1.68s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1790/3000 [49:09<37:33,  1.86s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1791/3000 [49:10<35:02,  1.74s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1792/3000 [49:12<33:01,  1.64s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1793/3000 [49:14<34:16,  1.70s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1794/3000 [49:15<29:19,  1.46s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1795/3000 [49:16<30:44,  1.53s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1796/3000 [49:17<26:28,  1.32s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1797/3000 [49:19<30:02,  1.50s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1798/3000 [49:20<28:50,  1.44s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1799/3000 [49:22<27:29,  1.37s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1800/3000 [49:24<33:22,  1.67s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1801/3000 [49:25<32:04,  1.61s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1802/3000 [49:27<30:15,  1.52s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1803/3000 [49:29<36:41,  1.84s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1804/3000 [49:31<33:23,  1.67s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1805/3000 [49:34<44:44,  2.25s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1806/3000 [49:36<43:41,  2.20s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1807/3000 [49:38<41:12,  2.07s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1808/3000 [49:39<37:03,  1.87s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1809/3000 [49:41<37:19,  1.88s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1810/3000 [49:43<37:20,  1.88s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1811/3000 [49:45<37:42,  1.90s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1812/3000 [49:47<39:27,  1.99s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1813/3000 [49:48<32:09,  1.63s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1814/3000 [49:49<30:26,  1.54s/it]a2c_tuned train:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1815/3000 [49:50<26:31,  1.34s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1816/3000 [49:52<27:16,  1.38s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1817/3000 [49:54<31:19,  1.59s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1818/3000 [49:55<26:56,  1.37s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1819/3000 [49:56<26:17,  1.34s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1820/3000 [49:57<26:24,  1.34s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1821/3000 [49:58<23:29,  1.20s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1822/3000 [50:00<27:03,  1.38s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1823/3000 [50:01<27:22,  1.40s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1824/3000 [50:03<30:06,  1.54s/it][step=1772] episode=1772.0000 return=-115.9838 length=28.0000 global_step=43137.0000 loss=124.6025 policy_loss=-0.0000 value_loss=249.2050 entropy=0.0000
[step=1773] episode=1773.0000 return=-115.9732 length=29.0000 global_step=43166.0000 loss=15.2993 policy_loss=-0.0000 value_loss=30.5987 entropy=0.0000
[step=1774] episode=1774.0000 return=-115.7558 length=13.0000 global_step=43179.0000 loss=8.4840 policy_loss=-0.0000 value_loss=16.9680 entropy=0.0000
[step=1775] episode=1775.0000 return=-115.9999 length=29.0000 global_step=43208.0000 loss=165.2821 policy_loss=-0.0000 value_loss=330.5642 entropy=0.0000
[step=1776] episode=1776.0000 return=-115.9982 length=21.0000 global_step=43229.0000 loss=25.8377 policy_loss=-0.0000 value_loss=51.6754 entropy=0.0000
[step=1777] episode=1777.0000 return=-115.8412 length=20.0000 global_step=43249.0000 loss=50.7363 policy_loss=-0.0000 value_loss=101.4726 entropy=0.0000
[step=1778] episode=1778.0000 return=-115.9977 length=28.0000 global_step=43277.0000 loss=21.0453 policy_loss=-0.0000 value_loss=42.0906 entropy=0.0000
[step=1779] episode=1779.0000 return=-115.9829 length=30.0000 global_step=43307.0000 loss=14.1985 policy_loss=-0.0000 value_loss=28.3970 entropy=0.0000
[step=1780] episode=1780.0000 return=-115.9718 length=19.0000 global_step=43326.0000 loss=14.2048 policy_loss=-0.0000 value_loss=28.4097 entropy=0.0000
[step=1781] episode=1781.0000 return=-115.9442 length=21.0000 global_step=43347.0000 loss=3.8287 policy_loss=-0.0000 value_loss=7.6574 entropy=0.0000
[step=1782] episode=1782.0000 return=-115.9384 length=13.0000 global_step=43360.0000 loss=10.5876 policy_loss=-0.0000 value_loss=21.1751 entropy=0.0000
[step=1783] episode=1783.0000 return=-104.9834 length=5.0000 global_step=43365.0000 loss=13.1013 policy_loss=-0.0000 value_loss=26.2025 entropy=0.0000
[step=1784] episode=1784.0000 return=-115.9096 length=21.0000 global_step=43386.0000 loss=30.1772 policy_loss=-0.0000 value_loss=60.3545 entropy=0.0000
[step=1785] episode=1785.0000 return=-115.9375 length=28.0000 global_step=43414.0000 loss=7.7925 policy_loss=-0.0000 value_loss=15.5850 entropy=0.0000
[step=1786] episode=1786.0000 return=-115.9096 length=22.0000 global_step=43436.0000 loss=53.1242 policy_loss=-0.0000 value_loss=106.2485 entropy=0.0000
[step=1787] episode=1787.0000 return=-115.8017 length=20.0000 global_step=43456.0000 loss=140.0028 policy_loss=-0.0000 value_loss=280.0057 entropy=0.0000
[step=1788] episode=1788.0000 return=-115.9984 length=30.0000 global_step=43486.0000 loss=15.7081 policy_loss=-0.0000 value_loss=31.4163 entropy=0.0000
[step=1789] episode=1789.0000 return=-115.9840 length=29.0000 global_step=43515.0000 loss=27.9940 policy_loss=-0.0000 value_loss=55.9881 entropy=0.0000
[step=1790] episode=1790.0000 return=-115.9724 length=34.0000 global_step=43549.0000 loss=30.0624 policy_loss=-0.0000 value_loss=60.1247 entropy=0.0000
[step=1791] episode=1791.0000 return=-115.8870 length=21.0000 global_step=43570.0000 loss=8.6236 policy_loss=-0.0000 value_loss=17.2473 entropy=0.0000
[step=1792] episode=1792.0000 return=-115.9960 length=20.0000 global_step=43590.0000 loss=9.2443 policy_loss=-0.0000 value_loss=18.4886 entropy=0.0000
[step=1793] episode=1793.0000 return=-115.9096 length=29.0000 global_step=43619.0000 loss=4.9803 policy_loss=0.0000 value_loss=9.9607 entropy=0.0000
[step=1794] episode=1794.0000 return=-115.7355 length=13.0000 global_step=43632.0000 loss=36.5534 policy_loss=-0.0000 value_loss=73.1068 entropy=0.0000
[step=1795] episode=1795.0000 return=-115.9986 length=26.0000 global_step=43658.0000 loss=23.0298 policy_loss=-0.0000 value_loss=46.0595 entropy=0.0000
[step=1796] episode=1796.0000 return=-109.7825 length=12.0000 global_step=43670.0000 loss=17.3436 policy_loss=-0.0000 value_loss=34.6872 entropy=0.0000
[step=1797] episode=1797.0000 return=-115.9985 length=29.0000 global_step=43699.0000 loss=66.1168 policy_loss=0.0000 value_loss=132.2335 entropy=0.0000
[step=1798] episode=1798.0000 return=-115.9797 length=19.0000 global_step=43718.0000 loss=7.0697 policy_loss=-0.0000 value_loss=14.1394 entropy=0.0000
[step=1799] episode=1799.0000 return=-115.9997 length=18.0000 global_step=43736.0000 loss=7.2892 policy_loss=-0.0000 value_loss=14.5784 entropy=0.0000
[step=1800] episode=1800.0000 return=-115.9102 length=34.0000 global_step=43770.0000 loss=18.4689 policy_loss=0.0000 value_loss=36.9377 entropy=0.0000
[step=1801] episode=1801.0000 return=-115.8870 length=22.0000 global_step=43792.0000 loss=17.1950 policy_loss=-0.0000 value_loss=34.3900 entropy=0.0001
[step=1802] episode=1802.0000 return=-115.7827 length=19.0000 global_step=43811.0000 loss=41.6225 policy_loss=-0.0001 value_loss=83.2450 entropy=0.0001
[step=1803] episode=1803.0000 return=-115.9892 length=38.0000 global_step=43849.0000 loss=29.4963 policy_loss=0.0000 value_loss=58.9925 entropy=0.0001
[step=1804] episode=1804.0000 return=-115.9971 length=19.0000 global_step=43868.0000 loss=6.7711 policy_loss=-0.0000 value_loss=13.5422 entropy=0.0001
[step=1805] episode=1805.0000 return=-115.9881 length=54.0000 global_step=43922.0000 loss=138.9266 policy_loss=0.0001 value_loss=277.8531 entropy=0.0001
[step=1806] episode=1806.0000 return=-115.9934 length=30.0000 global_step=43952.0000 loss=14.6687 policy_loss=0.0000 value_loss=29.3374 entropy=0.0000
[step=1807] episode=1807.0000 return=-115.9884 length=26.0000 global_step=43978.0000 loss=20.4939 policy_loss=-0.0000 value_loss=40.9877 entropy=0.0000
[step=1808] episode=1808.0000 return=-115.9998 length=21.0000 global_step=43999.0000 loss=50.6408 policy_loss=-0.0000 value_loss=101.2816 entropy=0.0000
[step=1809] episode=1809.0000 return=-115.9764 length=29.0000 global_step=44028.0000 loss=18.2530 policy_loss=-0.0000 value_loss=36.5061 entropy=0.0000
[step=1810] episode=1810.0000 return=-115.9976 length=28.0000 global_step=44056.0000 loss=14.6965 policy_loss=-0.0000 value_loss=29.3930 entropy=0.0000
[step=1811] episode=1811.0000 return=-115.9929 length=30.0000 global_step=44086.0000 loss=20.8552 policy_loss=-0.0000 value_loss=41.7105 entropy=0.0000
[step=1812] episode=1812.0000 return=-115.9986 length=34.0000 global_step=44120.0000 loss=78.5532 policy_loss=-0.0000 value_loss=157.1064 entropy=0.0000
[step=1813] episode=1813.0000 return=-115.8368 length=11.0000 global_step=44131.0000 loss=9.2383 policy_loss=-0.0000 value_loss=18.4765 entropy=0.0000
[step=1814] episode=1814.0000 return=-115.9366 length=20.0000 global_step=44151.0000 loss=14.0862 policy_loss=-0.0000 value_loss=28.1724 entropy=0.0000
[step=1815] episode=1815.0000 return=-115.9946 length=12.0000 global_step=44163.0000 loss=25.8335 policy_loss=-0.0000 value_loss=51.6670 entropy=0.0000
[step=1816] episode=1816.0000 return=-115.9776 length=21.0000 global_step=44184.0000 loss=3.8461 policy_loss=-0.0000 value_loss=7.6921 entropy=0.0000
[step=1817] episode=1817.0000 return=-115.9998 length=31.0000 global_step=44215.0000 loss=18.3697 policy_loss=-0.0000 value_loss=36.7393 entropy=0.0000
[step=1818] episode=1818.0000 return=-115.9995 length=12.0000 global_step=44227.0000 loss=42.0984 policy_loss=-0.0000 value_loss=84.1967 entropy=0.0000
[step=1819] episode=1819.0000 return=-115.8862 length=18.0000 global_step=44245.0000 loss=8.8823 policy_loss=-0.0000 value_loss=17.7646 entropy=0.0000
[step=1820] episode=1820.0000 return=-115.9998 length=21.0000 global_step=44266.0000 loss=8.3841 policy_loss=-0.0000 value_loss=16.7683 entropy=0.0000
[step=1821] episode=1821.0000 return=-115.9958 length=11.0000 global_step=44277.0000 loss=8.9103 policy_loss=-0.0000 value_loss=17.8206 entropy=0.0000
[step=1822] episode=1822.0000 return=-115.9996 length=27.0000 global_step=44304.0000 loss=62.4033 policy_loss=-0.0000 value_loss=124.8067 entropy=0.0000
[step=1823] episode=1823.0000 return=-115.9966 length=21.0000 global_step=44325.0000 loss=7.9220 policy_loss=-0.0000 value_loss=15.8440 entropy=0.0000
[step=1824] episode=1824.0000 return=-115.9955 length=29.0000 global_step=44354.0000 loss=6.0266 policy_loss=-0.0000 value_loss=12.0532 entropy=0.0000
a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1825/3000 [50:04<26:18,  1.34s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1826/3000 [50:06<29:58,  1.53s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1827/3000 [50:07<26:06,  1.34s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1828/3000 [50:08<23:12,  1.19s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1829/3000 [50:10<30:23,  1.56s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1830/3000 [50:12<30:02,  1.54s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1831/3000 [50:13<28:28,  1.46s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1832/3000 [50:14<24:30,  1.26s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1833/3000 [50:15<24:56,  1.28s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1834/3000 [50:18<35:01,  1.80s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1835/3000 [50:20<32:50,  1.69s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1836/3000 [50:21<30:46,  1.59s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1837/3000 [50:23<33:22,  1.72s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1838/3000 [50:24<31:29,  1.63s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1839/3000 [50:26<29:44,  1.54s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1840/3000 [50:28<31:13,  1.62s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1841/3000 [50:30<37:45,  1.95s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1842/3000 [50:32<34:48,  1.80s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1843/3000 [50:33<28:57,  1.50s/it]a2c_tuned train:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1844/3000 [50:34<28:06,  1.46s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1845/3000 [50:35<27:34,  1.43s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1846/3000 [50:37<31:23,  1.63s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1847/3000 [50:39<30:10,  1.57s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1848/3000 [50:41<32:04,  1.67s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1849/3000 [50:42<27:35,  1.44s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1850/3000 [50:43<24:53,  1.30s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1851/3000 [50:44<25:38,  1.34s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1852/3000 [50:46<28:38,  1.50s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1853/3000 [50:48<31:11,  1.63s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1854/3000 [50:49<26:09,  1.37s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1855/3000 [50:50<26:14,  1.38s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1856/3000 [50:51<26:30,  1.39s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1857/3000 [50:53<29:14,  1.54s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1858/3000 [50:55<27:31,  1.45s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1859/3000 [50:56<26:41,  1.40s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1860/3000 [50:58<32:58,  1.74s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1861/3000 [50:59<27:59,  1.47s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1862/3000 [51:01<27:44,  1.46s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1863/3000 [51:04<36:41,  1.94s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1864/3000 [51:06<36:16,  1.92s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1865/3000 [51:07<36:08,  1.91s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1866/3000 [51:08<30:40,  1.62s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1867/3000 [51:10<28:40,  1.52s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1868/3000 [51:11<27:32,  1.46s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1869/3000 [51:13<29:54,  1.59s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1870/3000 [51:14<25:41,  1.36s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1871/3000 [51:15<27:25,  1.46s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1872/3000 [51:17<28:42,  1.53s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1873/3000 [51:19<31:35,  1.68s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1874/3000 [51:21<33:24,  1.78s/it]a2c_tuned train:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1875/3000 [51:23<31:10,  1.66s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1876/3000 [51:24<32:21,  1.73s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1877/3000 [51:26<30:23,  1.62s/it][step=1825] episode=1825.0000 return=-115.8352 length=13.0000 global_step=44367.0000 loss=81.3183 policy_loss=-0.0000 value_loss=162.6366 entropy=0.0000
[step=1826] episode=1826.0000 return=-115.9904 length=30.0000 global_step=44397.0000 loss=16.0356 policy_loss=-0.0000 value_loss=32.0712 entropy=0.0000
[step=1827] episode=1827.0000 return=-115.8187 length=13.0000 global_step=44410.0000 loss=50.3528 policy_loss=-0.0000 value_loss=100.7055 entropy=0.0000
[step=1828] episode=1828.0000 return=-115.3707 length=12.0000 global_step=44422.0000 loss=23.5694 policy_loss=-0.0000 value_loss=47.1388 entropy=0.0000
[step=1829] episode=1829.0000 return=-115.9977 length=36.0000 global_step=44458.0000 loss=95.0485 policy_loss=-0.0000 value_loss=190.0971 entropy=0.0000
[step=1830] episode=1830.0000 return=-116.0000 length=22.0000 global_step=44480.0000 loss=107.9545 policy_loss=-0.0000 value_loss=215.9090 entropy=0.0000
[step=1831] episode=1831.0000 return=-115.9019 length=20.0000 global_step=44500.0000 loss=42.4223 policy_loss=-0.0000 value_loss=84.8446 entropy=0.0000
[step=1832] episode=1832.0000 return=-115.9835 length=12.0000 global_step=44512.0000 loss=16.5763 policy_loss=-0.0000 value_loss=33.1525 entropy=0.0000
[step=1833] episode=1833.0000 return=-115.8515 length=21.0000 global_step=44533.0000 loss=35.6390 policy_loss=-0.0000 value_loss=71.2780 entropy=0.0000
[step=1834] episode=1834.0000 return=-115.9930 length=44.0000 global_step=44577.0000 loss=65.7494 policy_loss=-0.0000 value_loss=131.4988 entropy=0.0000
[step=1835] episode=1835.0000 return=-115.9389 length=21.0000 global_step=44598.0000 loss=30.1292 policy_loss=-0.0000 value_loss=60.2584 entropy=0.0000
[step=1836] episode=1836.0000 return=-115.9328 length=19.0000 global_step=44617.0000 loss=43.5647 policy_loss=-0.0000 value_loss=87.1295 entropy=0.0000
[step=1837] episode=1837.0000 return=-116.0000 length=30.0000 global_step=44647.0000 loss=20.1337 policy_loss=-0.0000 value_loss=40.2673 entropy=0.0000
[step=1838] episode=1838.0000 return=-115.9985 length=20.0000 global_step=44667.0000 loss=7.2458 policy_loss=-0.0000 value_loss=14.4916 entropy=0.0000
[step=1839] episode=1839.0000 return=-115.9958 length=19.0000 global_step=44686.0000 loss=5.5533 policy_loss=-0.0000 value_loss=11.1066 entropy=0.0000
[step=1840] episode=1840.0000 return=-115.9536 length=26.0000 global_step=44712.0000 loss=36.3445 policy_loss=-0.0000 value_loss=72.6890 entropy=0.0000
[step=1841] episode=1841.0000 return=-115.9967 length=42.0000 global_step=44754.0000 loss=80.6495 policy_loss=-0.0000 value_loss=161.2990 entropy=0.0000
[step=1842] episode=1842.0000 return=-115.9823 length=21.0000 global_step=44775.0000 loss=65.6945 policy_loss=-0.0000 value_loss=131.3891 entropy=0.0000
[step=1843] episode=1843.0000 return=-115.9919 length=12.0000 global_step=44787.0000 loss=100.0482 policy_loss=-0.0000 value_loss=200.0965 entropy=0.0000
[step=1844] episode=1844.0000 return=-115.9983 length=20.0000 global_step=44807.0000 loss=10.4784 policy_loss=-0.0000 value_loss=20.9569 entropy=0.0000
[step=1845] episode=1845.0000 return=-115.9645 length=20.0000 global_step=44827.0000 loss=17.8222 policy_loss=-0.0000 value_loss=35.6443 entropy=0.0000
[step=1846] episode=1846.0000 return=-115.9969 length=30.0000 global_step=44857.0000 loss=83.7296 policy_loss=-0.0000 value_loss=167.4593 entropy=0.0000
[step=1847] episode=1847.0000 return=-115.9909 length=21.0000 global_step=44878.0000 loss=12.5258 policy_loss=-0.0000 value_loss=25.0516 entropy=0.0000
[step=1848] episode=1848.0000 return=-115.9998 length=28.0000 global_step=44906.0000 loss=22.0740 policy_loss=-0.0000 value_loss=44.1481 entropy=0.0000
[step=1849] episode=1849.0000 return=-115.9770 length=13.0000 global_step=44919.0000 loss=99.9796 policy_loss=-0.0000 value_loss=199.9593 entropy=0.0000
[step=1850] episode=1850.0000 return=-115.8374 length=13.0000 global_step=44932.0000 loss=93.3168 policy_loss=-0.0000 value_loss=186.6335 entropy=0.0000
[step=1851] episode=1851.0000 return=-115.7353 length=21.0000 global_step=44953.0000 loss=14.9638 policy_loss=-0.0000 value_loss=29.9277 entropy=0.0000
[step=1852] episode=1852.0000 return=-116.0000 length=28.0000 global_step=44981.0000 loss=24.7576 policy_loss=-0.0000 value_loss=49.5153 entropy=0.0000
[step=1853] episode=1853.0000 return=-115.9972 length=30.0000 global_step=45011.0000 loss=56.8553 policy_loss=-0.0000 value_loss=113.7105 entropy=0.0000
[step=1854] episode=1854.0000 return=-115.8192 length=11.0000 global_step=45022.0000 loss=5.9664 policy_loss=-0.0000 value_loss=11.9328 entropy=0.0000
[step=1855] episode=1855.0000 return=-115.9944 length=20.0000 global_step=45042.0000 loss=17.8664 policy_loss=-0.0000 value_loss=35.7328 entropy=0.0000
[step=1856] episode=1856.0000 return=-115.9886 length=21.0000 global_step=45063.0000 loss=4.5176 policy_loss=0.0000 value_loss=9.0353 entropy=0.0000
[step=1857] episode=1857.0000 return=-115.9909 length=28.0000 global_step=45091.0000 loss=17.3949 policy_loss=0.0000 value_loss=34.7898 entropy=0.0000
[step=1858] episode=1858.0000 return=-115.9999 length=20.0000 global_step=45111.0000 loss=29.5151 policy_loss=-0.0000 value_loss=59.0302 entropy=0.0001
[step=1859] episode=1859.0000 return=-115.8598 length=19.0000 global_step=45130.0000 loss=41.1248 policy_loss=-0.0000 value_loss=82.2497 entropy=0.0001
[step=1860] episode=1860.0000 return=-115.9754 length=36.0000 global_step=45166.0000 loss=18.9638 policy_loss=-0.0000 value_loss=37.9276 entropy=0.0001
[step=1861] episode=1861.0000 return=-115.9990 length=12.0000 global_step=45178.0000 loss=26.4343 policy_loss=-0.0000 value_loss=52.8687 entropy=0.0000
[step=1862] episode=1862.0000 return=-115.9968 length=21.0000 global_step=45199.0000 loss=20.7855 policy_loss=0.0000 value_loss=41.5709 entropy=0.0000
[step=1863] episode=1863.0000 return=-115.9977 length=45.0000 global_step=45244.0000 loss=202.1940 policy_loss=-0.0000 value_loss=404.3879 entropy=0.0000
[step=1864] episode=1864.0000 return=-116.0000 length=28.0000 global_step=45272.0000 loss=24.7524 policy_loss=-0.0000 value_loss=49.5047 entropy=0.0000
[step=1865] episode=1865.0000 return=-115.9096 length=30.0000 global_step=45302.0000 loss=29.2617 policy_loss=-0.0000 value_loss=58.5234 entropy=0.0000
[step=1866] episode=1866.0000 return=-115.7259 length=13.0000 global_step=45315.0000 loss=99.7198 policy_loss=-0.0000 value_loss=199.4396 entropy=0.0000
[step=1867] episode=1867.0000 return=-115.9933 length=19.0000 global_step=45334.0000 loss=60.6551 policy_loss=-0.0000 value_loss=121.3103 entropy=0.0000
[step=1868] episode=1868.0000 return=-115.9982 length=19.0000 global_step=45353.0000 loss=44.0711 policy_loss=-0.0000 value_loss=88.1422 entropy=0.0000
[step=1869] episode=1869.0000 return=-115.9871 length=28.0000 global_step=45381.0000 loss=8.0240 policy_loss=-0.0000 value_loss=16.0480 entropy=0.0000
[step=1870] episode=1870.0000 return=-115.9482 length=12.0000 global_step=45393.0000 loss=8.6379 policy_loss=-0.0000 value_loss=17.2759 entropy=0.0000
[step=1871] episode=1871.0000 return=-115.9939 length=25.0000 global_step=45418.0000 loss=108.3138 policy_loss=-0.0000 value_loss=216.6275 entropy=0.0000
[step=1872] episode=1872.0000 return=-115.9994 length=25.0000 global_step=45443.0000 loss=65.6296 policy_loss=-0.0000 value_loss=131.2592 entropy=0.0000
[step=1873] episode=1873.0000 return=-115.9939 length=30.0000 global_step=45473.0000 loss=115.6503 policy_loss=-0.0000 value_loss=231.3006 entropy=0.0000
[step=1874] episode=1874.0000 return=-115.7124 length=30.0000 global_step=45503.0000 loss=10.6775 policy_loss=-0.0000 value_loss=21.3551 entropy=0.0000
[step=1875] episode=1875.0000 return=-115.9840 length=21.0000 global_step=45524.0000 loss=18.6327 policy_loss=-0.0000 value_loss=37.2654 entropy=0.0000
[step=1876] episode=1876.0000 return=-115.8870 length=28.0000 global_step=45552.0000 loss=21.6048 policy_loss=-0.0000 value_loss=43.2096 entropy=0.0000
[step=1877] episode=1877.0000 return=-115.8271 length=21.0000 global_step=45573.0000 loss=86.2955 policy_loss=-0.0000 value_loss=172.5910 entropy=0.0000
a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1878/3000 [51:28<32:26,  1.73s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1879/3000 [51:29<27:17,  1.46s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1880/3000 [51:30<26:39,  1.43s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1881/3000 [51:32<29:00,  1.56s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1882/3000 [51:34<31:21,  1.68s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1883/3000 [51:35<26:54,  1.45s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1884/3000 [51:37<29:10,  1.57s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1885/3000 [51:37<25:29,  1.37s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1886/3000 [51:39<25:52,  1.39s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1887/3000 [51:41<29:03,  1.57s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1888/3000 [51:43<34:17,  1.85s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1889/3000 [51:45<31:20,  1.69s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1890/3000 [51:46<26:25,  1.43s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1891/3000 [51:47<26:07,  1.41s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1892/3000 [51:48<26:17,  1.42s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1893/3000 [51:50<29:10,  1.58s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1894/3000 [51:51<26:51,  1.46s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1895/3000 [51:53<26:00,  1.41s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1896/3000 [51:55<28:46,  1.56s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1897/3000 [51:56<27:29,  1.50s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1898/3000 [51:57<27:01,  1.47s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1899/3000 [51:59<29:30,  1.61s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1900/3000 [52:01<31:58,  1.74s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1901/3000 [52:03<33:30,  1.83s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1902/3000 [52:05<33:46,  1.85s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1903/3000 [52:08<36:26,  1.99s/it]a2c_tuned train:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1904/3000 [52:10<36:38,  2.01s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1905/3000 [52:12<37:31,  2.06s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1906/3000 [52:14<36:46,  2.02s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1907/3000 [52:15<32:50,  1.80s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1908/3000 [52:18<39:37,  2.18s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1909/3000 [52:19<34:37,  1.90s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1910/3000 [52:21<31:39,  1.74s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1911/3000 [52:22<29:39,  1.63s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1912/3000 [52:24<30:20,  1.67s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1913/3000 [52:25<29:11,  1.61s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1914/3000 [52:27<27:57,  1.54s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1915/3000 [52:29<33:08,  1.83s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1916/3000 [52:30<27:33,  1.53s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1917/3000 [52:31<24:12,  1.34s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1918/3000 [52:33<26:52,  1.49s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1919/3000 [52:34<23:18,  1.29s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1920/3000 [52:36<26:56,  1.50s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1921/3000 [52:37<26:38,  1.48s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1922/3000 [52:39<29:17,  1.63s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1923/3000 [52:41<28:18,  1.58s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1924/3000 [52:43<30:45,  1.72s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1925/3000 [52:44<28:25,  1.59s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1926/3000 [52:45<27:15,  1.52s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1927/3000 [52:47<26:13,  1.47s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1928/3000 [52:49<33:06,  1.85s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1929/3000 [52:51<32:11,  1.80s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1930/3000 [52:54<35:47,  2.01s/it][step=1878] episode=1878.0000 return=-115.9932 length=29.0000 global_step=45602.0000 loss=14.0499 policy_loss=-0.0000 value_loss=28.0998 entropy=0.0000
[step=1879] episode=1879.0000 return=-115.7423 length=11.0000 global_step=45613.0000 loss=26.9610 policy_loss=-0.0000 value_loss=53.9220 entropy=0.0000
[step=1880] episode=1880.0000 return=-115.9913 length=20.0000 global_step=45633.0000 loss=13.2694 policy_loss=-0.0000 value_loss=26.5387 entropy=0.0000
[step=1881] episode=1881.0000 return=-115.9988 length=28.0000 global_step=45661.0000 loss=102.7406 policy_loss=-0.0000 value_loss=205.4812 entropy=0.0000
[step=1882] episode=1882.0000 return=-115.9988 length=30.0000 global_step=45691.0000 loss=24.2181 policy_loss=-0.0000 value_loss=48.4361 entropy=0.0000
[step=1883] episode=1883.0000 return=-115.9963 length=13.0000 global_step=45704.0000 loss=33.3480 policy_loss=-0.0000 value_loss=66.6959 entropy=0.0000
[step=1884] episode=1884.0000 return=-115.9433 length=28.0000 global_step=45732.0000 loss=10.4531 policy_loss=-0.0000 value_loss=20.9062 entropy=0.0000
[step=1885] episode=1885.0000 return=-115.8370 length=12.0000 global_step=45744.0000 loss=50.3901 policy_loss=-0.0000 value_loss=100.7802 entropy=0.0000
[step=1886] episode=1886.0000 return=-116.0000 length=21.0000 global_step=45765.0000 loss=9.0013 policy_loss=-0.0000 value_loss=18.0027 entropy=0.0000
[step=1887] episode=1887.0000 return=-115.9950 length=30.0000 global_step=45795.0000 loss=55.2447 policy_loss=0.0000 value_loss=110.4895 entropy=0.0000
[step=1888] episode=1888.0000 return=-115.9911 length=36.0000 global_step=45831.0000 loss=24.8207 policy_loss=0.0000 value_loss=49.6415 entropy=0.0000
[step=1889] episode=1889.0000 return=-115.9679 length=20.0000 global_step=45851.0000 loss=13.0809 policy_loss=-0.0000 value_loss=26.1619 entropy=0.0000
[step=1890] episode=1890.0000 return=-115.9967 length=11.0000 global_step=45862.0000 loss=60.1415 policy_loss=-0.0000 value_loss=120.2830 entropy=0.0000
[step=1891] episode=1891.0000 return=-115.9968 length=21.0000 global_step=45883.0000 loss=6.4797 policy_loss=0.0000 value_loss=12.9595 entropy=0.0000
[step=1892] episode=1892.0000 return=-115.9110 length=21.0000 global_step=45904.0000 loss=4.4950 policy_loss=0.0000 value_loss=8.9900 entropy=0.0000
[step=1893] episode=1893.0000 return=-115.9990 length=29.0000 global_step=45933.0000 loss=70.5945 policy_loss=0.0000 value_loss=141.1890 entropy=0.0000
[step=1894] episode=1894.0000 return=-115.9371 length=18.0000 global_step=45951.0000 loss=8.9237 policy_loss=0.0000 value_loss=17.8474 entropy=0.0000
[step=1895] episode=1895.0000 return=-115.9401 length=19.0000 global_step=45970.0000 loss=11.2339 policy_loss=-0.0000 value_loss=22.4678 entropy=0.0000
[step=1896] episode=1896.0000 return=-115.9948 length=28.0000 global_step=45998.0000 loss=17.1777 policy_loss=-0.0000 value_loss=34.3554 entropy=0.0000
[step=1897] episode=1897.0000 return=-115.9999 length=20.0000 global_step=46018.0000 loss=24.4442 policy_loss=-0.0000 value_loss=48.8884 entropy=0.0000
[step=1898] episode=1898.0000 return=-115.9951 length=20.0000 global_step=46038.0000 loss=15.3369 policy_loss=-0.0000 value_loss=30.6737 entropy=0.0000
[step=1899] episode=1899.0000 return=-115.8473 length=28.0000 global_step=46066.0000 loss=4.9423 policy_loss=0.0000 value_loss=9.8847 entropy=0.0001
[step=1900] episode=1900.0000 return=-115.9490 length=30.0000 global_step=46096.0000 loss=48.8094 policy_loss=0.0000 value_loss=97.6188 entropy=0.0001
[step=1901] episode=1901.0000 return=-115.9989 length=29.0000 global_step=46125.0000 loss=39.1202 policy_loss=0.0000 value_loss=78.2403 entropy=0.0000
[step=1902] episode=1902.0000 return=-115.9760 length=28.0000 global_step=46153.0000 loss=8.0490 policy_loss=-0.0000 value_loss=16.0981 entropy=0.0000
[step=1903] episode=1903.0000 return=-115.9986 length=35.0000 global_step=46188.0000 loss=20.0519 policy_loss=-0.0000 value_loss=40.1038 entropy=0.0000
[step=1904] episode=1904.0000 return=-115.9439 length=30.0000 global_step=46218.0000 loss=30.2823 policy_loss=-0.0000 value_loss=60.5646 entropy=0.0000
[step=1905] episode=1905.0000 return=-115.9926 length=33.0000 global_step=46251.0000 loss=23.2701 policy_loss=-0.0000 value_loss=46.5403 entropy=0.0000
[step=1906] episode=1906.0000 return=-115.9925 length=28.0000 global_step=46279.0000 loss=16.8888 policy_loss=-0.0000 value_loss=33.7776 entropy=0.0000
[step=1907] episode=1907.0000 return=-115.9988 length=19.0000 global_step=46298.0000 loss=8.1840 policy_loss=-0.0000 value_loss=16.3681 entropy=0.0000
[step=1908] episode=1908.0000 return=-115.9986 length=46.0000 global_step=46344.0000 loss=149.1981 policy_loss=-0.0000 value_loss=298.3962 entropy=0.0000
[step=1909] episode=1909.0000 return=-115.9570 length=19.0000 global_step=46363.0000 loss=26.0378 policy_loss=-0.0000 value_loss=52.0757 entropy=0.0000
[step=1910] episode=1910.0000 return=-115.9909 length=19.0000 global_step=46382.0000 loss=53.6832 policy_loss=-0.0000 value_loss=107.3663 entropy=0.0000
[step=1911] episode=1911.0000 return=-115.9904 length=20.0000 global_step=46402.0000 loss=20.6066 policy_loss=-0.0000 value_loss=41.2132 entropy=0.0000
[step=1912] episode=1912.0000 return=-115.9898 length=27.0000 global_step=46429.0000 loss=25.0885 policy_loss=-0.0000 value_loss=50.1769 entropy=0.0000
[step=1913] episode=1913.0000 return=-115.9944 length=22.0000 global_step=46451.0000 loss=17.3128 policy_loss=-0.0000 value_loss=34.6257 entropy=0.0000
[step=1914] episode=1914.0000 return=-115.7758 length=20.0000 global_step=46471.0000 loss=9.3768 policy_loss=-0.0000 value_loss=18.7536 entropy=0.0000
[step=1915] episode=1915.0000 return=-115.9960 length=38.0000 global_step=46509.0000 loss=64.7147 policy_loss=-0.0000 value_loss=129.4293 entropy=0.0000
[step=1916] episode=1916.0000 return=-115.9096 length=12.0000 global_step=46521.0000 loss=27.9509 policy_loss=-0.0000 value_loss=55.9017 entropy=0.0000
[step=1917] episode=1917.0000 return=-115.9691 length=13.0000 global_step=46534.0000 loss=33.5954 policy_loss=-0.0000 value_loss=67.1907 entropy=0.0000
[step=1918] episode=1918.0000 return=-115.9991 length=27.0000 global_step=46561.0000 loss=39.7500 policy_loss=-0.0000 value_loss=79.5000 entropy=0.0000
[step=1919] episode=1919.0000 return=-115.8291 length=12.0000 global_step=46573.0000 loss=12.4690 policy_loss=-0.0000 value_loss=24.9380 entropy=0.0000
[step=1920] episode=1920.0000 return=-115.9993 length=30.0000 global_step=46603.0000 loss=67.9029 policy_loss=-0.0000 value_loss=135.8057 entropy=0.0000
[step=1921] episode=1921.0000 return=-115.9900 length=22.0000 global_step=46625.0000 loss=6.9133 policy_loss=-0.0000 value_loss=13.8265 entropy=0.0000
[step=1922] episode=1922.0000 return=-115.9957 length=29.0000 global_step=46654.0000 loss=8.5181 policy_loss=-0.0000 value_loss=17.0361 entropy=0.0000
[step=1923] episode=1923.0000 return=-115.9993 length=21.0000 global_step=46675.0000 loss=20.0763 policy_loss=-0.0000 value_loss=40.1526 entropy=0.0000
[step=1924] episode=1924.0000 return=-115.9952 length=31.0000 global_step=46706.0000 loss=24.8651 policy_loss=-0.0000 value_loss=49.7302 entropy=0.0000
[step=1925] episode=1925.0000 return=-115.9726 length=19.0000 global_step=46725.0000 loss=30.9472 policy_loss=-0.0000 value_loss=61.8944 entropy=0.0000
[step=1926] episode=1926.0000 return=-115.9890 length=20.0000 global_step=46745.0000 loss=21.6881 policy_loss=-0.0000 value_loss=43.3762 entropy=0.0000
[step=1927] episode=1927.0000 return=-115.9888 length=20.0000 global_step=46765.0000 loss=2.9056 policy_loss=-0.0000 value_loss=5.8112 entropy=0.0000
[step=1928] episode=1928.0000 return=-115.9370 length=41.0000 global_step=46806.0000 loss=91.1747 policy_loss=-0.0000 value_loss=182.3494 entropy=0.0000
[step=1929] episode=1929.0000 return=-115.9569 length=25.0000 global_step=46831.0000 loss=28.5806 policy_loss=-0.0000 value_loss=57.1612 entropy=0.0000
[step=1930] episode=1930.0000 return=-115.9984 length=36.0000 global_step=46867.0000 loss=66.6974 policy_loss=-0.0000 value_loss=133.3947 entropy=0.0000
a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1931/3000 [52:55<35:15,  1.98s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1932/3000 [52:58<38:03,  2.14s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1933/3000 [53:00<36:05,  2.03s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1934/3000 [53:01<29:50,  1.68s/it]a2c_tuned train:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1935/3000 [53:03<31:29,  1.77s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1936/3000 [53:05<34:51,  1.97s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1937/3000 [53:06<28:23,  1.60s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1938/3000 [53:07<26:34,  1.50s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1939/3000 [53:08<26:16,  1.49s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1940/3000 [53:09<23:07,  1.31s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1941/3000 [53:12<28:01,  1.59s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1942/3000 [53:12<24:08,  1.37s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1943/3000 [53:13<18:37,  1.06s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1944/3000 [53:15<25:37,  1.46s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1945/3000 [53:17<25:59,  1.48s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1946/3000 [53:18<25:57,  1.48s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1947/3000 [53:21<31:49,  1.81s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1948/3000 [53:24<37:57,  2.16s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1949/3000 [53:25<33:10,  1.89s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1950/3000 [53:26<30:45,  1.76s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1951/3000 [53:29<33:45,  1.93s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1952/3000 [53:30<29:50,  1.71s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1953/3000 [53:31<27:59,  1.60s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1954/3000 [53:33<26:31,  1.52s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1955/3000 [53:34<26:11,  1.50s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1956/3000 [53:35<25:13,  1.45s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1957/3000 [53:38<29:25,  1.69s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1958/3000 [53:40<30:30,  1.76s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1959/3000 [53:41<27:51,  1.61s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1960/3000 [53:42<26:32,  1.53s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1961/3000 [53:44<25:46,  1.49s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1962/3000 [53:45<25:03,  1.45s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1963/3000 [53:46<22:03,  1.28s/it]a2c_tuned train:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1964/3000 [53:47<22:54,  1.33s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1965/3000 [53:51<34:08,  1.98s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1966/3000 [53:53<35:02,  2.03s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1967/3000 [53:54<28:47,  1.67s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1968/3000 [53:56<30:22,  1.77s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1969/3000 [53:58<31:00,  1.80s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1970/3000 [53:59<30:57,  1.80s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1971/3000 [54:00<25:45,  1.50s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1972/3000 [54:02<24:48,  1.45s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1973/3000 [54:04<29:53,  1.75s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1974/3000 [54:06<32:31,  1.90s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1975/3000 [54:08<32:31,  1.90s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1976/3000 [54:10<32:13,  1.89s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1977/3000 [54:11<28:59,  1.70s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1978/3000 [54:13<26:32,  1.56s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1979/3000 [54:14<25:48,  1.52s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1980/3000 [54:15<21:56,  1.29s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1981/3000 [54:16<19:41,  1.16s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1982/3000 [54:17<21:02,  1.24s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1983/3000 [54:18<22:03,  1.30s/it][step=1931] episode=1931.0000 return=-115.9968 length=28.0000 global_step=46895.0000 loss=36.4739 policy_loss=-0.0000 value_loss=72.9478 entropy=0.0000
[step=1932] episode=1932.0000 return=-115.9939 length=37.0000 global_step=46932.0000 loss=57.5498 policy_loss=-0.0000 value_loss=115.0997 entropy=0.0000
[step=1933] episode=1933.0000 return=-115.9951 length=26.0000 global_step=46958.0000 loss=16.8964 policy_loss=-0.0000 value_loss=33.7927 entropy=0.0000
[step=1934] episode=1934.0000 return=-115.8313 length=12.0000 global_step=46970.0000 loss=10.1723 policy_loss=-0.0000 value_loss=20.3447 entropy=0.0000
[step=1935] episode=1935.0000 return=-115.9975 length=30.0000 global_step=47000.0000 loss=53.4491 policy_loss=-0.0000 value_loss=106.8983 entropy=0.0000
[step=1936] episode=1936.0000 return=-115.9676 length=36.0000 global_step=47036.0000 loss=13.8136 policy_loss=-0.0000 value_loss=27.6273 entropy=0.0000
[step=1937] episode=1937.0000 return=-115.7473 length=11.0000 global_step=47047.0000 loss=193.7994 policy_loss=-0.0000 value_loss=387.5987 entropy=0.0000
[step=1938] episode=1938.0000 return=-115.9868 length=19.0000 global_step=47066.0000 loss=13.9971 policy_loss=-0.0000 value_loss=27.9942 entropy=0.0000
[step=1939] episode=1939.0000 return=-115.9998 length=21.0000 global_step=47087.0000 loss=44.8552 policy_loss=-0.0000 value_loss=89.7103 entropy=0.0000
[step=1940] episode=1940.0000 return=-115.9986 length=12.0000 global_step=47099.0000 loss=48.4570 policy_loss=-0.0000 value_loss=96.9140 entropy=0.0000
[step=1941] episode=1941.0000 return=-115.9919 length=34.0000 global_step=47133.0000 loss=100.6306 policy_loss=-0.0000 value_loss=201.2612 entropy=0.0000
[step=1942] episode=1942.0000 return=-115.9955 length=12.0000 global_step=47145.0000 loss=153.3806 policy_loss=-0.0000 value_loss=306.7611 entropy=0.0000
[step=1943] episode=1943.0000 return=-106.9557 length=4.0000 global_step=47149.0000 loss=188.7937 policy_loss=-0.0000 value_loss=377.5875 entropy=0.0000
[step=1944] episode=1944.0000 return=-116.0000 length=37.0000 global_step=47186.0000 loss=89.7609 policy_loss=-0.0000 value_loss=179.5218 entropy=0.0000
[step=1945] episode=1945.0000 return=-115.8795 length=22.0000 global_step=47208.0000 loss=18.0089 policy_loss=-0.0000 value_loss=36.0177 entropy=0.0000
[step=1946] episode=1946.0000 return=-115.8106 length=21.0000 global_step=47229.0000 loss=19.6944 policy_loss=-0.0000 value_loss=39.3887 entropy=0.0000
[step=1947] episode=1947.0000 return=-115.9914 length=38.0000 global_step=47267.0000 loss=25.6379 policy_loss=-0.0000 value_loss=51.2758 entropy=0.0000
[step=1948] episode=1948.0000 return=-115.9939 length=46.0000 global_step=47313.0000 loss=49.0795 policy_loss=0.0000 value_loss=98.1590 entropy=0.0000
[step=1949] episode=1949.0000 return=-115.9350 length=20.0000 global_step=47333.0000 loss=194.2645 policy_loss=-0.0000 value_loss=388.5291 entropy=0.0000
[step=1950] episode=1950.0000 return=-115.9989 length=20.0000 global_step=47353.0000 loss=164.6008 policy_loss=-0.0001 value_loss=329.2019 entropy=0.0001
[step=1951] episode=1951.0000 return=-115.9998 length=35.0000 global_step=47388.0000 loss=18.9593 policy_loss=0.0088 value_loss=37.9014 entropy=0.0097
[step=1952] episode=1952.0000 return=-115.8870 length=18.0000 global_step=47406.0000 loss=11.3716 policy_loss=-0.0000 value_loss=22.7432 entropy=0.0000
[step=1953] episode=1953.0000 return=-115.9988 length=20.0000 global_step=47426.0000 loss=55.6141 policy_loss=-0.0000 value_loss=111.2281 entropy=0.0000
[step=1954] episode=1954.0000 return=-115.9968 length=20.0000 global_step=47446.0000 loss=32.2669 policy_loss=-0.0000 value_loss=64.5338 entropy=0.0000
[step=1955] episode=1955.0000 return=-115.9834 length=21.0000 global_step=47467.0000 loss=8.5606 policy_loss=-0.0000 value_loss=17.1212 entropy=0.0000
[step=1956] episode=1956.0000 return=-116.0000 length=20.0000 global_step=47487.0000 loss=17.4910 policy_loss=-0.0000 value_loss=34.9821 entropy=0.0000
[step=1957] episode=1957.0000 return=-115.9769 length=33.0000 global_step=47520.0000 loss=19.6304 policy_loss=-0.0000 value_loss=39.2608 entropy=0.0000
[step=1958] episode=1958.0000 return=-115.9998 length=30.0000 global_step=47550.0000 loss=22.2190 policy_loss=-0.0000 value_loss=44.4380 entropy=0.0000
[step=1959] episode=1959.0000 return=-116.0000 length=20.0000 global_step=47570.0000 loss=32.7168 policy_loss=-0.0000 value_loss=65.4336 entropy=0.0000
[step=1960] episode=1960.0000 return=-115.9958 length=20.0000 global_step=47590.0000 loss=9.7693 policy_loss=-0.0000 value_loss=19.5386 entropy=0.0000
[step=1961] episode=1961.0000 return=-115.9138 length=20.0000 global_step=47610.0000 loss=1.2213 policy_loss=-0.0000 value_loss=2.4425 entropy=0.0000
[step=1962] episode=1962.0000 return=-115.9973 length=20.0000 global_step=47630.0000 loss=34.4979 policy_loss=-0.0000 value_loss=68.9958 entropy=0.0000
[step=1963] episode=1963.0000 return=-115.8765 length=12.0000 global_step=47642.0000 loss=7.1090 policy_loss=-0.0000 value_loss=14.2181 entropy=0.0000
[step=1964] episode=1964.0000 return=-115.9883 length=22.0000 global_step=47664.0000 loss=26.3352 policy_loss=-0.0000 value_loss=52.6704 entropy=0.0000
[step=1965] episode=1965.0000 return=-115.9927 length=53.0000 global_step=47717.0000 loss=152.2125 policy_loss=-0.0000 value_loss=304.4251 entropy=0.0000
[step=1966] episode=1966.0000 return=-115.9997 length=33.0000 global_step=47750.0000 loss=14.2328 policy_loss=-0.0000 value_loss=28.4656 entropy=0.0000
[step=1967] episode=1967.0000 return=-110.7209 length=12.0000 global_step=47762.0000 loss=240.3995 policy_loss=-0.0000 value_loss=480.7989 entropy=0.0000
[step=1968] episode=1968.0000 return=-115.9863 length=29.0000 global_step=47791.0000 loss=49.0474 policy_loss=-0.0000 value_loss=98.0948 entropy=0.0000
[step=1969] episode=1969.0000 return=-115.9995 length=28.0000 global_step=47819.0000 loss=34.8513 policy_loss=-0.0000 value_loss=69.7025 entropy=0.0000
[step=1970] episode=1970.0000 return=-115.9818 length=26.0000 global_step=47845.0000 loss=14.3936 policy_loss=-0.0000 value_loss=28.7872 entropy=0.0000
[step=1971] episode=1971.0000 return=-115.9141 length=11.0000 global_step=47856.0000 loss=9.4045 policy_loss=-0.0000 value_loss=18.8089 entropy=0.0000
[step=1972] episode=1972.0000 return=-115.9989 length=19.0000 global_step=47875.0000 loss=35.5443 policy_loss=-0.0000 value_loss=71.0887 entropy=0.0000
[step=1973] episode=1973.0000 return=-115.9994 length=36.0000 global_step=47911.0000 loss=201.8025 policy_loss=-0.0000 value_loss=403.6049 entropy=0.0000
[step=1974] episode=1974.0000 return=-115.9866 length=34.0000 global_step=47945.0000 loss=61.7407 policy_loss=-0.0000 value_loss=123.4814 entropy=0.0000
[step=1975] episode=1975.0000 return=-115.9987 length=28.0000 global_step=47973.0000 loss=18.9316 policy_loss=-0.0000 value_loss=37.8632 entropy=0.0000
[step=1976] episode=1976.0000 return=-115.9984 length=28.0000 global_step=48001.0000 loss=29.9345 policy_loss=-0.0000 value_loss=59.8689 entropy=0.0000
[step=1977] episode=1977.0000 return=-115.7737 length=20.0000 global_step=48021.0000 loss=129.0973 policy_loss=-0.0000 value_loss=258.1946 entropy=0.0000
[step=1978] episode=1978.0000 return=-115.8644 length=18.0000 global_step=48039.0000 loss=132.6143 policy_loss=-0.0000 value_loss=265.2285 entropy=0.0000
[step=1979] episode=1979.0000 return=-115.9941 length=20.0000 global_step=48059.0000 loss=63.7702 policy_loss=-0.0000 value_loss=127.5403 entropy=0.0000
[step=1980] episode=1980.0000 return=-115.7788 length=11.0000 global_step=48070.0000 loss=38.5621 policy_loss=-0.0000 value_loss=77.1241 entropy=0.0000
[step=1981] episode=1981.0000 return=-115.7499 length=13.0000 global_step=48083.0000 loss=5.8841 policy_loss=-0.0000 value_loss=11.7682 entropy=0.0000
[step=1982] episode=1982.0000 return=-115.9949 length=21.0000 global_step=48104.0000 loss=130.5317 policy_loss=-0.0000 value_loss=261.0633 entropy=0.0000
[step=1983] episode=1983.0000 return=-115.7511 length=21.0000 global_step=48125.0000 loss=136.2027 policy_loss=-0.0000 value_loss=272.4053 entropy=0.0000
a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1984/3000 [54:20<24:56,  1.47s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1985/3000 [54:21<22:08,  1.31s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1986/3000 [54:23<25:45,  1.52s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1987/3000 [54:25<25:09,  1.49s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1988/3000 [54:26<21:47,  1.29s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1989/3000 [54:26<20:00,  1.19s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1990/3000 [54:28<20:48,  1.24s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1991/3000 [54:29<20:46,  1.23s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1992/3000 [54:31<25:45,  1.53s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1993/3000 [54:32<22:04,  1.32s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1994/3000 [54:33<22:27,  1.34s/it]a2c_tuned train:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1995/3000 [54:35<25:19,  1.51s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1996/3000 [54:37<27:11,  1.62s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1997/3000 [54:40<31:02,  1.86s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1998/3000 [54:41<29:09,  1.75s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1999/3000 [54:43<27:14,  1.63s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2000/3000 [54:44<25:58,  1.56s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2001/3000 [54:45<24:59,  1.50s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2002/3000 [54:47<24:45,  1.49s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2003/3000 [54:48<21:43,  1.31s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2004/3000 [54:50<25:02,  1.51s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2005/3000 [54:51<24:36,  1.48s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2006/3000 [54:52<24:18,  1.47s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2007/3000 [54:54<26:45,  1.62s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2008/3000 [54:55<22:42,  1.37s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2009/3000 [54:56<19:44,  1.20s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2010/3000 [54:59<28:34,  1.73s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2011/3000 [55:00<26:48,  1.63s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2012/3000 [55:02<28:41,  1.74s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2013/3000 [55:04<26:37,  1.62s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2014/3000 [55:05<26:16,  1.60s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2015/3000 [55:07<27:13,  1.66s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2016/3000 [55:08<22:39,  1.38s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2017/3000 [55:10<25:21,  1.55s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2018/3000 [55:11<23:47,  1.45s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2019/3000 [55:12<20:57,  1.28s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2020/3000 [55:14<22:55,  1.40s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2021/3000 [55:15<22:18,  1.37s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2022/3000 [55:17<24:52,  1.53s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2023/3000 [55:18<24:14,  1.49s/it]a2c_tuned train:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2024/3000 [55:21<29:03,  1.79s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2025/3000 [55:22<26:33,  1.63s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2026/3000 [55:23<25:55,  1.60s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2027/3000 [55:25<25:10,  1.55s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2028/3000 [55:27<26:04,  1.61s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2029/3000 [55:28<27:23,  1.69s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2030/3000 [55:30<27:52,  1.72s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2031/3000 [55:32<25:44,  1.59s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2032/3000 [55:32<22:17,  1.38s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2033/3000 [55:34<25:01,  1.55s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2034/3000 [55:36<26:18,  1.63s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2035/3000 [55:38<28:07,  1.75s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2036/3000 [55:39<23:21,  1.45s/it][step=1984] episode=1984.0000 return=-115.9875 length=29.0000 global_step=48154.0000 loss=136.8705 policy_loss=-0.0000 value_loss=273.7410 entropy=0.0000
[step=1985] episode=1985.0000 return=-115.7641 length=13.0000 global_step=48167.0000 loss=7.8798 policy_loss=-0.0000 value_loss=15.7597 entropy=0.0000
[step=1986] episode=1986.0000 return=-115.9999 length=29.0000 global_step=48196.0000 loss=25.5773 policy_loss=-0.0000 value_loss=51.1547 entropy=0.0000
[step=1987] episode=1987.0000 return=-115.9939 length=21.0000 global_step=48217.0000 loss=34.9934 policy_loss=-0.0000 value_loss=69.9868 entropy=0.0000
[step=1988] episode=1988.0000 return=-115.9940 length=12.0000 global_step=48229.0000 loss=142.2717 policy_loss=-0.0000 value_loss=284.5435 entropy=0.0000
[step=1989] episode=1989.0000 return=-115.7728 length=13.0000 global_step=48242.0000 loss=103.5431 policy_loss=-0.0000 value_loss=207.0863 entropy=0.0000
[step=1990] episode=1990.0000 return=-115.9954 length=20.0000 global_step=48262.0000 loss=12.8322 policy_loss=-0.0000 value_loss=25.6643 entropy=0.0000
[step=1991] episode=1991.0000 return=-115.8193 length=18.0000 global_step=48280.0000 loss=1.0955 policy_loss=-0.0000 value_loss=2.1911 entropy=0.0000
[step=1992] episode=1992.0000 return=-115.9783 length=34.0000 global_step=48314.0000 loss=135.1122 policy_loss=-0.0000 value_loss=270.2243 entropy=0.0000
[step=1993] episode=1993.0000 return=-115.9764 length=12.0000 global_step=48326.0000 loss=45.2892 policy_loss=-0.0000 value_loss=90.5784 entropy=0.0000
[step=1994] episode=1994.0000 return=-115.9460 length=20.0000 global_step=48346.0000 loss=28.1421 policy_loss=-0.0000 value_loss=56.2842 entropy=0.0000
[step=1995] episode=1995.0000 return=-115.9944 length=29.0000 global_step=48375.0000 loss=82.7317 policy_loss=-0.0000 value_loss=165.4633 entropy=0.0000
[step=1996] episode=1996.0000 return=-115.9926 length=28.0000 global_step=48403.0000 loss=17.2660 policy_loss=-0.0000 value_loss=34.5321 entropy=0.0000
[step=1997] episode=1997.0000 return=-115.9653 length=36.0000 global_step=48439.0000 loss=23.7665 policy_loss=-0.0000 value_loss=47.5331 entropy=0.0000
[step=1998] episode=1998.0000 return=-115.9981 length=22.0000 global_step=48461.0000 loss=148.6942 policy_loss=-0.0000 value_loss=297.3884 entropy=0.0000
[step=1999] episode=1999.0000 return=-115.7961 length=19.0000 global_step=48480.0000 loss=265.8011 policy_loss=-0.0000 value_loss=531.6022 entropy=0.0000
[step=2000] episode=2000.0000 return=-115.9363 length=20.0000 global_step=48500.0000 loss=61.6159 policy_loss=-0.0000 value_loss=123.2317 entropy=0.0000
[step=2001] episode=2001.0000 return=-115.9996 length=20.0000 global_step=48520.0000 loss=9.4492 policy_loss=-0.0000 value_loss=18.8985 entropy=0.0000
[step=2002] episode=2002.0000 return=-115.9966 length=21.0000 global_step=48541.0000 loss=54.6827 policy_loss=-0.0000 value_loss=109.3654 entropy=0.0000
[step=2003] episode=2003.0000 return=-115.9963 length=13.0000 global_step=48554.0000 loss=42.8396 policy_loss=-0.0000 value_loss=85.6793 entropy=0.0000
[step=2004] episode=2004.0000 return=-115.9942 length=30.0000 global_step=48584.0000 loss=212.3566 policy_loss=-0.0000 value_loss=424.7131 entropy=0.0000
[step=2005] episode=2005.0000 return=-115.9385 length=21.0000 global_step=48605.0000 loss=43.3749 policy_loss=-0.0000 value_loss=86.7498 entropy=0.0000
[step=2006] episode=2006.0000 return=-115.9948 length=20.0000 global_step=48625.0000 loss=4.7615 policy_loss=-0.0000 value_loss=9.5230 entropy=0.0000
[step=2007] episode=2007.0000 return=-115.9988 length=28.0000 global_step=48653.0000 loss=18.9425 policy_loss=-0.0000 value_loss=37.8851 entropy=0.0000
[step=2008] episode=2008.0000 return=-115.9972 length=12.0000 global_step=48665.0000 loss=179.4790 policy_loss=-0.0000 value_loss=358.9581 entropy=0.0000
[step=2009] episode=2009.0000 return=-115.9427 length=12.0000 global_step=48677.0000 loss=231.4585 policy_loss=-0.0000 value_loss=462.9171 entropy=0.0000
[step=2010] episode=2010.0000 return=-115.9968 length=45.0000 global_step=48722.0000 loss=18.8047 policy_loss=-0.0000 value_loss=37.6093 entropy=0.0000
[step=2011] episode=2011.0000 return=-115.9950 length=20.0000 global_step=48742.0000 loss=7.6650 policy_loss=-0.0000 value_loss=15.3301 entropy=0.0000
[step=2012] episode=2012.0000 return=-115.9805 length=29.0000 global_step=48771.0000 loss=20.5985 policy_loss=-0.0000 value_loss=41.1970 entropy=0.0000
[step=2013] episode=2013.0000 return=-115.9999 length=20.0000 global_step=48791.0000 loss=39.3752 policy_loss=-0.0000 value_loss=78.7503 entropy=0.0000
[step=2014] episode=2014.0000 return=-115.9978 length=21.0000 global_step=48812.0000 loss=25.7049 policy_loss=-0.0000 value_loss=51.4097 entropy=0.0000
[step=2015] episode=2015.0000 return=-115.9939 length=27.0000 global_step=48839.0000 loss=33.5978 policy_loss=-0.0000 value_loss=67.1955 entropy=0.0000
[step=2016] episode=2016.0000 return=-115.9822 length=12.0000 global_step=48851.0000 loss=31.4928 policy_loss=-0.0000 value_loss=62.9855 entropy=0.0000
[step=2017] episode=2017.0000 return=-115.9830 length=28.0000 global_step=48879.0000 loss=11.4175 policy_loss=-0.0000 value_loss=22.8350 entropy=0.0000
[step=2018] episode=2018.0000 return=-115.9990 length=18.0000 global_step=48897.0000 loss=24.9030 policy_loss=-0.0000 value_loss=49.8061 entropy=0.0000
[step=2019] episode=2019.0000 return=-115.7818 length=13.0000 global_step=48910.0000 loss=44.5242 policy_loss=-0.0000 value_loss=89.0483 entropy=0.0000
[step=2020] episode=2020.0000 return=-115.9948 length=25.0000 global_step=48935.0000 loss=18.8270 policy_loss=-0.0000 value_loss=37.6540 entropy=0.0000
[step=2021] episode=2021.0000 return=-115.9096 length=18.0000 global_step=48953.0000 loss=7.4737 policy_loss=-0.0000 value_loss=14.9474 entropy=0.0000
[step=2022] episode=2022.0000 return=-115.9939 length=30.0000 global_step=48983.0000 loss=49.7661 policy_loss=-0.0000 value_loss=99.5322 entropy=0.0000
[step=2023] episode=2023.0000 return=-115.9955 length=22.0000 global_step=49005.0000 loss=6.7507 policy_loss=-0.0000 value_loss=13.5014 entropy=0.0000
[step=2024] episode=2024.0000 return=-115.9990 length=38.0000 global_step=49043.0000 loss=27.0555 policy_loss=-0.0000 value_loss=54.1111 entropy=0.0000
[step=2025] episode=2025.0000 return=-115.9968 length=19.0000 global_step=49062.0000 loss=37.5990 policy_loss=-0.0000 value_loss=75.1981 entropy=0.0000
[step=2026] episode=2026.0000 return=-115.8795 length=22.0000 global_step=49084.0000 loss=70.5210 policy_loss=-0.0000 value_loss=141.0420 entropy=0.0000
[step=2027] episode=2027.0000 return=-115.9814 length=21.0000 global_step=49105.0000 loss=39.5828 policy_loss=-0.0000 value_loss=79.1655 entropy=0.0000
[step=2028] episode=2028.0000 return=-115.9963 length=26.0000 global_step=49131.0000 loss=22.9619 policy_loss=-0.0000 value_loss=45.9239 entropy=0.0000
[step=2029] episode=2029.0000 return=-115.9968 length=28.0000 global_step=49159.0000 loss=28.3683 policy_loss=-0.0000 value_loss=56.7366 entropy=0.0000
[step=2030] episode=2030.0000 return=-115.9925 length=28.0000 global_step=49187.0000 loss=45.8858 policy_loss=-0.0000 value_loss=91.7716 entropy=0.0000
[step=2031] episode=2031.0000 return=-115.9764 length=20.0000 global_step=49207.0000 loss=15.6871 policy_loss=-0.0000 value_loss=31.3742 entropy=0.0000
[step=2032] episode=2032.0000 return=-115.9930 length=13.0000 global_step=49220.0000 loss=15.2076 policy_loss=-0.0000 value_loss=30.4152 entropy=0.0000
[step=2033] episode=2033.0000 return=-115.9915 length=29.0000 global_step=49249.0000 loss=34.3476 policy_loss=-0.0000 value_loss=68.6953 entropy=0.0000
[step=2034] episode=2034.0000 return=-115.9840 length=27.0000 global_step=49276.0000 loss=14.2739 policy_loss=-0.0000 value_loss=28.5479 entropy=0.0000
[step=2035] episode=2035.0000 return=-115.9756 length=29.0000 global_step=49305.0000 loss=5.8993 policy_loss=-0.0000 value_loss=11.7986 entropy=0.0000
[step=2036] episode=2036.0000 return=-115.7102 length=11.0000 global_step=49316.0000 loss=80.0476 policy_loss=-0.0000 value_loss=160.0952 entropy=0.0000
a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2037/3000 [55:40<20:34,  1.28s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2038/3000 [55:41<21:24,  1.34s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2039/3000 [55:43<21:57,  1.37s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2040/3000 [55:44<21:41,  1.36s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2041/3000 [55:45<19:46,  1.24s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2042/3000 [55:47<25:06,  1.57s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2043/3000 [55:49<24:03,  1.51s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2044/3000 [55:51<28:33,  1.79s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2045/3000 [55:53<29:20,  1.84s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2046/3000 [55:54<23:56,  1.51s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2047/3000 [55:57<31:17,  1.97s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2048/3000 [55:58<25:52,  1.63s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2049/3000 [55:59<24:39,  1.56s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2050/3000 [56:00<21:46,  1.38s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2051/3000 [56:02<22:02,  1.39s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2052/3000 [56:02<19:24,  1.23s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2053/3000 [56:04<21:47,  1.38s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2054/3000 [56:06<21:42,  1.38s/it]a2c_tuned train:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2055/3000 [56:08<27:03,  1.72s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2056/3000 [56:11<30:30,  1.94s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2057/3000 [56:13<33:01,  2.10s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2058/3000 [56:14<26:28,  1.69s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2059/3000 [56:15<24:53,  1.59s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2060/3000 [56:18<29:11,  1.86s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2061/3000 [56:18<24:01,  1.53s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2062/3000 [56:19<20:39,  1.32s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2063/3000 [56:20<17:57,  1.15s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2064/3000 [56:21<18:47,  1.21s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2065/3000 [56:24<24:35,  1.58s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2066/3000 [56:25<23:25,  1.50s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2067/3000 [56:26<22:31,  1.45s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2068/3000 [56:28<24:45,  1.59s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2069/3000 [56:30<26:36,  1.71s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2070/3000 [56:32<27:20,  1.76s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2071/3000 [56:34<25:39,  1.66s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2072/3000 [56:34<22:01,  1.42s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2073/3000 [56:37<27:03,  1.75s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2074/3000 [56:39<28:09,  1.82s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2075/3000 [56:42<31:51,  2.07s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2076/3000 [56:43<28:39,  1.86s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2077/3000 [56:44<23:48,  1.55s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2078/3000 [56:45<23:04,  1.50s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2079/3000 [56:48<27:45,  1.81s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2080/3000 [56:49<25:05,  1.64s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2081/3000 [56:51<26:03,  1.70s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2082/3000 [56:53<28:36,  1.87s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2083/3000 [56:55<28:55,  1.89s/it]a2c_tuned train:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2084/3000 [56:58<33:57,  2.22s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2085/3000 [57:00<34:59,  2.29s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2086/3000 [57:03<35:15,  2.31s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2087/3000 [57:05<33:54,  2.23s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2088/3000 [57:07<34:50,  2.29s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2089/3000 [57:10<35:48,  2.36s/it][step=2037] episode=2037.0000 return=-115.9407 length=13.0000 global_step=49329.0000 loss=51.7727 policy_loss=-0.0000 value_loss=103.5454 entropy=0.0000
[step=2038] episode=2038.0000 return=-115.7909 length=21.0000 global_step=49350.0000 loss=5.0885 policy_loss=-0.0000 value_loss=10.1770 entropy=0.0000
[step=2039] episode=2039.0000 return=-115.9916 length=21.0000 global_step=49371.0000 loss=20.9406 policy_loss=-0.0000 value_loss=41.8811 entropy=0.0000
[step=2040] episode=2040.0000 return=-115.9989 length=20.0000 global_step=49391.0000 loss=42.3357 policy_loss=-0.0000 value_loss=84.6714 entropy=0.0000
[step=2041] episode=2041.0000 return=-115.7975 length=13.0000 global_step=49404.0000 loss=5.5808 policy_loss=-0.0000 value_loss=11.1616 entropy=0.0000
[step=2042] episode=2042.0000 return=-115.9978 length=35.0000 global_step=49439.0000 loss=108.1574 policy_loss=-0.0000 value_loss=216.3148 entropy=0.0000
[step=2043] episode=2043.0000 return=-115.9840 length=21.0000 global_step=49460.0000 loss=4.6530 policy_loss=-0.0000 value_loss=9.3061 entropy=0.0000
[step=2044] episode=2044.0000 return=-115.9944 length=38.0000 global_step=49498.0000 loss=16.5972 policy_loss=-0.0000 value_loss=33.1944 entropy=0.0000
[step=2045] episode=2045.0000 return=-115.7799 length=28.0000 global_step=49526.0000 loss=95.2501 policy_loss=-0.0000 value_loss=190.5001 entropy=0.0000
[step=2046] episode=2046.0000 return=-115.6949 length=11.0000 global_step=49537.0000 loss=205.6830 policy_loss=-0.0000 value_loss=411.3661 entropy=0.0000
[step=2047] episode=2047.0000 return=-115.9982 length=46.0000 global_step=49583.0000 loss=27.7610 policy_loss=-0.0000 value_loss=55.5219 entropy=0.0000
[step=2048] episode=2048.0000 return=-115.7952 length=12.0000 global_step=49595.0000 loss=153.4084 policy_loss=-0.0000 value_loss=306.8169 entropy=0.0000
[step=2049] episode=2049.0000 return=-115.9585 length=19.0000 global_step=49614.0000 loss=43.7477 policy_loss=-0.0000 value_loss=87.4953 entropy=0.0000
[step=2050] episode=2050.0000 return=-115.9994 length=13.0000 global_step=49627.0000 loss=6.0827 policy_loss=-0.0000 value_loss=12.1653 entropy=0.0000
[step=2051] episode=2051.0000 return=-115.9384 length=21.0000 global_step=49648.0000 loss=68.8891 policy_loss=-0.0000 value_loss=137.7781 entropy=0.0000
[step=2052] episode=2052.0000 return=-115.7697 length=12.0000 global_step=49660.0000 loss=68.9297 policy_loss=-0.0000 value_loss=137.8595 entropy=0.0000
[step=2053] episode=2053.0000 return=-115.9966 length=26.0000 global_step=49686.0000 loss=280.6437 policy_loss=-0.0000 value_loss=561.2874 entropy=0.0000
[step=2054] episode=2054.0000 return=-115.7721 length=21.0000 global_step=49707.0000 loss=134.5748 policy_loss=-0.0000 value_loss=269.1496 entropy=0.0000
[step=2055] episode=2055.0000 return=-115.9982 length=37.0000 global_step=49744.0000 loss=125.2304 policy_loss=-0.0000 value_loss=250.4607 entropy=0.0000
[step=2056] episode=2056.0000 return=-115.9993 length=37.0000 global_step=49781.0000 loss=21.0155 policy_loss=-0.0000 value_loss=42.0309 entropy=0.0000
[step=2057] episode=2057.0000 return=-115.9870 length=37.0000 global_step=49818.0000 loss=19.8480 policy_loss=-0.0000 value_loss=39.6960 entropy=0.0000
[step=2058] episode=2058.0000 return=-115.7517 length=11.0000 global_step=49829.0000 loss=245.6594 policy_loss=-0.0000 value_loss=491.3187 entropy=0.0000
[step=2059] episode=2059.0000 return=-115.9995 length=20.0000 global_step=49849.0000 loss=162.6326 policy_loss=-0.0000 value_loss=325.2651 entropy=0.0000
[step=2060] episode=2060.0000 return=-115.9996 length=37.0000 global_step=49886.0000 loss=67.9995 policy_loss=-0.0000 value_loss=135.9990 entropy=0.0000
[step=2061] episode=2061.0000 return=-115.9890 length=11.0000 global_step=49897.0000 loss=188.8007 policy_loss=-0.0000 value_loss=377.6014 entropy=0.0000
[step=2062] episode=2062.0000 return=-115.9971 length=12.0000 global_step=49909.0000 loss=85.0523 policy_loss=-0.0000 value_loss=170.1046 entropy=0.0000
[step=2063] episode=2063.0000 return=-115.7953 length=11.0000 global_step=49920.0000 loss=12.3949 policy_loss=-0.0000 value_loss=24.7898 entropy=0.0000
[step=2064] episode=2064.0000 return=-115.9880 length=20.0000 global_step=49940.0000 loss=76.8540 policy_loss=-0.0000 value_loss=153.7080 entropy=0.0000
[step=2065] episode=2065.0000 return=-115.9972 length=38.0000 global_step=49978.0000 loss=243.4324 policy_loss=-0.0000 value_loss=486.8649 entropy=0.0000
[step=2066] episode=2066.0000 return=-115.9920 length=19.0000 global_step=49997.0000 loss=183.8293 policy_loss=-0.0000 value_loss=367.6586 entropy=0.0000
[step=2067] episode=2067.0000 return=-115.9975 length=20.0000 global_step=50017.0000 loss=117.2265 policy_loss=-0.0000 value_loss=234.4531 entropy=0.0000
[step=2068] episode=2068.0000 return=-115.9993 length=28.0000 global_step=50045.0000 loss=55.3177 policy_loss=-0.0000 value_loss=110.6354 entropy=0.0000
[step=2069] episode=2069.0000 return=-115.9580 length=30.0000 global_step=50075.0000 loss=30.0266 policy_loss=-0.0000 value_loss=60.0532 entropy=0.0000
[step=2070] episode=2070.0000 return=-115.9776 length=28.0000 global_step=50103.0000 loss=17.9737 policy_loss=-0.0000 value_loss=35.9474 entropy=0.0000
[step=2071] episode=2071.0000 return=-115.9977 length=21.0000 global_step=50124.0000 loss=101.4092 policy_loss=-0.0000 value_loss=202.8184 entropy=0.0000
[step=2072] episode=2072.0000 return=-115.7696 length=13.0000 global_step=50137.0000 loss=251.7187 policy_loss=-0.0000 value_loss=503.4375 entropy=0.0000
[step=2073] episode=2073.0000 return=-115.9934 length=38.0000 global_step=50175.0000 loss=79.4237 policy_loss=-0.0000 value_loss=158.8475 entropy=0.0000
[step=2074] episode=2074.0000 return=-115.9985 length=29.0000 global_step=50204.0000 loss=41.5743 policy_loss=-0.0000 value_loss=83.1486 entropy=0.0000
[step=2075] episode=2075.0000 return=-115.9999 length=41.0000 global_step=50245.0000 loss=13.2619 policy_loss=-0.0000 value_loss=26.5238 entropy=0.0000
[step=2076] episode=2076.0000 return=-115.9466 length=20.0000 global_step=50265.0000 loss=7.4226 policy_loss=-0.0000 value_loss=14.8452 entropy=0.0000
[step=2077] episode=2077.0000 return=-115.8408 length=11.0000 global_step=50276.0000 loss=4.8071 policy_loss=-0.0000 value_loss=9.6143 entropy=0.0000
[step=2078] episode=2078.0000 return=-115.9828 length=21.0000 global_step=50297.0000 loss=46.7119 policy_loss=-0.0000 value_loss=93.4239 entropy=0.0000
[step=2079] episode=2079.0000 return=-115.9998 length=38.0000 global_step=50335.0000 loss=268.3432 policy_loss=-0.0000 value_loss=536.6863 entropy=0.0000
[step=2080] episode=2080.0000 return=-115.9941 length=18.0000 global_step=50353.0000 loss=39.6018 policy_loss=-0.0000 value_loss=79.2036 entropy=0.0000
[step=2081] episode=2081.0000 return=-115.9996 length=28.0000 global_step=50381.0000 loss=60.2666 policy_loss=-0.0000 value_loss=120.5332 entropy=0.0000
[step=2082] episode=2082.0000 return=-115.9959 length=34.0000 global_step=50415.0000 loss=15.3819 policy_loss=-0.0000 value_loss=30.7638 entropy=0.0000
[step=2083] episode=2083.0000 return=-115.9998 length=28.0000 global_step=50443.0000 loss=31.5675 policy_loss=-0.0000 value_loss=63.1351 entropy=0.0000
[step=2084] episode=2084.0000 return=-115.9999 length=44.0000 global_step=50487.0000 loss=48.7575 policy_loss=-0.0000 value_loss=97.5150 entropy=0.0000
[step=2085] episode=2085.0000 return=-115.9984 length=37.0000 global_step=50524.0000 loss=77.6892 policy_loss=-0.0000 value_loss=155.3784 entropy=0.0000
[step=2086] episode=2086.0000 return=-115.9948 length=36.0000 global_step=50560.0000 loss=79.7284 policy_loss=-0.0000 value_loss=159.4569 entropy=0.0000
[step=2087] episode=2087.0000 return=-115.9837 length=30.0000 global_step=50590.0000 loss=77.6146 policy_loss=-0.0000 value_loss=155.2292 entropy=0.0000
[step=2088] episode=2088.0000 return=-115.9984 length=37.0000 global_step=50627.0000 loss=27.6559 policy_loss=-0.0000 value_loss=55.3118 entropy=0.0000
[step=2089] episode=2089.0000 return=-115.9905 length=38.0000 global_step=50665.0000 loss=14.7925 policy_loss=-0.0000 value_loss=29.5850 entropy=0.0000
a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2090/3000 [57:11<31:22,  2.07s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2091/3000 [57:12<27:54,  1.84s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2092/3000 [57:14<26:02,  1.72s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2093/3000 [57:15<22:22,  1.48s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2094/3000 [57:16<22:10,  1.47s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2095/3000 [57:18<21:16,  1.41s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2096/3000 [57:19<20:36,  1.37s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2097/3000 [57:20<20:58,  1.39s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2098/3000 [57:21<18:31,  1.23s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2099/3000 [57:23<21:35,  1.44s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2100/3000 [57:26<27:57,  1.86s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2101/3000 [57:28<30:27,  2.03s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2102/3000 [57:30<29:48,  1.99s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2103/3000 [57:32<26:40,  1.78s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2104/3000 [57:33<26:52,  1.80s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2105/3000 [57:35<24:43,  1.66s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2106/3000 [57:37<25:58,  1.74s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2107/3000 [57:38<21:57,  1.48s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2108/3000 [57:39<21:14,  1.43s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2109/3000 [57:41<23:43,  1.60s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2110/3000 [57:42<19:51,  1.34s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2111/3000 [57:42<17:36,  1.19s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2112/3000 [57:44<18:15,  1.23s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2113/3000 [57:46<21:20,  1.44s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2114/3000 [57:48<26:21,  1.79s/it]a2c_tuned train:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2115/3000 [57:50<24:42,  1.68s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2116/3000 [57:52<29:47,  2.02s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2117/3000 [57:53<24:21,  1.65s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2118/3000 [57:56<26:59,  1.84s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2119/3000 [57:57<25:55,  1.77s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2120/3000 [57:59<25:21,  1.73s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2121/3000 [58:02<31:19,  2.14s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2122/3000 [58:04<29:06,  1.99s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2123/3000 [58:05<27:06,  1.86s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2124/3000 [58:06<22:00,  1.51s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2125/3000 [58:07<22:07,  1.52s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2126/3000 [58:08<18:37,  1.28s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2127/3000 [58:10<19:45,  1.36s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2128/3000 [58:11<19:25,  1.34s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2129/3000 [58:12<18:42,  1.29s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2130/3000 [58:13<18:28,  1.27s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2131/3000 [58:15<18:57,  1.31s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2132/3000 [58:16<18:56,  1.31s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2133/3000 [58:17<19:00,  1.31s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2134/3000 [58:20<23:39,  1.64s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2135/3000 [58:22<24:54,  1.73s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2136/3000 [58:22<20:53,  1.45s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2137/3000 [58:25<25:39,  1.78s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2138/3000 [58:27<28:21,  1.97s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2139/3000 [58:29<25:42,  1.79s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2140/3000 [58:30<24:31,  1.71s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2141/3000 [58:32<23:07,  1.62s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2142/3000 [58:33<22:10,  1.55s/it][step=2090] episode=2090.0000 return=-115.9872 length=21.0000 global_step=50686.0000 loss=4.8569 policy_loss=-0.0000 value_loss=9.7138 entropy=0.0000
[step=2091] episode=2091.0000 return=-115.7758 length=20.0000 global_step=50706.0000 loss=6.6519 policy_loss=-0.0000 value_loss=13.3038 entropy=0.0000
[step=2092] episode=2092.0000 return=-115.9595 length=21.0000 global_step=50727.0000 loss=34.1391 policy_loss=-0.0000 value_loss=68.2783 entropy=0.0000
[step=2093] episode=2093.0000 return=-115.9385 length=13.0000 global_step=50740.0000 loss=3.2175 policy_loss=-0.0000 value_loss=6.4349 entropy=0.0000
[step=2094] episode=2094.0000 return=-115.9872 length=21.0000 global_step=50761.0000 loss=44.1496 policy_loss=-0.0000 value_loss=88.2991 entropy=0.0000
[step=2095] episode=2095.0000 return=-115.9968 length=19.0000 global_step=50780.0000 loss=19.1260 policy_loss=-0.0000 value_loss=38.2521 entropy=0.0000
[step=2096] episode=2096.0000 return=-115.9984 length=19.0000 global_step=50799.0000 loss=8.6500 policy_loss=-0.0000 value_loss=17.3000 entropy=0.0000
[step=2097] episode=2097.0000 return=-115.9939 length=21.0000 global_step=50820.0000 loss=16.5796 policy_loss=-0.0000 value_loss=33.1592 entropy=0.0000
[step=2098] episode=2098.0000 return=-115.8789 length=12.0000 global_step=50832.0000 loss=97.8405 policy_loss=-0.0000 value_loss=195.6810 entropy=0.0000
[step=2099] episode=2099.0000 return=-115.9999 length=29.0000 global_step=50861.0000 loss=18.0901 policy_loss=-0.0000 value_loss=36.1802 entropy=0.0000
[step=2100] episode=2100.0000 return=-115.9999 length=41.0000 global_step=50902.0000 loss=45.4840 policy_loss=-0.0000 value_loss=90.9681 entropy=0.0000
[step=2101] episode=2101.0000 return=-115.9925 length=36.0000 global_step=50938.0000 loss=30.1390 policy_loss=-0.0000 value_loss=60.2781 entropy=0.0000
[step=2102] episode=2102.0000 return=-115.9970 length=29.0000 global_step=50967.0000 loss=14.9419 policy_loss=-0.0000 value_loss=29.8837 entropy=0.0000
[step=2103] episode=2103.0000 return=-115.9929 length=19.0000 global_step=50986.0000 loss=29.8627 policy_loss=-0.0000 value_loss=59.7255 entropy=0.0000
[step=2104] episode=2104.0000 return=-115.9904 length=29.0000 global_step=51015.0000 loss=9.8441 policy_loss=-0.0000 value_loss=19.6883 entropy=0.0000
[step=2105] episode=2105.0000 return=-115.8869 length=19.0000 global_step=51034.0000 loss=11.8013 policy_loss=-0.0000 value_loss=23.6027 entropy=0.0000
[step=2106] episode=2106.0000 return=-115.9970 length=29.0000 global_step=51063.0000 loss=39.9864 policy_loss=-0.0000 value_loss=79.9728 entropy=0.0000
[step=2107] episode=2107.0000 return=-115.9933 length=12.0000 global_step=51075.0000 loss=5.3942 policy_loss=-0.0000 value_loss=10.7884 entropy=0.0000
[step=2108] episode=2108.0000 return=-115.8481 length=19.0000 global_step=51094.0000 loss=31.1037 policy_loss=-0.0000 value_loss=62.2074 entropy=0.0000
[step=2109] episode=2109.0000 return=-115.9928 length=29.0000 global_step=51123.0000 loss=83.1695 policy_loss=-0.0000 value_loss=166.3391 entropy=0.0000
[step=2110] episode=2110.0000 return=-115.7281 length=11.0000 global_step=51134.0000 loss=6.1693 policy_loss=-0.0000 value_loss=12.3386 entropy=0.0000
[step=2111] episode=2111.0000 return=-115.9998 length=12.0000 global_step=51146.0000 loss=9.3316 policy_loss=-0.0000 value_loss=18.6632 entropy=0.0000
[step=2112] episode=2112.0000 return=-115.9999 length=19.0000 global_step=51165.0000 loss=12.7231 policy_loss=-0.0000 value_loss=25.4461 entropy=0.0000
[step=2113] episode=2113.0000 return=-115.9972 length=28.0000 global_step=51193.0000 loss=9.1300 policy_loss=-0.0000 value_loss=18.2600 entropy=0.0000
[step=2114] episode=2114.0000 return=-115.9840 length=38.0000 global_step=51231.0000 loss=47.1955 policy_loss=-0.0000 value_loss=94.3910 entropy=0.0000
[step=2115] episode=2115.0000 return=-115.8685 length=20.0000 global_step=51251.0000 loss=31.3476 policy_loss=-0.0000 value_loss=62.6953 entropy=0.0000
[step=2116] episode=2116.0000 return=-115.9990 length=42.0000 global_step=51293.0000 loss=31.5153 policy_loss=-0.0000 value_loss=63.0305 entropy=0.0000
[step=2117] episode=2117.0000 return=-115.8686 length=11.0000 global_step=51304.0000 loss=150.8610 policy_loss=-0.0000 value_loss=301.7219 entropy=0.0000
[step=2118] episode=2118.0000 return=-115.8395 length=36.0000 global_step=51340.0000 loss=74.6728 policy_loss=-0.0000 value_loss=149.3457 entropy=0.0000
[step=2119] episode=2119.0000 return=-115.9897 length=28.0000 global_step=51368.0000 loss=14.2486 policy_loss=-0.0000 value_loss=28.4972 entropy=0.0000
[step=2120] episode=2120.0000 return=-115.9945 length=29.0000 global_step=51397.0000 loss=7.4941 policy_loss=-0.0000 value_loss=14.9882 entropy=0.0000
[step=2121] episode=2121.0000 return=-115.9999 length=55.0000 global_step=51452.0000 loss=180.0104 policy_loss=-0.0000 value_loss=360.0207 entropy=0.0000
[step=2122] episode=2122.0000 return=-115.9986 length=28.0000 global_step=51480.0000 loss=9.6127 policy_loss=-0.0000 value_loss=19.2253 entropy=0.0000
[step=2123] episode=2123.0000 return=-115.9991 length=26.0000 global_step=51506.0000 loss=10.9867 policy_loss=-0.0000 value_loss=21.9734 entropy=0.0000
[step=2124] episode=2124.0000 return=-115.8968 length=12.0000 global_step=51518.0000 loss=51.0644 policy_loss=-0.0000 value_loss=102.1287 entropy=0.0000
[step=2125] episode=2125.0000 return=-115.9988 length=26.0000 global_step=51544.0000 loss=14.9942 policy_loss=-0.0000 value_loss=29.9884 entropy=0.0000
[step=2126] episode=2126.0000 return=-115.8765 length=12.0000 global_step=51556.0000 loss=57.9923 policy_loss=-0.0000 value_loss=115.9846 entropy=0.0000
[step=2127] episode=2127.0000 return=-115.9805 length=27.0000 global_step=51583.0000 loss=17.9107 policy_loss=-0.0000 value_loss=35.8214 entropy=0.0000
[step=2128] episode=2128.0000 return=-115.9896 length=21.0000 global_step=51604.0000 loss=1.6953 policy_loss=-0.0000 value_loss=3.3906 entropy=0.0000
[step=2129] episode=2129.0000 return=-115.9353 length=20.0000 global_step=51624.0000 loss=18.1965 policy_loss=-0.0000 value_loss=36.3931 entropy=0.0000
[step=2130] episode=2130.0000 return=-115.9653 length=21.0000 global_step=51645.0000 loss=16.4589 policy_loss=-0.0000 value_loss=32.9178 entropy=0.0000
[step=2131] episode=2131.0000 return=-115.9926 length=20.0000 global_step=51665.0000 loss=8.9121 policy_loss=-0.0000 value_loss=17.8242 entropy=0.0000
[step=2132] episode=2132.0000 return=-115.9975 length=19.0000 global_step=51684.0000 loss=15.6627 policy_loss=-0.0000 value_loss=31.3253 entropy=0.0000
[step=2133] episode=2133.0000 return=-115.9936 length=20.0000 global_step=51704.0000 loss=6.9653 policy_loss=-0.0000 value_loss=13.9306 entropy=0.0000
[step=2134] episode=2134.0000 return=-115.9889 length=37.0000 global_step=51741.0000 loss=27.1128 policy_loss=-0.0000 value_loss=54.2256 entropy=0.0000
[step=2135] episode=2135.0000 return=-115.9995 length=29.0000 global_step=51770.0000 loss=17.9693 policy_loss=-0.0000 value_loss=35.9386 entropy=0.0000
[step=2136] episode=2136.0000 return=-115.9859 length=13.0000 global_step=51783.0000 loss=54.3881 policy_loss=-0.0000 value_loss=108.7762 entropy=0.0000
[step=2137] episode=2137.0000 return=-115.9821 length=37.0000 global_step=51820.0000 loss=14.3200 policy_loss=-0.0000 value_loss=28.6401 entropy=0.0000
[step=2138] episode=2138.0000 return=-115.9968 length=36.0000 global_step=51856.0000 loss=12.7456 policy_loss=-0.0000 value_loss=25.4911 entropy=0.0000
[step=2139] episode=2139.0000 return=-115.9995 length=21.0000 global_step=51877.0000 loss=21.0710 policy_loss=-0.0000 value_loss=42.1419 entropy=0.0000
[step=2140] episode=2140.0000 return=-115.9294 length=21.0000 global_step=51898.0000 loss=14.6435 policy_loss=-0.0000 value_loss=29.2871 entropy=0.0000
[step=2141] episode=2141.0000 return=-115.9898 length=21.0000 global_step=51919.0000 loss=7.4676 policy_loss=-0.0000 value_loss=14.9352 entropy=0.0000
[step=2142] episode=2142.0000 return=-115.9967 length=20.0000 global_step=51939.0000 loss=7.6542 policy_loss=-0.0000 value_loss=15.3084 entropy=0.0000
a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2143/3000 [58:34<18:48,  1.32s/it]a2c_tuned train:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2144/3000 [58:36<24:22,  1.71s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2145/3000 [58:38<22:34,  1.58s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2146/3000 [58:39<19:49,  1.39s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2147/3000 [58:40<17:19,  1.22s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2148/3000 [58:42<20:32,  1.45s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2149/3000 [58:43<22:29,  1.59s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2150/3000 [58:45<23:48,  1.68s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2151/3000 [58:46<20:06,  1.42s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2152/3000 [58:48<20:10,  1.43s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2153/3000 [58:48<17:25,  1.23s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2154/3000 [58:51<22:19,  1.58s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2155/3000 [58:53<25:18,  1.80s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2156/3000 [58:55<25:49,  1.84s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2157/3000 [58:56<23:59,  1.71s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2158/3000 [58:58<22:29,  1.60s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2159/3000 [58:59<20:58,  1.50s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2160/3000 [59:01<22:41,  1.62s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2161/3000 [59:02<19:12,  1.37s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2162/3000 [59:04<21:54,  1.57s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2163/3000 [59:06<22:50,  1.64s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2164/3000 [59:07<21:38,  1.55s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2165/3000 [59:08<21:11,  1.52s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2166/3000 [59:09<18:06,  1.30s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2167/3000 [59:11<19:51,  1.43s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2168/3000 [59:12<19:28,  1.40s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2169/3000 [59:14<19:33,  1.41s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2170/3000 [59:16<21:50,  1.58s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2171/3000 [59:17<22:36,  1.64s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2172/3000 [59:19<23:25,  1.70s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2173/3000 [59:21<21:46,  1.58s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2174/3000 [59:21<18:53,  1.37s/it]a2c_tuned train:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2175/3000 [59:23<18:52,  1.37s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2176/3000 [59:25<20:54,  1.52s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2177/3000 [59:25<18:05,  1.32s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2178/3000 [59:27<20:01,  1.46s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2179/3000 [59:29<21:39,  1.58s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2180/3000 [59:30<18:24,  1.35s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2181/3000 [59:32<23:08,  1.69s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2182/3000 [59:35<26:46,  1.96s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2183/3000 [59:37<25:37,  1.88s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2184/3000 [59:38<21:05,  1.55s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2185/3000 [59:41<27:04,  1.99s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2186/3000 [59:41<22:21,  1.65s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2187/3000 [59:44<25:04,  1.85s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2188/3000 [59:45<23:20,  1.73s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2189/3000 [59:48<26:31,  1.96s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2190/3000 [59:50<27:42,  2.05s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2191/3000 [59:53<32:00,  2.37s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2192/3000 [59:55<29:47,  2.21s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2193/3000 [59:56<26:27,  1.97s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2194/3000 [59:58<23:51,  1.78s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2195/3000 [1:00:00<26:43,  1.99s/it][step=2143] episode=2143.0000 return=-115.8386 length=11.0000 global_step=51950.0000 loss=5.0909 policy_loss=-0.0000 value_loss=10.1819 entropy=0.0000
[step=2144] episode=2144.0000 return=-115.9998 length=38.0000 global_step=51988.0000 loss=100.9292 policy_loss=-0.0000 value_loss=201.8584 entropy=0.0000
[step=2145] episode=2145.0000 return=-115.8156 length=19.0000 global_step=52007.0000 loss=8.5299 policy_loss=-0.0000 value_loss=17.0598 entropy=0.0000
[step=2146] episode=2146.0000 return=-115.7546 length=13.0000 global_step=52020.0000 loss=4.1938 policy_loss=-0.0000 value_loss=8.3875 entropy=0.0000
[step=2147] episode=2147.0000 return=-115.9942 length=12.0000 global_step=52032.0000 loss=9.9359 policy_loss=-0.0000 value_loss=19.8718 entropy=0.0000
[step=2148] episode=2148.0000 return=-115.9837 length=29.0000 global_step=52061.0000 loss=31.6708 policy_loss=-0.0000 value_loss=63.3417 entropy=0.0000
[step=2149] episode=2149.0000 return=-115.9955 length=28.0000 global_step=52089.0000 loss=14.4821 policy_loss=-0.0000 value_loss=28.9642 entropy=0.0000
[step=2150] episode=2150.0000 return=-115.9998 length=29.0000 global_step=52118.0000 loss=13.6235 policy_loss=-0.0000 value_loss=27.2471 entropy=0.0000
[step=2151] episode=2151.0000 return=-115.9120 length=12.0000 global_step=52130.0000 loss=83.8028 policy_loss=-0.0000 value_loss=167.6055 entropy=0.0000
[step=2152] episode=2152.0000 return=-115.9913 length=21.0000 global_step=52151.0000 loss=78.1005 policy_loss=-0.0000 value_loss=156.2010 entropy=0.0000
[step=2153] episode=2153.0000 return=-115.7216 length=11.0000 global_step=52162.0000 loss=33.2880 policy_loss=-0.0000 value_loss=66.5760 entropy=0.0000
[step=2154] episode=2154.0000 return=-115.9998 length=36.0000 global_step=52198.0000 loss=84.0457 policy_loss=-0.0000 value_loss=168.0914 entropy=0.0000
[step=2155] episode=2155.0000 return=-115.9955 length=35.0000 global_step=52233.0000 loss=86.9413 policy_loss=-0.0000 value_loss=173.8825 entropy=0.0000
[step=2156] episode=2156.0000 return=-115.9935 length=29.0000 global_step=52262.0000 loss=42.3722 policy_loss=-0.0000 value_loss=84.7445 entropy=0.0000
[step=2157] episode=2157.0000 return=-115.8636 length=21.0000 global_step=52283.0000 loss=3.4917 policy_loss=-0.0000 value_loss=6.9834 entropy=0.0000
[step=2158] episode=2158.0000 return=-115.9903 length=20.0000 global_step=52303.0000 loss=7.3082 policy_loss=-0.0000 value_loss=14.6163 entropy=0.0000
[step=2159] episode=2159.0000 return=-115.7743 length=18.0000 global_step=52321.0000 loss=37.5930 policy_loss=-0.0000 value_loss=75.1860 entropy=0.0000
[step=2160] episode=2160.0000 return=-115.9948 length=28.0000 global_step=52349.0000 loss=24.1486 policy_loss=-0.0000 value_loss=48.2973 entropy=0.0000
[step=2161] episode=2161.0000 return=-115.9990 length=12.0000 global_step=52361.0000 loss=17.5577 policy_loss=-0.0000 value_loss=35.1154 entropy=0.0000
[step=2162] episode=2162.0000 return=-115.9985 length=28.0000 global_step=52389.0000 loss=10.5373 policy_loss=-0.0000 value_loss=21.0746 entropy=0.0000
[step=2163] episode=2163.0000 return=-115.9887 length=26.0000 global_step=52415.0000 loss=32.9392 policy_loss=-0.0000 value_loss=65.8784 entropy=0.0000
[step=2164] episode=2164.0000 return=-115.8433 length=20.0000 global_step=52435.0000 loss=10.5400 policy_loss=-0.0000 value_loss=21.0801 entropy=0.0000
[step=2165] episode=2165.0000 return=-115.9918 length=21.0000 global_step=52456.0000 loss=5.7017 policy_loss=-0.0000 value_loss=11.4035 entropy=0.0000
[step=2166] episode=2166.0000 return=-115.9697 length=11.0000 global_step=52467.0000 loss=32.7373 policy_loss=-0.0000 value_loss=65.4745 entropy=0.0000
[step=2167] episode=2167.0000 return=-115.9821 length=26.0000 global_step=52493.0000 loss=4.7170 policy_loss=-0.0000 value_loss=9.4341 entropy=0.0000
[step=2168] episode=2168.0000 return=-115.9767 length=19.0000 global_step=52512.0000 loss=6.2510 policy_loss=-0.0000 value_loss=12.5020 entropy=0.0000
[step=2169] episode=2169.0000 return=-115.9968 length=20.0000 global_step=52532.0000 loss=6.2804 policy_loss=-0.0000 value_loss=12.5607 entropy=0.0000
[step=2170] episode=2170.0000 return=-115.9840 length=29.0000 global_step=52561.0000 loss=7.4801 policy_loss=-0.0000 value_loss=14.9601 entropy=0.0000
[step=2171] episode=2171.0000 return=-115.8771 length=26.0000 global_step=52587.0000 loss=5.5553 policy_loss=-0.0000 value_loss=11.1106 entropy=0.0000
[step=2172] episode=2172.0000 return=-115.9812 length=26.0000 global_step=52613.0000 loss=6.6551 policy_loss=-0.0000 value_loss=13.3102 entropy=0.0000
[step=2173] episode=2173.0000 return=-115.9814 length=20.0000 global_step=52633.0000 loss=4.9610 policy_loss=-0.0000 value_loss=9.9221 entropy=0.0000
[step=2174] episode=2174.0000 return=-115.9939 length=12.0000 global_step=52645.0000 loss=23.2421 policy_loss=-0.0000 value_loss=46.4842 entropy=0.0000
[step=2175] episode=2175.0000 return=-115.9990 length=20.0000 global_step=52665.0000 loss=10.5004 policy_loss=-0.0000 value_loss=21.0008 entropy=0.0000
[step=2176] episode=2176.0000 return=-115.8240 length=29.0000 global_step=52694.0000 loss=15.7811 policy_loss=-0.0000 value_loss=31.5623 entropy=0.0000
[step=2177] episode=2177.0000 return=-115.7571 length=13.0000 global_step=52707.0000 loss=14.7008 policy_loss=-0.0000 value_loss=29.4016 entropy=0.0000
[step=2178] episode=2178.0000 return=-115.9939 length=26.0000 global_step=52733.0000 loss=9.5785 policy_loss=-0.0000 value_loss=19.1570 entropy=0.0000
[step=2179] episode=2179.0000 return=-115.9984 length=28.0000 global_step=52761.0000 loss=27.6872 policy_loss=-0.0000 value_loss=55.3744 entropy=0.0000
[step=2180] episode=2180.0000 return=-115.9986 length=12.0000 global_step=52773.0000 loss=33.1055 policy_loss=-0.0000 value_loss=66.2109 entropy=0.0000
[step=2181] episode=2181.0000 return=-115.8871 length=38.0000 global_step=52811.0000 loss=25.9273 policy_loss=-0.0000 value_loss=51.8547 entropy=0.0000
[step=2182] episode=2182.0000 return=-115.9998 length=38.0000 global_step=52849.0000 loss=36.6920 policy_loss=-0.0000 value_loss=73.3839 entropy=0.0000
[step=2183] episode=2183.0000 return=-115.8870 length=26.0000 global_step=52875.0000 loss=34.1259 policy_loss=-0.0000 value_loss=68.2518 entropy=0.0000
[step=2184] episode=2184.0000 return=-115.8629 length=11.0000 global_step=52886.0000 loss=105.7932 policy_loss=-0.0000 value_loss=211.5863 entropy=0.0000
[step=2185] episode=2185.0000 return=-115.9840 length=44.0000 global_step=52930.0000 loss=23.9274 policy_loss=-0.0000 value_loss=47.8549 entropy=0.0000
[step=2186] episode=2186.0000 return=-115.9948 length=12.0000 global_step=52942.0000 loss=82.7386 policy_loss=-0.0000 value_loss=165.4772 entropy=0.0000
[step=2187] episode=2187.0000 return=-115.9949 length=34.0000 global_step=52976.0000 loss=13.5340 policy_loss=-0.0000 value_loss=27.0680 entropy=0.0000
[step=2188] episode=2188.0000 return=-115.9886 length=21.0000 global_step=52997.0000 loss=3.5691 policy_loss=-0.0000 value_loss=7.1383 entropy=0.0000
[step=2189] episode=2189.0000 return=-115.9998 length=38.0000 global_step=53035.0000 loss=102.5183 policy_loss=-0.0000 value_loss=205.0366 entropy=0.0000
[step=2190] episode=2190.0000 return=-115.9994 length=33.0000 global_step=53068.0000 loss=61.9486 policy_loss=-0.0000 value_loss=123.8972 entropy=0.0000
[step=2191] episode=2191.0000 return=-115.7833 length=45.0000 global_step=53113.0000 loss=82.4170 policy_loss=-0.0000 value_loss=164.8341 entropy=0.0000
[step=2192] episode=2192.0000 return=-115.8869 length=28.0000 global_step=53141.0000 loss=23.7992 policy_loss=-0.0000 value_loss=47.5984 entropy=0.0000
[step=2193] episode=2193.0000 return=-115.9836 length=20.0000 global_step=53161.0000 loss=51.3737 policy_loss=-0.0000 value_loss=102.7474 entropy=0.0000
[step=2194] episode=2194.0000 return=-115.9999 length=20.0000 global_step=53181.0000 loss=30.0581 policy_loss=-0.0000 value_loss=60.1161 entropy=0.0000
[step=2195] episode=2195.0000 return=-115.9829 length=38.0000 global_step=53219.0000 loss=14.5887 policy_loss=-0.0000 value_loss=29.1775 entropy=0.0000
a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2196/3000 [1:00:01<21:54,  1.64s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2197/3000 [1:00:03<23:02,  1.72s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2198/3000 [1:00:04<19:44,  1.48s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2199/3000 [1:00:06<23:18,  1.75s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2200/3000 [1:00:09<27:21,  2.05s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2201/3000 [1:00:11<28:09,  2.12s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2202/3000 [1:00:13<26:55,  2.02s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2203/3000 [1:00:15<27:04,  2.04s/it]a2c_tuned train:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2204/3000 [1:00:18<30:25,  2.29s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2205/3000 [1:00:19<26:22,  1.99s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2206/3000 [1:00:22<28:30,  2.15s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2207/3000 [1:00:23<25:11,  1.91s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2208/3000 [1:00:26<27:30,  2.08s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2209/3000 [1:00:28<27:10,  2.06s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2210/3000 [1:00:29<24:37,  1.87s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2211/3000 [1:00:30<20:36,  1.57s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2212/3000 [1:00:32<21:40,  1.65s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2213/3000 [1:00:34<22:53,  1.74s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2214/3000 [1:00:36<23:49,  1.82s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2215/3000 [1:00:37<21:38,  1.65s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2216/3000 [1:00:38<18:14,  1.40s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2217/3000 [1:00:40<21:50,  1.67s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2218/3000 [1:00:41<20:54,  1.60s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2219/3000 [1:00:44<24:16,  1.86s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2220/3000 [1:00:47<28:43,  2.21s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2221/3000 [1:00:50<31:02,  2.39s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2222/3000 [1:00:52<29:07,  2.25s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2223/3000 [1:00:54<29:32,  2.28s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2224/3000 [1:00:55<25:53,  2.00s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2225/3000 [1:00:57<23:06,  1.79s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2226/3000 [1:00:58<21:36,  1.67s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2227/3000 [1:00:59<18:36,  1.44s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2228/3000 [1:01:02<26:25,  2.05s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2229/3000 [1:01:04<23:34,  1.83s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2230/3000 [1:01:06<26:02,  2.03s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2231/3000 [1:01:09<27:45,  2.17s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2232/3000 [1:01:11<26:30,  2.07s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2233/3000 [1:01:12<23:41,  1.85s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2234/3000 [1:01:13<19:26,  1.52s/it]a2c_tuned train:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2235/3000 [1:01:15<22:23,  1.76s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2236/3000 [1:01:17<22:17,  1.75s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2237/3000 [1:01:18<21:08,  1.66s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2238/3000 [1:01:20<19:52,  1.57s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2239/3000 [1:01:21<18:51,  1.49s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2240/3000 [1:01:22<18:06,  1.43s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2241/3000 [1:01:24<20:22,  1.61s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2242/3000 [1:01:26<19:52,  1.57s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2243/3000 [1:01:27<19:03,  1.51s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2244/3000 [1:01:29<22:25,  1.78s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2245/3000 [1:01:31<23:13,  1.85s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2246/3000 [1:01:32<19:37,  1.56s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2247/3000 [1:01:36<27:04,  2.16s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2248/3000 [1:01:37<23:45,  1.90s/it][step=2196] episode=2196.0000 return=-115.9707 length=12.0000 global_step=53231.0000 loss=60.9740 policy_loss=-0.0000 value_loss=121.9481 entropy=0.0000
[step=2197] episode=2197.0000 return=-115.9931 length=28.0000 global_step=53259.0000 loss=4.6082 policy_loss=-0.0000 value_loss=9.2163 entropy=0.0000
[step=2198] episode=2198.0000 return=-115.9968 length=12.0000 global_step=53271.0000 loss=17.5880 policy_loss=-0.0000 value_loss=35.1760 entropy=0.0000
[step=2199] episode=2199.0000 return=-115.9824 length=35.0000 global_step=53306.0000 loss=94.5355 policy_loss=-0.0000 value_loss=189.0710 entropy=0.0000
[step=2200] episode=2200.0000 return=-115.9840 length=42.0000 global_step=53348.0000 loss=154.7707 policy_loss=-0.0000 value_loss=309.5414 entropy=0.0000
[step=2201] episode=2201.0000 return=-115.9911 length=34.0000 global_step=53382.0000 loss=36.6444 policy_loss=-0.0000 value_loss=73.2888 entropy=0.0000
[step=2202] episode=2202.0000 return=-115.9363 length=28.0000 global_step=53410.0000 loss=21.6133 policy_loss=-0.0000 value_loss=43.2266 entropy=0.0000
[step=2203] episode=2203.0000 return=-115.9996 length=30.0000 global_step=53440.0000 loss=16.0939 policy_loss=-0.0000 value_loss=32.1878 entropy=0.0000
[step=2204] episode=2204.0000 return=-115.9781 length=41.0000 global_step=53481.0000 loss=32.8723 policy_loss=-0.0000 value_loss=65.7446 entropy=0.0000
[step=2205] episode=2205.0000 return=-115.9973 length=19.0000 global_step=53500.0000 loss=91.4824 policy_loss=-0.0000 value_loss=182.9649 entropy=0.0000
[step=2206] episode=2206.0000 return=-115.9968 length=38.0000 global_step=53538.0000 loss=29.6383 policy_loss=-0.0000 value_loss=59.2767 entropy=0.0000
[step=2207] episode=2207.0000 return=-115.9968 length=19.0000 global_step=53557.0000 loss=50.7722 policy_loss=-0.0000 value_loss=101.5444 entropy=0.0000
[step=2208] episode=2208.0000 return=-115.9971 length=37.0000 global_step=53594.0000 loss=13.4659 policy_loss=-0.0000 value_loss=26.9319 entropy=0.0000
[step=2209] episode=2209.0000 return=-115.9986 length=29.0000 global_step=53623.0000 loss=10.2932 policy_loss=-0.0000 value_loss=20.5863 entropy=0.0000
[step=2210] episode=2210.0000 return=-115.9506 length=21.0000 global_step=53644.0000 loss=5.9423 policy_loss=-0.0000 value_loss=11.8846 entropy=0.0000
[step=2211] episode=2211.0000 return=-115.8423 length=13.0000 global_step=53657.0000 loss=24.8254 policy_loss=-0.0000 value_loss=49.6507 entropy=0.0000
[step=2212] episode=2212.0000 return=-115.9637 length=28.0000 global_step=53685.0000 loss=6.7859 policy_loss=-0.0000 value_loss=13.5718 entropy=0.0000
[step=2213] episode=2213.0000 return=-115.9384 length=30.0000 global_step=53715.0000 loss=21.6834 policy_loss=-0.0000 value_loss=43.3669 entropy=0.0000
[step=2214] episode=2214.0000 return=-115.9492 length=30.0000 global_step=53745.0000 loss=22.2318 policy_loss=-0.0000 value_loss=44.4635 entropy=0.0000
[step=2215] episode=2215.0000 return=-115.9096 length=18.0000 global_step=53763.0000 loss=13.7684 policy_loss=-0.0000 value_loss=27.5368 entropy=0.0000
[step=2216] episode=2216.0000 return=-115.9980 length=11.0000 global_step=53774.0000 loss=46.3386 policy_loss=-0.0000 value_loss=92.6771 entropy=0.0000
[step=2217] episode=2217.0000 return=-115.9999 length=34.0000 global_step=53808.0000 loss=32.5206 policy_loss=-0.0000 value_loss=65.0412 entropy=0.0000
[step=2218] episode=2218.0000 return=-115.9990 length=20.0000 global_step=53828.0000 loss=11.5703 policy_loss=-0.0000 value_loss=23.1407 entropy=0.0000
[step=2219] episode=2219.0000 return=-115.9968 length=37.0000 global_step=53865.0000 loss=12.7842 policy_loss=-0.0000 value_loss=25.5684 entropy=0.0000
[step=2220] episode=2220.0000 return=-115.9990 length=46.0000 global_step=53911.0000 loss=68.4336 policy_loss=-0.0000 value_loss=136.8672 entropy=0.0000
[step=2221] episode=2221.0000 return=-115.9585 length=42.0000 global_step=53953.0000 loss=32.5634 policy_loss=-0.0000 value_loss=65.1268 entropy=0.0000
[step=2222] episode=2222.0000 return=-115.9000 length=27.0000 global_step=53980.0000 loss=43.5062 policy_loss=-0.0000 value_loss=87.0123 entropy=0.0000
[step=2223] episode=2223.0000 return=-115.9826 length=35.0000 global_step=54015.0000 loss=32.6883 policy_loss=-0.0000 value_loss=65.3766 entropy=0.0000
[step=2224] episode=2224.0000 return=-115.9930 length=20.0000 global_step=54035.0000 loss=63.4567 policy_loss=-0.0000 value_loss=126.9133 entropy=0.0000
[step=2225] episode=2225.0000 return=-115.9946 length=19.0000 global_step=54054.0000 loss=37.3952 policy_loss=-0.0000 value_loss=74.7904 entropy=0.0000
[step=2226] episode=2226.0000 return=-115.9900 length=20.0000 global_step=54074.0000 loss=11.4111 policy_loss=-0.0000 value_loss=22.8223 entropy=0.0000
[step=2227] episode=2227.0000 return=-115.8340 length=13.0000 global_step=54087.0000 loss=10.3094 policy_loss=-0.0000 value_loss=20.6189 entropy=0.0000
[step=2228] episode=2228.0000 return=-115.9921 length=53.0000 global_step=54140.0000 loss=232.5094 policy_loss=-0.0000 value_loss=465.0188 entropy=0.0000
[step=2229] episode=2229.0000 return=-115.9925 length=20.0000 global_step=54160.0000 loss=77.5182 policy_loss=-0.0000 value_loss=155.0364 entropy=0.0000
[step=2230] episode=2230.0000 return=-115.9803 length=38.0000 global_step=54198.0000 loss=234.4864 policy_loss=-0.0000 value_loss=468.9727 entropy=0.0000
[step=2231] episode=2231.0000 return=-115.9955 length=37.0000 global_step=54235.0000 loss=102.1942 policy_loss=-0.0000 value_loss=204.3884 entropy=0.0000
[step=2232] episode=2232.0000 return=-115.9995 length=28.0000 global_step=54263.0000 loss=8.8739 policy_loss=-0.0000 value_loss=17.7478 entropy=0.0000
[step=2233] episode=2233.0000 return=-115.9988 length=19.0000 global_step=54282.0000 loss=18.3310 policy_loss=-0.0000 value_loss=36.6620 entropy=0.0000
[step=2234] episode=2234.0000 return=-115.8124 length=11.0000 global_step=54293.0000 loss=102.6208 policy_loss=-0.0000 value_loss=205.2416 entropy=0.0000
[step=2235] episode=2235.0000 return=-115.9886 length=35.0000 global_step=54328.0000 loss=65.9245 policy_loss=-0.0000 value_loss=131.8490 entropy=0.0000
[step=2236] episode=2236.0000 return=-115.9837 length=25.0000 global_step=54353.0000 loss=39.3214 policy_loss=-0.0000 value_loss=78.6428 entropy=0.0000
[step=2237] episode=2237.0000 return=-115.9417 length=21.0000 global_step=54374.0000 loss=60.9057 policy_loss=-0.0000 value_loss=121.8115 entropy=0.0000
[step=2238] episode=2238.0000 return=-115.9945 length=20.0000 global_step=54394.0000 loss=7.1453 policy_loss=-0.0000 value_loss=14.2906 entropy=0.0000
[step=2239] episode=2239.0000 return=-115.9808 length=20.0000 global_step=54414.0000 loss=8.3232 policy_loss=-0.0000 value_loss=16.6465 entropy=0.0000
[step=2240] episode=2240.0000 return=-115.8870 length=19.0000 global_step=54433.0000 loss=38.8545 policy_loss=-0.0000 value_loss=77.7090 entropy=0.0000
[step=2241] episode=2241.0000 return=-115.9998 length=30.0000 global_step=54463.0000 loss=108.5208 policy_loss=-0.0000 value_loss=217.0415 entropy=0.0000
[step=2242] episode=2242.0000 return=-115.9828 length=21.0000 global_step=54484.0000 loss=20.8590 policy_loss=-0.0000 value_loss=41.7180 entropy=0.0000
[step=2243] episode=2243.0000 return=-115.9904 length=20.0000 global_step=54504.0000 loss=8.9501 policy_loss=-0.0000 value_loss=17.9001 entropy=0.0000
[step=2244] episode=2244.0000 return=-115.9986 length=36.0000 global_step=54540.0000 loss=31.8211 policy_loss=-0.0000 value_loss=63.6422 entropy=0.0000
[step=2245] episode=2245.0000 return=-115.9941 length=30.0000 global_step=54570.0000 loss=16.0996 policy_loss=-0.0000 value_loss=32.1992 entropy=0.0000
[step=2246] episode=2246.0000 return=-115.7849 length=13.0000 global_step=54583.0000 loss=132.1051 policy_loss=-0.0000 value_loss=264.2103 entropy=0.0000
[step=2247] episode=2247.0000 return=-115.9992 length=54.0000 global_step=54637.0000 loss=59.3538 policy_loss=-0.0000 value_loss=118.7076 entropy=0.0000
[step=2248] episode=2248.0000 return=-115.9975 length=19.0000 global_step=54656.0000 loss=109.1050 policy_loss=-0.0000 value_loss=218.2100 entropy=0.0000
a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2249/3000 [1:01:38<19:49,  1.58s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2250/3000 [1:01:40<19:31,  1.56s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2251/3000 [1:01:41<19:27,  1.56s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2252/3000 [1:01:43<20:25,  1.64s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2253/3000 [1:01:43<15:21,  1.23s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2254/3000 [1:01:46<20:01,  1.61s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2255/3000 [1:01:48<23:37,  1.90s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2256/3000 [1:01:51<25:49,  2.08s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2257/3000 [1:01:52<22:49,  1.84s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2258/3000 [1:01:55<25:15,  2.04s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2259/3000 [1:01:55<20:48,  1.68s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2260/3000 [1:01:57<19:13,  1.56s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2261/3000 [1:01:58<16:53,  1.37s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2262/3000 [1:01:59<16:13,  1.32s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2263/3000 [1:02:00<16:33,  1.35s/it]a2c_tuned train:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2264/3000 [1:02:02<16:45,  1.37s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2265/3000 [1:02:03<17:08,  1.40s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2266/3000 [1:02:04<16:55,  1.38s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2267/3000 [1:02:07<21:09,  1.73s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2268/3000 [1:02:09<22:25,  1.84s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2269/3000 [1:02:11<21:01,  1.73s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2270/3000 [1:02:11<17:48,  1.46s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2271/3000 [1:02:13<17:42,  1.46s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2272/3000 [1:02:15<19:17,  1.59s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2273/3000 [1:02:15<16:07,  1.33s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2274/3000 [1:02:18<20:33,  1.70s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2275/3000 [1:02:19<17:31,  1.45s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2276/3000 [1:02:21<19:12,  1.59s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2277/3000 [1:02:22<16:22,  1.36s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2278/3000 [1:02:23<18:00,  1.50s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2279/3000 [1:02:25<19:25,  1.62s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2280/3000 [1:02:27<18:53,  1.57s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2281/3000 [1:02:29<21:50,  1.82s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2282/3000 [1:02:31<20:19,  1.70s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2283/3000 [1:02:33<21:41,  1.82s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2284/3000 [1:02:34<18:04,  1.51s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2285/3000 [1:02:35<17:59,  1.51s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2286/3000 [1:02:36<15:22,  1.29s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2287/3000 [1:02:37<15:42,  1.32s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2288/3000 [1:02:38<15:29,  1.31s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2289/3000 [1:02:40<15:31,  1.31s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2290/3000 [1:02:41<15:23,  1.30s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2291/3000 [1:02:42<15:35,  1.32s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2292/3000 [1:02:44<16:09,  1.37s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2293/3000 [1:02:46<20:13,  1.72s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2294/3000 [1:02:48<18:41,  1.59s/it]a2c_tuned train:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2295/3000 [1:02:50<19:13,  1.64s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2296/3000 [1:02:51<18:21,  1.56s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2297/3000 [1:02:52<15:41,  1.34s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2298/3000 [1:02:53<16:12,  1.39s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2299/3000 [1:02:56<19:45,  1.69s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2300/3000 [1:02:57<18:29,  1.58s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2301/3000 [1:02:58<17:37,  1.51s/it][step=2249] episode=2249.0000 return=-115.9993 length=12.0000 global_step=54668.0000 loss=149.2931 policy_loss=-0.0000 value_loss=298.5863 entropy=0.0000
[step=2250] episode=2250.0000 return=-115.9995 length=20.0000 global_step=54688.0000 loss=41.4492 policy_loss=-0.0000 value_loss=82.8984 entropy=0.0000
[step=2251] episode=2251.0000 return=-115.9933 length=22.0000 global_step=54710.0000 loss=8.4909 policy_loss=-0.0000 value_loss=16.9818 entropy=0.0000
[step=2252] episode=2252.0000 return=-115.9969 length=27.0000 global_step=54737.0000 loss=44.8647 policy_loss=-0.0000 value_loss=89.7293 entropy=0.0000
[step=2253] episode=2253.0000 return=-115.7415 length=4.0000 global_step=54741.0000 loss=26.6753 policy_loss=-0.0000 value_loss=53.3506 entropy=0.0000
[step=2254] episode=2254.0000 return=-115.9995 length=37.0000 global_step=54778.0000 loss=254.5471 policy_loss=-0.0000 value_loss=509.0942 entropy=0.0000
[step=2255] episode=2255.0000 return=-115.9979 length=38.0000 global_step=54816.0000 loss=256.1259 policy_loss=-0.0000 value_loss=512.2518 entropy=0.0000
[step=2256] episode=2256.0000 return=-115.9385 length=37.0000 global_step=54853.0000 loss=210.1425 policy_loss=-0.0000 value_loss=420.2849 entropy=0.0000
[step=2257] episode=2257.0000 return=-115.8188 length=19.0000 global_step=54872.0000 loss=0.5966 policy_loss=-0.0000 value_loss=1.1933 entropy=0.0000
[step=2258] episode=2258.0000 return=-108.8755 length=38.0000 global_step=54910.0000 loss=82.4474 policy_loss=-0.0000 value_loss=164.8949 entropy=0.0000
[step=2259] episode=2259.0000 return=-115.9953 length=13.0000 global_step=54923.0000 loss=158.1944 policy_loss=-0.0000 value_loss=316.3888 entropy=0.0000
[step=2260] episode=2260.0000 return=-115.9904 length=20.0000 global_step=54943.0000 loss=147.1047 policy_loss=-0.0000 value_loss=294.2094 entropy=0.0000
[step=2261] episode=2261.0000 return=-115.6962 length=13.0000 global_step=54956.0000 loss=237.2280 policy_loss=-0.0000 value_loss=474.4560 entropy=0.0000
[step=2262] episode=2262.0000 return=-115.7653 length=18.0000 global_step=54974.0000 loss=172.6339 policy_loss=-0.0000 value_loss=345.2679 entropy=0.0000
[step=2263] episode=2263.0000 return=-115.9998 length=20.0000 global_step=54994.0000 loss=49.6602 policy_loss=-0.0000 value_loss=99.3205 entropy=0.0000
[step=2264] episode=2264.0000 return=-115.9989 length=20.0000 global_step=55014.0000 loss=7.0067 policy_loss=-0.0000 value_loss=14.0134 entropy=0.0000
[step=2265] episode=2265.0000 return=-115.9770 length=21.0000 global_step=55035.0000 loss=27.2469 policy_loss=-0.0000 value_loss=54.4938 entropy=0.0000
[step=2266] episode=2266.0000 return=-115.9998 length=19.0000 global_step=55054.0000 loss=68.8396 policy_loss=-0.0000 value_loss=137.6792 entropy=0.0000
[step=2267] episode=2267.0000 return=-115.9989 length=36.0000 global_step=55090.0000 loss=211.1539 policy_loss=-0.0000 value_loss=422.3079 entropy=0.0000
[step=2268] episode=2268.0000 return=-115.9762 length=30.0000 global_step=55120.0000 loss=137.8747 policy_loss=-0.0000 value_loss=275.7494 entropy=0.0000
[step=2269] episode=2269.0000 return=-115.9931 length=21.0000 global_step=55141.0000 loss=33.2189 policy_loss=-0.0000 value_loss=66.4377 entropy=0.0000
[step=2270] episode=2270.0000 return=-115.8789 length=13.0000 global_step=55154.0000 loss=20.3946 policy_loss=-0.0000 value_loss=40.7893 entropy=0.0000
[step=2271] episode=2271.0000 return=-115.9840 length=21.0000 global_step=55175.0000 loss=15.4255 policy_loss=-0.0000 value_loss=30.8510 entropy=0.0000
[step=2272] episode=2272.0000 return=-115.9856 length=28.0000 global_step=55203.0000 loss=14.1893 policy_loss=-0.0000 value_loss=28.3785 entropy=0.0000
[step=2273] episode=2273.0000 return=-115.9962 length=11.0000 global_step=55214.0000 loss=82.6433 policy_loss=-0.0000 value_loss=165.2865 entropy=0.0000
[step=2274] episode=2274.0000 return=-115.8866 length=38.0000 global_step=55252.0000 loss=21.7976 policy_loss=-0.0000 value_loss=43.5951 entropy=0.0000
[step=2275] episode=2275.0000 return=-115.8199 length=13.0000 global_step=55265.0000 loss=50.3491 policy_loss=-0.0000 value_loss=100.6982 entropy=0.0000
[step=2276] episode=2276.0000 return=-115.9978 length=29.0000 global_step=55294.0000 loss=15.6854 policy_loss=-0.0000 value_loss=31.3708 entropy=0.0000
[step=2277] episode=2277.0000 return=-115.8503 length=12.0000 global_step=55306.0000 loss=15.2885 policy_loss=-0.0000 value_loss=30.5769 entropy=0.0000
[step=2278] episode=2278.0000 return=-115.9948 length=27.0000 global_step=55333.0000 loss=35.1722 policy_loss=-0.0000 value_loss=70.3444 entropy=0.0000
[step=2279] episode=2279.0000 return=-115.9857 length=28.0000 global_step=55361.0000 loss=23.2337 policy_loss=-0.0000 value_loss=46.4674 entropy=0.0000
[step=2280] episode=2280.0000 return=-115.9946 length=22.0000 global_step=55383.0000 loss=7.1125 policy_loss=-0.0000 value_loss=14.2250 entropy=0.0000
[step=2281] episode=2281.0000 return=-115.9925 length=34.0000 global_step=55417.0000 loss=38.9465 policy_loss=-0.0000 value_loss=77.8929 entropy=0.0000
[step=2282] episode=2282.0000 return=-115.9850 length=20.0000 global_step=55437.0000 loss=27.3477 policy_loss=-0.0000 value_loss=54.6955 entropy=0.0000
[step=2283] episode=2283.0000 return=-115.9978 length=30.0000 global_step=55467.0000 loss=16.8401 policy_loss=-0.0000 value_loss=33.6802 entropy=0.0000
[step=2284] episode=2284.0000 return=-115.9923 length=12.0000 global_step=55479.0000 loss=107.3184 policy_loss=-0.0000 value_loss=214.6369 entropy=0.0000
[step=2285] episode=2285.0000 return=-115.7969 length=22.0000 global_step=55501.0000 loss=27.2839 policy_loss=-0.0000 value_loss=54.5678 entropy=0.0000
[step=2286] episode=2286.0000 return=-115.8870 length=12.0000 global_step=55513.0000 loss=16.8419 policy_loss=-0.0000 value_loss=33.6838 entropy=0.0000
[step=2287] episode=2287.0000 return=-115.9946 length=20.0000 global_step=55533.0000 loss=18.2143 policy_loss=-0.0000 value_loss=36.4286 entropy=0.0000
[step=2288] episode=2288.0000 return=-115.9955 length=20.0000 global_step=55553.0000 loss=35.7258 policy_loss=-0.0000 value_loss=71.4516 entropy=0.0000
[step=2289] episode=2289.0000 return=-115.9975 length=20.0000 global_step=55573.0000 loss=49.8892 policy_loss=-0.0000 value_loss=99.7783 entropy=0.0000
[step=2290] episode=2290.0000 return=-115.9938 length=19.0000 global_step=55592.0000 loss=35.7045 policy_loss=-0.0000 value_loss=71.4089 entropy=0.0000
[step=2291] episode=2291.0000 return=-115.9985 length=21.0000 global_step=55613.0000 loss=14.6053 policy_loss=-0.0000 value_loss=29.2105 entropy=0.0000
[step=2292] episode=2292.0000 return=-115.9021 length=22.0000 global_step=55635.0000 loss=5.8723 policy_loss=-0.0000 value_loss=11.7445 entropy=0.0000
[step=2293] episode=2293.0000 return=-115.8870 length=36.0000 global_step=55671.0000 loss=18.4420 policy_loss=-0.0000 value_loss=36.8840 entropy=0.0000
[step=2294] episode=2294.0000 return=-115.8069 length=20.0000 global_step=55691.0000 loss=94.2261 policy_loss=-0.0000 value_loss=188.4521 entropy=0.0000
[step=2295] episode=2295.0000 return=-115.9998 length=26.0000 global_step=55717.0000 loss=28.2111 policy_loss=-0.0000 value_loss=56.4222 entropy=0.0000
[step=2296] episode=2296.0000 return=-115.9939 length=21.0000 global_step=55738.0000 loss=38.6821 policy_loss=-0.0000 value_loss=77.3643 entropy=0.0000
[step=2297] episode=2297.0000 return=-115.7384 length=12.0000 global_step=55750.0000 loss=63.9690 policy_loss=-0.0000 value_loss=127.9379 entropy=0.0000
[step=2298] episode=2298.0000 return=-115.9096 length=21.0000 global_step=55771.0000 loss=6.3646 policy_loss=-0.0000 value_loss=12.7293 entropy=0.0000
[step=2299] episode=2299.0000 return=-115.9948 length=36.0000 global_step=55807.0000 loss=103.2956 policy_loss=-0.0000 value_loss=206.5911 entropy=0.0000
[step=2300] episode=2300.0000 return=-114.9537 length=20.0000 global_step=55827.0000 loss=4.1705 policy_loss=-0.0000 value_loss=8.3410 entropy=0.0000
[step=2301] episode=2301.0000 return=-115.9096 length=19.0000 global_step=55846.0000 loss=26.1424 policy_loss=-0.0000 value_loss=52.2848 entropy=0.0000
a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2302/3000 [1:03:00<16:45,  1.44s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2303/3000 [1:03:00<14:36,  1.26s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2304/3000 [1:03:01<13:17,  1.15s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2305/3000 [1:03:03<15:36,  1.35s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2306/3000 [1:03:06<20:28,  1.77s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2307/3000 [1:03:07<19:23,  1.68s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2308/3000 [1:03:09<18:40,  1.62s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2309/3000 [1:03:10<16:08,  1.40s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2310/3000 [1:03:11<15:53,  1.38s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2311/3000 [1:03:13<16:10,  1.41s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2312/3000 [1:03:14<17:53,  1.56s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2313/3000 [1:03:16<19:26,  1.70s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2314/3000 [1:03:18<18:08,  1.59s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2315/3000 [1:03:20<19:14,  1.68s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2316/3000 [1:03:22<20:04,  1.76s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2317/3000 [1:03:22<16:57,  1.49s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2318/3000 [1:03:24<16:20,  1.44s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2319/3000 [1:03:25<16:00,  1.41s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2320/3000 [1:03:26<14:07,  1.25s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2321/3000 [1:03:28<18:17,  1.62s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2322/3000 [1:03:29<15:30,  1.37s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2323/3000 [1:03:31<15:20,  1.36s/it]a2c_tuned train:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2324/3000 [1:03:33<17:52,  1.59s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2325/3000 [1:03:36<23:23,  2.08s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2326/3000 [1:03:38<24:09,  2.15s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2327/3000 [1:03:40<23:10,  2.07s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2328/3000 [1:03:42<22:29,  2.01s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2329/3000 [1:03:43<20:01,  1.79s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2330/3000 [1:03:45<18:17,  1.64s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2331/3000 [1:03:46<18:00,  1.62s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2332/3000 [1:03:49<22:21,  2.01s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2333/3000 [1:03:51<22:15,  2.00s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2334/3000 [1:03:53<23:25,  2.11s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2335/3000 [1:03:54<18:53,  1.70s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2336/3000 [1:03:57<21:34,  1.95s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2337/3000 [1:03:58<19:39,  1.78s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2338/3000 [1:04:00<20:28,  1.86s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2339/3000 [1:04:01<18:36,  1.69s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2340/3000 [1:04:03<17:42,  1.61s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2341/3000 [1:04:05<20:21,  1.85s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2342/3000 [1:04:07<20:31,  1.87s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2343/3000 [1:04:10<24:07,  2.20s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2344/3000 [1:04:12<22:55,  2.10s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2345/3000 [1:04:14<22:07,  2.03s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2346/3000 [1:04:16<21:24,  1.96s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2347/3000 [1:04:17<19:53,  1.83s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2348/3000 [1:04:18<18:03,  1.66s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2349/3000 [1:04:20<18:17,  1.69s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2350/3000 [1:04:21<15:45,  1.46s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2351/3000 [1:04:23<17:06,  1.58s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2352/3000 [1:04:24<15:50,  1.47s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2353/3000 [1:04:27<18:54,  1.75s/it]a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2354/3000 [1:04:28<18:59,  1.76s/it][step=2302] episode=2302.0000 return=-115.9971 length=18.0000 global_step=55864.0000 loss=7.1863 policy_loss=-0.0000 value_loss=14.3726 entropy=0.0000
[step=2303] episode=2303.0000 return=-115.9996 length=12.0000 global_step=55876.0000 loss=11.8378 policy_loss=-0.0000 value_loss=23.6755 entropy=0.0000
[step=2304] episode=2304.0000 return=-115.9745 length=12.0000 global_step=55888.0000 loss=13.1405 policy_loss=-0.0000 value_loss=26.2810 entropy=0.0000
[step=2305] episode=2305.0000 return=-115.9343 length=26.0000 global_step=55914.0000 loss=6.4226 policy_loss=-0.0000 value_loss=12.8451 entropy=0.0000
[step=2306] episode=2306.0000 return=-115.9979 length=42.0000 global_step=55956.0000 loss=42.2069 policy_loss=-0.0000 value_loss=84.4137 entropy=0.0000
[step=2307] episode=2307.0000 return=-115.9984 length=21.0000 global_step=55977.0000 loss=7.2325 policy_loss=-0.0000 value_loss=14.4649 entropy=0.0000
[step=2308] episode=2308.0000 return=-115.9968 length=22.0000 global_step=55999.0000 loss=8.2170 policy_loss=-0.0000 value_loss=16.4340 entropy=0.0000
[step=2309] episode=2309.0000 return=-115.9608 length=13.0000 global_step=56012.0000 loss=35.3805 policy_loss=-0.0000 value_loss=70.7610 entropy=0.0000
[step=2310] episode=2310.0000 return=-115.9955 length=20.0000 global_step=56032.0000 loss=6.2606 policy_loss=-0.0000 value_loss=12.5213 entropy=0.0000
[step=2311] episode=2311.0000 return=-115.9939 length=21.0000 global_step=56053.0000 loss=6.4723 policy_loss=-0.0000 value_loss=12.9447 entropy=0.0000
[step=2312] episode=2312.0000 return=-115.9948 length=28.0000 global_step=56081.0000 loss=32.7769 policy_loss=-0.0000 value_loss=65.5538 entropy=0.0000
[step=2313] episode=2313.0000 return=-115.9834 length=29.0000 global_step=56110.0000 loss=18.2507 policy_loss=-0.0000 value_loss=36.5014 entropy=0.0000
[step=2314] episode=2314.0000 return=-115.9995 length=19.0000 global_step=56129.0000 loss=14.2273 policy_loss=-0.0000 value_loss=28.4547 entropy=0.0000
[step=2315] episode=2315.0000 return=-115.9925 length=28.0000 global_step=56157.0000 loss=12.2695 policy_loss=-0.0000 value_loss=24.5391 entropy=0.0000
[step=2316] episode=2316.0000 return=-115.9935 length=30.0000 global_step=56187.0000 loss=12.5158 policy_loss=-0.0000 value_loss=25.0316 entropy=0.0000
[step=2317] episode=2317.0000 return=-115.9990 length=13.0000 global_step=56200.0000 loss=46.2740 policy_loss=-0.0000 value_loss=92.5480 entropy=0.0000
[step=2318] episode=2318.0000 return=-115.9968 length=19.0000 global_step=56219.0000 loss=5.7660 policy_loss=-0.0000 value_loss=11.5321 entropy=0.0000
[step=2319] episode=2319.0000 return=-115.9983 length=19.0000 global_step=56238.0000 loss=0.6556 policy_loss=-0.0000 value_loss=1.3111 entropy=0.0000
[step=2320] episode=2320.0000 return=-115.9959 length=12.0000 global_step=56250.0000 loss=4.8859 policy_loss=-0.0000 value_loss=9.7719 entropy=0.0000
[step=2321] episode=2321.0000 return=-115.9975 length=36.0000 global_step=56286.0000 loss=126.5570 policy_loss=-0.0000 value_loss=253.1139 entropy=0.0000
[step=2322] episode=2322.0000 return=-115.9960 length=12.0000 global_step=56298.0000 loss=5.7428 policy_loss=-0.0000 value_loss=11.4857 entropy=0.0000
[step=2323] episode=2323.0000 return=-115.9992 length=19.0000 global_step=56317.0000 loss=16.4950 policy_loss=-0.0000 value_loss=32.9900 entropy=0.0000
[step=2324] episode=2324.0000 return=-115.9384 length=30.0000 global_step=56347.0000 loss=24.4673 policy_loss=-0.0000 value_loss=48.9345 entropy=0.0000
[step=2325] episode=2325.0000 return=-115.9941 length=49.0000 global_step=56396.0000 loss=94.2989 policy_loss=-0.0000 value_loss=188.5978 entropy=0.0000
[step=2326] episode=2326.0000 return=-116.0000 length=34.0000 global_step=56430.0000 loss=20.4161 policy_loss=-0.0000 value_loss=40.8323 entropy=0.0000
[step=2327] episode=2327.0000 return=-115.9987 length=28.0000 global_step=56458.0000 loss=69.9924 policy_loss=-0.0000 value_loss=139.9847 entropy=0.0000
[step=2328] episode=2328.0000 return=-115.9979 length=28.0000 global_step=56486.0000 loss=51.2284 policy_loss=-0.0000 value_loss=102.4568 entropy=0.0000
[step=2329] episode=2329.0000 return=-115.9096 length=19.0000 global_step=56505.0000 loss=76.0260 policy_loss=-0.0000 value_loss=152.0520 entropy=0.0000
[step=2330] episode=2330.0000 return=-115.9989 length=19.0000 global_step=56524.0000 loss=42.2594 policy_loss=-0.0000 value_loss=84.5188 entropy=0.0000
[step=2331] episode=2331.0000 return=-115.8431 length=22.0000 global_step=56546.0000 loss=14.4357 policy_loss=-0.0000 value_loss=28.8715 entropy=0.0000
[step=2332] episode=2332.0000 return=-115.9997 length=44.0000 global_step=56590.0000 loss=76.5773 policy_loss=-0.0000 value_loss=153.1545 entropy=0.0000
[step=2333] episode=2333.0000 return=-115.9961 length=29.0000 global_step=56619.0000 loss=68.8135 policy_loss=-0.0000 value_loss=137.6270 entropy=0.0000
[step=2334] episode=2334.0000 return=-115.9998 length=34.0000 global_step=56653.0000 loss=119.4921 policy_loss=-0.0000 value_loss=238.9843 entropy=0.0000
[step=2335] episode=2335.0000 return=-115.7826 length=11.0000 global_step=56664.0000 loss=4.8708 policy_loss=-0.0000 value_loss=9.7417 entropy=0.0000
[step=2336] episode=2336.0000 return=-115.9959 length=38.0000 global_step=56702.0000 loss=75.5141 policy_loss=-0.0000 value_loss=151.0281 entropy=0.0000
[step=2337] episode=2337.0000 return=-115.9986 length=21.0000 global_step=56723.0000 loss=5.4798 policy_loss=-0.0000 value_loss=10.9595 entropy=0.0000
[step=2338] episode=2338.0000 return=-115.9999 length=30.0000 global_step=56753.0000 loss=13.8004 policy_loss=-0.0000 value_loss=27.6007 entropy=0.0000
[step=2339] episode=2339.0000 return=-115.9834 length=19.0000 global_step=56772.0000 loss=29.3915 policy_loss=-0.0000 value_loss=58.7830 entropy=0.0000
[step=2340] episode=2340.0000 return=-115.9948 length=20.0000 global_step=56792.0000 loss=30.8601 policy_loss=-0.0000 value_loss=61.7203 entropy=0.0000
[step=2341] episode=2341.0000 return=-115.9997 length=37.0000 global_step=56829.0000 loss=12.3201 policy_loss=-0.0000 value_loss=24.6402 entropy=0.0000
[step=2342] episode=2342.0000 return=-115.9977 length=28.0000 global_step=56857.0000 loss=13.2977 policy_loss=-0.0000 value_loss=26.5954 entropy=0.0000
[step=2343] episode=2343.0000 return=-115.9985 length=45.0000 global_step=56902.0000 loss=30.1368 policy_loss=-0.0000 value_loss=60.2737 entropy=0.0000
[step=2344] episode=2344.0000 return=-115.8645 length=28.0000 global_step=56930.0000 loss=18.5821 policy_loss=-0.0000 value_loss=37.1641 entropy=0.0000
[step=2345] episode=2345.0000 return=-115.9085 length=28.0000 global_step=56958.0000 loss=9.4063 policy_loss=-0.0000 value_loss=18.8126 entropy=0.0000
[step=2346] episode=2346.0000 return=-115.9858 length=27.0000 global_step=56985.0000 loss=7.6477 policy_loss=-0.0000 value_loss=15.2954 entropy=0.0000
[step=2347] episode=2347.0000 return=-115.9975 length=22.0000 global_step=57007.0000 loss=8.4392 policy_loss=-0.0000 value_loss=16.8785 entropy=0.0000
[step=2348] episode=2348.0000 return=-115.9242 length=19.0000 global_step=57026.0000 loss=6.7236 policy_loss=-0.0000 value_loss=13.4472 entropy=0.0000
[step=2349] episode=2349.0000 return=-115.9968 length=26.0000 global_step=57052.0000 loss=15.9396 policy_loss=-0.0000 value_loss=31.8791 entropy=0.0000
[step=2350] episode=2350.0000 return=-115.9803 length=13.0000 global_step=57065.0000 loss=38.2699 policy_loss=-0.0000 value_loss=76.5398 entropy=0.0000
[step=2351] episode=2351.0000 return=-115.9955 length=28.0000 global_step=57093.0000 loss=12.1478 policy_loss=-0.0000 value_loss=24.2956 entropy=0.0000
[step=2352] episode=2352.0000 return=-115.7233 length=18.0000 global_step=57111.0000 loss=21.9648 policy_loss=-0.0000 value_loss=43.9297 entropy=0.0000
[step=2353] episode=2353.0000 return=-115.9971 length=36.0000 global_step=57147.0000 loss=9.3237 policy_loss=-0.0000 value_loss=18.6473 entropy=0.0000
[step=2354] episode=2354.0000 return=-115.9955 length=27.0000 global_step=57174.0000 loss=11.1208 policy_loss=-0.0000 value_loss=22.2416 entropy=0.0000
a2c_tuned train:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2355/3000 [1:04:29<16:11,  1.51s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2356/3000 [1:04:31<15:55,  1.48s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2357/3000 [1:04:32<15:28,  1.44s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2358/3000 [1:04:32<11:54,  1.11s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2359/3000 [1:04:34<12:33,  1.18s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2360/3000 [1:04:36<14:31,  1.36s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2361/3000 [1:04:37<14:24,  1.35s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2362/3000 [1:04:39<17:30,  1.65s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2363/3000 [1:04:40<14:42,  1.39s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2364/3000 [1:04:42<16:03,  1.51s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2365/3000 [1:04:43<15:43,  1.49s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2366/3000 [1:04:44<13:38,  1.29s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2367/3000 [1:04:45<12:23,  1.17s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2368/3000 [1:04:46<11:40,  1.11s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2369/3000 [1:04:49<17:46,  1.69s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2370/3000 [1:04:51<19:36,  1.87s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2371/3000 [1:04:53<19:29,  1.86s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2372/3000 [1:04:54<16:27,  1.57s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2373/3000 [1:04:55<16:03,  1.54s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2374/3000 [1:04:57<15:14,  1.46s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2375/3000 [1:04:59<16:29,  1.58s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2376/3000 [1:04:59<14:07,  1.36s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2377/3000 [1:05:00<12:08,  1.17s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2378/3000 [1:05:02<12:39,  1.22s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2379/3000 [1:05:03<14:54,  1.44s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2380/3000 [1:05:06<17:54,  1.73s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2381/3000 [1:05:07<16:49,  1.63s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2382/3000 [1:05:09<16:04,  1.56s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2383/3000 [1:05:10<15:34,  1.51s/it]a2c_tuned train:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2384/3000 [1:05:13<18:26,  1.80s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2385/3000 [1:05:14<17:07,  1.67s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2386/3000 [1:05:15<15:55,  1.56s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2387/3000 [1:05:16<15:04,  1.48s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2388/3000 [1:05:19<16:45,  1.64s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2389/3000 [1:05:20<17:17,  1.70s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2390/3000 [1:05:22<16:34,  1.63s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2391/3000 [1:05:23<15:41,  1.55s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2392/3000 [1:05:26<20:09,  1.99s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2393/3000 [1:05:28<20:14,  2.00s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2394/3000 [1:05:29<16:27,  1.63s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2395/3000 [1:05:30<15:55,  1.58s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2396/3000 [1:05:32<15:05,  1.50s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2397/3000 [1:05:35<20:05,  2.00s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2398/3000 [1:05:36<18:08,  1.81s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2399/3000 [1:05:38<18:42,  1.87s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2400/3000 [1:05:41<20:37,  2.06s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2401/3000 [1:05:43<20:03,  2.01s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2402/3000 [1:05:44<18:12,  1.83s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2403/3000 [1:05:46<17:59,  1.81s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2404/3000 [1:05:48<18:12,  1.83s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2405/3000 [1:05:49<17:36,  1.78s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2406/3000 [1:05:51<16:27,  1.66s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2407/3000 [1:05:54<20:10,  2.04s/it][step=2355] episode=2355.0000 return=-115.9940 length=13.0000 global_step=57187.0000 loss=40.4471 policy_loss=-0.0000 value_loss=80.8942 entropy=0.0000
[step=2356] episode=2356.0000 return=-115.9564 length=20.0000 global_step=57207.0000 loss=15.3002 policy_loss=-0.0000 value_loss=30.6003 entropy=0.0000
[step=2357] episode=2357.0000 return=-115.9840 length=20.0000 global_step=57227.0000 loss=12.9667 policy_loss=-0.0000 value_loss=25.9334 entropy=0.0000
[step=2358] episode=2358.0000 return=-115.7171 length=5.0000 global_step=57232.0000 loss=22.0908 policy_loss=-0.0000 value_loss=44.1816 entropy=0.0000
[step=2359] episode=2359.0000 return=-115.9805 length=20.0000 global_step=57252.0000 loss=92.1945 policy_loss=-0.0000 value_loss=184.3891 entropy=0.0000
[step=2360] episode=2360.0000 return=-115.9989 length=27.0000 global_step=57279.0000 loss=155.6280 policy_loss=-0.0000 value_loss=311.2560 entropy=0.0000
[step=2361] episode=2361.0000 return=-115.9855 length=20.0000 global_step=57299.0000 loss=60.6427 policy_loss=-0.0000 value_loss=121.2854 entropy=0.0000
[step=2362] episode=2362.0000 return=-115.9753 length=36.0000 global_step=57335.0000 loss=55.3676 policy_loss=-0.0000 value_loss=110.7353 entropy=0.0000
[step=2363] episode=2363.0000 return=-115.9990 length=11.0000 global_step=57346.0000 loss=54.5144 policy_loss=-0.0000 value_loss=109.0288 entropy=0.0000
[step=2364] episode=2364.0000 return=-115.9858 length=26.0000 global_step=57372.0000 loss=31.7940 policy_loss=-0.0000 value_loss=63.5880 entropy=0.0000
[step=2365] episode=2365.0000 return=-115.9782 length=20.0000 global_step=57392.0000 loss=125.4965 policy_loss=-0.0000 value_loss=250.9931 entropy=0.0000
[step=2366] episode=2366.0000 return=-115.9982 length=12.0000 global_step=57404.0000 loss=89.0825 policy_loss=-0.0000 value_loss=178.1649 entropy=0.0000
[step=2367] episode=2367.0000 return=-115.9990 length=13.0000 global_step=57417.0000 loss=67.2370 policy_loss=-0.0000 value_loss=134.4739 entropy=0.0000
[step=2368] episode=2368.0000 return=-115.9149 length=13.0000 global_step=57430.0000 loss=5.6441 policy_loss=-0.0000 value_loss=11.2882 entropy=0.0000
[step=2369] episode=2369.0000 return=-115.9886 length=46.0000 global_step=57476.0000 loss=328.5482 policy_loss=-0.0000 value_loss=657.0963 entropy=0.0000
[step=2370] episode=2370.0000 return=-115.9956 length=36.0000 global_step=57512.0000 loss=260.1007 policy_loss=-0.0000 value_loss=520.2015 entropy=0.0000
[step=2371] episode=2371.0000 return=-115.8749 length=27.0000 global_step=57539.0000 loss=65.1370 policy_loss=-0.0000 value_loss=130.2739 entropy=0.0000
[step=2372] episode=2372.0000 return=-115.8415 length=13.0000 global_step=57552.0000 loss=3.2650 policy_loss=-0.0000 value_loss=6.5300 entropy=0.0000
[step=2373] episode=2373.0000 return=-115.9964 length=22.0000 global_step=57574.0000 loss=5.3662 policy_loss=-0.0000 value_loss=10.7323 entropy=0.0000
[step=2374] episode=2374.0000 return=-115.9984 length=20.0000 global_step=57594.0000 loss=12.6494 policy_loss=-0.0000 value_loss=25.2988 entropy=0.0000
[step=2375] episode=2375.0000 return=-115.9996 length=29.0000 global_step=57623.0000 loss=13.5589 policy_loss=-0.0000 value_loss=27.1177 entropy=0.0000
[step=2376] episode=2376.0000 return=-115.8694 length=12.0000 global_step=57635.0000 loss=73.8948 policy_loss=-0.0000 value_loss=147.7896 entropy=0.0000
[step=2377] episode=2377.0000 return=-115.7432 length=10.0000 global_step=57645.0000 loss=35.9781 policy_loss=-0.0000 value_loss=71.9562 entropy=0.0000
[step=2378] episode=2378.0000 return=-115.9700 length=20.0000 global_step=57665.0000 loss=11.4781 policy_loss=-0.0000 value_loss=22.9561 entropy=0.0000
[step=2379] episode=2379.0000 return=-115.9961 length=29.0000 global_step=57694.0000 loss=98.7711 policy_loss=-0.0000 value_loss=197.5421 entropy=0.0000
[step=2380] episode=2380.0000 return=-115.9986 length=36.0000 global_step=57730.0000 loss=72.2779 policy_loss=-0.0000 value_loss=144.5558 entropy=0.0000
[step=2381] episode=2381.0000 return=-115.9854 length=20.0000 global_step=57750.0000 loss=4.9640 policy_loss=-0.0000 value_loss=9.9279 entropy=0.0000
[step=2382] episode=2382.0000 return=-115.9096 length=20.0000 global_step=57770.0000 loss=16.1043 policy_loss=-0.0000 value_loss=32.2086 entropy=0.0000
[step=2383] episode=2383.0000 return=-115.8512 length=20.0000 global_step=57790.0000 loss=39.1594 policy_loss=-0.0000 value_loss=78.3188 entropy=0.0000
[step=2384] episode=2384.0000 return=-115.9764 length=36.0000 global_step=57826.0000 loss=36.8760 policy_loss=-0.0000 value_loss=73.7520 entropy=0.0000
[step=2385] episode=2385.0000 return=-115.9991 length=21.0000 global_step=57847.0000 loss=23.3675 policy_loss=-0.0000 value_loss=46.7351 entropy=0.0000
[step=2386] episode=2386.0000 return=-115.9880 length=19.0000 global_step=57866.0000 loss=10.4866 policy_loss=-0.0000 value_loss=20.9731 entropy=0.0000
[step=2387] episode=2387.0000 return=-115.8870 length=19.0000 global_step=57885.0000 loss=8.5169 policy_loss=-0.0000 value_loss=17.0337 entropy=0.0000
[step=2388] episode=2388.0000 return=-116.0000 length=29.0000 global_step=57914.0000 loss=76.5412 policy_loss=-0.0000 value_loss=153.0824 entropy=0.0000
[step=2389] episode=2389.0000 return=-115.9922 length=28.0000 global_step=57942.0000 loss=28.3245 policy_loss=-0.0000 value_loss=56.6491 entropy=0.0000
[step=2390] episode=2390.0000 return=-115.9968 length=22.0000 global_step=57964.0000 loss=17.9583 policy_loss=-0.0000 value_loss=35.9165 entropy=0.0000
[step=2391] episode=2391.0000 return=-115.9999 length=20.0000 global_step=57984.0000 loss=46.9025 policy_loss=-0.0000 value_loss=93.8050 entropy=0.0000
[step=2392] episode=2392.0000 return=-115.9840 length=46.0000 global_step=58030.0000 loss=31.9997 policy_loss=-0.0000 value_loss=63.9994 entropy=0.0000
[step=2393] episode=2393.0000 return=-115.9991 length=30.0000 global_step=58060.0000 loss=13.1804 policy_loss=-0.0000 value_loss=26.3608 entropy=0.0000
[step=2394] episode=2394.0000 return=-115.6949 length=12.0000 global_step=58072.0000 loss=68.4594 policy_loss=-0.0000 value_loss=136.9189 entropy=0.0000
[step=2395] episode=2395.0000 return=-115.7544 length=20.0000 global_step=58092.0000 loss=17.2858 policy_loss=-0.0000 value_loss=34.5716 entropy=0.0000
[step=2396] episode=2396.0000 return=-115.9974 length=20.0000 global_step=58112.0000 loss=54.0850 policy_loss=-0.0000 value_loss=108.1701 entropy=0.0000
[step=2397] episode=2397.0000 return=-115.9999 length=48.0000 global_step=58160.0000 loss=160.7077 policy_loss=-0.0000 value_loss=321.4155 entropy=0.0000
[step=2398] episode=2398.0000 return=-115.9999 length=20.0000 global_step=58180.0000 loss=17.9557 policy_loss=-0.0000 value_loss=35.9114 entropy=0.0000
[step=2399] episode=2399.0000 return=-115.9917 length=30.0000 global_step=58210.0000 loss=40.5070 policy_loss=-0.0000 value_loss=81.0140 entropy=0.0000
[step=2400] episode=2400.0000 return=-115.9934 length=36.0000 global_step=58246.0000 loss=71.7590 policy_loss=-0.0000 value_loss=143.5181 entropy=0.0000
[step=2401] episode=2401.0000 return=-115.9968 length=28.0000 global_step=58274.0000 loss=20.2849 policy_loss=-0.0000 value_loss=40.5697 entropy=0.0000
[step=2402] episode=2402.0000 return=-115.9997 length=21.0000 global_step=58295.0000 loss=6.3829 policy_loss=-0.0000 value_loss=12.7657 entropy=0.0000
[step=2403] episode=2403.0000 return=-115.9939 length=26.0000 global_step=58321.0000 loss=55.2693 policy_loss=-0.0000 value_loss=110.5386 entropy=0.0000
[step=2404] episode=2404.0000 return=-115.9984 length=28.0000 global_step=58349.0000 loss=20.8816 policy_loss=-0.0000 value_loss=41.7631 entropy=0.0000
[step=2405] episode=2405.0000 return=-115.9917 length=25.0000 global_step=58374.0000 loss=46.7891 policy_loss=-0.0000 value_loss=93.5783 entropy=0.0000
[step=2406] episode=2406.0000 return=-115.9794 length=21.0000 global_step=58395.0000 loss=17.9274 policy_loss=-0.0000 value_loss=35.8549 entropy=0.0000
[step=2407] episode=2407.0000 return=-115.9887 length=42.0000 global_step=58437.0000 loss=63.3928 policy_loss=-0.0000 value_loss=126.7856 entropy=0.0000
a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2408/3000 [1:05:56<19:45,  2.00s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2409/3000 [1:05:58<19:39,  2.00s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2410/3000 [1:05:58<16:06,  1.64s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2411/3000 [1:05:59<13:50,  1.41s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2412/3000 [1:06:01<14:03,  1.43s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2413/3000 [1:06:02<13:59,  1.43s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2414/3000 [1:06:04<13:43,  1.40s/it]a2c_tuned train:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2415/3000 [1:06:04<12:03,  1.24s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2416/3000 [1:06:05<10:54,  1.12s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2417/3000 [1:06:06<10:12,  1.05s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2418/3000 [1:06:08<11:26,  1.18s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2419/3000 [1:06:09<12:00,  1.24s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2420/3000 [1:06:11<15:38,  1.62s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2421/3000 [1:06:13<16:22,  1.70s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2422/3000 [1:06:14<13:40,  1.42s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2423/3000 [1:06:15<11:55,  1.24s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2424/3000 [1:06:17<13:48,  1.44s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2425/3000 [1:06:18<13:13,  1.38s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2426/3000 [1:06:19<11:53,  1.24s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2427/3000 [1:06:21<13:23,  1.40s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2428/3000 [1:06:23<14:58,  1.57s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2429/3000 [1:06:24<14:17,  1.50s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2430/3000 [1:06:26<14:03,  1.48s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2431/3000 [1:06:28<16:42,  1.76s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2432/3000 [1:06:30<17:09,  1.81s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2433/3000 [1:06:31<16:11,  1.71s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2434/3000 [1:06:32<13:51,  1.47s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2435/3000 [1:06:34<13:35,  1.44s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2436/3000 [1:06:36<16:35,  1.76s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2437/3000 [1:06:37<14:02,  1.50s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2438/3000 [1:06:39<13:57,  1.49s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2439/3000 [1:06:40<14:48,  1.58s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2440/3000 [1:06:43<16:36,  1.78s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2441/3000 [1:06:43<13:47,  1.48s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2442/3000 [1:06:45<14:57,  1.61s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2443/3000 [1:06:47<15:43,  1.69s/it]a2c_tuned train:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2444/3000 [1:06:49<16:44,  1.81s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2445/3000 [1:06:51<15:24,  1.67s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2446/3000 [1:06:52<14:48,  1.60s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2447/3000 [1:06:54<15:28,  1.68s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2448/3000 [1:06:56<16:53,  1.84s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2449/3000 [1:06:58<16:41,  1.82s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2450/3000 [1:06:59<15:19,  1.67s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2451/3000 [1:07:00<12:50,  1.40s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2452/3000 [1:07:01<11:22,  1.25s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2453/3000 [1:07:02<10:18,  1.13s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2454/3000 [1:07:03<10:52,  1.20s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2455/3000 [1:07:04<11:17,  1.24s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2456/3000 [1:07:06<11:41,  1.29s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2457/3000 [1:07:07<11:58,  1.32s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2458/3000 [1:07:08<10:39,  1.18s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2459/3000 [1:07:09<11:23,  1.26s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2460/3000 [1:07:12<14:33,  1.62s/it][step=2408] episode=2408.0000 return=-115.9969 length=28.0000 global_step=58465.0000 loss=9.8099 policy_loss=-0.0000 value_loss=19.6199 entropy=0.0000
[step=2409] episode=2409.0000 return=-115.9998 length=29.0000 global_step=58494.0000 loss=16.0296 policy_loss=-0.0000 value_loss=32.0591 entropy=0.0000
[step=2410] episode=2410.0000 return=-115.9991 length=11.0000 global_step=58505.0000 loss=155.6309 policy_loss=-0.0000 value_loss=311.2617 entropy=0.0000
[step=2411] episode=2411.0000 return=-115.8790 length=12.0000 global_step=58517.0000 loss=67.5659 policy_loss=-0.0000 value_loss=135.1317 entropy=0.0000
[step=2412] episode=2412.0000 return=-115.8872 length=22.0000 global_step=58539.0000 loss=36.6009 policy_loss=-0.0000 value_loss=73.2018 entropy=0.0000
[step=2413] episode=2413.0000 return=-115.9840 length=22.0000 global_step=58561.0000 loss=111.4143 policy_loss=-0.0000 value_loss=222.8286 entropy=0.0000
[step=2414] episode=2414.0000 return=-115.8124 length=19.0000 global_step=58580.0000 loss=13.8173 policy_loss=-0.0000 value_loss=27.6345 entropy=0.0000
[step=2415] episode=2415.0000 return=-115.9786 length=12.0000 global_step=58592.0000 loss=17.1674 policy_loss=-0.0000 value_loss=34.3347 entropy=0.0000
[step=2416] episode=2416.0000 return=-115.9981 length=13.0000 global_step=58605.0000 loss=28.1146 policy_loss=-0.0000 value_loss=56.2293 entropy=0.0000
[step=2417] episode=2417.0000 return=-115.8570 length=13.0000 global_step=58618.0000 loss=12.9402 policy_loss=-0.0000 value_loss=25.8804 entropy=0.0000
[step=2418] episode=2418.0000 return=-115.9974 length=21.0000 global_step=58639.0000 loss=26.6393 policy_loss=-0.0000 value_loss=53.2786 entropy=0.0000
[step=2419] episode=2419.0000 return=-115.9343 length=20.0000 global_step=58659.0000 loss=35.0154 policy_loss=-0.0000 value_loss=70.0308 entropy=0.0000
[step=2420] episode=2420.0000 return=-115.9990 length=36.0000 global_step=58695.0000 loss=24.5509 policy_loss=-0.0000 value_loss=49.1018 entropy=0.0000
[step=2421] episode=2421.0000 return=-115.9808 length=27.0000 global_step=58722.0000 loss=17.6709 policy_loss=-0.0000 value_loss=35.3418 entropy=0.0000
[step=2422] episode=2422.0000 return=-115.9629 length=12.0000 global_step=58734.0000 loss=146.3830 policy_loss=-0.0000 value_loss=292.7661 entropy=0.0000
[step=2423] episode=2423.0000 return=-115.7415 length=11.0000 global_step=58745.0000 loss=55.1652 policy_loss=-0.0000 value_loss=110.3303 entropy=0.0000
[step=2424] episode=2424.0000 return=-115.9948 length=28.0000 global_step=58773.0000 loss=75.0379 policy_loss=-0.0000 value_loss=150.0757 entropy=0.0000
[step=2425] episode=2425.0000 return=-115.8181 length=18.0000 global_step=58791.0000 loss=14.5784 policy_loss=-0.0000 value_loss=29.1568 entropy=0.0000
[step=2426] episode=2426.0000 return=-115.8180 length=13.0000 global_step=58804.0000 loss=14.9561 policy_loss=-0.0000 value_loss=29.9123 entropy=0.0000
[step=2427] episode=2427.0000 return=-115.9941 length=27.0000 global_step=58831.0000 loss=46.1454 policy_loss=-0.0000 value_loss=92.2909 entropy=0.0000
[step=2428] episode=2428.0000 return=-115.9994 length=30.0000 global_step=58861.0000 loss=11.1045 policy_loss=-0.0000 value_loss=22.2091 entropy=0.0000
[step=2429] episode=2429.0000 return=-115.9678 length=19.0000 global_step=58880.0000 loss=109.9902 policy_loss=-0.0000 value_loss=219.9805 entropy=0.0000
[step=2430] episode=2430.0000 return=-115.8409 length=21.0000 global_step=58901.0000 loss=126.1613 policy_loss=-0.0000 value_loss=252.3226 entropy=0.0000
[step=2431] episode=2431.0000 return=-116.0000 length=34.0000 global_step=58935.0000 loss=11.8380 policy_loss=-0.0000 value_loss=23.6761 entropy=0.0000
[step=2432] episode=2432.0000 return=-115.9995 length=29.0000 global_step=58964.0000 loss=40.2599 policy_loss=-0.0000 value_loss=80.5198 entropy=0.0000
[step=2433] episode=2433.0000 return=-115.9968 length=21.0000 global_step=58985.0000 loss=23.6234 policy_loss=-0.0000 value_loss=47.2468 entropy=0.0000
[step=2434] episode=2434.0000 return=-115.8340 length=13.0000 global_step=58998.0000 loss=4.7064 policy_loss=-0.0000 value_loss=9.4129 entropy=0.0000
[step=2435] episode=2435.0000 return=-115.9096 length=21.0000 global_step=59019.0000 loss=30.8000 policy_loss=-0.0000 value_loss=61.6000 entropy=0.0000
[step=2436] episode=2436.0000 return=-115.9995 length=37.0000 global_step=59056.0000 loss=37.2482 policy_loss=-0.0000 value_loss=74.4963 entropy=0.0000
[step=2437] episode=2437.0000 return=-115.9930 length=12.0000 global_step=59068.0000 loss=58.6619 policy_loss=-0.0000 value_loss=117.3238 entropy=0.0000
[step=2438] episode=2438.0000 return=-115.9955 length=20.0000 global_step=59088.0000 loss=15.7643 policy_loss=-0.0000 value_loss=31.5285 entropy=0.0000
[step=2439] episode=2439.0000 return=-115.9890 length=26.0000 global_step=59114.0000 loss=11.7837 policy_loss=-0.0000 value_loss=23.5675 entropy=0.0000
[step=2440] episode=2440.0000 return=-115.9953 length=34.0000 global_step=59148.0000 loss=8.7253 policy_loss=-0.0000 value_loss=17.4507 entropy=0.0000
[step=2441] episode=2441.0000 return=-115.9845 length=12.0000 global_step=59160.0000 loss=24.9720 policy_loss=-0.0000 value_loss=49.9440 entropy=0.0000
[step=2442] episode=2442.0000 return=-115.9955 length=28.0000 global_step=59188.0000 loss=50.1506 policy_loss=-0.0000 value_loss=100.3012 entropy=0.0000
[step=2443] episode=2443.0000 return=-115.9831 length=29.0000 global_step=59217.0000 loss=48.0404 policy_loss=-0.0000 value_loss=96.0808 entropy=0.0000
[step=2444] episode=2444.0000 return=-115.9911 length=29.0000 global_step=59246.0000 loss=7.6715 policy_loss=-0.0000 value_loss=15.3430 entropy=0.0000
[step=2445] episode=2445.0000 return=-115.9965 length=20.0000 global_step=59266.0000 loss=17.3710 policy_loss=-0.0000 value_loss=34.7420 entropy=0.0000
[step=2446] episode=2446.0000 return=-115.9886 length=22.0000 global_step=59288.0000 loss=23.3818 policy_loss=-0.0000 value_loss=46.7637 entropy=0.0000
[step=2447] episode=2447.0000 return=-115.9697 length=28.0000 global_step=59316.0000 loss=11.2277 policy_loss=-0.0000 value_loss=22.4554 entropy=0.0000
[step=2448] episode=2448.0000 return=-116.0000 length=33.0000 global_step=59349.0000 loss=27.1779 policy_loss=-0.0000 value_loss=54.3558 entropy=0.0000
[step=2449] episode=2449.0000 return=-115.9988 length=27.0000 global_step=59376.0000 loss=8.2922 policy_loss=-0.0000 value_loss=16.5845 entropy=0.0000
[step=2450] episode=2450.0000 return=-115.9917 length=19.0000 global_step=59395.0000 loss=6.8845 policy_loss=-0.0000 value_loss=13.7691 entropy=0.0000
[step=2451] episode=2451.0000 return=-115.9918 length=12.0000 global_step=59407.0000 loss=15.1518 policy_loss=-0.0000 value_loss=30.3036 entropy=0.0000
[step=2452] episode=2452.0000 return=-115.7243 length=12.0000 global_step=59419.0000 loss=5.9703 policy_loss=-0.0000 value_loss=11.9405 entropy=0.0000
[step=2453] episode=2453.0000 return=-112.7363 length=13.0000 global_step=59432.0000 loss=6.1790 policy_loss=-0.0000 value_loss=12.3579 entropy=0.0000
[step=2454] episode=2454.0000 return=-115.9224 length=20.0000 global_step=59452.0000 loss=56.7138 policy_loss=-0.0000 value_loss=113.4276 entropy=0.0000
[step=2455] episode=2455.0000 return=-115.9228 length=19.0000 global_step=59471.0000 loss=6.4053 policy_loss=-0.0000 value_loss=12.8106 entropy=0.0000
[step=2456] episode=2456.0000 return=-115.9704 length=21.0000 global_step=59492.0000 loss=1.3679 policy_loss=-0.0000 value_loss=2.7358 entropy=0.0000
[step=2457] episode=2457.0000 return=-115.9703 length=21.0000 global_step=59513.0000 loss=8.0952 policy_loss=-0.0000 value_loss=16.1905 entropy=0.0000
[step=2458] episode=2458.0000 return=-115.8174 length=12.0000 global_step=59525.0000 loss=75.9914 policy_loss=-0.0000 value_loss=151.9827 entropy=0.0000
[step=2459] episode=2459.0000 return=-115.9996 length=21.0000 global_step=59546.0000 loss=12.2556 policy_loss=-0.0000 value_loss=24.5111 entropy=0.0000
[step=2460] episode=2460.0000 return=-115.9955 length=36.0000 global_step=59582.0000 loss=56.9529 policy_loss=-0.0000 value_loss=113.9058 entropy=0.0000
a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2461/3000 [1:07:14<15:05,  1.68s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2462/3000 [1:07:15<14:36,  1.63s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2463/3000 [1:07:17<13:46,  1.54s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2464/3000 [1:07:19<16:31,  1.85s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2465/3000 [1:07:21<15:26,  1.73s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2466/3000 [1:07:23<16:01,  1.80s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2467/3000 [1:07:24<14:50,  1.67s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2468/3000 [1:07:26<15:30,  1.75s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2469/3000 [1:07:28<17:22,  1.96s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2470/3000 [1:07:30<17:24,  1.97s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2471/3000 [1:07:32<15:53,  1.80s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2472/3000 [1:07:33<14:54,  1.69s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2473/3000 [1:07:35<14:04,  1.60s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2474/3000 [1:07:37<16:38,  1.90s/it]a2c_tuned train:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2475/3000 [1:07:39<16:54,  1.93s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2476/3000 [1:07:40<15:14,  1.75s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2477/3000 [1:07:44<19:30,  2.24s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2478/3000 [1:07:46<18:01,  2.07s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2479/3000 [1:07:47<17:20,  2.00s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2480/3000 [1:07:50<17:49,  2.06s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2481/3000 [1:07:50<14:42,  1.70s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2482/3000 [1:07:52<15:03,  1.74s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2483/3000 [1:07:53<12:33,  1.46s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2484/3000 [1:07:55<13:23,  1.56s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2485/3000 [1:07:57<15:16,  1.78s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2486/3000 [1:07:59<15:36,  1.82s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2487/3000 [1:08:01<16:49,  1.97s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2488/3000 [1:08:03<16:39,  1.95s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2489/3000 [1:08:05<16:40,  1.96s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2490/3000 [1:08:07<16:15,  1.91s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2491/3000 [1:08:08<14:39,  1.73s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2492/3000 [1:08:11<16:19,  1.93s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2493/3000 [1:08:13<16:20,  1.93s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2494/3000 [1:08:15<16:24,  1.95s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2495/3000 [1:08:16<13:52,  1.65s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2496/3000 [1:08:17<13:15,  1.58s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2497/3000 [1:08:19<14:00,  1.67s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2498/3000 [1:08:21<14:37,  1.75s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2499/3000 [1:08:22<13:39,  1.64s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2500/3000 [1:08:23<11:32,  1.38s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2501/3000 [1:08:25<12:19,  1.48s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2502/3000 [1:08:26<12:02,  1.45s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2503/3000 [1:08:28<13:26,  1.62s/it]a2c_tuned train:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2504/3000 [1:08:29<11:17,  1.37s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2505/3000 [1:08:31<12:15,  1.49s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2506/3000 [1:08:33<14:57,  1.82s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2507/3000 [1:08:36<17:30,  2.13s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2508/3000 [1:08:37<15:22,  1.87s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2509/3000 [1:08:39<14:10,  1.73s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2510/3000 [1:08:40<13:28,  1.65s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2511/3000 [1:08:41<11:49,  1.45s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2512/3000 [1:08:43<13:05,  1.61s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2513/3000 [1:08:45<12:10,  1.50s/it][step=2461] episode=2461.0000 return=-115.9828 length=28.0000 global_step=59610.0000 loss=17.1958 policy_loss=-0.0000 value_loss=34.3915 entropy=0.0000
[step=2462] episode=2462.0000 return=-115.8200 length=22.0000 global_step=59632.0000 loss=7.0336 policy_loss=-0.0000 value_loss=14.0671 entropy=0.0000
[step=2463] episode=2463.0000 return=-115.9668 length=19.0000 global_step=59651.0000 loss=7.8802 policy_loss=-0.0000 value_loss=15.7604 entropy=0.0000
[step=2464] episode=2464.0000 return=-115.9942 length=37.0000 global_step=59688.0000 loss=15.9434 policy_loss=-0.0000 value_loss=31.8868 entropy=0.0000
[step=2465] episode=2465.0000 return=-115.9840 length=21.0000 global_step=59709.0000 loss=5.3240 policy_loss=-0.0000 value_loss=10.6480 entropy=0.0000
[step=2466] episode=2466.0000 return=-115.9953 length=29.0000 global_step=59738.0000 loss=27.7839 policy_loss=-0.0000 value_loss=55.5678 entropy=0.0000
[step=2467] episode=2467.0000 return=-115.2739 length=20.0000 global_step=59758.0000 loss=50.0439 policy_loss=-0.0000 value_loss=100.0878 entropy=0.0000
[step=2468] episode=2468.0000 return=-115.7521 length=30.0000 global_step=59788.0000 loss=8.2361 policy_loss=-0.0000 value_loss=16.4722 entropy=0.0000
[step=2469] episode=2469.0000 return=-115.9897 length=38.0000 global_step=59826.0000 loss=28.6409 policy_loss=-0.0000 value_loss=57.2818 entropy=0.0000
[step=2470] episode=2470.0000 return=-115.9847 length=29.0000 global_step=59855.0000 loss=5.5646 policy_loss=-0.0000 value_loss=11.1292 entropy=0.0000
[step=2471] episode=2471.0000 return=-115.9941 length=22.0000 global_step=59877.0000 loss=22.4618 policy_loss=-0.0000 value_loss=44.9235 entropy=0.0000
[step=2472] episode=2472.0000 return=-115.9837 length=22.0000 global_step=59899.0000 loss=26.1874 policy_loss=-0.0000 value_loss=52.3747 entropy=0.0000
[step=2473] episode=2473.0000 return=-115.9927 length=20.0000 global_step=59919.0000 loss=11.6782 policy_loss=-0.0000 value_loss=23.3564 entropy=0.0000
[step=2474] episode=2474.0000 return=-115.9968 length=37.0000 global_step=59956.0000 loss=74.8774 policy_loss=-0.0000 value_loss=149.7549 entropy=0.0000
[step=2475] episode=2475.0000 return=-115.9998 length=29.0000 global_step=59985.0000 loss=18.8690 policy_loss=-0.0000 value_loss=37.7380 entropy=0.0000
[step=2476] episode=2476.0000 return=-115.9815 length=19.0000 global_step=60004.0000 loss=4.2809 policy_loss=-0.0000 value_loss=8.5618 entropy=0.0000
[step=2477] episode=2477.0000 return=-115.9822 length=51.0000 global_step=60055.0000 loss=85.5466 policy_loss=-0.0000 value_loss=171.0931 entropy=0.0000
[step=2478] episode=2478.0000 return=-115.9390 length=26.0000 global_step=60081.0000 loss=14.9312 policy_loss=-0.0000 value_loss=29.8625 entropy=0.0000
[step=2479] episode=2479.0000 return=-115.9948 length=27.0000 global_step=60108.0000 loss=24.6021 policy_loss=-0.0000 value_loss=49.2043 entropy=0.0000
[step=2480] episode=2480.0000 return=-115.9840 length=34.0000 global_step=60142.0000 loss=22.7049 policy_loss=-0.0000 value_loss=45.4097 entropy=0.0000
[step=2481] episode=2481.0000 return=-115.9939 length=12.0000 global_step=60154.0000 loss=88.2050 policy_loss=-0.0000 value_loss=176.4100 entropy=0.0000
[step=2482] episode=2482.0000 return=-115.9858 length=28.0000 global_step=60182.0000 loss=13.1490 policy_loss=-0.0000 value_loss=26.2979 entropy=0.0000
[step=2483] episode=2483.0000 return=-115.9999 length=12.0000 global_step=60194.0000 loss=5.8972 policy_loss=-0.0000 value_loss=11.7944 entropy=0.0000
[step=2484] episode=2484.0000 return=-115.9998 length=26.0000 global_step=60220.0000 loss=76.0144 policy_loss=-0.0000 value_loss=152.0288 entropy=0.0000
[step=2485] episode=2485.0000 return=-115.9901 length=34.0000 global_step=60254.0000 loss=96.4920 policy_loss=-0.0000 value_loss=192.9839 entropy=0.0000
[step=2486] episode=2486.0000 return=-115.9963 length=28.0000 global_step=60282.0000 loss=7.0262 policy_loss=-0.0000 value_loss=14.0524 entropy=0.0000
[step=2487] episode=2487.0000 return=-115.8644 length=34.0000 global_step=60316.0000 loss=60.3565 policy_loss=-0.0000 value_loss=120.7130 entropy=0.0000
[step=2488] episode=2488.0000 return=-115.9837 length=28.0000 global_step=60344.0000 loss=70.3419 policy_loss=-0.0000 value_loss=140.6838 entropy=0.0000
[step=2489] episode=2489.0000 return=-115.9978 length=29.0000 global_step=60373.0000 loss=17.0880 policy_loss=-0.0000 value_loss=34.1759 entropy=0.0000
[step=2490] episode=2490.0000 return=-115.9914 length=26.0000 global_step=60399.0000 loss=14.2769 policy_loss=-0.0000 value_loss=28.5538 entropy=0.0000
[step=2491] episode=2491.0000 return=-115.9845 length=20.0000 global_step=60419.0000 loss=8.0408 policy_loss=-0.0000 value_loss=16.0817 entropy=0.0000
[step=2492] episode=2492.0000 return=-115.9707 length=37.0000 global_step=60456.0000 loss=98.9784 policy_loss=-0.0000 value_loss=197.9569 entropy=0.0000
[step=2493] episode=2493.0000 return=-115.9998 length=29.0000 global_step=60485.0000 loss=20.8961 policy_loss=-0.0000 value_loss=41.7921 entropy=0.0000
[step=2494] episode=2494.0000 return=-115.9788 length=29.0000 global_step=60514.0000 loss=29.8395 policy_loss=-0.0000 value_loss=59.6790 entropy=0.0000
[step=2495] episode=2495.0000 return=-115.8133 length=13.0000 global_step=60527.0000 loss=143.3728 policy_loss=-0.0000 value_loss=286.7455 entropy=0.0000
[step=2496] episode=2496.0000 return=-115.9887 length=19.0000 global_step=60546.0000 loss=26.4969 policy_loss=-0.0000 value_loss=52.9939 entropy=0.0000
[step=2497] episode=2497.0000 return=-115.9814 length=28.0000 global_step=60574.0000 loss=9.1165 policy_loss=-0.0000 value_loss=18.2330 entropy=0.0000
[step=2498] episode=2498.0000 return=-115.9955 length=28.0000 global_step=60602.0000 loss=77.4438 policy_loss=-0.0000 value_loss=154.8877 entropy=0.0000
[step=2499] episode=2499.0000 return=-115.9936 length=19.0000 global_step=60621.0000 loss=27.0245 policy_loss=-0.0000 value_loss=54.0491 entropy=0.0000
[step=2500] episode=2500.0000 return=-115.9990 length=11.0000 global_step=60632.0000 loss=10.4231 policy_loss=-0.0000 value_loss=20.8461 entropy=0.0000
[step=2501] episode=2501.0000 return=-115.9987 length=26.0000 global_step=60658.0000 loss=5.3911 policy_loss=-0.0000 value_loss=10.7822 entropy=0.0000
[step=2502] episode=2502.0000 return=-115.9898 length=20.0000 global_step=60678.0000 loss=8.4862 policy_loss=-0.0000 value_loss=16.9725 entropy=0.0000
[step=2503] episode=2503.0000 return=-115.9997 length=29.0000 global_step=60707.0000 loss=14.1871 policy_loss=-0.0000 value_loss=28.3743 entropy=0.0000
[step=2504] episode=2504.0000 return=-115.8177 length=12.0000 global_step=60719.0000 loss=58.2220 policy_loss=-0.0000 value_loss=116.4441 entropy=0.0000
[step=2505] episode=2505.0000 return=-115.9976 length=27.0000 global_step=60746.0000 loss=13.6906 policy_loss=-0.0000 value_loss=27.3811 entropy=0.0000
[step=2506] episode=2506.0000 return=-116.0000 length=38.0000 global_step=60784.0000 loss=46.6100 policy_loss=-0.0000 value_loss=93.2200 entropy=0.0000
[step=2507] episode=2507.0000 return=-115.9990 length=42.0000 global_step=60826.0000 loss=58.6243 policy_loss=-0.0000 value_loss=117.2487 entropy=0.0000
[step=2508] episode=2508.0000 return=-115.9797 length=19.0000 global_step=60845.0000 loss=63.0742 policy_loss=-0.0000 value_loss=126.1485 entropy=0.0000
[step=2509] episode=2509.0000 return=-115.9956 length=20.0000 global_step=60865.0000 loss=61.7518 policy_loss=-0.0000 value_loss=123.5036 entropy=0.0000
[step=2510] episode=2510.0000 return=-115.9998 length=22.0000 global_step=60887.0000 loss=24.7420 policy_loss=-0.0000 value_loss=49.4840 entropy=0.0000
[step=2511] episode=2511.0000 return=-115.8370 length=14.0000 global_step=60901.0000 loss=19.4944 policy_loss=-0.0000 value_loss=38.9889 entropy=0.0000
[step=2512] episode=2512.0000 return=-115.9939 length=30.0000 global_step=60931.0000 loss=86.2997 policy_loss=-0.0000 value_loss=172.5993 entropy=0.0000
[step=2513] episode=2513.0000 return=-115.9966 length=18.0000 global_step=60949.0000 loss=38.1885 policy_loss=-0.0000 value_loss=76.3770 entropy=0.0000
a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2514/3000 [1:08:47<13:25,  1.66s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2515/3000 [1:08:47<11:17,  1.40s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2516/3000 [1:08:49<12:45,  1.58s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2517/3000 [1:08:51<13:32,  1.68s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2518/3000 [1:08:54<15:04,  1.88s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2519/3000 [1:08:55<13:44,  1.71s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2520/3000 [1:08:56<13:13,  1.65s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2521/3000 [1:08:58<12:38,  1.58s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2522/3000 [1:08:59<12:17,  1.54s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2523/3000 [1:09:00<10:19,  1.30s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2524/3000 [1:09:01<09:21,  1.18s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2525/3000 [1:09:02<09:58,  1.26s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2526/3000 [1:09:05<12:46,  1.62s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2527/3000 [1:09:07<13:05,  1.66s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2528/3000 [1:09:09<13:49,  1.76s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2529/3000 [1:09:11<15:39,  1.99s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2530/3000 [1:09:12<13:05,  1.67s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2531/3000 [1:09:13<11:06,  1.42s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2532/3000 [1:09:14<09:55,  1.27s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2533/3000 [1:09:16<12:23,  1.59s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2534/3000 [1:09:18<13:07,  1.69s/it]a2c_tuned train:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2535/3000 [1:09:19<12:13,  1.58s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2536/3000 [1:09:20<10:21,  1.34s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2537/3000 [1:09:23<12:50,  1.66s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2538/3000 [1:09:25<13:29,  1.75s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2539/3000 [1:09:25<11:31,  1.50s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2540/3000 [1:09:26<09:45,  1.27s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2541/3000 [1:09:28<11:22,  1.49s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2542/3000 [1:09:30<10:59,  1.44s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2543/3000 [1:09:31<12:00,  1.58s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2544/3000 [1:09:34<14:29,  1.91s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2545/3000 [1:09:36<15:33,  2.05s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2546/3000 [1:09:38<13:51,  1.83s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2547/3000 [1:09:39<12:43,  1.69s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2548/3000 [1:09:41<11:59,  1.59s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2549/3000 [1:09:44<15:51,  2.11s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2550/3000 [1:09:46<15:40,  2.09s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2551/3000 [1:09:47<12:51,  1.72s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2552/3000 [1:09:48<10:56,  1.47s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2553/3000 [1:09:49<10:40,  1.43s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2554/3000 [1:09:50<10:30,  1.41s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2555/3000 [1:09:52<10:18,  1.39s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2556/3000 [1:09:54<11:28,  1.55s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2557/3000 [1:09:55<11:49,  1.60s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2558/3000 [1:09:57<12:27,  1.69s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2559/3000 [1:09:58<10:18,  1.40s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2560/3000 [1:09:59<10:22,  1.42s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2561/3000 [1:10:01<10:11,  1.39s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2562/3000 [1:10:02<10:12,  1.40s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2563/3000 [1:10:05<13:18,  1.83s/it]a2c_tuned train:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2564/3000 [1:10:06<12:20,  1.70s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2565/3000 [1:10:09<13:26,  1.85s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2566/3000 [1:10:10<12:09,  1.68s/it][step=2514] episode=2514.0000 return=-115.9992 length=30.0000 global_step=60979.0000 loss=106.2092 policy_loss=-0.0000 value_loss=212.4183 entropy=0.0000
[step=2515] episode=2515.0000 return=-115.7667 length=12.0000 global_step=60991.0000 loss=7.4061 policy_loss=-0.0000 value_loss=14.8123 entropy=0.0000
[step=2516] episode=2516.0000 return=-115.9885 length=30.0000 global_step=61021.0000 loss=19.6523 policy_loss=-0.0000 value_loss=39.3045 entropy=0.0000
[step=2517] episode=2517.0000 return=-115.9840 length=29.0000 global_step=61050.0000 loss=12.8028 policy_loss=-0.0000 value_loss=25.6055 entropy=0.0000
[step=2518] episode=2518.0000 return=-115.9897 length=35.0000 global_step=61085.0000 loss=20.4638 policy_loss=-0.0000 value_loss=40.9275 entropy=0.0000
[step=2519] episode=2519.0000 return=-115.9841 length=20.0000 global_step=61105.0000 loss=60.2462 policy_loss=-0.0000 value_loss=120.4923 entropy=0.0000
[step=2520] episode=2520.0000 return=-115.9837 length=22.0000 global_step=61127.0000 loss=34.2076 policy_loss=-0.0000 value_loss=68.4152 entropy=0.0000
[step=2521] episode=2521.0000 return=-115.9840 length=21.0000 global_step=61148.0000 loss=6.3865 policy_loss=-0.0000 value_loss=12.7730 entropy=0.0000
[step=2522] episode=2522.0000 return=-115.9960 length=21.0000 global_step=61169.0000 loss=23.2904 policy_loss=-0.0000 value_loss=46.5808 entropy=0.0000
[step=2523] episode=2523.0000 return=-115.7233 length=11.0000 global_step=61180.0000 loss=21.3942 policy_loss=-0.0000 value_loss=42.7884 entropy=0.0000
[step=2524] episode=2524.0000 return=-115.9913 length=12.0000 global_step=61192.0000 loss=10.6166 policy_loss=-0.0000 value_loss=21.2333 entropy=0.0000
[step=2525] episode=2525.0000 return=-115.9944 length=21.0000 global_step=61213.0000 loss=38.2969 policy_loss=-0.0000 value_loss=76.5939 entropy=0.0000
[step=2526] episode=2526.0000 return=-115.9782 length=36.0000 global_step=61249.0000 loss=73.1137 policy_loss=-0.0000 value_loss=146.2274 entropy=0.0000
[step=2527] episode=2527.0000 return=-115.9939 length=26.0000 global_step=61275.0000 loss=17.2226 policy_loss=-0.0000 value_loss=34.4453 entropy=0.0000
[step=2528] episode=2528.0000 return=-115.9995 length=29.0000 global_step=61304.0000 loss=78.9606 policy_loss=-0.0000 value_loss=157.9213 entropy=0.0000
[step=2529] episode=2529.0000 return=-115.9893 length=38.0000 global_step=61342.0000 loss=32.9770 policy_loss=-0.0000 value_loss=65.9539 entropy=0.0000
[step=2530] episode=2530.0000 return=-115.8870 length=13.0000 global_step=61355.0000 loss=140.2408 policy_loss=-0.0000 value_loss=280.4816 entropy=0.0000
[step=2531] episode=2531.0000 return=-115.9270 length=12.0000 global_step=61367.0000 loss=31.0571 policy_loss=-0.0000 value_loss=62.1143 entropy=0.0000
[step=2532] episode=2532.0000 return=-115.5558 length=13.0000 global_step=61380.0000 loss=15.2166 policy_loss=-0.0000 value_loss=30.4333 entropy=0.0000
[step=2533] episode=2533.0000 return=-115.9202 length=36.0000 global_step=61416.0000 loss=341.8304 policy_loss=-0.0000 value_loss=683.6608 entropy=0.0000
[step=2534] episode=2534.0000 return=-115.9858 length=29.0000 global_step=61445.0000 loss=274.2090 policy_loss=-0.0000 value_loss=548.4180 entropy=0.0000
[step=2535] episode=2535.0000 return=-115.9997 length=19.0000 global_step=61464.0000 loss=89.7547 policy_loss=-0.0000 value_loss=179.5094 entropy=0.0000
[step=2536] episode=2536.0000 return=-115.9152 length=11.0000 global_step=61475.0000 loss=26.3593 policy_loss=-0.0000 value_loss=52.7186 entropy=0.0000
[step=2537] episode=2537.0000 return=-115.9948 length=36.0000 global_step=61511.0000 loss=30.4257 policy_loss=-0.0000 value_loss=60.8513 entropy=0.0000
[step=2538] episode=2538.0000 return=-115.9993 length=29.0000 global_step=61540.0000 loss=114.1595 policy_loss=-0.0000 value_loss=228.3190 entropy=0.0000
[step=2539] episode=2539.0000 return=-115.7874 length=13.0000 global_step=61553.0000 loss=270.3864 policy_loss=-0.0000 value_loss=540.7728 entropy=0.0000
[step=2540] episode=2540.0000 return=-115.8331 length=10.0000 global_step=61563.0000 loss=96.6640 policy_loss=-0.0000 value_loss=193.3279 entropy=0.0000
[step=2541] episode=2541.0000 return=-115.9924 length=29.0000 global_step=61592.0000 loss=107.2877 policy_loss=-0.0000 value_loss=214.5755 entropy=0.0000
[step=2542] episode=2542.0000 return=-115.9975 length=20.0000 global_step=61612.0000 loss=247.1446 policy_loss=-0.0000 value_loss=494.2892 entropy=0.0000
[step=2543] episode=2543.0000 return=-115.9993 length=28.0000 global_step=61640.0000 loss=258.1476 policy_loss=-0.0000 value_loss=516.2952 entropy=0.0000
[step=2544] episode=2544.0000 return=-115.9968 length=39.0000 global_step=61679.0000 loss=75.6372 policy_loss=-0.0000 value_loss=151.2744 entropy=0.0000
[step=2545] episode=2545.0000 return=-115.9997 length=37.0000 global_step=61716.0000 loss=91.7998 policy_loss=-0.0000 value_loss=183.5995 entropy=0.0000
[step=2546] episode=2546.0000 return=-115.9112 length=19.0000 global_step=61735.0000 loss=477.8855 policy_loss=-0.0000 value_loss=955.7710 entropy=0.0000
[step=2547] episode=2547.0000 return=-115.8343 length=19.0000 global_step=61754.0000 loss=399.1599 policy_loss=-0.0000 value_loss=798.3197 entropy=0.0000
[step=2548] episode=2548.0000 return=-115.7288 length=20.0000 global_step=61774.0000 loss=40.6514 policy_loss=-0.0000 value_loss=81.3027 entropy=0.0000
[step=2549] episode=2549.0000 return=-115.9986 length=50.0000 global_step=61824.0000 loss=507.9230 policy_loss=-0.0000 value_loss=1015.8461 entropy=0.0000
[step=2550] episode=2550.0000 return=-115.9975 length=29.0000 global_step=61853.0000 loss=329.9443 policy_loss=-0.0000 value_loss=659.8886 entropy=0.0000
[step=2551] episode=2551.0000 return=-115.9921 length=12.0000 global_step=61865.0000 loss=37.3188 policy_loss=-0.0000 value_loss=74.6376 entropy=0.0000
[step=2552] episode=2552.0000 return=-115.9707 length=12.0000 global_step=61877.0000 loss=28.3722 policy_loss=-0.0000 value_loss=56.7443 entropy=0.0000
[step=2553] episode=2553.0000 return=-115.9967 length=20.0000 global_step=61897.0000 loss=54.9750 policy_loss=-0.0000 value_loss=109.9500 entropy=0.0000
[step=2554] episode=2554.0000 return=-115.9774 length=20.0000 global_step=61917.0000 loss=77.8361 policy_loss=-0.0000 value_loss=155.6723 entropy=0.0000
[step=2555] episode=2555.0000 return=-115.9880 length=20.0000 global_step=61937.0000 loss=26.4476 policy_loss=-0.0000 value_loss=52.8952 entropy=0.0000
[step=2556] episode=2556.0000 return=-115.9948 length=28.0000 global_step=61965.0000 loss=42.8089 policy_loss=-0.0000 value_loss=85.6179 entropy=0.0000
[step=2557] episode=2557.0000 return=-115.9998 length=25.0000 global_step=61990.0000 loss=52.0245 policy_loss=-0.0000 value_loss=104.0489 entropy=0.0000
[step=2558] episode=2558.0000 return=-115.9836 length=28.0000 global_step=62018.0000 loss=11.1941 policy_loss=-0.0000 value_loss=22.3883 entropy=0.0000
[step=2559] episode=2559.0000 return=-115.8378 length=11.0000 global_step=62029.0000 loss=44.8610 policy_loss=-0.0000 value_loss=89.7221 entropy=0.0000
[step=2560] episode=2560.0000 return=-115.9939 length=22.0000 global_step=62051.0000 loss=11.9822 policy_loss=-0.0000 value_loss=23.9644 entropy=0.0000
[step=2561] episode=2561.0000 return=-115.9953 length=18.0000 global_step=62069.0000 loss=6.3340 policy_loss=-0.0000 value_loss=12.6680 entropy=0.0000
[step=2562] episode=2562.0000 return=-115.9837 length=21.0000 global_step=62090.0000 loss=13.9776 policy_loss=-0.0000 value_loss=27.9553 entropy=0.0000
[step=2563] episode=2563.0000 return=-115.9840 length=42.0000 global_step=62132.0000 loss=164.8142 policy_loss=-0.0000 value_loss=329.6284 entropy=0.0000
[step=2564] episode=2564.0000 return=-115.9919 length=20.0000 global_step=62152.0000 loss=29.1131 policy_loss=-0.0000 value_loss=58.2262 entropy=0.0000
[step=2565] episode=2565.0000 return=-115.9890 length=34.0000 global_step=62186.0000 loss=37.4377 policy_loss=-0.0000 value_loss=74.8753 entropy=0.0000
[step=2566] episode=2566.0000 return=-115.9961 length=20.0000 global_step=62206.0000 loss=86.3374 policy_loss=-0.0000 value_loss=172.6749 entropy=0.0000
a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2567/3000 [1:10:12<12:41,  1.76s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2568/3000 [1:10:14<13:55,  1.93s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2569/3000 [1:10:16<12:55,  1.80s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2570/3000 [1:10:16<10:42,  1.50s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2571/3000 [1:10:18<10:22,  1.45s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2572/3000 [1:10:20<12:21,  1.73s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2573/3000 [1:10:21<11:23,  1.60s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2574/3000 [1:10:23<11:01,  1.55s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2575/3000 [1:10:24<09:33,  1.35s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2576/3000 [1:10:26<10:41,  1.51s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2577/3000 [1:10:27<10:16,  1.46s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2578/3000 [1:10:28<08:55,  1.27s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2579/3000 [1:10:30<11:04,  1.58s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2580/3000 [1:10:32<12:37,  1.80s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2581/3000 [1:10:33<10:30,  1.50s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2582/3000 [1:10:36<12:33,  1.80s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2583/3000 [1:10:37<11:38,  1.67s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2584/3000 [1:10:38<09:49,  1.42s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2585/3000 [1:10:39<09:35,  1.39s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2586/3000 [1:10:41<09:40,  1.40s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2587/3000 [1:10:43<12:00,  1.74s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2588/3000 [1:10:45<11:26,  1.67s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2589/3000 [1:10:47<12:38,  1.84s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2590/3000 [1:10:50<14:56,  2.19s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2591/3000 [1:10:52<15:24,  2.26s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2592/3000 [1:10:54<13:37,  2.00s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2593/3000 [1:10:56<14:28,  2.13s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2594/3000 [1:10:59<15:10,  2.24s/it]a2c_tuned train:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2595/3000 [1:11:00<13:32,  2.01s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2596/3000 [1:11:02<14:03,  2.09s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2597/3000 [1:11:03<11:27,  1.71s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2598/3000 [1:11:05<10:47,  1.61s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2599/3000 [1:11:06<11:08,  1.67s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2600/3000 [1:11:08<11:23,  1.71s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2601/3000 [1:11:09<08:39,  1.30s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2602/3000 [1:11:11<10:01,  1.51s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2603/3000 [1:11:12<09:51,  1.49s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2604/3000 [1:11:14<10:41,  1.62s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2605/3000 [1:11:15<10:06,  1.54s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2606/3000 [1:11:17<09:53,  1.51s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2607/3000 [1:11:19<10:29,  1.60s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2608/3000 [1:11:22<14:30,  2.22s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2609/3000 [1:11:24<12:59,  1.99s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2610/3000 [1:11:25<11:48,  1.82s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2611/3000 [1:11:26<10:48,  1.67s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2612/3000 [1:11:28<10:11,  1.58s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2613/3000 [1:11:30<12:01,  1.87s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2614/3000 [1:11:32<11:04,  1.72s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2615/3000 [1:11:33<10:31,  1.64s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2616/3000 [1:11:36<12:07,  1.89s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2617/3000 [1:11:37<10:57,  1.72s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2618/3000 [1:11:38<10:03,  1.58s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2619/3000 [1:11:40<10:36,  1.67s/it][step=2567] episode=2567.0000 return=-115.9923 length=29.0000 global_step=62235.0000 loss=56.0843 policy_loss=-0.0000 value_loss=112.1686 entropy=0.0000
[step=2568] episode=2568.0000 return=-115.9945 length=35.0000 global_step=62270.0000 loss=88.5525 policy_loss=-0.0000 value_loss=177.1050 entropy=0.0000
[step=2569] episode=2569.0000 return=-115.9870 length=22.0000 global_step=62292.0000 loss=5.7744 policy_loss=-0.0000 value_loss=11.5489 entropy=0.0000
[step=2570] episode=2570.0000 return=-115.7820 length=11.0000 global_step=62303.0000 loss=112.1232 policy_loss=-0.0000 value_loss=224.2465 entropy=0.0000
[step=2571] episode=2571.0000 return=-115.9984 length=20.0000 global_step=62323.0000 loss=12.9526 policy_loss=-0.0000 value_loss=25.9053 entropy=0.0000
[step=2572] episode=2572.0000 return=-115.9965 length=36.0000 global_step=62359.0000 loss=121.6044 policy_loss=-0.0000 value_loss=243.2087 entropy=0.0000
[step=2573] episode=2573.0000 return=-115.9968 length=19.0000 global_step=62378.0000 loss=5.8848 policy_loss=-0.0000 value_loss=11.7695 entropy=0.0000
[step=2574] episode=2574.0000 return=-115.8987 length=21.0000 global_step=62399.0000 loss=15.3943 policy_loss=-0.0000 value_loss=30.7887 entropy=0.0000
[step=2575] episode=2575.0000 return=-115.9420 length=13.0000 global_step=62412.0000 loss=61.4280 policy_loss=-0.0000 value_loss=122.8561 entropy=0.0000
[step=2576] episode=2576.0000 return=-115.9999 length=28.0000 global_step=62440.0000 loss=47.2501 policy_loss=-0.0000 value_loss=94.5002 entropy=0.0000
[step=2577] episode=2577.0000 return=-115.9978 length=20.0000 global_step=62460.0000 loss=9.4445 policy_loss=-0.0000 value_loss=18.8890 entropy=0.0000
[step=2578] episode=2578.0000 return=-115.9885 length=13.0000 global_step=62473.0000 loss=13.9315 policy_loss=-0.0000 value_loss=27.8631 entropy=0.0000
[step=2579] episode=2579.0000 return=-115.9937 length=33.0000 global_step=62506.0000 loss=33.5839 policy_loss=-0.0000 value_loss=67.1679 entropy=0.0000
[step=2580] episode=2580.0000 return=-115.9310 length=34.0000 global_step=62540.0000 loss=9.2949 policy_loss=-0.0000 value_loss=18.5897 entropy=0.0000
[step=2581] episode=2581.0000 return=-115.9968 length=12.0000 global_step=62552.0000 loss=108.0406 policy_loss=-0.0000 value_loss=216.0813 entropy=0.0000
[step=2582] episode=2582.0000 return=-115.9939 length=38.0000 global_step=62590.0000 loss=43.7246 policy_loss=-0.0000 value_loss=87.4491 entropy=0.0000
[step=2583] episode=2583.0000 return=-115.9818 length=21.0000 global_step=62611.0000 loss=27.1070 policy_loss=-0.0000 value_loss=54.2140 entropy=0.0000
[step=2584] episode=2584.0000 return=-115.9998 length=11.0000 global_step=62622.0000 loss=8.2523 policy_loss=-0.0000 value_loss=16.5045 entropy=0.0000
[step=2585] episode=2585.0000 return=-115.9966 length=20.0000 global_step=62642.0000 loss=72.5315 policy_loss=-0.0000 value_loss=145.0629 entropy=0.0000
[step=2586] episode=2586.0000 return=-115.9655 length=21.0000 global_step=62663.0000 loss=51.8085 policy_loss=-0.0000 value_loss=103.6169 entropy=0.0000
[step=2587] episode=2587.0000 return=-116.0000 length=37.0000 global_step=62700.0000 loss=56.0214 policy_loss=-0.0000 value_loss=112.0428 entropy=0.0000
[step=2588] episode=2588.0000 return=-115.9941 length=21.0000 global_step=62721.0000 loss=120.8815 policy_loss=-0.0000 value_loss=241.7630 entropy=0.0000
[step=2589] episode=2589.0000 return=-115.9955 length=35.0000 global_step=62756.0000 loss=73.4681 policy_loss=-0.0000 value_loss=146.9361 entropy=0.0000
[step=2590] episode=2590.0000 return=-115.9402 length=44.0000 global_step=62800.0000 loss=27.8761 policy_loss=-0.0000 value_loss=55.7523 entropy=0.0000
[step=2591] episode=2591.0000 return=-112.6963 length=36.0000 global_step=62836.0000 loss=47.1337 policy_loss=-0.0000 value_loss=94.2674 entropy=0.0000
[step=2592] episode=2592.0000 return=-115.9669 length=20.0000 global_step=62856.0000 loss=10.8864 policy_loss=-0.0000 value_loss=21.7729 entropy=0.0000
[step=2593] episode=2593.0000 return=-115.9996 length=38.0000 global_step=62894.0000 loss=42.3792 policy_loss=-0.0000 value_loss=84.7583 entropy=0.0000
[step=2594] episode=2594.0000 return=-115.9989 length=37.0000 global_step=62931.0000 loss=52.3095 policy_loss=-0.0000 value_loss=104.6190 entropy=0.0000
[step=2595] episode=2595.0000 return=-115.9860 length=21.0000 global_step=62952.0000 loss=59.0261 policy_loss=-0.0000 value_loss=118.0523 entropy=0.0000
[step=2596] episode=2596.0000 return=-115.9973 length=34.0000 global_step=62986.0000 loss=17.6345 policy_loss=-0.0000 value_loss=35.2690 entropy=0.0000
[step=2597] episode=2597.0000 return=-115.9182 length=11.0000 global_step=62997.0000 loss=54.8110 policy_loss=-0.0000 value_loss=109.6220 entropy=0.0000
[step=2598] episode=2598.0000 return=-115.9948 length=20.0000 global_step=63017.0000 loss=21.1435 policy_loss=-0.0000 value_loss=42.2870 entropy=0.0000
[step=2599] episode=2599.0000 return=-115.9998 length=26.0000 global_step=63043.0000 loss=98.9443 policy_loss=-0.0000 value_loss=197.8886 entropy=0.0000
[step=2600] episode=2600.0000 return=-115.9877 length=28.0000 global_step=63071.0000 loss=51.4470 policy_loss=-0.0000 value_loss=102.8941 entropy=0.0000
[step=2601] episode=2601.0000 return=-115.7415 length=5.0000 global_step=63076.0000 loss=189.0751 policy_loss=-0.0000 value_loss=378.1501 entropy=0.0000
[step=2602] episode=2602.0000 return=-115.9840 length=29.0000 global_step=63105.0000 loss=11.3963 policy_loss=-0.0000 value_loss=22.7925 entropy=0.0000
[step=2603] episode=2603.0000 return=-115.9613 length=21.0000 global_step=63126.0000 loss=5.5016 policy_loss=-0.0000 value_loss=11.0032 entropy=0.0000
[step=2604] episode=2604.0000 return=-115.9968 length=29.0000 global_step=63155.0000 loss=48.0090 policy_loss=-0.0000 value_loss=96.0181 entropy=0.0000
[step=2605] episode=2605.0000 return=-115.9962 length=20.0000 global_step=63175.0000 loss=4.6464 policy_loss=-0.0000 value_loss=9.2929 entropy=0.0000
[step=2606] episode=2606.0000 return=-115.9997 length=22.0000 global_step=63197.0000 loss=7.2363 policy_loss=-0.0000 value_loss=14.4725 entropy=0.0000
[step=2607] episode=2607.0000 return=-115.9996 length=27.0000 global_step=63224.0000 loss=10.0319 policy_loss=-0.0000 value_loss=20.0638 entropy=0.0000
[step=2608] episode=2608.0000 return=-115.9994 length=55.0000 global_step=63279.0000 loss=174.9595 policy_loss=-0.0000 value_loss=349.9189 entropy=0.0000
[step=2609] episode=2609.0000 return=-115.9996 length=22.0000 global_step=63301.0000 loss=54.2681 policy_loss=-0.0000 value_loss=108.5362 entropy=0.0000
[step=2610] episode=2610.0000 return=-115.8866 length=21.0000 global_step=63322.0000 loss=78.0384 policy_loss=-0.0000 value_loss=156.0767 entropy=0.0000
[step=2611] episode=2611.0000 return=-115.9982 length=20.0000 global_step=63342.0000 loss=6.6197 policy_loss=-0.0000 value_loss=13.2394 entropy=0.0000
[step=2612] episode=2612.0000 return=-115.9988 length=19.0000 global_step=63361.0000 loss=56.9325 policy_loss=-0.0000 value_loss=113.8650 entropy=0.0000
[step=2613] episode=2613.0000 return=-116.0000 length=37.0000 global_step=63398.0000 loss=209.6165 policy_loss=-0.0000 value_loss=419.2330 entropy=0.0000
[step=2614] episode=2614.0000 return=-115.8923 length=20.0000 global_step=63418.0000 loss=39.5194 policy_loss=-0.0000 value_loss=79.0388 entropy=0.0000
[step=2615] episode=2615.0000 return=-115.9682 length=21.0000 global_step=63439.0000 loss=56.2061 policy_loss=-0.0000 value_loss=112.4122 entropy=0.0000
[step=2616] episode=2616.0000 return=-115.9959 length=37.0000 global_step=63476.0000 loss=30.9154 policy_loss=-0.0000 value_loss=61.8307 entropy=0.0000
[step=2617] episode=2617.0000 return=-115.9096 length=20.0000 global_step=63496.0000 loss=20.5408 policy_loss=-0.0000 value_loss=41.0816 entropy=0.0000
[step=2618] episode=2618.0000 return=-115.8850 length=19.0000 global_step=63515.0000 loss=7.6089 policy_loss=-0.0000 value_loss=15.2179 entropy=0.0000
[step=2619] episode=2619.0000 return=-115.9764 length=28.0000 global_step=63543.0000 loss=71.6037 policy_loss=-0.0000 value_loss=143.2074 entropy=0.0000
a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2620/3000 [1:11:41<09:55,  1.57s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2621/3000 [1:11:44<11:29,  1.82s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2622/3000 [1:11:45<09:42,  1.54s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2623/3000 [1:11:46<08:27,  1.35s/it]a2c_tuned train:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2624/3000 [1:11:47<09:18,  1.48s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2625/3000 [1:11:48<07:58,  1.28s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2626/3000 [1:11:50<09:12,  1.48s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2627/3000 [1:11:53<11:54,  1.92s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2628/3000 [1:11:54<10:52,  1.75s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2629/3000 [1:11:55<09:03,  1.46s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2630/3000 [1:11:57<08:55,  1.45s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2631/3000 [1:11:58<08:54,  1.45s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2632/3000 [1:11:59<08:37,  1.41s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2633/3000 [1:12:01<08:45,  1.43s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2634/3000 [1:12:03<10:09,  1.66s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2635/3000 [1:12:05<09:35,  1.58s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2636/3000 [1:12:06<09:20,  1.54s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2637/3000 [1:12:08<10:41,  1.77s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2638/3000 [1:12:10<10:46,  1.79s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2639/3000 [1:12:12<10:04,  1.68s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2640/3000 [1:12:13<10:28,  1.74s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2641/3000 [1:12:15<09:56,  1.66s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2642/3000 [1:12:16<09:11,  1.54s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2643/3000 [1:12:19<10:57,  1.84s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2644/3000 [1:12:20<10:12,  1.72s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2645/3000 [1:12:21<08:47,  1.49s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2646/3000 [1:12:22<07:37,  1.29s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2647/3000 [1:12:23<07:43,  1.31s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2648/3000 [1:12:25<08:55,  1.52s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2649/3000 [1:12:27<08:29,  1.45s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2650/3000 [1:12:28<08:21,  1.43s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2651/3000 [1:12:29<08:07,  1.40s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2652/3000 [1:12:31<08:54,  1.54s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2653/3000 [1:12:33<08:44,  1.51s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2654/3000 [1:12:33<07:24,  1.29s/it]a2c_tuned train:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2655/3000 [1:12:36<09:35,  1.67s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2656/3000 [1:12:37<09:07,  1.59s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2657/3000 [1:12:39<08:49,  1.54s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2658/3000 [1:12:40<07:32,  1.32s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2659/3000 [1:12:41<07:31,  1.32s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2660/3000 [1:12:42<07:34,  1.34s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2661/3000 [1:12:43<06:45,  1.19s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2662/3000 [1:12:44<07:01,  1.25s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2663/3000 [1:12:46<07:31,  1.34s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2664/3000 [1:12:47<07:31,  1.34s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2665/3000 [1:12:49<07:28,  1.34s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2666/3000 [1:12:51<08:12,  1.47s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2667/3000 [1:12:51<07:05,  1.28s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2668/3000 [1:12:53<07:59,  1.44s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2669/3000 [1:12:55<07:54,  1.43s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2670/3000 [1:12:56<07:47,  1.42s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2671/3000 [1:12:58<08:44,  1.59s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2672/3000 [1:13:00<10:11,  1.86s/it][step=2620] episode=2620.0000 return=-115.9707 length=20.0000 global_step=63563.0000 loss=7.6958 policy_loss=-0.0000 value_loss=15.3916 entropy=0.0000
[step=2621] episode=2621.0000 return=-115.7556 length=36.0000 global_step=63599.0000 loss=20.0681 policy_loss=-0.0000 value_loss=40.1361 entropy=0.0000
[step=2622] episode=2622.0000 return=-115.7164 length=13.0000 global_step=63612.0000 loss=98.3575 policy_loss=-0.0000 value_loss=196.7150 entropy=0.0000
[step=2623] episode=2623.0000 return=-115.8783 length=12.0000 global_step=63624.0000 loss=5.5415 policy_loss=-0.0000 value_loss=11.0829 entropy=0.0000
[step=2624] episode=2624.0000 return=-115.9945 length=27.0000 global_step=63651.0000 loss=209.7587 policy_loss=-0.0000 value_loss=419.5174 entropy=0.0000
[step=2625] episode=2625.0000 return=-115.9900 length=12.0000 global_step=63663.0000 loss=15.1076 policy_loss=-0.0000 value_loss=30.2153 entropy=0.0000
[step=2626] episode=2626.0000 return=-115.9991 length=29.0000 global_step=63692.0000 loss=10.3612 policy_loss=-0.0000 value_loss=20.7224 entropy=0.0000
[step=2627] episode=2627.0000 return=-115.9986 length=44.0000 global_step=63736.0000 loss=48.6142 policy_loss=-0.0000 value_loss=97.2283 entropy=0.0000
[step=2628] episode=2628.0000 return=-115.9950 length=19.0000 global_step=63755.0000 loss=131.1512 policy_loss=-0.0000 value_loss=262.3024 entropy=0.0000
[step=2629] episode=2629.0000 return=-115.9996 length=12.0000 global_step=63767.0000 loss=8.8333 policy_loss=-0.0000 value_loss=17.6666 entropy=0.0000
[step=2630] episode=2630.0000 return=-115.9941 length=21.0000 global_step=63788.0000 loss=337.3731 policy_loss=-0.0000 value_loss=674.7462 entropy=0.0000
[step=2631] episode=2631.0000 return=-115.9839 length=21.0000 global_step=63809.0000 loss=43.6839 policy_loss=-0.0000 value_loss=87.3678 entropy=0.0000
[step=2632] episode=2632.0000 return=-115.9951 length=20.0000 global_step=63829.0000 loss=198.4244 policy_loss=-0.0000 value_loss=396.8489 entropy=0.0000
[step=2633] episode=2633.0000 return=-115.9955 length=22.0000 global_step=63851.0000 loss=149.0858 policy_loss=-0.0000 value_loss=298.1716 entropy=0.0000
[step=2634] episode=2634.0000 return=-115.9871 length=33.0000 global_step=63884.0000 loss=105.8968 policy_loss=-0.0000 value_loss=211.7936 entropy=0.0000
[step=2635] episode=2635.0000 return=-115.9900 length=20.0000 global_step=63904.0000 loss=90.2721 policy_loss=-0.0000 value_loss=180.5442 entropy=0.0000
[step=2636] episode=2636.0000 return=-115.9385 length=21.0000 global_step=63925.0000 loss=14.9077 policy_loss=-0.0000 value_loss=29.8154 entropy=0.0000
[step=2637] episode=2637.0000 return=-115.9096 length=34.0000 global_step=63959.0000 loss=29.5145 policy_loss=-0.0000 value_loss=59.0290 entropy=0.0000
[step=2638] episode=2638.0000 return=-115.9989 length=28.0000 global_step=63987.0000 loss=29.2673 policy_loss=-0.0000 value_loss=58.5346 entropy=0.0000
[step=2639] episode=2639.0000 return=-115.9765 length=21.0000 global_step=64008.0000 loss=6.6044 policy_loss=-0.0000 value_loss=13.2088 entropy=0.0000
[step=2640] episode=2640.0000 return=-115.8841 length=29.0000 global_step=64037.0000 loss=68.5824 policy_loss=-0.0000 value_loss=137.1648 entropy=0.0000
[step=2641] episode=2641.0000 return=-115.9765 length=21.0000 global_step=64058.0000 loss=17.0894 policy_loss=-0.0000 value_loss=34.1789 entropy=0.0000
[step=2642] episode=2642.0000 return=-115.9946 length=20.0000 global_step=64078.0000 loss=31.3340 policy_loss=-0.0000 value_loss=62.6680 entropy=0.0000
[step=2643] episode=2643.0000 return=-115.9995 length=37.0000 global_step=64115.0000 loss=108.3950 policy_loss=-0.0000 value_loss=216.7900 entropy=0.0000
[step=2644] episode=2644.0000 return=-115.9995 length=21.0000 global_step=64136.0000 loss=59.6764 policy_loss=-0.0000 value_loss=119.3527 entropy=0.0000
[step=2645] episode=2645.0000 return=-115.8751 length=13.0000 global_step=64149.0000 loss=28.4666 policy_loss=-0.0000 value_loss=56.9332 entropy=0.0000
[step=2646] episode=2646.0000 return=-115.9911 length=12.0000 global_step=64161.0000 loss=141.6819 policy_loss=-0.0000 value_loss=283.3637 entropy=0.0000
[step=2647] episode=2647.0000 return=-115.9959 length=20.0000 global_step=64181.0000 loss=21.9444 policy_loss=-0.0000 value_loss=43.8888 entropy=0.0000
[step=2648] episode=2648.0000 return=-115.9997 length=30.0000 global_step=64211.0000 loss=166.1281 policy_loss=-0.0000 value_loss=332.2563 entropy=0.0000
[step=2649] episode=2649.0000 return=-115.9955 length=20.0000 global_step=64231.0000 loss=57.4803 policy_loss=-0.0000 value_loss=114.9606 entropy=0.0000
[step=2650] episode=2650.0000 return=-115.9359 length=20.0000 global_step=64251.0000 loss=336.6437 policy_loss=-0.0000 value_loss=673.2874 entropy=0.0000
[step=2651] episode=2651.0000 return=-115.9919 length=19.0000 global_step=64270.0000 loss=6.0689 policy_loss=-0.0000 value_loss=12.1377 entropy=0.0000
[step=2652] episode=2652.0000 return=-115.9889 length=28.0000 global_step=64298.0000 loss=188.1090 policy_loss=-0.0000 value_loss=376.2180 entropy=0.0000
[step=2653] episode=2653.0000 return=-115.9840 length=21.0000 global_step=64319.0000 loss=10.2227 policy_loss=-0.0000 value_loss=20.4455 entropy=0.0000
[step=2654] episode=2654.0000 return=-115.9197 length=11.0000 global_step=64330.0000 loss=101.5318 policy_loss=-0.0000 value_loss=203.0635 entropy=0.0000
[step=2655] episode=2655.0000 return=-115.9970 length=38.0000 global_step=64368.0000 loss=30.2770 policy_loss=-0.0000 value_loss=60.5540 entropy=0.0000
[step=2656] episode=2656.0000 return=-115.9765 length=20.0000 global_step=64388.0000 loss=580.6003 policy_loss=-0.0000 value_loss=1161.2006 entropy=0.0000
[step=2657] episode=2657.0000 return=-115.9968 length=21.0000 global_step=64409.0000 loss=100.7147 policy_loss=-0.0000 value_loss=201.4294 entropy=0.0000
[step=2658] episode=2658.0000 return=-115.8717 length=11.0000 global_step=64420.0000 loss=198.3799 policy_loss=-0.0000 value_loss=396.7599 entropy=0.0000
[step=2659] episode=2659.0000 return=-115.9916 length=20.0000 global_step=64440.0000 loss=48.6023 policy_loss=-0.0000 value_loss=97.2047 entropy=0.0000
[step=2660] episode=2660.0000 return=-115.9964 length=19.0000 global_step=64459.0000 loss=93.2991 policy_loss=-0.0000 value_loss=186.5982 entropy=0.0000
[step=2661] episode=2661.0000 return=-115.9944 length=13.0000 global_step=64472.0000 loss=6.9763 policy_loss=-0.0000 value_loss=13.9526 entropy=0.0000
[step=2662] episode=2662.0000 return=-115.9964 length=19.0000 global_step=64491.0000 loss=231.8157 policy_loss=-0.0000 value_loss=463.6315 entropy=0.0000
[step=2663] episode=2663.0000 return=-115.8529 length=22.0000 global_step=64513.0000 loss=26.2419 policy_loss=-0.0000 value_loss=52.4837 entropy=0.0000
[step=2664] episode=2664.0000 return=-115.9990 length=20.0000 global_step=64533.0000 loss=130.7917 policy_loss=-0.0000 value_loss=261.5833 entropy=0.0000
[step=2665] episode=2665.0000 return=-115.9955 length=20.0000 global_step=64553.0000 loss=6.4151 policy_loss=-0.0000 value_loss=12.8302 entropy=0.0000
[step=2666] episode=2666.0000 return=-115.9993 length=26.0000 global_step=64579.0000 loss=191.6126 policy_loss=-0.0000 value_loss=383.2252 entropy=0.0000
[step=2667] episode=2667.0000 return=-115.8989 length=12.0000 global_step=64591.0000 loss=58.3755 policy_loss=-0.0000 value_loss=116.7509 entropy=0.0000
[step=2668] episode=2668.0000 return=-115.9972 length=27.0000 global_step=64618.0000 loss=13.9427 policy_loss=-0.0000 value_loss=27.8854 entropy=0.0000
[step=2669] episode=2669.0000 return=-115.9590 length=21.0000 global_step=64639.0000 loss=9.7005 policy_loss=-0.0000 value_loss=19.4010 entropy=0.0000
[step=2670] episode=2670.0000 return=-115.7864 length=20.0000 global_step=64659.0000 loss=10.5123 policy_loss=-0.0000 value_loss=21.0245 entropy=0.0000
[step=2671] episode=2671.0000 return=-115.9837 length=30.0000 global_step=64689.0000 loss=133.7359 policy_loss=-0.0000 value_loss=267.4719 entropy=0.0000
[step=2672] episode=2672.0000 return=-115.9968 length=37.0000 global_step=64726.0000 loss=38.3955 policy_loss=-0.0000 value_loss=76.7909 entropy=0.0000
a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2673/3000 [1:13:02<10:17,  1.89s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2674/3000 [1:13:03<08:34,  1.58s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2675/3000 [1:13:05<08:46,  1.62s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2676/3000 [1:13:07<10:14,  1.90s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2677/3000 [1:13:10<11:11,  2.08s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2678/3000 [1:13:11<10:03,  1.88s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2679/3000 [1:13:13<10:09,  1.90s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2680/3000 [1:13:15<09:10,  1.72s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2681/3000 [1:13:18<10:58,  2.07s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2682/3000 [1:13:20<11:38,  2.20s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2683/3000 [1:13:21<09:27,  1.79s/it]a2c_tuned train:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2684/3000 [1:13:23<09:28,  1.80s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2685/3000 [1:13:25<09:45,  1.86s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2686/3000 [1:13:26<08:06,  1.55s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2687/3000 [1:13:28<09:17,  1.78s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2688/3000 [1:13:30<09:24,  1.81s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2689/3000 [1:13:31<08:43,  1.68s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2690/3000 [1:13:33<09:06,  1.76s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2691/3000 [1:13:34<07:48,  1.51s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2692/3000 [1:13:35<07:23,  1.44s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2693/3000 [1:13:38<08:55,  1.75s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2694/3000 [1:13:39<08:16,  1.62s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2695/3000 [1:13:40<07:05,  1.39s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2696/3000 [1:13:42<08:28,  1.67s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2697/3000 [1:13:44<08:05,  1.60s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2698/3000 [1:13:46<09:14,  1.84s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2699/3000 [1:13:48<08:42,  1.74s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2700/3000 [1:13:50<09:46,  1.96s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2701/3000 [1:13:52<09:41,  1.95s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2702/3000 [1:13:53<08:00,  1.61s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2703/3000 [1:13:55<08:21,  1.69s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2704/3000 [1:13:56<07:50,  1.59s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2705/3000 [1:13:57<07:35,  1.54s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2706/3000 [1:13:59<07:51,  1.60s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2707/3000 [1:14:01<08:23,  1.72s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2708/3000 [1:14:03<08:40,  1.78s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2709/3000 [1:14:05<08:11,  1.69s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2710/3000 [1:14:07<09:20,  1.93s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2711/3000 [1:14:09<08:39,  1.80s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2712/3000 [1:14:10<08:02,  1.67s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2713/3000 [1:14:11<07:36,  1.59s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2714/3000 [1:14:13<08:20,  1.75s/it]a2c_tuned train:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2715/3000 [1:14:15<08:23,  1.77s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2716/3000 [1:14:17<08:25,  1.78s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2717/3000 [1:14:19<08:00,  1.70s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2718/3000 [1:14:20<07:42,  1.64s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2719/3000 [1:14:23<08:55,  1.90s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2720/3000 [1:14:23<07:25,  1.59s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2721/3000 [1:14:25<07:31,  1.62s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2722/3000 [1:14:26<06:29,  1.40s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2723/3000 [1:14:27<06:24,  1.39s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2724/3000 [1:14:29<07:19,  1.59s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2725/3000 [1:14:32<08:57,  1.95s/it][step=2673] episode=2673.0000 return=-115.9951 length=30.0000 global_step=64756.0000 loss=254.7222 policy_loss=-0.0000 value_loss=509.4445 entropy=0.0000
[step=2674] episode=2674.0000 return=-115.8346 length=12.0000 global_step=64768.0000 loss=38.0794 policy_loss=-0.0000 value_loss=76.1587 entropy=0.0000
[step=2675] episode=2675.0000 return=-115.9952 length=26.0000 global_step=64794.0000 loss=1238.9852 policy_loss=-0.0000 value_loss=2477.9705 entropy=0.0000
[step=2676] episode=2676.0000 return=-115.9995 length=35.0000 global_step=64829.0000 loss=10.2293 policy_loss=-0.0000 value_loss=20.4585 entropy=0.0000
[step=2677] episode=2677.0000 return=-115.9927 length=37.0000 global_step=64866.0000 loss=629.6353 policy_loss=-0.0000 value_loss=1259.2705 entropy=0.0000
[step=2678] episode=2678.0000 return=-115.9998 length=20.0000 global_step=64886.0000 loss=93.2936 policy_loss=-0.0000 value_loss=186.5873 entropy=0.0000
[step=2679] episode=2679.0000 return=-115.9913 length=29.0000 global_step=64915.0000 loss=1148.7780 policy_loss=-0.0000 value_loss=2297.5559 entropy=0.0000
[step=2680] episode=2680.0000 return=-115.9988 length=19.0000 global_step=64934.0000 loss=32.1688 policy_loss=-0.0000 value_loss=64.3377 entropy=0.0000
[step=2681] episode=2681.0000 return=-116.0000 length=44.0000 global_step=64978.0000 loss=555.5850 policy_loss=-0.0000 value_loss=1111.1700 entropy=0.0000
[step=2682] episode=2682.0000 return=-115.9979 length=37.0000 global_step=65015.0000 loss=269.4330 policy_loss=-0.0000 value_loss=538.8660 entropy=0.0000
[step=2683] episode=2683.0000 return=-115.9955 length=12.0000 global_step=65027.0000 loss=101.3992 policy_loss=-0.0000 value_loss=202.7985 entropy=0.0000
[step=2684] episode=2684.0000 return=-115.9945 length=26.0000 global_step=65053.0000 loss=969.1964 policy_loss=-0.0000 value_loss=1938.3927 entropy=0.0000
[step=2685] episode=2685.0000 return=-115.9999 length=29.0000 global_step=65082.0000 loss=68.1540 policy_loss=-0.0000 value_loss=136.3081 entropy=0.0000
[step=2686] episode=2686.0000 return=-115.8424 length=12.0000 global_step=65094.0000 loss=1351.2810 policy_loss=-0.0000 value_loss=2702.5620 entropy=0.0000
[step=2687] episode=2687.0000 return=-115.9666 length=34.0000 global_step=65128.0000 loss=85.6245 policy_loss=-0.0000 value_loss=171.2490 entropy=0.0000
[step=2688] episode=2688.0000 return=-115.9906 length=28.0000 global_step=65156.0000 loss=662.5246 policy_loss=-0.0000 value_loss=1325.0492 entropy=0.0000
[step=2689] episode=2689.0000 return=-115.9978 length=21.0000 global_step=65177.0000 loss=18.5714 policy_loss=-0.0000 value_loss=37.1427 entropy=0.0000
[step=2690] episode=2690.0000 return=-115.9998 length=28.0000 global_step=65205.0000 loss=399.3558 policy_loss=-0.0000 value_loss=798.7115 entropy=0.0000
[step=2691] episode=2691.0000 return=-115.9761 length=13.0000 global_step=65218.0000 loss=472.9947 policy_loss=-0.0000 value_loss=945.9894 entropy=0.0000
[step=2692] episode=2692.0000 return=-115.9824 length=19.0000 global_step=65237.0000 loss=299.4929 policy_loss=-0.0000 value_loss=598.9857 entropy=0.0000
[step=2693] episode=2693.0000 return=-115.9966 length=37.0000 global_step=65274.0000 loss=1024.8251 policy_loss=-0.0000 value_loss=2049.6501 entropy=0.0000
[step=2694] episode=2694.0000 return=-115.9013 length=20.0000 global_step=65294.0000 loss=67.4123 policy_loss=-0.0000 value_loss=134.8247 entropy=0.0000
[step=2695] episode=2695.0000 return=-115.8448 length=13.0000 global_step=65307.0000 loss=939.0974 policy_loss=-0.0000 value_loss=1878.1948 entropy=0.0000
[step=2696] episode=2696.0000 return=-115.9959 length=36.0000 global_step=65343.0000 loss=22.8407 policy_loss=-0.0000 value_loss=45.6815 entropy=0.0000
[step=2697] episode=2697.0000 return=-115.9840 length=21.0000 global_step=65364.0000 loss=283.8243 policy_loss=-0.0000 value_loss=567.6486 entropy=0.0000
[step=2698] episode=2698.0000 return=-116.0000 length=37.0000 global_step=65401.0000 loss=421.3438 policy_loss=-0.0000 value_loss=842.6875 entropy=0.0000
[step=2699] episode=2699.0000 return=-115.9978 length=22.0000 global_step=65423.0000 loss=25.8160 policy_loss=-0.0000 value_loss=51.6319 entropy=0.0000
[step=2700] episode=2700.0000 return=-115.9968 length=36.0000 global_step=65459.0000 loss=170.4556 policy_loss=-0.0000 value_loss=340.9113 entropy=0.0000
[step=2701] episode=2701.0000 return=-115.9823 length=28.0000 global_step=65487.0000 loss=243.4100 policy_loss=-0.0000 value_loss=486.8199 entropy=0.0000
[step=2702] episode=2702.0000 return=-115.8347 length=12.0000 global_step=65499.0000 loss=11.7049 policy_loss=-0.0000 value_loss=23.4099 entropy=0.0000
[step=2703] episode=2703.0000 return=-115.8777 length=28.0000 global_step=65527.0000 loss=571.7599 policy_loss=-0.0000 value_loss=1143.5199 entropy=0.0000
[step=2704] episode=2704.0000 return=-115.9732 length=20.0000 global_step=65547.0000 loss=212.7319 policy_loss=-0.0000 value_loss=425.4637 entropy=0.0000
[step=2705] episode=2705.0000 return=-115.8432 length=21.0000 global_step=65568.0000 loss=109.3188 policy_loss=-0.0000 value_loss=218.6376 entropy=0.0000
[step=2706] episode=2706.0000 return=-115.9995 length=25.0000 global_step=65593.0000 loss=300.7542 policy_loss=-0.0000 value_loss=601.5084 entropy=0.0000
[step=2707] episode=2707.0000 return=-115.9914 length=29.0000 global_step=65622.0000 loss=41.5758 policy_loss=-0.0000 value_loss=83.1516 entropy=0.0000
[step=2708] episode=2708.0000 return=-115.9973 length=28.0000 global_step=65650.0000 loss=99.9263 policy_loss=-0.0000 value_loss=199.8527 entropy=0.0000
[step=2709] episode=2709.0000 return=-115.9968 length=21.0000 global_step=65671.0000 loss=129.6310 policy_loss=-0.0000 value_loss=259.2621 entropy=0.0000
[step=2710] episode=2710.0000 return=-115.9008 length=38.0000 global_step=65709.0000 loss=22.4887 policy_loss=-0.0000 value_loss=44.9774 entropy=0.0000
[step=2711] episode=2711.0000 return=-115.9986 length=22.0000 global_step=65731.0000 loss=181.3168 policy_loss=-0.0000 value_loss=362.6336 entropy=0.0000
[step=2712] episode=2712.0000 return=-115.9958 length=20.0000 global_step=65751.0000 loss=144.7849 policy_loss=-0.0000 value_loss=289.5698 entropy=0.0000
[step=2713] episode=2713.0000 return=-115.9949 length=20.0000 global_step=65771.0000 loss=20.9424 policy_loss=-0.0000 value_loss=41.8849 entropy=0.0000
[step=2714] episode=2714.0000 return=-115.9824 length=29.0000 global_step=65800.0000 loss=241.3751 policy_loss=-0.0000 value_loss=482.7501 entropy=0.0000
[step=2715] episode=2715.0000 return=-115.9998 length=28.0000 global_step=65828.0000 loss=66.3544 policy_loss=-0.0000 value_loss=132.7087 entropy=0.0000
[step=2716] episode=2716.0000 return=-115.8870 length=26.0000 global_step=65854.0000 loss=120.9300 policy_loss=-0.0000 value_loss=241.8599 entropy=0.0000
[step=2717] episode=2717.0000 return=-115.9989 length=22.0000 global_step=65876.0000 loss=223.3741 policy_loss=-0.0000 value_loss=446.7481 entropy=0.0000
[step=2718] episode=2718.0000 return=-115.9941 length=22.0000 global_step=65898.0000 loss=41.9381 policy_loss=-0.0000 value_loss=83.8762 entropy=0.0000
[step=2719] episode=2719.0000 return=-115.9968 length=38.0000 global_step=65936.0000 loss=477.7868 policy_loss=-0.0000 value_loss=955.5736 entropy=0.0000
[step=2720] episode=2720.0000 return=-115.9882 length=12.0000 global_step=65948.0000 loss=52.9284 policy_loss=-0.0000 value_loss=105.8569 entropy=0.0000
[step=2721] episode=2721.0000 return=-115.9945 length=25.0000 global_step=65973.0000 loss=7.6053 policy_loss=-0.0000 value_loss=15.2105 entropy=0.0000
[step=2722] episode=2722.0000 return=-115.8795 length=13.0000 global_step=65986.0000 loss=297.9560 policy_loss=-0.0000 value_loss=595.9119 entropy=0.0000
[step=2723] episode=2723.0000 return=-115.9895 length=20.0000 global_step=66006.0000 loss=67.0322 policy_loss=-0.0000 value_loss=134.0644 entropy=0.0000
[step=2724] episode=2724.0000 return=-115.9998 length=30.0000 global_step=66036.0000 loss=97.4201 policy_loss=-0.0000 value_loss=194.8403 entropy=0.0000
[step=2725] episode=2725.0000 return=-115.9989 length=42.0000 global_step=66078.0000 loss=252.4382 policy_loss=-0.0000 value_loss=504.8764 entropy=0.0000
a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2726/3000 [1:14:33<07:26,  1.63s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2727/3000 [1:14:34<06:26,  1.42s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2728/3000 [1:14:36<07:42,  1.70s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2729/3000 [1:14:38<07:19,  1.62s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2730/3000 [1:14:39<07:01,  1.56s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2731/3000 [1:14:41<07:27,  1.66s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2732/3000 [1:14:43<06:58,  1.56s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2733/3000 [1:14:44<06:37,  1.49s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2734/3000 [1:14:46<07:02,  1.59s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2735/3000 [1:14:47<06:03,  1.37s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2736/3000 [1:14:48<06:02,  1.37s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2737/3000 [1:14:50<06:49,  1.56s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2738/3000 [1:14:51<05:56,  1.36s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2739/3000 [1:14:53<07:29,  1.72s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2740/3000 [1:14:55<07:00,  1.62s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2741/3000 [1:14:57<08:08,  1.89s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2742/3000 [1:14:59<07:24,  1.72s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2743/3000 [1:15:01<08:16,  1.93s/it]a2c_tuned train:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2744/3000 [1:15:03<08:13,  1.93s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2745/3000 [1:15:05<08:15,  1.94s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2746/3000 [1:15:07<08:14,  1.95s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2747/3000 [1:15:08<06:46,  1.60s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2748/3000 [1:15:09<06:30,  1.55s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2749/3000 [1:15:10<06:12,  1.49s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2750/3000 [1:15:11<04:44,  1.14s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2751/3000 [1:15:13<05:43,  1.38s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2752/3000 [1:15:14<05:06,  1.24s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2753/3000 [1:15:15<05:19,  1.29s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2754/3000 [1:15:17<06:13,  1.52s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2755/3000 [1:15:18<05:59,  1.47s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2756/3000 [1:15:19<05:17,  1.30s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2757/3000 [1:15:20<04:41,  1.16s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2758/3000 [1:15:22<05:06,  1.27s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2759/3000 [1:15:24<06:16,  1.56s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2760/3000 [1:15:25<06:05,  1.52s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2761/3000 [1:15:26<05:19,  1.34s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2762/3000 [1:15:29<07:00,  1.77s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2763/3000 [1:15:31<07:12,  1.82s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2764/3000 [1:15:32<06:33,  1.67s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2765/3000 [1:15:34<06:39,  1.70s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2766/3000 [1:15:36<06:59,  1.79s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2767/3000 [1:15:37<06:18,  1.62s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2768/3000 [1:15:39<05:55,  1.53s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2769/3000 [1:15:39<05:05,  1.32s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2770/3000 [1:15:41<05:09,  1.35s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2771/3000 [1:15:42<05:09,  1.35s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2772/3000 [1:15:43<04:35,  1.21s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2773/3000 [1:15:45<05:33,  1.47s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2774/3000 [1:15:46<04:50,  1.29s/it]a2c_tuned train:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2775/3000 [1:15:47<04:59,  1.33s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2776/3000 [1:15:49<04:54,  1.32s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2777/3000 [1:15:51<05:34,  1.50s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2778/3000 [1:15:52<05:29,  1.49s/it][step=2726] episode=2726.0000 return=-115.8365 length=13.0000 global_step=66091.0000 loss=73.3400 policy_loss=-0.0000 value_loss=146.6800 entropy=0.0000
[step=2727] episode=2727.0000 return=-115.8765 length=13.0000 global_step=66104.0000 loss=138.0782 policy_loss=-0.0000 value_loss=276.1565 entropy=0.0000
[step=2728] episode=2728.0000 return=-115.9837 length=35.0000 global_step=66139.0000 loss=59.7470 policy_loss=-0.0000 value_loss=119.4940 entropy=0.0000
[step=2729] episode=2729.0000 return=-115.9874 length=21.0000 global_step=66160.0000 loss=14.4123 policy_loss=-0.0000 value_loss=28.8247 entropy=0.0000
[step=2730] episode=2730.0000 return=-115.9960 length=21.0000 global_step=66181.0000 loss=7.0279 policy_loss=-0.0000 value_loss=14.0559 entropy=0.0000
[step=2731] episode=2731.0000 return=-115.8870 length=28.0000 global_step=66209.0000 loss=6.9728 policy_loss=-0.0000 value_loss=13.9456 entropy=0.0000
[step=2732] episode=2732.0000 return=-115.9962 length=19.0000 global_step=66228.0000 loss=17.7689 policy_loss=-0.0000 value_loss=35.5378 entropy=0.0000
[step=2733] episode=2733.0000 return=-115.9938 length=19.0000 global_step=66247.0000 loss=13.0985 policy_loss=-0.0000 value_loss=26.1970 entropy=0.0000
[step=2734] episode=2734.0000 return=-115.8844 length=27.0000 global_step=66274.0000 loss=9.2764 policy_loss=-0.0000 value_loss=18.5528 entropy=0.0000
[step=2735] episode=2735.0000 return=-115.8369 length=11.0000 global_step=66285.0000 loss=13.0296 policy_loss=-0.0000 value_loss=26.0591 entropy=0.0000
[step=2736] episode=2736.0000 return=-115.8412 length=19.0000 global_step=66304.0000 loss=25.7186 policy_loss=-0.0000 value_loss=51.4371 entropy=0.0000
[step=2737] episode=2737.0000 return=-115.9975 length=29.0000 global_step=66333.0000 loss=59.3750 policy_loss=-0.0000 value_loss=118.7499 entropy=0.0000
[step=2738] episode=2738.0000 return=-115.6949 length=12.0000 global_step=66345.0000 loss=82.0552 policy_loss=-0.0000 value_loss=164.1104 entropy=0.0000
[step=2739] episode=2739.0000 return=-115.9976 length=37.0000 global_step=66382.0000 loss=19.3240 policy_loss=-0.0000 value_loss=38.6480 entropy=0.0000
[step=2740] episode=2740.0000 return=-115.9941 length=21.0000 global_step=66403.0000 loss=37.3924 policy_loss=-0.0000 value_loss=74.7847 entropy=0.0000
[step=2741] episode=2741.0000 return=-115.9998 length=38.0000 global_step=66441.0000 loss=35.4051 policy_loss=-0.0000 value_loss=70.8102 entropy=0.0000
[step=2742] episode=2742.0000 return=-115.9976 length=20.0000 global_step=66461.0000 loss=15.7782 policy_loss=-0.0000 value_loss=31.5564 entropy=0.0000
[step=2743] episode=2743.0000 return=-115.8644 length=37.0000 global_step=66498.0000 loss=17.2296 policy_loss=-0.0000 value_loss=34.4592 entropy=0.0000
[step=2744] episode=2744.0000 return=-115.9947 length=28.0000 global_step=66526.0000 loss=24.3755 policy_loss=-0.0000 value_loss=48.7510 entropy=0.0000
[step=2745] episode=2745.0000 return=-115.8793 length=29.0000 global_step=66555.0000 loss=12.5732 policy_loss=-0.0000 value_loss=25.1463 entropy=0.0000
[step=2746] episode=2746.0000 return=-115.9987 length=29.0000 global_step=66584.0000 loss=17.1856 policy_loss=-0.0000 value_loss=34.3712 entropy=0.0000
[step=2747] episode=2747.0000 return=-115.9785 length=12.0000 global_step=66596.0000 loss=43.8583 policy_loss=-0.0000 value_loss=87.7166 entropy=0.0000
[step=2748] episode=2748.0000 return=-115.9855 length=21.0000 global_step=66617.0000 loss=17.0011 policy_loss=-0.0000 value_loss=34.0022 entropy=0.0000
[step=2749] episode=2749.0000 return=-115.9958 length=20.0000 global_step=66637.0000 loss=62.1397 policy_loss=-0.0000 value_loss=124.2794 entropy=0.0000
[step=2750] episode=2750.0000 return=-100.0000 length=4.0000 global_step=66641.0000 loss=0.9578 policy_loss=-0.0000 value_loss=1.9155 entropy=0.0000
[step=2751] episode=2751.0000 return=-115.8649 length=29.0000 global_step=66670.0000 loss=6.2714 policy_loss=-0.0000 value_loss=12.5427 entropy=0.0000
[step=2752] episode=2752.0000 return=-115.8149 length=13.0000 global_step=66683.0000 loss=90.0641 policy_loss=-0.0000 value_loss=180.1282 entropy=0.0000
[step=2753] episode=2753.0000 return=-115.9840 length=21.0000 global_step=66704.0000 loss=7.2713 policy_loss=-0.0000 value_loss=14.5427 entropy=0.0000
[step=2754] episode=2754.0000 return=-115.9840 length=29.0000 global_step=66733.0000 loss=81.7578 policy_loss=-0.0000 value_loss=163.5156 entropy=0.0000
[step=2755] episode=2755.0000 return=-115.8632 length=20.0000 global_step=66753.0000 loss=8.5493 policy_loss=-0.0000 value_loss=17.0985 entropy=0.0000
[step=2756] episode=2756.0000 return=-115.8126 length=13.0000 global_step=66766.0000 loss=30.9078 policy_loss=-0.0000 value_loss=61.8155 entropy=0.0000
[step=2757] episode=2757.0000 return=-115.8850 length=12.0000 global_step=66778.0000 loss=21.1858 policy_loss=-0.0000 value_loss=42.3715 entropy=0.0000
[step=2758] episode=2758.0000 return=-115.9990 length=21.0000 global_step=66799.0000 loss=8.7970 policy_loss=-0.0000 value_loss=17.5940 entropy=0.0000
[step=2759] episode=2759.0000 return=-116.0000 length=34.0000 global_step=66833.0000 loss=75.6905 policy_loss=-0.0000 value_loss=151.3810 entropy=0.0000
[step=2760] episode=2760.0000 return=-115.8870 length=21.0000 global_step=66854.0000 loss=10.1500 policy_loss=-0.0000 value_loss=20.3000 entropy=0.0000
[step=2761] episode=2761.0000 return=-115.9182 length=12.0000 global_step=66866.0000 loss=85.9128 policy_loss=-0.0000 value_loss=171.8255 entropy=0.0000
[step=2762] episode=2762.0000 return=-115.9921 length=41.0000 global_step=66907.0000 loss=33.2849 policy_loss=-0.0000 value_loss=66.5698 entropy=0.0000
[step=2763] episode=2763.0000 return=-115.9979 length=29.0000 global_step=66936.0000 loss=8.9638 policy_loss=-0.0000 value_loss=17.9276 entropy=0.0000
[step=2764] episode=2764.0000 return=-115.9095 length=19.0000 global_step=66955.0000 loss=20.1839 policy_loss=-0.0000 value_loss=40.3679 entropy=0.0000
[step=2765] episode=2765.0000 return=-115.9975 length=27.0000 global_step=66982.0000 loss=17.2378 policy_loss=-0.0000 value_loss=34.4756 entropy=0.0000
[step=2766] episode=2766.0000 return=-115.9958 length=30.0000 global_step=67012.0000 loss=16.9718 policy_loss=-0.0000 value_loss=33.9436 entropy=0.0000
[step=2767] episode=2767.0000 return=-115.9965 length=18.0000 global_step=67030.0000 loss=40.1230 policy_loss=-0.0000 value_loss=80.2461 entropy=0.0000
[step=2768] episode=2768.0000 return=-115.9855 length=20.0000 global_step=67050.0000 loss=12.4954 policy_loss=-0.0000 value_loss=24.9908 entropy=0.0000
[step=2769] episode=2769.0000 return=-115.9997 length=12.0000 global_step=67062.0000 loss=8.5668 policy_loss=-0.0000 value_loss=17.1335 entropy=0.0000
[step=2770] episode=2770.0000 return=-115.9984 length=20.0000 global_step=67082.0000 loss=33.3648 policy_loss=-0.0000 value_loss=66.7296 entropy=0.0000
[step=2771] episode=2771.0000 return=-115.9999 length=20.0000 global_step=67102.0000 loss=106.1449 policy_loss=-0.0000 value_loss=212.2899 entropy=0.0000
[step=2772] episode=2772.0000 return=-115.8263 length=13.0000 global_step=67115.0000 loss=9.7806 policy_loss=-0.0000 value_loss=19.5612 entropy=0.0000
[step=2773] episode=2773.0000 return=-115.9999 length=29.0000 global_step=67144.0000 loss=18.0620 policy_loss=-0.0000 value_loss=36.1239 entropy=0.0000
[step=2774] episode=2774.0000 return=-115.9796 length=12.0000 global_step=67156.0000 loss=165.9537 policy_loss=-0.0000 value_loss=331.9074 entropy=0.0000
[step=2775] episode=2775.0000 return=-115.8840 length=22.0000 global_step=67178.0000 loss=31.6784 policy_loss=-0.0000 value_loss=63.3568 entropy=0.0000
[step=2776] episode=2776.0000 return=-115.9848 length=19.0000 global_step=67197.0000 loss=19.8374 policy_loss=-0.0000 value_loss=39.6749 entropy=0.0000
[step=2777] episode=2777.0000 return=-115.9728 length=28.0000 global_step=67225.0000 loss=87.0757 policy_loss=-0.0000 value_loss=174.1513 entropy=0.0000
[step=2778] episode=2778.0000 return=-115.9867 length=21.0000 global_step=67246.0000 loss=32.6439 policy_loss=-0.0000 value_loss=65.2878 entropy=0.0000
a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2779/3000 [1:15:54<05:59,  1.63s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2780/3000 [1:15:57<07:48,  2.13s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2781/3000 [1:15:59<06:52,  1.89s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2782/3000 [1:16:01<06:55,  1.90s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2783/3000 [1:16:01<05:40,  1.57s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2784/3000 [1:16:04<06:33,  1.82s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2785/3000 [1:16:06<06:46,  1.89s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2786/3000 [1:16:09<07:46,  2.18s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2787/3000 [1:16:10<06:14,  1.76s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2788/3000 [1:16:11<06:11,  1.75s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2789/3000 [1:16:12<05:15,  1.49s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2790/3000 [1:16:13<04:29,  1.28s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2791/3000 [1:16:15<05:39,  1.62s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2792/3000 [1:16:17<05:17,  1.53s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2793/3000 [1:16:19<05:38,  1.63s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2794/3000 [1:16:21<06:37,  1.93s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2795/3000 [1:16:22<05:30,  1.61s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2796/3000 [1:16:25<06:43,  1.98s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2797/3000 [1:16:26<06:04,  1.80s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2798/3000 [1:16:28<05:29,  1.63s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2799/3000 [1:16:30<05:50,  1.75s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2800/3000 [1:16:30<04:55,  1.48s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2801/3000 [1:16:33<06:21,  1.92s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2802/3000 [1:16:35<05:35,  1.70s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2803/3000 [1:16:37<06:15,  1.91s/it]a2c_tuned train:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2804/3000 [1:16:38<05:42,  1.75s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2805/3000 [1:16:40<05:50,  1.80s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2806/3000 [1:16:41<04:51,  1.50s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2807/3000 [1:16:43<05:32,  1.72s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2808/3000 [1:16:45<05:48,  1.82s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2809/3000 [1:16:48<06:56,  2.18s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2810/3000 [1:16:50<06:33,  2.07s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2811/3000 [1:16:51<05:50,  1.85s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2812/3000 [1:16:53<05:50,  1.86s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2813/3000 [1:16:54<04:52,  1.56s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2814/3000 [1:16:55<04:16,  1.38s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2815/3000 [1:16:56<04:07,  1.34s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2816/3000 [1:16:58<04:13,  1.38s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2817/3000 [1:17:00<04:38,  1.52s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2818/3000 [1:17:01<04:26,  1.47s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2819/3000 [1:17:03<05:14,  1.74s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2820/3000 [1:17:04<04:27,  1.49s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2821/3000 [1:17:06<04:26,  1.49s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2822/3000 [1:17:07<04:24,  1.48s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2823/3000 [1:17:09<04:47,  1.63s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2824/3000 [1:17:10<04:01,  1.37s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2825/3000 [1:17:11<03:33,  1.22s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2826/3000 [1:17:12<03:43,  1.28s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2827/3000 [1:17:14<04:06,  1.42s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2828/3000 [1:17:15<03:32,  1.24s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2829/3000 [1:17:16<03:36,  1.27s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2830/3000 [1:17:18<04:06,  1.45s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2831/3000 [1:17:20<04:31,  1.60s/it][step=2779] episode=2779.0000 return=-115.9910 length=28.0000 global_step=67274.0000 loss=8.3924 policy_loss=-0.0000 value_loss=16.7849 entropy=0.0000
[step=2780] episode=2780.0000 return=-115.9896 length=49.0000 global_step=67323.0000 loss=51.7580 policy_loss=-0.0000 value_loss=103.5161 entropy=0.0000
[step=2781] episode=2781.0000 return=-115.8844 length=19.0000 global_step=67342.0000 loss=209.7795 policy_loss=-0.0000 value_loss=419.5590 entropy=0.0000
[step=2782] episode=2782.0000 return=-115.8870 length=29.0000 global_step=67371.0000 loss=59.5465 policy_loss=-0.0000 value_loss=119.0930 entropy=0.0000
[step=2783] episode=2783.0000 return=-115.8169 length=12.0000 global_step=67383.0000 loss=25.8124 policy_loss=-0.0000 value_loss=51.6247 entropy=0.0000
[step=2784] episode=2784.0000 return=-115.9968 length=36.0000 global_step=67419.0000 loss=330.0745 policy_loss=-0.0000 value_loss=660.1490 entropy=0.0000
[step=2785] episode=2785.0000 return=-115.9999 length=29.0000 global_step=67448.0000 loss=201.3240 policy_loss=-0.0000 value_loss=402.6480 entropy=0.0000
[step=2786] episode=2786.0000 return=-115.9264 length=42.0000 global_step=67490.0000 loss=52.0703 policy_loss=-0.0000 value_loss=104.1407 entropy=0.0000
[step=2787] episode=2787.0000 return=-115.9337 length=12.0000 global_step=67502.0000 loss=344.7797 policy_loss=-0.0000 value_loss=689.5594 entropy=0.0000
[step=2788] episode=2788.0000 return=-115.9993 length=25.0000 global_step=67527.0000 loss=160.2374 policy_loss=-0.0000 value_loss=320.4747 entropy=0.0000
[step=2789] episode=2789.0000 return=-115.9885 length=13.0000 global_step=67540.0000 loss=117.1380 policy_loss=-0.0000 value_loss=234.2760 entropy=0.0000
[step=2790] episode=2790.0000 return=-115.9464 length=12.0000 global_step=67552.0000 loss=22.6923 policy_loss=-0.0000 value_loss=45.3845 entropy=0.0000
[step=2791] episode=2791.0000 return=-115.9894 length=36.0000 global_step=67588.0000 loss=548.5709 policy_loss=-0.0000 value_loss=1097.1418 entropy=0.0000
[step=2792] episode=2792.0000 return=-114.2084 length=19.0000 global_step=67607.0000 loss=156.0908 policy_loss=-0.0000 value_loss=312.1817 entropy=0.0000
[step=2793] episode=2793.0000 return=-115.9951 length=28.0000 global_step=67635.0000 loss=18.6349 policy_loss=-0.0000 value_loss=37.2698 entropy=0.0000
[step=2794] episode=2794.0000 return=-115.9993 length=38.0000 global_step=67673.0000 loss=98.1807 policy_loss=-0.0000 value_loss=196.3615 entropy=0.0000
[step=2795] episode=2795.0000 return=-115.7863 length=12.0000 global_step=67685.0000 loss=781.7360 policy_loss=-0.0000 value_loss=1563.4720 entropy=0.0000
[step=2796] episode=2796.0000 return=-115.9995 length=43.0000 global_step=67728.0000 loss=58.4473 policy_loss=-0.0000 value_loss=116.8947 entropy=0.0000
[step=2797] episode=2797.0000 return=-115.9944 length=20.0000 global_step=67748.0000 loss=10.7858 policy_loss=-0.0000 value_loss=21.5716 entropy=0.0000
[step=2798] episode=2798.0000 return=-115.8983 length=18.0000 global_step=67766.0000 loss=114.4039 policy_loss=-0.0000 value_loss=228.8077 entropy=0.0000
[step=2799] episode=2799.0000 return=-115.9941 length=30.0000 global_step=67796.0000 loss=314.5302 policy_loss=-0.0000 value_loss=629.0603 entropy=0.0000
[step=2800] episode=2800.0000 return=-115.9462 length=12.0000 global_step=67808.0000 loss=21.5060 policy_loss=-0.0000 value_loss=43.0120 entropy=0.0000
[step=2801] episode=2801.0000 return=-115.9955 length=45.0000 global_step=67853.0000 loss=82.3523 policy_loss=-0.0000 value_loss=164.7046 entropy=0.0000
[step=2802] episode=2802.0000 return=-115.8941 length=18.0000 global_step=67871.0000 loss=180.1775 policy_loss=-0.0000 value_loss=360.3550 entropy=0.0000
[step=2803] episode=2803.0000 return=-115.9386 length=36.0000 global_step=67907.0000 loss=181.8007 policy_loss=-0.0000 value_loss=363.6013 entropy=0.0000
[step=2804] episode=2804.0000 return=-115.9990 length=20.0000 global_step=67927.0000 loss=160.4905 policy_loss=-0.0000 value_loss=320.9809 entropy=0.0000
[step=2805] episode=2805.0000 return=-115.8929 length=28.0000 global_step=67955.0000 loss=12.4815 policy_loss=-0.0000 value_loss=24.9631 entropy=0.0000
[step=2806] episode=2806.0000 return=-115.9515 length=11.0000 global_step=67966.0000 loss=10.5921 policy_loss=-0.0000 value_loss=21.1842 entropy=0.0000
[step=2807] episode=2807.0000 return=-115.9756 length=33.0000 global_step=67999.0000 loss=277.0896 policy_loss=-0.0000 value_loss=554.1791 entropy=0.0000
[step=2808] episode=2808.0000 return=-115.9955 length=28.0000 global_step=68027.0000 loss=221.8251 policy_loss=-0.0000 value_loss=443.6502 entropy=0.0000
[step=2809] episode=2809.0000 return=-115.9933 length=46.0000 global_step=68073.0000 loss=196.3578 policy_loss=-0.0000 value_loss=392.7155 entropy=0.0000
[step=2810] episode=2810.0000 return=-115.9888 length=27.0000 global_step=68100.0000 loss=30.7470 policy_loss=-0.0000 value_loss=61.4940 entropy=0.0000
[step=2811] episode=2811.0000 return=-115.9096 length=20.0000 global_step=68120.0000 loss=228.8319 policy_loss=-0.0000 value_loss=457.6639 entropy=0.0000
[step=2812] episode=2812.0000 return=-115.9090 length=29.0000 global_step=68149.0000 loss=189.6204 policy_loss=-0.0000 value_loss=379.2408 entropy=0.0000
[step=2813] episode=2813.0000 return=-115.9827 length=12.0000 global_step=68161.0000 loss=281.5053 policy_loss=-0.0000 value_loss=563.0106 entropy=0.0000
[step=2814] episode=2814.0000 return=-115.7664 length=13.0000 global_step=68174.0000 loss=33.1212 policy_loss=-0.0000 value_loss=66.2424 entropy=0.0000
[step=2815] episode=2815.0000 return=-115.9210 length=18.0000 global_step=68192.0000 loss=42.9753 policy_loss=-0.0000 value_loss=85.9506 entropy=0.0000
[step=2816] episode=2816.0000 return=-115.9981 length=22.0000 global_step=68214.0000 loss=395.4271 policy_loss=-0.0000 value_loss=790.8542 entropy=0.0000
[step=2817] episode=2817.0000 return=-115.9961 length=27.0000 global_step=68241.0000 loss=433.5141 policy_loss=-0.0000 value_loss=867.0282 entropy=0.0000
[step=2818] episode=2818.0000 return=-115.8609 length=19.0000 global_step=68260.0000 loss=45.1703 policy_loss=-0.0000 value_loss=90.3407 entropy=0.0000
[step=2819] episode=2819.0000 return=-115.9921 length=37.0000 global_step=68297.0000 loss=15.1524 policy_loss=-0.0000 value_loss=30.3048 entropy=0.0000
[step=2820] episode=2820.0000 return=-115.9846 length=13.0000 global_step=68310.0000 loss=263.9073 policy_loss=-0.0000 value_loss=527.8146 entropy=0.0000
[step=2821] episode=2821.0000 return=-115.9589 length=22.0000 global_step=68332.0000 loss=244.7056 policy_loss=-0.0000 value_loss=489.4112 entropy=0.0000
[step=2822] episode=2822.0000 return=-115.9986 length=21.0000 global_step=68353.0000 loss=215.4583 policy_loss=-0.0000 value_loss=430.9167 entropy=0.0000
[step=2823] episode=2823.0000 return=-115.9984 length=29.0000 global_step=68382.0000 loss=25.1949 policy_loss=-0.0000 value_loss=50.3897 entropy=0.0000
[step=2824] episode=2824.0000 return=-115.8378 length=11.0000 global_step=68393.0000 loss=14.0607 policy_loss=-0.0000 value_loss=28.1214 entropy=0.0000
[step=2825] episode=2825.0000 return=-115.9505 length=12.0000 global_step=68405.0000 loss=59.4565 policy_loss=-0.0000 value_loss=118.9131 entropy=0.0000
[step=2826] episode=2826.0000 return=-115.9011 length=21.0000 global_step=68426.0000 loss=235.7721 policy_loss=-0.0000 value_loss=471.5443 entropy=0.0000
[step=2827] episode=2827.0000 return=-115.9950 length=26.0000 global_step=68452.0000 loss=314.5369 policy_loss=-0.0000 value_loss=629.0739 entropy=0.0000
[step=2828] episode=2828.0000 return=-115.7390 length=12.0000 global_step=68464.0000 loss=22.9676 policy_loss=-0.0000 value_loss=45.9351 entropy=0.0000
[step=2829] episode=2829.0000 return=-115.9718 length=19.0000 global_step=68483.0000 loss=8.0505 policy_loss=-0.0000 value_loss=16.1009 entropy=0.0000
[step=2830] episode=2830.0000 return=-115.9721 length=28.0000 global_step=68511.0000 loss=40.1764 policy_loss=-0.0000 value_loss=80.3529 entropy=0.0000
[step=2831] episode=2831.0000 return=-115.9818 length=29.0000 global_step=68540.0000 loss=83.9367 policy_loss=-0.0000 value_loss=167.8734 entropy=0.0000
a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2832/3000 [1:17:21<04:19,  1.55s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2833/3000 [1:17:23<04:39,  1.67s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2834/3000 [1:17:28<06:36,  2.39s/it]a2c_tuned train:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2835/3000 [1:17:28<05:19,  1.93s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2836/3000 [1:17:30<04:49,  1.77s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2837/3000 [1:17:32<04:57,  1.82s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2838/3000 [1:17:34<04:55,  1.83s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2839/3000 [1:17:36<05:03,  1.89s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2840/3000 [1:17:38<05:03,  1.90s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2841/3000 [1:17:38<04:09,  1.57s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2842/3000 [1:17:41<04:49,  1.83s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2843/3000 [1:17:43<04:54,  1.88s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2844/3000 [1:17:44<04:02,  1.55s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2845/3000 [1:17:44<03:24,  1.32s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2846/3000 [1:17:46<03:54,  1.52s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2847/3000 [1:17:49<04:29,  1.76s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2848/3000 [1:17:51<04:35,  1.82s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2849/3000 [1:17:53<04:41,  1.87s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2850/3000 [1:17:54<04:15,  1.71s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2851/3000 [1:17:56<04:16,  1.72s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2852/3000 [1:17:57<03:38,  1.48s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2853/3000 [1:17:58<03:55,  1.60s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2854/3000 [1:18:00<03:42,  1.52s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2855/3000 [1:18:02<04:27,  1.84s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2856/3000 [1:18:04<04:25,  1.85s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2857/3000 [1:18:06<04:28,  1.88s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2858/3000 [1:18:08<04:07,  1.74s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2859/3000 [1:18:08<03:27,  1.47s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2860/3000 [1:18:10<03:18,  1.42s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2861/3000 [1:18:11<03:15,  1.41s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2862/3000 [1:18:13<03:36,  1.57s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2863/3000 [1:18:15<03:51,  1.69s/it]a2c_tuned train:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2864/3000 [1:18:16<03:14,  1.43s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2865/3000 [1:18:17<03:12,  1.43s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2866/3000 [1:18:18<02:47,  1.25s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2867/3000 [1:18:19<02:30,  1.13s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2868/3000 [1:18:20<02:23,  1.09s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2869/3000 [1:18:21<02:15,  1.04s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2870/3000 [1:18:23<02:51,  1.32s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2871/3000 [1:18:26<03:58,  1.85s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2872/3000 [1:18:27<03:36,  1.69s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2873/3000 [1:18:31<04:35,  2.17s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2874/3000 [1:18:33<04:46,  2.28s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2875/3000 [1:18:34<04:10,  2.00s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2876/3000 [1:18:37<04:41,  2.27s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2877/3000 [1:18:38<03:47,  1.85s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2878/3000 [1:18:39<03:22,  1.66s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2879/3000 [1:18:41<03:32,  1.75s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2880/3000 [1:18:43<03:17,  1.64s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2881/3000 [1:18:44<03:07,  1.58s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2882/3000 [1:18:46<02:57,  1.50s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2883/3000 [1:18:49<04:11,  2.15s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2884/3000 [1:18:52<04:17,  2.22s/it][step=2832] episode=2832.0000 return=-115.8389 length=20.0000 global_step=68560.0000 loss=90.1978 policy_loss=-0.0000 value_loss=180.3956 entropy=0.0000
[step=2833] episode=2833.0000 return=-115.9956 length=30.0000 global_step=68590.0000 loss=15.8131 policy_loss=-0.0000 value_loss=31.6261 entropy=0.0000
[step=2834] episode=2834.0000 return=-115.9978 length=61.0000 global_step=68651.0000 loss=168.5260 policy_loss=-0.0000 value_loss=337.0520 entropy=0.0000
[step=2835] episode=2835.0000 return=-115.9948 length=12.0000 global_step=68663.0000 loss=26.0677 policy_loss=-0.0000 value_loss=52.1353 entropy=0.0000
[step=2836] episode=2836.0000 return=-115.9711 length=20.0000 global_step=68683.0000 loss=13.6110 policy_loss=-0.0000 value_loss=27.2219 entropy=0.0000
[step=2837] episode=2837.0000 return=-115.9986 length=29.0000 global_step=68712.0000 loss=23.1178 policy_loss=-0.0000 value_loss=46.2356 entropy=0.0000
[step=2838] episode=2838.0000 return=-115.9955 length=27.0000 global_step=68739.0000 loss=21.2531 policy_loss=-0.0000 value_loss=42.5062 entropy=0.0000
[step=2839] episode=2839.0000 return=-115.8370 length=30.0000 global_step=68769.0000 loss=14.8984 policy_loss=-0.0000 value_loss=29.7968 entropy=0.0000
[step=2840] episode=2840.0000 return=-115.9871 length=28.0000 global_step=68797.0000 loss=29.2727 policy_loss=-0.0000 value_loss=58.5454 entropy=0.0000
[step=2841] episode=2841.0000 return=-115.9992 length=12.0000 global_step=68809.0000 loss=94.3002 policy_loss=-0.0000 value_loss=188.6004 entropy=0.0000
[step=2842] episode=2842.0000 return=-115.9949 length=37.0000 global_step=68846.0000 loss=33.0614 policy_loss=-0.0000 value_loss=66.1228 entropy=0.0000
[step=2843] episode=2843.0000 return=-115.9942 length=29.0000 global_step=68875.0000 loss=19.5393 policy_loss=-0.0000 value_loss=39.0786 entropy=0.0000
[step=2844] episode=2844.0000 return=-115.9928 length=12.0000 global_step=68887.0000 loss=61.9869 policy_loss=-0.0000 value_loss=123.9737 entropy=0.0000
[step=2845] episode=2845.0000 return=-115.7987 length=11.0000 global_step=68898.0000 loss=10.4195 policy_loss=-0.0000 value_loss=20.8389 entropy=0.0000
[step=2846] episode=2846.0000 return=-115.9096 length=28.0000 global_step=68926.0000 loss=141.1202 policy_loss=-0.0000 value_loss=282.2403 entropy=0.0000
[step=2847] episode=2847.0000 return=-115.9983 length=34.0000 global_step=68960.0000 loss=212.2676 policy_loss=-0.0000 value_loss=424.5352 entropy=0.0000
[step=2848] episode=2848.0000 return=-115.9772 length=29.0000 global_step=68989.0000 loss=71.8171 policy_loss=-0.0000 value_loss=143.6341 entropy=0.0000
[step=2849] episode=2849.0000 return=-115.9990 length=29.0000 global_step=69018.0000 loss=6.6892 policy_loss=-0.0000 value_loss=13.3784 entropy=0.0000
[step=2850] episode=2850.0000 return=-115.9894 length=18.0000 global_step=69036.0000 loss=100.6720 policy_loss=-0.0000 value_loss=201.3440 entropy=0.0000
[step=2851] episode=2851.0000 return=-115.9574 length=27.0000 global_step=69063.0000 loss=76.0659 policy_loss=-0.0000 value_loss=152.1318 entropy=0.0000
[step=2852] episode=2852.0000 return=-115.8122 length=13.0000 global_step=69076.0000 loss=169.3969 policy_loss=-0.0000 value_loss=338.7939 entropy=0.0000
[step=2853] episode=2853.0000 return=-115.9966 length=28.0000 global_step=69104.0000 loss=14.6267 policy_loss=-0.0000 value_loss=29.2535 entropy=0.0000
[step=2854] episode=2854.0000 return=-115.9622 length=20.0000 global_step=69124.0000 loss=16.0102 policy_loss=-0.0000 value_loss=32.0203 entropy=0.0000
[step=2855] episode=2855.0000 return=-115.9939 length=38.0000 global_step=69162.0000 loss=207.6231 policy_loss=-0.0000 value_loss=415.2462 entropy=0.0000
[step=2856] episode=2856.0000 return=-115.9996 length=28.0000 global_step=69190.0000 loss=81.9030 policy_loss=-0.0000 value_loss=163.8061 entropy=0.0000
[step=2857] episode=2857.0000 return=-115.9986 length=29.0000 global_step=69219.0000 loss=35.3433 policy_loss=-0.0000 value_loss=70.6866 entropy=0.0000
[step=2858] episode=2858.0000 return=-115.9670 length=20.0000 global_step=69239.0000 loss=76.1735 policy_loss=-0.0000 value_loss=152.3469 entropy=0.0000
[step=2859] episode=2859.0000 return=-115.9879 length=12.0000 global_step=69251.0000 loss=158.3265 policy_loss=-0.0000 value_loss=316.6529 entropy=0.0000
[step=2860] episode=2860.0000 return=-115.9986 length=19.0000 global_step=69270.0000 loss=56.5905 policy_loss=-0.0000 value_loss=113.1810 entropy=0.0000
[step=2861] episode=2861.0000 return=-115.9987 length=20.0000 global_step=69290.0000 loss=9.5965 policy_loss=-0.0000 value_loss=19.1929 entropy=0.0000
[step=2862] episode=2862.0000 return=-115.9913 length=29.0000 global_step=69319.0000 loss=69.8083 policy_loss=-0.0000 value_loss=139.6167 entropy=0.0000
[step=2863] episode=2863.0000 return=-115.9941 length=28.0000 global_step=69347.0000 loss=28.9967 policy_loss=-0.0000 value_loss=57.9935 entropy=0.0000
[step=2864] episode=2864.0000 return=-115.9996 length=12.0000 global_step=69359.0000 loss=12.6240 policy_loss=-0.0000 value_loss=25.2479 entropy=0.0000
[step=2865] episode=2865.0000 return=-115.9944 length=20.0000 global_step=69379.0000 loss=11.4344 policy_loss=-0.0000 value_loss=22.8687 entropy=0.0000
[step=2866] episode=2866.0000 return=-115.9995 length=12.0000 global_step=69391.0000 loss=28.3750 policy_loss=-0.0000 value_loss=56.7500 entropy=0.0000
[step=2867] episode=2867.0000 return=-115.9720 length=13.0000 global_step=69404.0000 loss=20.6283 policy_loss=-0.0000 value_loss=41.2565 entropy=0.0000
[step=2868] episode=2868.0000 return=-115.9414 length=13.0000 global_step=69417.0000 loss=7.3745 policy_loss=-0.0000 value_loss=14.7491 entropy=0.0000
[step=2869] episode=2869.0000 return=-115.7997 length=13.0000 global_step=69430.0000 loss=13.7823 policy_loss=-0.0000 value_loss=27.5646 entropy=0.0000
[step=2870] episode=2870.0000 return=-115.9890 length=29.0000 global_step=69459.0000 loss=70.9925 policy_loss=-0.0000 value_loss=141.9849 entropy=0.0000
[step=2871] episode=2871.0000 return=-115.9985 length=46.0000 global_step=69505.0000 loss=220.8656 policy_loss=-0.0000 value_loss=441.7311 entropy=0.0000
[step=2872] episode=2872.0000 return=-115.8188 length=20.0000 global_step=69525.0000 loss=15.4357 policy_loss=-0.0000 value_loss=30.8715 entropy=0.0000
[step=2873] episode=2873.0000 return=-115.9986 length=48.0000 global_step=69573.0000 loss=25.6621 policy_loss=-0.0000 value_loss=51.3241 entropy=0.0000
[step=2874] episode=2874.0000 return=-115.9928 length=38.0000 global_step=69611.0000 loss=52.4525 policy_loss=-0.0000 value_loss=104.9051 entropy=0.0000
[step=2875] episode=2875.0000 return=-115.8218 length=20.0000 global_step=69631.0000 loss=243.3695 policy_loss=-0.0000 value_loss=486.7391 entropy=0.0000
[step=2876] episode=2876.0000 return=-116.0000 length=43.0000 global_step=69674.0000 loss=34.3755 policy_loss=-0.0000 value_loss=68.7511 entropy=0.0000
[step=2877] episode=2877.0000 return=-115.7558 length=12.0000 global_step=69686.0000 loss=110.9285 policy_loss=-0.0000 value_loss=221.8569 entropy=0.0000
[step=2878] episode=2878.0000 return=-115.9096 length=18.0000 global_step=69704.0000 loss=16.1900 policy_loss=-0.0000 value_loss=32.3800 entropy=0.0000
[step=2879] episode=2879.0000 return=-115.9930 length=29.0000 global_step=69733.0000 loss=158.5012 policy_loss=-0.0000 value_loss=317.0025 entropy=0.0000
[step=2880] episode=2880.0000 return=-115.9707 length=20.0000 global_step=69753.0000 loss=106.2423 policy_loss=-0.0000 value_loss=212.4846 entropy=0.0000
[step=2881] episode=2881.0000 return=-115.9919 length=21.0000 global_step=69774.0000 loss=46.8996 policy_loss=-0.0000 value_loss=93.7992 entropy=0.0000
[step=2882] episode=2882.0000 return=-115.8318 length=20.0000 global_step=69794.0000 loss=11.1585 policy_loss=-0.0000 value_loss=22.3171 entropy=0.0000
[step=2883] episode=2883.0000 return=-115.9999 length=54.0000 global_step=69848.0000 loss=100.0166 policy_loss=-0.0000 value_loss=200.0332 entropy=0.0000
[step=2884] episode=2884.0000 return=-115.9658 length=35.0000 global_step=69883.0000 loss=36.4239 policy_loss=-0.0000 value_loss=72.8478 entropy=0.0000
a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2885/3000 [1:18:53<03:41,  1.92s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2886/3000 [1:18:55<03:36,  1.90s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2887/3000 [1:18:56<03:32,  1.88s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2888/3000 [1:18:57<02:55,  1.57s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2889/3000 [1:18:59<03:08,  1.70s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2890/3000 [1:19:01<02:58,  1.63s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2891/3000 [1:19:02<02:45,  1.52s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2892/3000 [1:19:04<02:42,  1.50s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2893/3000 [1:19:05<02:36,  1.46s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2894/3000 [1:19:06<02:30,  1.42s/it]a2c_tuned train:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2895/3000 [1:19:08<02:33,  1.46s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2896/3000 [1:19:09<02:11,  1.26s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2897/3000 [1:19:10<02:09,  1.26s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2898/3000 [1:19:12<02:24,  1.41s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2899/3000 [1:19:13<02:22,  1.41s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2900/3000 [1:19:15<02:38,  1.58s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2901/3000 [1:19:16<02:15,  1.37s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2902/3000 [1:19:18<02:29,  1.52s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2903/3000 [1:19:20<02:43,  1.68s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2904/3000 [1:19:21<02:36,  1.63s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2905/3000 [1:19:23<02:43,  1.72s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2906/3000 [1:19:24<02:14,  1.43s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2907/3000 [1:19:26<02:26,  1.57s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2908/3000 [1:19:28<02:33,  1.67s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2909/3000 [1:19:30<02:50,  1.88s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2910/3000 [1:19:32<02:43,  1.82s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2911/3000 [1:19:33<02:28,  1.67s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2912/3000 [1:19:34<02:03,  1.41s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2913/3000 [1:19:35<02:01,  1.40s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2914/3000 [1:19:36<01:44,  1.21s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2915/3000 [1:19:37<01:46,  1.25s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2916/3000 [1:19:39<01:48,  1.29s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2917/3000 [1:19:40<01:48,  1.31s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2918/3000 [1:19:41<01:34,  1.16s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2919/3000 [1:19:42<01:27,  1.07s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2920/3000 [1:19:44<01:47,  1.34s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2921/3000 [1:19:45<01:47,  1.37s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2922/3000 [1:19:48<02:21,  1.81s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2923/3000 [1:19:49<02:05,  1.63s/it]a2c_tuned train:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2924/3000 [1:19:51<01:58,  1.55s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2925/3000 [1:19:53<02:20,  1.88s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2926/3000 [1:19:55<02:11,  1.77s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2927/3000 [1:19:56<01:49,  1.50s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2928/3000 [1:19:59<02:22,  1.97s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2929/3000 [1:20:00<02:05,  1.77s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2930/3000 [1:20:01<01:55,  1.65s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2931/3000 [1:20:02<01:35,  1.38s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2932/3000 [1:20:04<01:47,  1.58s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2933/3000 [1:20:06<01:43,  1.54s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2934/3000 [1:20:07<01:42,  1.55s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2935/3000 [1:20:10<01:58,  1.83s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2936/3000 [1:20:12<02:01,  1.90s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2937/3000 [1:20:13<01:47,  1.71s/it][step=2885] episode=2885.0000 return=-115.9845 length=19.0000 global_step=69902.0000 loss=161.8585 policy_loss=-0.0000 value_loss=323.7171 entropy=0.0000
[step=2886] episode=2886.0000 return=-115.9888 length=28.0000 global_step=69930.0000 loss=85.5435 policy_loss=-0.0000 value_loss=171.0870 entropy=0.0000
[step=2887] episode=2887.0000 return=-115.8570 length=26.0000 global_step=69956.0000 loss=25.4540 policy_loss=-0.0000 value_loss=50.9080 entropy=0.0000
[step=2888] episode=2888.0000 return=-113.4077 length=12.0000 global_step=69968.0000 loss=23.0960 policy_loss=-0.0000 value_loss=46.1920 entropy=0.0000
[step=2889] episode=2889.0000 return=-115.9940 length=29.0000 global_step=69997.0000 loss=137.2435 policy_loss=-0.0000 value_loss=274.4870 entropy=0.0000
[step=2890] episode=2890.0000 return=-115.9096 length=21.0000 global_step=70018.0000 loss=92.0877 policy_loss=-0.0000 value_loss=184.1754 entropy=0.0000
[step=2891] episode=2891.0000 return=-115.7350 length=19.0000 global_step=70037.0000 loss=31.6334 policy_loss=-0.0000 value_loss=63.2668 entropy=0.0000
[step=2892] episode=2892.0000 return=-115.9934 length=21.0000 global_step=70058.0000 loss=39.2800 policy_loss=-0.0000 value_loss=78.5600 entropy=0.0000
[step=2893] episode=2893.0000 return=-115.9969 length=20.0000 global_step=70078.0000 loss=8.5669 policy_loss=-0.0000 value_loss=17.1338 entropy=0.0000
[step=2894] episode=2894.0000 return=-115.9881 length=21.0000 global_step=70099.0000 loss=38.9407 policy_loss=-0.0000 value_loss=77.8814 entropy=0.0000
[step=2895] episode=2895.0000 return=-115.9359 length=22.0000 global_step=70121.0000 loss=73.2497 policy_loss=-0.0000 value_loss=146.4994 entropy=0.0000
[step=2896] episode=2896.0000 return=-115.8880 length=11.0000 global_step=70132.0000 loss=148.4127 policy_loss=-0.0000 value_loss=296.8253 entropy=0.0000
[step=2897] episode=2897.0000 return=-115.9962 length=18.0000 global_step=70150.0000 loss=25.0911 policy_loss=-0.0000 value_loss=50.1823 entropy=0.0000
[step=2898] episode=2898.0000 return=-115.9576 length=25.0000 global_step=70175.0000 loss=48.5420 policy_loss=-0.0000 value_loss=97.0840 entropy=0.0000
[step=2899] episode=2899.0000 return=-115.9678 length=21.0000 global_step=70196.0000 loss=24.9797 policy_loss=-0.0000 value_loss=49.9594 entropy=0.0000
[step=2900] episode=2900.0000 return=-115.9638 length=29.0000 global_step=70225.0000 loss=119.3148 policy_loss=-0.0000 value_loss=238.6296 entropy=0.0000
[step=2901] episode=2901.0000 return=-115.7078 length=12.0000 global_step=70237.0000 loss=10.9006 policy_loss=-0.0000 value_loss=21.8011 entropy=0.0000
[step=2902] episode=2902.0000 return=-115.9997 length=28.0000 global_step=70265.0000 loss=46.8395 policy_loss=-0.0000 value_loss=93.6790 entropy=0.0000
[step=2903] episode=2903.0000 return=-115.9967 length=29.0000 global_step=70294.0000 loss=5.9014 policy_loss=-0.0000 value_loss=11.8027 entropy=0.0000
[step=2904] episode=2904.0000 return=-115.9965 length=21.0000 global_step=70315.0000 loss=36.3398 policy_loss=-0.0000 value_loss=72.6796 entropy=0.0000
[step=2905] episode=2905.0000 return=-115.9966 length=30.0000 global_step=70345.0000 loss=29.7549 policy_loss=-0.0000 value_loss=59.5097 entropy=0.0000
[step=2906] episode=2906.0000 return=-115.8876 length=10.0000 global_step=70355.0000 loss=168.4505 policy_loss=-0.0000 value_loss=336.9011 entropy=0.0000
[step=2907] episode=2907.0000 return=-115.9989 length=28.0000 global_step=70383.0000 loss=16.4404 policy_loss=-0.0000 value_loss=32.8809 entropy=0.0000
[step=2908] episode=2908.0000 return=-115.9788 length=27.0000 global_step=70410.0000 loss=19.0288 policy_loss=-0.0000 value_loss=38.0577 entropy=0.0000
[step=2909] episode=2909.0000 return=-115.9895 length=36.0000 global_step=70446.0000 loss=54.6486 policy_loss=-0.0000 value_loss=109.2971 entropy=0.0000
[step=2910] episode=2910.0000 return=-115.9881 length=26.0000 global_step=70472.0000 loss=16.7255 policy_loss=-0.0000 value_loss=33.4509 entropy=0.0000
[step=2911] episode=2911.0000 return=-115.8770 length=20.0000 global_step=70492.0000 loss=16.7545 policy_loss=-0.0000 value_loss=33.5090 entropy=0.0000
[step=2912] episode=2912.0000 return=-115.9660 length=12.0000 global_step=70504.0000 loss=51.6640 policy_loss=-0.0000 value_loss=103.3281 entropy=0.0000
[step=2913] episode=2913.0000 return=-115.9895 length=20.0000 global_step=70524.0000 loss=7.2578 policy_loss=-0.0000 value_loss=14.5156 entropy=0.0000
[step=2914] episode=2914.0000 return=-115.6942 length=12.0000 global_step=70536.0000 loss=11.6766 policy_loss=-0.0000 value_loss=23.3532 entropy=0.0000
[step=2915] episode=2915.0000 return=-115.9902 length=20.0000 global_step=70556.0000 loss=29.4028 policy_loss=-0.0000 value_loss=58.8057 entropy=0.0000
[step=2916] episode=2916.0000 return=-115.9846 length=20.0000 global_step=70576.0000 loss=55.1624 policy_loss=-0.0000 value_loss=110.3248 entropy=0.0000
[step=2917] episode=2917.0000 return=-115.9974 length=19.0000 global_step=70595.0000 loss=12.0361 policy_loss=-0.0000 value_loss=24.0721 entropy=0.0000
[step=2918] episode=2918.0000 return=-115.9774 length=12.0000 global_step=70607.0000 loss=8.7691 policy_loss=-0.0000 value_loss=17.5382 entropy=0.0000
[step=2919] episode=2919.0000 return=-115.8525 length=12.0000 global_step=70619.0000 loss=15.4526 policy_loss=-0.0000 value_loss=30.9051 entropy=0.0000
[step=2920] episode=2920.0000 return=-115.9921 length=29.0000 global_step=70648.0000 loss=14.9678 policy_loss=-0.0000 value_loss=29.9355 entropy=0.0000
[step=2921] episode=2921.0000 return=-115.9948 length=21.0000 global_step=70669.0000 loss=6.2234 policy_loss=-0.0000 value_loss=12.4468 entropy=0.0000
[step=2922] episode=2922.0000 return=-115.9819 length=43.0000 global_step=70712.0000 loss=48.8109 policy_loss=-0.0000 value_loss=97.6219 entropy=0.0000
[step=2923] episode=2923.0000 return=-115.9356 length=18.0000 global_step=70730.0000 loss=23.0265 policy_loss=-0.0000 value_loss=46.0531 entropy=0.0000
[step=2924] episode=2924.0000 return=-115.8367 length=20.0000 global_step=70750.0000 loss=45.6860 policy_loss=-0.0000 value_loss=91.3719 entropy=0.0000
[step=2925] episode=2925.0000 return=-115.9837 length=39.0000 global_step=70789.0000 loss=50.5470 policy_loss=-0.0000 value_loss=101.0940 entropy=0.0000
[step=2926] episode=2926.0000 return=-115.9987 length=22.0000 global_step=70811.0000 loss=9.1209 policy_loss=-0.0000 value_loss=18.2419 entropy=0.0000
[step=2927] episode=2927.0000 return=-115.8765 length=12.0000 global_step=70823.0000 loss=31.2955 policy_loss=-0.0000 value_loss=62.5910 entropy=0.0000
[step=2928] episode=2928.0000 return=-115.9986 length=46.0000 global_step=70869.0000 loss=148.7316 policy_loss=-0.0000 value_loss=297.4633 entropy=0.0000
[step=2929] episode=2929.0000 return=-115.9209 length=19.0000 global_step=70888.0000 loss=4.0238 policy_loss=-0.0000 value_loss=8.0475 entropy=0.0000
[step=2930] episode=2930.0000 return=-115.9934 length=20.0000 global_step=70908.0000 loss=7.0338 policy_loss=-0.0000 value_loss=14.0677 entropy=0.0000
[step=2931] episode=2931.0000 return=-107.6810 length=11.0000 global_step=70919.0000 loss=36.1082 policy_loss=-0.0000 value_loss=72.2163 entropy=0.0000
[step=2932] episode=2932.0000 return=-115.9989 length=30.0000 global_step=70949.0000 loss=30.1661 policy_loss=-0.0000 value_loss=60.3322 entropy=0.0000
[step=2933] episode=2933.0000 return=-115.9947 length=21.0000 global_step=70970.0000 loss=6.6479 policy_loss=-0.0000 value_loss=13.2958 entropy=0.0000
[step=2934] episode=2934.0000 return=-115.8866 length=21.0000 global_step=70991.0000 loss=2.5420 policy_loss=-0.0000 value_loss=5.0840 entropy=0.0000
[step=2935] episode=2935.0000 return=-115.8941 length=38.0000 global_step=71029.0000 loss=74.5643 policy_loss=-0.0000 value_loss=149.1287 entropy=0.0000
[step=2936] episode=2936.0000 return=-115.9969 length=30.0000 global_step=71059.0000 loss=20.8133 policy_loss=-0.0000 value_loss=41.6266 entropy=0.0000
[step=2937] episode=2937.0000 return=-115.8656 length=19.0000 global_step=71078.0000 loss=116.0032 policy_loss=-0.0000 value_loss=232.0063 entropy=0.0000
a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2938/3000 [1:20:14<01:39,  1.61s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2939/3000 [1:20:17<01:51,  1.84s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2940/3000 [1:20:18<01:32,  1.55s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2941/3000 [1:20:19<01:18,  1.34s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2942/3000 [1:20:20<01:26,  1.49s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2943/3000 [1:20:22<01:23,  1.46s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2944/3000 [1:20:23<01:21,  1.45s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2945/3000 [1:20:25<01:19,  1.45s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2946/3000 [1:20:26<01:24,  1.56s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2947/3000 [1:20:28<01:19,  1.51s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2948/3000 [1:20:29<01:16,  1.47s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2949/3000 [1:20:31<01:14,  1.47s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2950/3000 [1:20:34<01:36,  1.92s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2951/3000 [1:20:36<01:35,  1.94s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2952/3000 [1:20:37<01:23,  1.73s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2953/3000 [1:20:39<01:23,  1.77s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2954/3000 [1:20:41<01:24,  1.84s/it]a2c_tuned train:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2955/3000 [1:20:42<01:16,  1.70s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2956/3000 [1:20:43<01:03,  1.44s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2957/3000 [1:20:44<00:59,  1.39s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2958/3000 [1:20:46<00:58,  1.38s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2959/3000 [1:20:48<01:03,  1.54s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2960/3000 [1:20:50<01:10,  1.77s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2961/3000 [1:20:51<01:04,  1.66s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2962/3000 [1:20:53<01:09,  1.84s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2963/3000 [1:20:54<00:57,  1.56s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2964/3000 [1:20:56<00:54,  1.52s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2965/3000 [1:20:57<00:52,  1.49s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2966/3000 [1:20:59<00:49,  1.44s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2967/3000 [1:21:01<00:58,  1.78s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2968/3000 [1:21:03<01:01,  1.93s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2969/3000 [1:21:06<01:05,  2.11s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2970/3000 [1:21:08<01:00,  2.03s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2971/3000 [1:21:09<00:48,  1.66s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2972/3000 [1:21:10<00:48,  1.74s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2973/3000 [1:21:13<00:55,  2.06s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2974/3000 [1:21:15<00:48,  1.87s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2975/3000 [1:21:16<00:39,  1.58s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2976/3000 [1:21:17<00:40,  1.67s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2977/3000 [1:21:20<00:40,  1.78s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2978/3000 [1:21:20<00:33,  1.50s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2979/3000 [1:21:22<00:34,  1.63s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2980/3000 [1:21:24<00:31,  1.56s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2981/3000 [1:21:25<00:28,  1.50s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2982/3000 [1:21:27<00:26,  1.49s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2983/3000 [1:21:28<00:24,  1.47s/it]a2c_tuned train:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2984/3000 [1:21:29<00:22,  1.43s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2985/3000 [1:21:31<00:21,  1.43s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2986/3000 [1:21:32<00:19,  1.41s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2987/3000 [1:21:34<00:20,  1.56s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2988/3000 [1:21:36<00:21,  1.80s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2989/3000 [1:21:38<00:20,  1.84s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2990/3000 [1:21:40<00:18,  1.87s/it][step=2938] episode=2938.0000 return=-115.8708 length=20.0000 global_step=71098.0000 loss=18.2418 policy_loss=-0.0000 value_loss=36.4836 entropy=0.0000
[step=2939] episode=2939.0000 return=-115.9869 length=37.0000 global_step=71135.0000 loss=29.3166 policy_loss=-0.0000 value_loss=58.6332 entropy=0.0000
[step=2940] episode=2940.0000 return=-115.7124 length=12.0000 global_step=71147.0000 loss=26.0934 policy_loss=-0.0000 value_loss=52.1869 entropy=0.0000
[step=2941] episode=2941.0000 return=-115.7684 length=12.0000 global_step=71159.0000 loss=13.1043 policy_loss=-0.0000 value_loss=26.2086 entropy=0.0000
[step=2942] episode=2942.0000 return=-115.9966 length=27.0000 global_step=71186.0000 loss=82.0821 policy_loss=-0.0000 value_loss=164.1642 entropy=0.0000
[step=2943] episode=2943.0000 return=-115.9961 length=21.0000 global_step=71207.0000 loss=39.9891 policy_loss=-0.0000 value_loss=79.9781 entropy=0.0000
[step=2944] episode=2944.0000 return=-115.9855 length=20.0000 global_step=71227.0000 loss=13.8509 policy_loss=-0.0000 value_loss=27.7018 entropy=0.0000
[step=2945] episode=2945.0000 return=-115.9096 length=21.0000 global_step=71248.0000 loss=12.3116 policy_loss=-0.0000 value_loss=24.6233 entropy=0.0000
[step=2946] episode=2946.0000 return=-115.8881 length=26.0000 global_step=71274.0000 loss=17.7999 policy_loss=-0.0000 value_loss=35.5997 entropy=0.0000
[step=2947] episode=2947.0000 return=-115.9973 length=20.0000 global_step=71294.0000 loss=32.1179 policy_loss=-0.0000 value_loss=64.2359 entropy=0.0000
[step=2948] episode=2948.0000 return=-115.9943 length=20.0000 global_step=71314.0000 loss=16.7064 policy_loss=-0.0000 value_loss=33.4128 entropy=0.0000
[step=2949] episode=2949.0000 return=-115.9579 length=21.0000 global_step=71335.0000 loss=8.0595 policy_loss=-0.0000 value_loss=16.1191 entropy=0.0000
[step=2950] episode=2950.0000 return=-115.9962 length=45.0000 global_step=71380.0000 loss=153.8242 policy_loss=-0.0000 value_loss=307.6483 entropy=0.0000
[step=2951] episode=2951.0000 return=-115.8952 length=29.0000 global_step=71409.0000 loss=6.2032 policy_loss=-0.0000 value_loss=12.4064 entropy=0.0000
[step=2952] episode=2952.0000 return=-115.9964 length=19.0000 global_step=71428.0000 loss=13.8438 policy_loss=-0.0000 value_loss=27.6876 entropy=0.0000
[step=2953] episode=2953.0000 return=-115.9939 length=27.0000 global_step=71455.0000 loss=11.4569 policy_loss=-0.0000 value_loss=22.9138 entropy=0.0000
[step=2954] episode=2954.0000 return=-115.9986 length=30.0000 global_step=71485.0000 loss=11.3648 policy_loss=-0.0000 value_loss=22.7296 entropy=0.0000
[step=2955] episode=2955.0000 return=-115.9823 length=20.0000 global_step=71505.0000 loss=52.9896 policy_loss=-0.0000 value_loss=105.9792 entropy=0.0000
[step=2956] episode=2956.0000 return=-115.9828 length=12.0000 global_step=71517.0000 loss=35.1695 policy_loss=-0.0000 value_loss=70.3390 entropy=0.0000
[step=2957] episode=2957.0000 return=-115.9858 length=18.0000 global_step=71535.0000 loss=4.2193 policy_loss=-0.0000 value_loss=8.4385 entropy=0.0000
[step=2958] episode=2958.0000 return=-115.9916 length=19.0000 global_step=71554.0000 loss=45.5218 policy_loss=-0.0000 value_loss=91.0436 entropy=0.0000
[step=2959] episode=2959.0000 return=-115.9939 length=28.0000 global_step=71582.0000 loss=100.5134 policy_loss=-0.0000 value_loss=201.0268 entropy=0.0000
[step=2960] episode=2960.0000 return=-115.9990 length=34.0000 global_step=71616.0000 loss=78.9456 policy_loss=-0.0000 value_loss=157.8913 entropy=0.0000
[step=2961] episode=2961.0000 return=-115.9921 length=21.0000 global_step=71637.0000 loss=33.0548 policy_loss=-0.0000 value_loss=66.1097 entropy=0.0000
[step=2962] episode=2962.0000 return=-115.9990 length=34.0000 global_step=71671.0000 loss=39.7511 policy_loss=-0.0000 value_loss=79.5023 entropy=0.0000
[step=2963] episode=2963.0000 return=-115.9968 length=13.0000 global_step=71684.0000 loss=248.0812 policy_loss=-0.0000 value_loss=496.1625 entropy=0.0000
[step=2964] episode=2964.0000 return=-115.9997 length=20.0000 global_step=71704.0000 loss=45.9914 policy_loss=-0.0000 value_loss=91.9828 entropy=0.0000
[step=2965] episode=2965.0000 return=-115.9651 length=21.0000 global_step=71725.0000 loss=9.8848 policy_loss=-0.0000 value_loss=19.7696 entropy=0.0000
[step=2966] episode=2966.0000 return=-115.9988 length=20.0000 global_step=71745.0000 loss=46.9610 policy_loss=-0.0000 value_loss=93.9221 entropy=0.0000
[step=2967] episode=2967.0000 return=-115.9982 length=38.0000 global_step=71783.0000 loss=225.3795 policy_loss=-0.0000 value_loss=450.7591 entropy=0.0000
[step=2968] episode=2968.0000 return=-115.9968 length=33.0000 global_step=71816.0000 loss=88.5644 policy_loss=-0.0000 value_loss=177.1288 entropy=0.0000
[step=2969] episode=2969.0000 return=-115.9941 length=36.0000 global_step=71852.0000 loss=16.0634 policy_loss=-0.0000 value_loss=32.1268 entropy=0.0000
[step=2970] episode=2970.0000 return=-115.7738 length=28.0000 global_step=71880.0000 loss=65.2076 policy_loss=-0.0000 value_loss=130.4151 entropy=0.0000
[step=2971] episode=2971.0000 return=-114.7535 length=12.0000 global_step=71892.0000 loss=254.3742 policy_loss=-0.0000 value_loss=508.7485 entropy=0.0000
[step=2972] episode=2972.0000 return=-115.9369 length=29.0000 global_step=71921.0000 loss=18.5652 policy_loss=-0.0000 value_loss=37.1305 entropy=0.0000
[step=2973] episode=2973.0000 return=-115.9935 length=43.0000 global_step=71964.0000 loss=67.0449 policy_loss=-0.0000 value_loss=134.0898 entropy=0.0000
[step=2974] episode=2974.0000 return=-115.9986 length=21.0000 global_step=71985.0000 loss=7.4094 policy_loss=-0.0000 value_loss=14.8188 entropy=0.0000
[step=2975] episode=2975.0000 return=-115.8040 length=13.0000 global_step=71998.0000 loss=7.9886 policy_loss=-0.0000 value_loss=15.9771 entropy=0.0000
[step=2976] episode=2976.0000 return=-115.9991 length=28.0000 global_step=72026.0000 loss=33.6132 policy_loss=-0.0000 value_loss=67.2264 entropy=0.0000
[step=2977] episode=2977.0000 return=-115.9840 length=30.0000 global_step=72056.0000 loss=20.8434 policy_loss=-0.0000 value_loss=41.6868 entropy=0.0000
[step=2978] episode=2978.0000 return=-115.8174 length=12.0000 global_step=72068.0000 loss=24.4267 policy_loss=-0.0000 value_loss=48.8533 entropy=0.0000
[step=2979] episode=2979.0000 return=-115.9955 length=28.0000 global_step=72096.0000 loss=15.4628 policy_loss=-0.0000 value_loss=30.9255 entropy=0.0000
[step=2980] episode=2980.0000 return=-115.8204 length=19.0000 global_step=72115.0000 loss=28.5049 policy_loss=-0.0000 value_loss=57.0099 entropy=0.0000
[step=2981] episode=2981.0000 return=-115.9764 length=19.0000 global_step=72134.0000 loss=15.0266 policy_loss=-0.0000 value_loss=30.0531 entropy=0.0000
[step=2982] episode=2982.0000 return=-115.9955 length=21.0000 global_step=72155.0000 loss=7.4166 policy_loss=-0.0000 value_loss=14.8333 entropy=0.0000
[step=2983] episode=2983.0000 return=-115.8183 length=21.0000 global_step=72176.0000 loss=2.3537 policy_loss=-0.0000 value_loss=4.7075 entropy=0.0000
[step=2984] episode=2984.0000 return=-115.9997 length=21.0000 global_step=72197.0000 loss=23.3422 policy_loss=-0.0000 value_loss=46.6844 entropy=0.0000
[step=2985] episode=2985.0000 return=-115.7969 length=21.0000 global_step=72218.0000 loss=3.2620 policy_loss=-0.0000 value_loss=6.5240 entropy=0.0000
[step=2986] episode=2986.0000 return=-115.9465 length=20.0000 global_step=72238.0000 loss=12.4792 policy_loss=-0.0000 value_loss=24.9583 entropy=0.0000
[step=2987] episode=2987.0000 return=-115.9385 length=29.0000 global_step=72267.0000 loss=13.5274 policy_loss=-0.0000 value_loss=27.0548 entropy=0.0000
[step=2988] episode=2988.0000 return=-115.9941 length=35.0000 global_step=72302.0000 loss=21.3510 policy_loss=-0.0000 value_loss=42.7021 entropy=0.0000
[step=2989] episode=2989.0000 return=-115.9998 length=30.0000 global_step=72332.0000 loss=42.1006 policy_loss=-0.0000 value_loss=84.2012 entropy=0.0000
[step=2990] episode=2990.0000 return=-115.9999 length=28.0000 global_step=72360.0000 loss=57.6570 policy_loss=-0.0000 value_loss=115.3139 entropy=0.0000
a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2991/3000 [1:21:41<00:14,  1.58s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2992/3000 [1:21:44<00:14,  1.85s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2993/3000 [1:21:46<00:14,  2.00s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2994/3000 [1:21:47<00:10,  1.82s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2995/3000 [1:21:50<00:09,  2.00s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2996/3000 [1:21:51<00:07,  1.84s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2997/3000 [1:21:53<00:05,  1.85s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2998/3000 [1:21:55<00:03,  1.74s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2999/3000 [1:21:56<00:01,  1.48s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [1:21:58<00:00,  1.75s/it]a2c_tuned train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [1:21:58<00:00,  1.64s/it]
wandb: updating run metadata
wandb: uploading wandb-summary.json; uploading output.log; uploading config.yaml
wandb: uploading output.log
wandb: uploading data
wandb: 
wandb: Run history:
wandb:     entropy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:     episode ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      length ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÅ
wandb:        loss ‚ñÇ‚ñá‚ñÅ‚ñÅ‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ
wandb: policy_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      return ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÉ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÅ‚ñÜ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÅ
wandb:  value_loss ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:     entropy 0
wandb:     episode 3000
wandb: global_step 72617
wandb:      length 34
wandb:        loss 56.76844
wandb: policy_loss 0
wandb:      return -115.9969
wandb:  value_loss 113.53688
wandb: 
wandb: üöÄ View run a2c_tuned_seed0 at: https://wandb.ai/lee_changmin-sangmyung-uni/RLDoom/runs/8w4npn8j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lee_changmin-sangmyung-uni/RLDoom
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./logs/wandb/wandb/run-20251206_211410-8w4npn8j/logs
[step=2991] episode=2991.0000 return=-115.9986 length=13.0000 global_step=72373.0000 loss=202.0582 policy_loss=-0.0000 value_loss=404.1165 entropy=0.0000
[step=2992] episode=2992.0000 return=-115.9965 length=37.0000 global_step=72410.0000 loss=28.9960 policy_loss=-0.0000 value_loss=57.9919 entropy=0.0000
[step=2993] episode=2993.0000 return=-115.9996 length=35.0000 global_step=72445.0000 loss=56.6402 policy_loss=-0.0000 value_loss=113.2805 entropy=0.0000
[step=2994] episode=2994.0000 return=-115.9913 length=20.0000 global_step=72465.0000 loss=6.1995 policy_loss=-0.0000 value_loss=12.3989 entropy=0.0000
[step=2995] episode=2995.0000 return=-115.9810 length=37.0000 global_step=72502.0000 loss=76.7725 policy_loss=-0.0000 value_loss=153.5450 entropy=0.0000
[step=2996] episode=2996.0000 return=-115.9659 length=21.0000 global_step=72523.0000 loss=9.0857 policy_loss=-0.0000 value_loss=18.1713 entropy=0.0000
[step=2997] episode=2997.0000 return=-115.9999 length=26.0000 global_step=72549.0000 loss=9.4022 policy_loss=-0.0000 value_loss=18.8044 entropy=0.0000
[step=2998] episode=2998.0000 return=-115.9978 length=21.0000 global_step=72570.0000 loss=14.2876 policy_loss=-0.0000 value_loss=28.5751 entropy=0.0000
[step=2999] episode=2999.0000 return=-115.7536 length=13.0000 global_step=72583.0000 loss=46.6083 policy_loss=-0.0000 value_loss=93.2166 entropy=0.0000
[step=3000] episode=3000.0000 return=-115.9969 length=34.0000 global_step=72617.0000 loss=56.7684 policy_loss=-0.0000 value_loss=113.5369 entropy=0.0000
